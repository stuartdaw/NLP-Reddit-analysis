subreddit_name_prefixed,selftext,author_fullname,title,link_flair_css_class,name,upvote_ratio,ups,link_flair_text,score,created,selftext_html,id,author,num_comments,permalink,url,created_utc
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 26 Jul 2020 - 02 Aug 2020,,t3_hy5rc9,0.88,6,Discussion,6,1595793630.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hy5rc9,datascience-bot,123,/r/datascience/comments/hy5rc9/weekly_entering_transitioning_thread_26_jul_2020/,https://www.reddit.com/r/datascience/comments/hy5rc9/weekly_entering_transitioning_thread_26_jul_2020/,1595764830.0
r/datascience,,t2_62mano1t,Data Science Projects With Source Code &amp; Step by Step Implementation,projects,t3_i1nfpy,0.98,272,Projects,272,1596290769.0,,i1nfpy,TheInsaneApp,12,/r/datascience/comments/i1nfpy/data_science_projects_with_source_code_step_by/,https://www.theinsaneapp.com/2020/08/data-science-project-ideas-with-source-code.html,1596261969.0
r/datascience,,t2_aji41,"Developer, data science jobs: US tech is taking a worse hit than other sectors | ZDNet",discussion,t3_i1ammb,0.91,189,Discussion,189,1596241983.0,,i1ammb,moqiwf,80,/r/datascience/comments/i1ammb/developer_data_science_jobs_us_tech_is_taking_a/,https://www.zdnet.com/article/developer-data-scientist-us-tech-job-postings-are-taking-a-worse-hit-than-in-other-sectors/,1596213183.0
r/datascience,"I am working on a disambiguation model which needs to work at scale - for mentions of entities from a ~50k taxonomy across hundreds of millions to billions of documents.

We initially looked at BERT, but getting it working at the required scale is proving to be a huge challenge, so we are considering falling back to much more scalable GloVe based embeddings, where we would instead average the individual embeddings across several words near to the word which we want to disambiguate, and use this to measure similarity between each candidate mention and the document mention.

Is this a good idea?",t2_79k3r,Can context insensitive word embeddings (I.e. GloVe) be used successfully for word-sense disambiguation?,discussion,t3_i1sn59,1.0,3,Discussion,3,1596319198.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working on a disambiguation model which needs to work at scale - for mentions of entities from a ~50k taxonomy across hundreds of millions to billions of documents.&lt;/p&gt;

&lt;p&gt;We initially looked at BERT, but getting it working at the required scale is proving to be a huge challenge, so we are considering falling back to much more scalable GloVe based embeddings, where we would instead average the individual embeddings across several words near to the word which we want to disambiguate, and use this to measure similarity between each candidate mention and the document mention.&lt;/p&gt;

&lt;p&gt;Is this a good idea?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1sn59,iRoygbiv,0,/r/datascience/comments/i1sn59/can_context_insensitive_word_embeddings_ie_glove/,https://www.reddit.com/r/datascience/comments/i1sn59/can_context_insensitive_word_embeddings_ie_glove/,1596290398.0
r/datascience,"I've been reading a little about maximum likelihood estimation, but I'm having some trouble understanding how (and why) companies use it to estimate parameters about a population. Can anyone please give me some idea as to how it is used in the industry?",t2_3loxj2cz,How is parameter estimation used in day-to-day data science?,discussion,t3_i1q48q,1.0,3,Discussion,3,1596306595.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been reading a little about maximum likelihood estimation, but I&amp;#39;m having some trouble understanding how (and why) companies use it to estimate parameters about a population. Can anyone please give me some idea as to how it is used in the industry?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1q48q,hedgehogist,1,/r/datascience/comments/i1q48q/how_is_parameter_estimation_used_in_daytoday_data/,https://www.reddit.com/r/datascience/comments/i1q48q/how_is_parameter_estimation_used_in_daytoday_data/,1596277795.0
r/datascience,"I have been making models for work and fun projects for some time now (last 2-3 years) and I always get really nervous when I present the certainties of my models. For instance, if you take the testing set (I specifically do machine learning, but this question can be applied to even basic linear models) and predict the results with 100% accuracy. I can't just report ""yep. Had 100% accuracy"" because then people I'm reporting that to will likely misinterpret that to mean the model will never be wrong (which is really close to if not impossible). I know there are other metrics to score things on (such as recall and precision), but I was wondering how certainty was calculated, as well as the ""error bars"" of the certainty. And if there is a direct formula for this m, how does it handle the extreme ends (if you have 100% prediction success you can't say it's 100% certainty, so how low do you drop that certainty; same with 0% success and 0% certainty)? Thank you.",t2_s1q046f,On Calculating Certainty,education,t3_i1tkre,1.0,1,Education,1,1596322922.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been making models for work and fun projects for some time now (last 2-3 years) and I always get really nervous when I present the certainties of my models. For instance, if you take the testing set (I specifically do machine learning, but this question can be applied to even basic linear models) and predict the results with 100% accuracy. I can&amp;#39;t just report &amp;quot;yep. Had 100% accuracy&amp;quot; because then people I&amp;#39;m reporting that to will likely misinterpret that to mean the model will never be wrong (which is really close to if not impossible). I know there are other metrics to score things on (such as recall and precision), but I was wondering how certainty was calculated, as well as the &amp;quot;error bars&amp;quot; of the certainty. And if there is a direct formula for this m, how does it handle the extreme ends (if you have 100% prediction success you can&amp;#39;t say it&amp;#39;s 100% certainty, so how low do you drop that certainty; same with 0% success and 0% certainty)? Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1tkre,muh_reddit_accout,1,/r/datascience/comments/i1tkre/on_calculating_certainty/,https://www.reddit.com/r/datascience/comments/i1tkre/on_calculating_certainty/,1596294122.0
r/datascience,,t2_1nyyvx1d,"Developing a Deep Learning Library - Adam, RELU and Scikit-learn API - Part 2",education,t3_i1ti56,1.0,1,Education,1,1596322638.0,,i1ti56,Fedzbar,0,/r/datascience/comments/i1ti56/developing_a_deep_learning_library_adam_relu_and/,/r/Python/comments/i1th3v/developing_a_deep_learning_library_adam_relu_and/,1596293838.0
r/datascience,"Someone I know is in a start-up that might be acquired soon by a parent company. This parent company has appointed a 3rd party to run due diligence on the tech stack/data scene of said company. The auditors will basically be trying to assess the quality and value of said start-up's data.

I'm wondering if anyone here has some experience with a process like this, who might be able to elaborate on what the process is like.

The auditor also requested for full production database access (but anonymized so that user info isn't shown). This seems like a pretty shocking ask!",t2_k01zajj,Anyone's company ever been subjected to a data audit/data inspection by a 3rd party? Curious as to what industry standards are around this practice - is it normal for an auditor to request full access to the production database?,discussion,t3_i1qa8b,0.67,1,Discussion,1,1596307571.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Someone I know is in a start-up that might be acquired soon by a parent company. This parent company has appointed a 3rd party to run due diligence on the tech stack/data scene of said company. The auditors will basically be trying to assess the quality and value of said start-up&amp;#39;s data.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m wondering if anyone here has some experience with a process like this, who might be able to elaborate on what the process is like.&lt;/p&gt;

&lt;p&gt;The auditor also requested for full production database access (but anonymized so that user info isn&amp;#39;t shown). This seems like a pretty shocking ask!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1qa8b,Lostwhispers05,1,/r/datascience/comments/i1qa8b/anyones_company_ever_been_subjected_to_a_data/,https://www.reddit.com/r/datascience/comments/i1qa8b/anyones_company_ever_been_subjected_to_a_data/,1596278771.0
r/datascience,"Does anyone else feel nostalgic about leaving their scientific research life to become a data scientist in industry?

I've been a physical scientist in my field for almost 8 years now, published 4 scientific manuscripts, but decided  to switch careers to a data scientist so I can escape the lab coat life.

However, I'm starting to miss my scientific community. I really don't care that much about figuring out website viewership trends or customer churn rates.

Any ex-scientists feel this way too about their current industry job but was able to deal with it?",t2_d30qo,Leaving your scientific research life to become a data scientist in industry,discussion,t3_i1gi1b,0.7,8,Discussion,8,1596261515.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone else feel nostalgic about leaving their scientific research life to become a data scientist in industry?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been a physical scientist in my field for almost 8 years now, published 4 scientific manuscripts, but decided  to switch careers to a data scientist so I can escape the lab coat life.&lt;/p&gt;

&lt;p&gt;However, I&amp;#39;m starting to miss my scientific community. I really don&amp;#39;t care that much about figuring out website viewership trends or customer churn rates.&lt;/p&gt;

&lt;p&gt;Any ex-scientists feel this way too about their current industry job but was able to deal with it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1gi1b,Ryien,29,/r/datascience/comments/i1gi1b/leaving_your_scientific_research_life_to_become_a/,https://www.reddit.com/r/datascience/comments/i1gi1b/leaving_your_scientific_research_life_to_become_a/,1596232715.0
r/datascience,"Hello everyone ! I'm new to this field of data science so I'm trying to learn the basics. I just came up with this question. What algorithms are the best to generate more data when it isnt enough to work with? 

Thank you everyone. :)",t2_2vwbwbhs,What kind of algorithms are used to generate more data ?,discussion,t3_i1npkc,0.5,0,Discussion,0,1596292256.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone ! I&amp;#39;m new to this field of data science so I&amp;#39;m trying to learn the basics. I just came up with this question. What algorithms are the best to generate more data when it isnt enough to work with? &lt;/p&gt;

&lt;p&gt;Thank you everyone. :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1npkc,nelyher98,6,/r/datascience/comments/i1npkc/what_kind_of_algorithms_are_used_to_generate_more/,https://www.reddit.com/r/datascience/comments/i1npkc/what_kind_of_algorithms_are_used_to_generate_more/,1596263456.0
r/datascience,"Hello everyone,

I am a pharmacist that works in the managed care world. I will be working with data scientists (mostly fresh to the company). I wanted to know some advice to make sure we can work together and provide unique insight into data. I have a strong working knowledge of the field and will provide the ideas of new programs and cost saving strategies as a clinician. 

I am currently taking a bootcamp track of data science to get my feet wet. Mostly learning python with pandas, numpy and now learning SQL. I won't finish this by the time I start to work with them, but its better than nothing. Any advice would be appreciated!",t2_1kan9df6,Pharmacist working with data scientists advice,discussion,t3_i1az1r,0.74,10,Discussion,10,1596243119.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I am a pharmacist that works in the managed care world. I will be working with data scientists (mostly fresh to the company). I wanted to know some advice to make sure we can work together and provide unique insight into data. I have a strong working knowledge of the field and will provide the ideas of new programs and cost saving strategies as a clinician. &lt;/p&gt;

&lt;p&gt;I am currently taking a bootcamp track of data science to get my feet wet. Mostly learning python with pandas, numpy and now learning SQL. I won&amp;#39;t finish this by the time I start to work with them, but its better than nothing. Any advice would be appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1az1r,sunshao1031,14,/r/datascience/comments/i1az1r/pharmacist_working_with_data_scientists_advice/,https://www.reddit.com/r/datascience/comments/i1az1r/pharmacist_working_with_data_scientists_advice/,1596214319.0
r/datascience,"Admittedly, “big data” is a phrase I hear mostly from non-data scientists who are trying to impress people but I’m curious: when someone tells you they work with big data or list it as a skill on their resume, what do you imagine? Terabytes? Petabytes? Exabytes? Maybe it’s not about the actual size but how you use it, for example the ability to set up a spark cluster that can scale up and down as needed or to use tools like dask. 

Just curious what people’s opinion are—if the term carries any weight or if it’s just another corporate buzz word.",t2_autc9vc,How big is “big data?”,discussion,t3_i0y3po,0.93,165,Discussion,165,1596185897.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Admittedly, “big data” is a phrase I hear mostly from non-data scientists who are trying to impress people but I’m curious: when someone tells you they work with big data or list it as a skill on their resume, what do you imagine? Terabytes? Petabytes? Exabytes? Maybe it’s not about the actual size but how you use it, for example the ability to set up a spark cluster that can scale up and down as needed or to use tools like dask. &lt;/p&gt;

&lt;p&gt;Just curious what people’s opinion are—if the term carries any weight or if it’s just another corporate buzz word.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0y3po,bigno53,101,/r/datascience/comments/i0y3po/how_big_is_big_data/,https://www.reddit.com/r/datascience/comments/i0y3po/how_big_is_big_data/,1596157097.0
r/datascience,Hey guys I just finished the coursera Stanford machine learning certification and it really bumped up my career opportunities and I’m looking to take another course. What new skill or language or platform should I prioritize? I just graduated in May so any advice helps.,t2_3qribcw1,Best certification to add to my resume?,career,t3_i1mche,0.5,0,Career,0,1596285261.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys I just finished the coursera Stanford machine learning certification and it really bumped up my career opportunities and I’m looking to take another course. What new skill or language or platform should I prioritize? I just graduated in May so any advice helps.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1mche,therapperboolio,1,/r/datascience/comments/i1mche/best_certification_to_add_to_my_resume/,https://www.reddit.com/r/datascience/comments/i1mche/best_certification_to_add_to_my_resume/,1596256461.0
r/datascience,"\[Pre COVID\] Like for example if you're following a large population over time and are looking at behavior change, just because an 98 year old woman or a male in their 20s who repeatedly drove drunk stopped shopping at a certain grocery store is not always due to our Y value(s); the reality is they might have just died.

I know there is a standard but I cannot remember it, it is something like:

A) 8%

B) .8%

or

C) .08%

8% seems high so that's automatically eliminated in my mind, anyone know for sure?",t2_1tgq8rm3,What's the standard death metric?,discussion,t3_i1lx35,0.33,0,Discussion,0,1596283331.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[Pre COVID] Like for example if you&amp;#39;re following a large population over time and are looking at behavior change, just because an 98 year old woman or a male in their 20s who repeatedly drove drunk stopped shopping at a certain grocery store is not always due to our Y value(s); the reality is they might have just died.&lt;/p&gt;

&lt;p&gt;I know there is a standard but I cannot remember it, it is something like:&lt;/p&gt;

&lt;p&gt;A) 8%&lt;/p&gt;

&lt;p&gt;B) .8%&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;C) .08%&lt;/p&gt;

&lt;p&gt;8% seems high so that&amp;#39;s automatically eliminated in my mind, anyone know for sure?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1lx35,CleanDataDirtyMind,2,/r/datascience/comments/i1lx35/whats_the_standard_death_metric/,https://www.reddit.com/r/datascience/comments/i1lx35/whats_the_standard_death_metric/,1596254531.0
r/datascience,"I'm talking about visual cognition and human factors in the Edward Tufte vein of things (and not just picking nice color pallets for your pie charts).

Advanced D3/ggplot/Shiny/matplotlib charting for data exploration and discovery - is this considered a branch of DS?

Or is this just ""making shit pretty"", as the guys in IT like to say?",t2_44v4b5cn,Is data visualization a data science sub specialty?,discussion,t3_i1g60q,0.5,0,Discussion,0,1596260323.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m talking about visual cognition and human factors in the Edward Tufte vein of things (and not just picking nice color pallets for your pie charts).&lt;/p&gt;

&lt;p&gt;Advanced D3/ggplot/Shiny/matplotlib charting for data exploration and discovery - is this considered a branch of DS?&lt;/p&gt;

&lt;p&gt;Or is this just &amp;quot;making shit pretty&amp;quot;, as the guys in IT like to say?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i1g60q,morningtundra,10,/r/datascience/comments/i1g60q/is_data_visualization_a_data_science_sub_specialty/,https://www.reddit.com/r/datascience/comments/i1g60q/is_data_visualization_a_data_science_sub_specialty/,1596231523.0
r/datascience,"I came across this open source tool [https://github.com/airbnb/knowledge-repo](https://github.com/airbnb/knowledge-repo) 

It 's meant to share your work with your teammates. Has anyone used this? What was your experience like? How does your team share all the DS knowledge internally?",t2_3mkirll5,Has anyone used. the AirBnb knowledge repo?,tooling,t3_i101x6,0.84,8,Tooling,8,1596193694.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I came across this open source tool &lt;a href=""https://github.com/airbnb/knowledge-repo""&gt;https://github.com/airbnb/knowledge-repo&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;It &amp;#39;s meant to share your work with your teammates. Has anyone used this? What was your experience like? How does your team share all the DS knowledge internally?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i101x6,crossvalidator,2,/r/datascience/comments/i101x6/has_anyone_used_the_airbnb_knowledge_repo/,https://www.reddit.com/r/datascience/comments/i101x6/has_anyone_used_the_airbnb_knowledge_repo/,1596164894.0
r/datascience,"I work as a data analyst at a clean tech company.  Over the last couple of years I have integrated using R for data wrangling, creating mathematical models and data visualization.  I am beginning to use ML.  

Currently, I  am pretty comfortable in R and Python with data wrangling, analysis and visualization, novice in Machine Learning and little experience in SQL,ETL, etc

The company is relatively small (&lt;100 people) and there is no real formal data science group.

I am currently working with my manager to propose a promotion for myself and want to move further in a data science direction and help fill this gap.  Basically, provide analytics, prediction, translation of technical issues between technical and non-technical people, subject knowledge on data science.

I am trying to come up with a name for this position.  Obviously, I want an attractive sounding title but also do not want to oversell my capacities and current level of skills.

Would it be too much to say Data Scientist - is that a relatively senior title?

What other titles might make sense?",t2_k0wt9,Proposing a new data science promotion in my company - what title makes sense?,career,t3_i0jw4q,0.92,133,Career,133,1596134725.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work as a data analyst at a clean tech company.  Over the last couple of years I have integrated using R for data wrangling, creating mathematical models and data visualization.  I am beginning to use ML.  &lt;/p&gt;

&lt;p&gt;Currently, I  am pretty comfortable in R and Python with data wrangling, analysis and visualization, novice in Machine Learning and little experience in SQL,ETL, etc&lt;/p&gt;

&lt;p&gt;The company is relatively small (&amp;lt;100 people) and there is no real formal data science group.&lt;/p&gt;

&lt;p&gt;I am currently working with my manager to propose a promotion for myself and want to move further in a data science direction and help fill this gap.  Basically, provide analytics, prediction, translation of technical issues between technical and non-technical people, subject knowledge on data science.&lt;/p&gt;

&lt;p&gt;I am trying to come up with a name for this position.  Obviously, I want an attractive sounding title but also do not want to oversell my capacities and current level of skills.&lt;/p&gt;

&lt;p&gt;Would it be too much to say Data Scientist - is that a relatively senior title?&lt;/p&gt;

&lt;p&gt;What other titles might make sense?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0jw4q,kw_hipster,108,/r/datascience/comments/i0jw4q/proposing_a_new_data_science_promotion_in_my/,https://www.reddit.com/r/datascience/comments/i0jw4q/proposing_a_new_data_science_promotion_in_my/,1596105925.0
r/datascience,"Hi all,

I have about 1 year of data science experience and about 1+ years of data analyst experience (total 2.5 YOE). I'm grateful to receive two offers so I am curious about fellow data science practitioners' opinions here.

I'm located in an Asian city and I received an offer from ByteDance as a data analyst, which is the parent company of TikTok. The compensation package is actually higher than the data scientist offer from a top Asian bank that is going all-in on digital transformation.

From what I gathered during the interview, the data analyst will be insight generation and building the analytics framework for the particular business function in the APAC HQ from scratch. However, there would be no predictive modeling (even though this role would be involved in building the data pipelines for the predictive models). As for the data scientist role, there are interesting projects involving NLP, marketing analytics, and customer segmentation / churn prediction, customer geo-targeting. The bank's main operations are in Southeast Asia, China, Hong Kong, India, and Australia.

From a career development viewpoint, ByteDance offers better prestige and the exit opps to other tech firms would be great. As for the bank DS, it would expose me less to the tech world but the projects would allow me to develop my skills in machine learning.

People may point to the potential banning of TikTok in US, but in Asia, TikTok is still wildly popular, and ByteDance is still one of the highest-valued unicorn in the world. Even without the US and Indian market, TikTok is still wildly successful.

Thanks in advance, I appreciate your opinions!",t2_50viu8,Data Analyst at top-tier tech company vs Data Scientist at Top Regional Bank in Asia,career,t3_i0yxsf,0.73,5,Career,5,1596189180.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I have about 1 year of data science experience and about 1+ years of data analyst experience (total 2.5 YOE). I&amp;#39;m grateful to receive two offers so I am curious about fellow data science practitioners&amp;#39; opinions here.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m located in an Asian city and I received an offer from ByteDance as a data analyst, which is the parent company of TikTok. The compensation package is actually higher than the data scientist offer from a top Asian bank that is going all-in on digital transformation.&lt;/p&gt;

&lt;p&gt;From what I gathered during the interview, the data analyst will be insight generation and building the analytics framework for the particular business function in the APAC HQ from scratch. However, there would be no predictive modeling (even though this role would be involved in building the data pipelines for the predictive models). As for the data scientist role, there are interesting projects involving NLP, marketing analytics, and customer segmentation / churn prediction, customer geo-targeting. The bank&amp;#39;s main operations are in Southeast Asia, China, Hong Kong, India, and Australia.&lt;/p&gt;

&lt;p&gt;From a career development viewpoint, ByteDance offers better prestige and the exit opps to other tech firms would be great. As for the bank DS, it would expose me less to the tech world but the projects would allow me to develop my skills in machine learning.&lt;/p&gt;

&lt;p&gt;People may point to the potential banning of TikTok in US, but in Asia, TikTok is still wildly popular, and ByteDance is still one of the highest-valued unicorn in the world. Even without the US and Indian market, TikTok is still wildly successful.&lt;/p&gt;

&lt;p&gt;Thanks in advance, I appreciate your opinions!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0yxsf,Ha0zh,20,/r/datascience/comments/i0yxsf/data_analyst_at_toptier_tech_company_vs_data/,https://www.reddit.com/r/datascience/comments/i0yxsf/data_analyst_at_toptier_tech_company_vs_data/,1596160380.0
r/datascience,"I have been a data scientist for a few years now and do anything from writing and testing machine learning algorithms to more straightforward data and visualization related stuff. At my company, once a model is ready to be implemented, it is passed off to software engineers to get it production ready. This means I never get any experience writing production level code and feel that it is a skill I may need as I get to a more senior position or work at a different company. Any one have suggestions with this?",t2_6zqdq,How to learn to write production quality code?,career,t3_i0mxil,0.9,27,Career,27,1596147891.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been a data scientist for a few years now and do anything from writing and testing machine learning algorithms to more straightforward data and visualization related stuff. At my company, once a model is ready to be implemented, it is passed off to software engineers to get it production ready. This means I never get any experience writing production level code and feel that it is a skill I may need as I get to a more senior position or work at a different company. Any one have suggestions with this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0mxil,edisekeed,37,/r/datascience/comments/i0mxil/how_to_learn_to_write_production_quality_code/,https://www.reddit.com/r/datascience/comments/i0mxil/how_to_learn_to_write_production_quality_code/,1596119091.0
r/datascience,"Some of the most important kinds of information for data science are encoded in graphs. Organizational information, transactional information, hierarchical information, knowledge graphs.

The math of characterizing and working with graphs is well documented and understood, but as far as I can tell, not well implemented in data science tools.

The problem seems to be memory explosions as low-level engines sequentially calculate Cartesian products of every possible relation and then filter for the specific types of relations you happen to be looking for. Do this over more than a few hops and you'll bring any small or medium sized system to its knees.

This problem has obviously been solved by people who work with truly big graphs (Google and Facebook and friends), but I suspect that at least some of the time they are doing it simply with brute force, and anything more clever than this they keep proprietary.

This matters because you can actually represent graph information as a matrix, and  (some) matrix manipulations are extremely well implemented with open source software and accelerated by GPU hardware. You still have a risk of a memory explosion for dense graphs, but you've got built-in ways to serialize these kinds of calculations so that you're just slowing down, not crashing. 

The most important bit is that real-world graphs are more often than not sparse matrices. Sparse matrices can be serialized with a triplet structure, that is extremely efficient. There are both R and Python implementations of this available.

It should be possible to write wrapper functions that can take graph data structures as Node set, Edge set and transform them efficiently to sparse matrix triplets. It should also be possible to implement the most common graph algorithms to work as matrix operations in a way that is suitable for GPU acceleration. 

If anyone knows if this has already been done in open source, please let me know. 

I've been thinking about this for awhile and wanted to post these observations someplace public before I get too deep building stuff on them.",t2_gz1di,"Graphs as matrices, matrices as triplets",,t3_i0qd37,0.82,10,,10,1596159393.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Some of the most important kinds of information for data science are encoded in graphs. Organizational information, transactional information, hierarchical information, knowledge graphs.&lt;/p&gt;

&lt;p&gt;The math of characterizing and working with graphs is well documented and understood, but as far as I can tell, not well implemented in data science tools.&lt;/p&gt;

&lt;p&gt;The problem seems to be memory explosions as low-level engines sequentially calculate Cartesian products of every possible relation and then filter for the specific types of relations you happen to be looking for. Do this over more than a few hops and you&amp;#39;ll bring any small or medium sized system to its knees.&lt;/p&gt;

&lt;p&gt;This problem has obviously been solved by people who work with truly big graphs (Google and Facebook and friends), but I suspect that at least some of the time they are doing it simply with brute force, and anything more clever than this they keep proprietary.&lt;/p&gt;

&lt;p&gt;This matters because you can actually represent graph information as a matrix, and  (some) matrix manipulations are extremely well implemented with open source software and accelerated by GPU hardware. You still have a risk of a memory explosion for dense graphs, but you&amp;#39;ve got built-in ways to serialize these kinds of calculations so that you&amp;#39;re just slowing down, not crashing. &lt;/p&gt;

&lt;p&gt;The most important bit is that real-world graphs are more often than not sparse matrices. Sparse matrices can be serialized with a triplet structure, that is extremely efficient. There are both R and Python implementations of this available.&lt;/p&gt;

&lt;p&gt;It should be possible to write wrapper functions that can take graph data structures as Node set, Edge set and transform them efficiently to sparse matrix triplets. It should also be possible to implement the most common graph algorithms to work as matrix operations in a way that is suitable for GPU acceleration. &lt;/p&gt;

&lt;p&gt;If anyone knows if this has already been done in open source, please let me know. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been thinking about this for awhile and wanted to post these observations someplace public before I get too deep building stuff on them.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0qd37,spinur1848,9,/r/datascience/comments/i0qd37/graphs_as_matrices_matrices_as_triplets/,https://www.reddit.com/r/datascience/comments/i0qd37/graphs_as_matrices_matrices_as_triplets/,1596130593.0
r/datascience,"Hello all, 

I am interested in data science but not sure I really want to go back to school.. I am a compensation analyst now and generally use Tableau and Tableau Prep for all my data cleaning and visualizing/analysis.

My question is this: What is one thing important thing I should try to start learning more about if I want to pursue a more data intensive position in the future? R, Python, SQL, etc? I don't know how to code, and am not sure how necessary it would be for me to do so. I don't use Microsoft Access because I always can get whatever I need just by using Tableau Prep or Desktop.

I love to learn, and would love to be in a position where I can really get heavier into data",t2_3uru89fj,What is an important skill you use every day?,career,t3_i0q9sq,0.82,7,Career,7,1596159092.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all, &lt;/p&gt;

&lt;p&gt;I am interested in data science but not sure I really want to go back to school.. I am a compensation analyst now and generally use Tableau and Tableau Prep for all my data cleaning and visualizing/analysis.&lt;/p&gt;

&lt;p&gt;My question is this: What is one thing important thing I should try to start learning more about if I want to pursue a more data intensive position in the future? R, Python, SQL, etc? I don&amp;#39;t know how to code, and am not sure how necessary it would be for me to do so. I don&amp;#39;t use Microsoft Access because I always can get whatever I need just by using Tableau Prep or Desktop.&lt;/p&gt;

&lt;p&gt;I love to learn, and would love to be in a position where I can really get heavier into data&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0q9sq,chloepart,22,/r/datascience/comments/i0q9sq/what_is_an_important_skill_you_use_every_day/,https://www.reddit.com/r/datascience/comments/i0q9sq/what_is_an_important_skill_you_use_every_day/,1596130292.0
r/datascience,"Hi DS community,

Just wanted to thank you all for you help and questions, this group has been invaluable for me studying for interviews. Over the last month, I have been interviewing around at various companies and in the last couple days have received two offers. I don’t know exactly what “market rate” is for data science, so I was hoping for some help evaluating the better offer as I may have to make a decision on this while still in the pipeline at other companies so it’s unlikely I can wait to see if I get more offers or what they would be. 

This role is remote (I’m currently based in Dallas and company is not but they don’t mind where I work).

The offer is 160k base, 15% annual bonus, 5.5k annually towards tuition (I’m working on my MS part time with Georgia Tech OMAnalytics), 6% 1:1 401k match, 4 weeks vacation, 2 weeks worth of company holidays.

As far as my background, I have 4 YOE and have a dual BS in Math &amp; Econ, like I mentioned also currently part time enrolled in the Georgia Tech online masters. 

The team and would be manager seem awesome. I really clicked with the manager and it seems like the company cares and that they’re genuinely good people. 

As far as cost of living, I could stay in Dallas, which is definitely lower than the Bay Area or NYC. 

I’m in the pipeline at other companies, but is this offer worth taking and dropping out of the running elsewhere? I suppose I could take it and continue interviewing, but I really would like to avoid that because I did have a strong connection and wouldn’t want to leave them high and dry. 

Any advice, insights, data points, things to think about, etc would be sincerely appreciated! 

Thank you all!",t2_5anj104l,Offer Evaluation Help!!,,t3_i0sbp6,0.5,0,,0,1596165709.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi DS community,&lt;/p&gt;

&lt;p&gt;Just wanted to thank you all for you help and questions, this group has been invaluable for me studying for interviews. Over the last month, I have been interviewing around at various companies and in the last couple days have received two offers. I don’t know exactly what “market rate” is for data science, so I was hoping for some help evaluating the better offer as I may have to make a decision on this while still in the pipeline at other companies so it’s unlikely I can wait to see if I get more offers or what they would be. &lt;/p&gt;

&lt;p&gt;This role is remote (I’m currently based in Dallas and company is not but they don’t mind where I work).&lt;/p&gt;

&lt;p&gt;The offer is 160k base, 15% annual bonus, 5.5k annually towards tuition (I’m working on my MS part time with Georgia Tech OMAnalytics), 6% 1:1 401k match, 4 weeks vacation, 2 weeks worth of company holidays.&lt;/p&gt;

&lt;p&gt;As far as my background, I have 4 YOE and have a dual BS in Math &amp;amp; Econ, like I mentioned also currently part time enrolled in the Georgia Tech online masters. &lt;/p&gt;

&lt;p&gt;The team and would be manager seem awesome. I really clicked with the manager and it seems like the company cares and that they’re genuinely good people. &lt;/p&gt;

&lt;p&gt;As far as cost of living, I could stay in Dallas, which is definitely lower than the Bay Area or NYC. &lt;/p&gt;

&lt;p&gt;I’m in the pipeline at other companies, but is this offer worth taking and dropping out of the running elsewhere? I suppose I could take it and continue interviewing, but I really would like to avoid that because I did have a strong connection and wouldn’t want to leave them high and dry. &lt;/p&gt;

&lt;p&gt;Any advice, insights, data points, things to think about, etc would be sincerely appreciated! &lt;/p&gt;

&lt;p&gt;Thank you all!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0sbp6,byongsun6,25,/r/datascience/comments/i0sbp6/offer_evaluation_help/,https://www.reddit.com/r/datascience/comments/i0sbp6/offer_evaluation_help/,1596136909.0
r/datascience,"What do you use for your data science job search?

LinkedIn?
Indeed?
Dice?
Some industry specific site?

What's your go to site for job hunting",t2_1n8owavv,Where do you job search?,,t3_i0m3md,0.5,0,Job Search,0,1596144755.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What do you use for your data science job search?&lt;/p&gt;

&lt;p&gt;LinkedIn?
Indeed?
Dice?
Some industry specific site?&lt;/p&gt;

&lt;p&gt;What&amp;#39;s your go to site for job hunting&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0m3md,DS_throwitaway,11,/r/datascience/comments/i0m3md/where_do_you_job_search/,https://www.reddit.com/r/datascience/comments/i0m3md/where_do_you_job_search/,1596115955.0
r/datascience,"I just took one of those hacker rank coding tests and completely bombed it. I've been trying to switch into data science from physics and thought "" I should be able to transition smooth enough, I mean most of my work involved using pandas and matplotlib, so I should be set!"". Big nope! Like not even close, I was tested on using SQL and creating a predictive model. To be fair the predictive modeling was not completely out of my range, but I've only ever used simple linear regression to make a model that I'd then use to forecast.

That test was a huge wake up call that I dont know squat about DS. I really need to get serious about learning DS and stop resting on the laurels of bring a physics grad",t2_17iju0,"Absolutely failed a data science pre-screening test, huge wake up call for me",,t3_hzq8s8,0.97,504,,504,1596010206.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just took one of those hacker rank coding tests and completely bombed it. I&amp;#39;ve been trying to switch into data science from physics and thought &amp;quot; I should be able to transition smooth enough, I mean most of my work involved using pandas and matplotlib, so I should be set!&amp;quot;. Big nope! Like not even close, I was tested on using SQL and creating a predictive model. To be fair the predictive modeling was not completely out of my range, but I&amp;#39;ve only ever used simple linear regression to make a model that I&amp;#39;d then use to forecast.&lt;/p&gt;

&lt;p&gt;That test was a huge wake up call that I dont know squat about DS. I really need to get serious about learning DS and stop resting on the laurels of bring a physics grad&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzq8s8,datdutho,108,/r/datascience/comments/hzq8s8/absolutely_failed_a_data_science_prescreening/,https://www.reddit.com/r/datascience/comments/hzq8s8/absolutely_failed_a_data_science_prescreening/,1595981406.0
r/datascience,"Is it a red flag when a (truly) entry-level job description requires experience with closed source software tools that few college students would have access to? 

I was lucky to have a year of access to SAS 9.4 in grad school, but a lot of job postings want Tableau, Alteryx, specialized SAS products (Viya, Visual Studio, etc.), or other tools that are difficult or impossible to learn. *(Yes, Tableau has a student version, but you must be currently enrolled to download for some reason...)*

Should I take these job req bullet points with a grain of salt, or is it a sign HR or leadership is out of touch at that company?",t2_4zfdco3k,New-grad jobs requiring &gt;1yr experience with closed source software tools,,t3_i04cpf,0.82,19,Job Search,19,1596071393.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it a red flag when a (truly) entry-level job description requires experience with closed source software tools that few college students would have access to? &lt;/p&gt;

&lt;p&gt;I was lucky to have a year of access to SAS 9.4 in grad school, but a lot of job postings want Tableau, Alteryx, specialized SAS products (Viya, Visual Studio, etc.), or other tools that are difficult or impossible to learn. &lt;em&gt;(Yes, Tableau has a student version, but you must be currently enrolled to download for some reason...)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Should I take these job req bullet points with a grain of salt, or is it a sign HR or leadership is out of touch at that company?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i04cpf,VocRehabber,22,/r/datascience/comments/i04cpf/newgrad_jobs_requiring_1yr_experience_with_closed/,https://www.reddit.com/r/datascience/comments/i04cpf/newgrad_jobs_requiring_1yr_experience_with_closed/,1596042593.0
r/datascience,"If you've ever used Google Docs, Sheets, or Slides you will know how lovely it is to have multiple people working on the same document. Everything updates live and you can see everyone's cursor live and everything that they are typing. It's great. No worrying about merge conflicts or out of sync files/documents. I was wondering if there is something like this for Jupyter Notebooks? Does anyone know of something like that?",t2_f4itz0w,Live editing Jupyter Notebooks,tooling,t3_i0mcx0,0.29,0,Tooling,0,1596145755.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If you&amp;#39;ve ever used Google Docs, Sheets, or Slides you will know how lovely it is to have multiple people working on the same document. Everything updates live and you can see everyone&amp;#39;s cursor live and everything that they are typing. It&amp;#39;s great. No worrying about merge conflicts or out of sync files/documents. I was wondering if there is something like this for Jupyter Notebooks? Does anyone know of something like that?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0mcx0,xblackacid,7,/r/datascience/comments/i0mcx0/live_editing_jupyter_notebooks/,https://www.reddit.com/r/datascience/comments/i0mcx0/live_editing_jupyter_notebooks/,1596116955.0
r/datascience,"I’ve participated in a few Kaggle competitions (competitions expert now, but only 2 bronze :/)

Are there some local competitors in my area that would like meet (after quarantine ends) to discuss/collaborate future competitions?",t2_6zw4hqke,Are there any individuals in the northern Virginia (NOVA) area who are interested in competitive data science?,network,t3_i0d1kb,0.64,4,Networking,4,1596101152.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve participated in a few Kaggle competitions (competitions expert now, but only 2 bronze :/)&lt;/p&gt;

&lt;p&gt;Are there some local competitors in my area that would like meet (after quarantine ends) to discuss/collaborate future competitions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0d1kb,targetXING,0,/r/datascience/comments/i0d1kb/are_there_any_individuals_in_the_northern/,https://www.reddit.com/r/datascience/comments/i0d1kb/are_there_any_individuals_in_the_northern/,1596072352.0
r/datascience,"Specifically for news, something that incorporates machine learning to recognise differing classifiers in different websites for the same types of things i.e headline, author, date, text body, etc..

Right now I am only finding methods that require each website to be handled independently",t2_mdyw3,Is there any content scraping machine learning code out there?,discussion,t3_i0mgil,0.22,0,Discussion,0,1596146138.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Specifically for news, something that incorporates machine learning to recognise differing classifiers in different websites for the same types of things i.e headline, author, date, text body, etc..&lt;/p&gt;

&lt;p&gt;Right now I am only finding methods that require each website to be handled independently&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i0mgil,F1jk,0,/r/datascience/comments/i0mgil/is_there_any_content_scraping_machine_learning/,https://www.reddit.com/r/datascience/comments/i0mgil/is_there_any_content_scraping_machine_learning/,1596117338.0
r/datascience," Hello everyone!

I keep running into the same issue at my company: we want to evaluate the performance of a new feature/MVP, but the flow of users we see just isn't high enough to be able to run a test in an acceptable time window (there's no point running an experiment that takes 12 months since our user demographic might have completely shifted during that time).

I'm trying to figure out ways to gain some sort of confidence in the results I'm seeing, even if I don't have a significant result due to lack of sample size. What do/would you do to determine effect, if running a ""classical"" A/B test is out of the question?",t2_13ijyk,Alternatives to A/B testing due to lack of data,discussion,t3_i01t6p,0.82,13,Discussion,13,1596062350.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;

&lt;p&gt;I keep running into the same issue at my company: we want to evaluate the performance of a new feature/MVP, but the flow of users we see just isn&amp;#39;t high enough to be able to run a test in an acceptable time window (there&amp;#39;s no point running an experiment that takes 12 months since our user demographic might have completely shifted during that time).&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to figure out ways to gain some sort of confidence in the results I&amp;#39;m seeing, even if I don&amp;#39;t have a significant result due to lack of sample size. What do/would you do to determine effect, if running a &amp;quot;classical&amp;quot; A/B test is out of the question?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i01t6p,HiddenNegev,20,/r/datascience/comments/i01t6p/alternatives_to_ab_testing_due_to_lack_of_data/,https://www.reddit.com/r/datascience/comments/i01t6p/alternatives_to_ab_testing_due_to_lack_of_data/,1596033550.0
r/datascience,Right now Im currently working from home on a macbook pro. At work I use a dell optiplex micro 3070 and thinking of getting one for home. Looking to upgrade and was wondering what you guys work off of.,t2_6czjsf70,What is your home workspace set up?,discussion,t3_i02h44,0.82,10,Discussion,10,1596064770.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Right now Im currently working from home on a macbook pro. At work I use a dell optiplex micro 3070 and thinking of getting one for home. Looking to upgrade and was wondering what you guys work off of.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i02h44,baby_urbanist,22,/r/datascience/comments/i02h44/what_is_your_home_workspace_set_up/,https://www.reddit.com/r/datascience/comments/i02h44/what_is_your_home_workspace_set_up/,1596035970.0
r/datascience,"I have worked in a few finance companies now in the UK where the model-building framework tends to have a few common characteristics.

For example:

* Logistic and linear regression are almost always used
* In classification, features are manually binned and replaced by their WOE (basically impact-encoding is used for all features)
* Variable selection: removing correlated features -&gt; filter method to exclude some features -&gt; stepwise feature selection, with strict p-value-based criteria for features entering/leaving the model
* The final model rarely has more than 10 features (selected from a pool of 200-300)

These practices seem *very* common in finance talking to more experienced people on my team. My manager is very open to modernizing and increasing the flexibility of our approach, but based on conversations i've had with senior managers and directors they tend to be more skeptical.

&amp;#x200B;

For example, if we were suggest implemeting a non-linear/ensemble approach (e.g. lightgbm/xgboost/random forest) with 100 features, common concerns might be:

1. **Stability** \- Flexible models with many features produce 'less-stable predictions'
2. **Deterioration** \- Flexible models with many features may perform better initially but will degrade in performance much faster and require re-training/re-development more frequently
3. **Diagnosis** \- If something goes wrong, it's harder to figure out why
4. **Interpretability** \- There is a real trade-off between performance and parsimony, and that a simpler method is worth sacrificing (sometimes considerable) cross-validation/test/future data accuracy

I personally haven't seen evidence to support 1, 2 &amp; 4. It particularly makes very little sense when we might include externally sourced features in our 'simple model' that are outputs of another predictive model, so these 'individual features' aren't so simple and are basically a function of 300 others! I think that 3 is a more legitimate concern, but that approaches like SHAP or simply monitoring changes in features over time could help with this.

&amp;#x200B;

I am not a big paper-reader but a lot of [Statistical Modeling: The Two Cultures](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726) resonated with things I have seen in industry. I suspect that many of these concerns and best practices probably originate from a mixture of explanatory statistics and tradition in credit risk modeling. I also think that a certain amount of it might be hearsay or a fear of the unknown.

Having said that, these directors have decades of practical modeling experience combined (most of it follows this classical credit-risk/banking framework) and are very intelligent and knowledgeable. On the other hand, I am in the first few years of my career and am still learning all the time.

I am curious if there has been much research on this topic, if you guys have found (in your experience) any/all of these concerns to be legitimate, and how you might approach alleviating them if they aren't. Thanks!",t2_e6iwm,The fear (in industry) of complex models with many features,discussion,t3_hzxzu6,0.81,12,Discussion,12,1596045419.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have worked in a few finance companies now in the UK where the model-building framework tends to have a few common characteristics.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Logistic and linear regression are almost always used&lt;/li&gt;
&lt;li&gt;In classification, features are manually binned and replaced by their WOE (basically impact-encoding is used for all features)&lt;/li&gt;
&lt;li&gt;Variable selection: removing correlated features -&amp;gt; filter method to exclude some features -&amp;gt; stepwise feature selection, with strict p-value-based criteria for features entering/leaving the model&lt;/li&gt;
&lt;li&gt;The final model rarely has more than 10 features (selected from a pool of 200-300)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These practices seem &lt;em&gt;very&lt;/em&gt; common in finance talking to more experienced people on my team. My manager is very open to modernizing and increasing the flexibility of our approach, but based on conversations i&amp;#39;ve had with senior managers and directors they tend to be more skeptical.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;For example, if we were suggest implemeting a non-linear/ensemble approach (e.g. lightgbm/xgboost/random forest) with 100 features, common concerns might be:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Stability&lt;/strong&gt; - Flexible models with many features produce &amp;#39;less-stable predictions&amp;#39;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deterioration&lt;/strong&gt; - Flexible models with many features may perform better initially but will degrade in performance much faster and require re-training/re-development more frequently&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Diagnosis&lt;/strong&gt; - If something goes wrong, it&amp;#39;s harder to figure out why&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interpretability&lt;/strong&gt; - There is a real trade-off between performance and parsimony, and that a simpler method is worth sacrificing (sometimes considerable) cross-validation/test/future data accuracy&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I personally haven&amp;#39;t seen evidence to support 1, 2 &amp;amp; 4. It particularly makes very little sense when we might include externally sourced features in our &amp;#39;simple model&amp;#39; that are outputs of another predictive model, so these &amp;#39;individual features&amp;#39; aren&amp;#39;t so simple and are basically a function of 300 others! I think that 3 is a more legitimate concern, but that approaches like SHAP or simply monitoring changes in features over time could help with this.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am not a big paper-reader but a lot of &lt;a href=""https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726""&gt;Statistical Modeling: The Two Cultures&lt;/a&gt; resonated with things I have seen in industry. I suspect that many of these concerns and best practices probably originate from a mixture of explanatory statistics and tradition in credit risk modeling. I also think that a certain amount of it might be hearsay or a fear of the unknown.&lt;/p&gt;

&lt;p&gt;Having said that, these directors have decades of practical modeling experience combined (most of it follows this classical credit-risk/banking framework) and are very intelligent and knowledgeable. On the other hand, I am in the first few years of my career and am still learning all the time.&lt;/p&gt;

&lt;p&gt;I am curious if there has been much research on this topic, if you guys have found (in your experience) any/all of these concerns to be legitimate, and how you might approach alleviating them if they aren&amp;#39;t. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzxzu6,supra95,34,/r/datascience/comments/hzxzu6/the_fear_in_industry_of_complex_models_with_many/,https://www.reddit.com/r/datascience/comments/hzxzu6/the_fear_in_industry_of_complex_models_with_many/,1596016619.0
r/datascience,"Many DS job offers require project or product management skills. 

How can I get experience in management if I work on a company that does not give me the opportunity?   


I thought about making a group to develop an MVP just so I can be the manager. Then we create another MVP and another member becomes the manager and so on.",t2_1284cj,How to get product/project Management Skills?,career,t3_i02m35,1.0,3,Career,3,1596065276.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Many DS job offers require project or product management skills. &lt;/p&gt;

&lt;p&gt;How can I get experience in management if I work on a company that does not give me the opportunity?   &lt;/p&gt;

&lt;p&gt;I thought about making a group to develop an MVP just so I can be the manager. Then we create another MVP and another member becomes the manager and so on.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i02m35,umbrelamafia,7,/r/datascience/comments/i02m35/how_to_get_productproject_management_skills/,https://www.reddit.com/r/datascience/comments/i02m35/how_to_get_productproject_management_skills/,1596036476.0
r/datascience,"Hey DS crew, I really like it here I hope this is a place where I can let of a bit of steam and hear your thoughts. 

I hate my current position as a DS. I found a new job that aligned with my values and my future boss was great to talk to. I was rejected today because I submitted a take home assignment too late. This was my mistake and i feel like such an idiot for not checking the deadline. 

My probation period is now over and quitting will be much more difficult / finding a new job. 

I feel tired of data science. I worked hard to be where I’m at, and nothing has helped me more in this career than the fantastic people I’ve worked with. To all of you out there suffering in the job market, you have my empathy and I’m right there with you. 

I’m stuck in a job that’s completely focused on office politics, gossip, limited experience and huge expectations. My girlfriend sees me come home absolute destroyed from my day. 

I feel so god damn worn out. I just want to be a data scientist. 

I can’t stand that my job is high school drama. I want to Analyse data, not why John has mysteriously left at 2pm. 

I feel so tired. 

Thank you for listening. I love this community and it always inspires me to see the interesting ideas being thrown around.",t2_5e34w9d2,I missed out on a new job opportunity and I’m so bummed out. [RANT],discussion,t3_hzk8cs,0.97,95,Discussion,95,1595990317.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey DS crew, I really like it here I hope this is a place where I can let of a bit of steam and hear your thoughts. &lt;/p&gt;

&lt;p&gt;I hate my current position as a DS. I found a new job that aligned with my values and my future boss was great to talk to. I was rejected today because I submitted a take home assignment too late. This was my mistake and i feel like such an idiot for not checking the deadline. &lt;/p&gt;

&lt;p&gt;My probation period is now over and quitting will be much more difficult / finding a new job. &lt;/p&gt;

&lt;p&gt;I feel tired of data science. I worked hard to be where I’m at, and nothing has helped me more in this career than the fantastic people I’ve worked with. To all of you out there suffering in the job market, you have my empathy and I’m right there with you. &lt;/p&gt;

&lt;p&gt;I’m stuck in a job that’s completely focused on office politics, gossip, limited experience and huge expectations. My girlfriend sees me come home absolute destroyed from my day. &lt;/p&gt;

&lt;p&gt;I feel so god damn worn out. I just want to be a data scientist. &lt;/p&gt;

&lt;p&gt;I can’t stand that my job is high school drama. I want to Analyse data, not why John has mysteriously left at 2pm. &lt;/p&gt;

&lt;p&gt;I feel so tired. &lt;/p&gt;

&lt;p&gt;Thank you for listening. I love this community and it always inspires me to see the interesting ideas being thrown around.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzk8cs,expatwithajetpack,57,/r/datascience/comments/hzk8cs/i_missed_out_on_a_new_job_opportunity_and_im_so/,https://www.reddit.com/r/datascience/comments/hzk8cs/i_missed_out_on_a_new_job_opportunity_and_im_so/,1595961517.0
r/datascience,"Booz Allen Hamilton is a legitimate company, but I believe someone is posing as them to scam job seekers.

This morning, I got an email for a remote Data Scientist position with BAH. The job description sounded legitimate and it said ""We successfully reviewed your resume and it has been approved for an virtual screening test/interview by Booz Allen Hamilton Inc, for the position of ***Data Scientist*** (REMOTE)."" They also asked me to confirm my name and city listed on my resume, which I thought was strange, but not out of the realm of possibility. The person listed to contact has a LinkedIn profile with 300 connections and is listed as a BAH employee.

I said I was interested in the interview and that I had availability tomorrow. A few hours later, they emailed me with the screening test and let me know I had three hours to complete it. Kind of a dick move, but okay. It consisted of mostly technical questions related to machine learning algorithms.

I sent my answers back to them and received a reply stating they had gotten my answers, would ""forward the \[answers\] to the Hiring Board for their decision,"" and would get back to me with ""feedback from the Board's decision in about an hour or more."" I did not reply. At this point, there were a few warning signs, but nothing overtly obvious that this was a scam.

30 minutes later, I received another email stating that ""I am glad to inform you that due to your level of experience and your working skills, the company has decided to hire you as one of our ***Data Scientists.""***  They wanted my full name, address, email, and phone number for the HR hiring letter. They would also send me a check ""to set up your mini office by purchasing the office equipment and software needed to start your training and work."" They also said I would undergo a few days' training at $20 an hour and then work itself would be $60 an hour.

I was very suspicious at this point, and eventually found [this article](https://adage.com/article/agency-news/job-offer-agency-fake/314615) from two years ago detailing a scam with almost the same details but from a different company. This has confirmed to me that it is indeed a scam, which is disappointing given the current job market. I have been looking for a job for a while now and it's unfortunate that people are trying to take advantage of that, especially now. I wanted to post this in case anyone else had received this email and to let them know it's not legitimate.",t2_95507,"Caution- Job offer scam from ""Booz Allen Hamilton""",,t3_hzqc27,0.87,20,Job Search,20,1596010552.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Booz Allen Hamilton is a legitimate company, but I believe someone is posing as them to scam job seekers.&lt;/p&gt;

&lt;p&gt;This morning, I got an email for a remote Data Scientist position with BAH. The job description sounded legitimate and it said &amp;quot;We successfully reviewed your resume and it has been approved for an virtual screening test/interview by Booz Allen Hamilton Inc, for the position of &lt;strong&gt;&lt;em&gt;Data Scientist&lt;/em&gt;&lt;/strong&gt; (REMOTE).&amp;quot; They also asked me to confirm my name and city listed on my resume, which I thought was strange, but not out of the realm of possibility. The person listed to contact has a LinkedIn profile with 300 connections and is listed as a BAH employee.&lt;/p&gt;

&lt;p&gt;I said I was interested in the interview and that I had availability tomorrow. A few hours later, they emailed me with the screening test and let me know I had three hours to complete it. Kind of a dick move, but okay. It consisted of mostly technical questions related to machine learning algorithms.&lt;/p&gt;

&lt;p&gt;I sent my answers back to them and received a reply stating they had gotten my answers, would &amp;quot;forward the [answers] to the Hiring Board for their decision,&amp;quot; and would get back to me with &amp;quot;feedback from the Board&amp;#39;s decision in about an hour or more.&amp;quot; I did not reply. At this point, there were a few warning signs, but nothing overtly obvious that this was a scam.&lt;/p&gt;

&lt;p&gt;30 minutes later, I received another email stating that &amp;quot;I am glad to inform you that due to your level of experience and your working skills, the company has decided to hire you as one of our &lt;strong&gt;&lt;em&gt;Data Scientists.&amp;quot;&lt;/em&gt;&lt;/strong&gt;  They wanted my full name, address, email, and phone number for the HR hiring letter. They would also send me a check &amp;quot;to set up your mini office by purchasing the office equipment and software needed to start your training and work.&amp;quot; They also said I would undergo a few days&amp;#39; training at $20 an hour and then work itself would be $60 an hour.&lt;/p&gt;

&lt;p&gt;I was very suspicious at this point, and eventually found &lt;a href=""https://adage.com/article/agency-news/job-offer-agency-fake/314615""&gt;this article&lt;/a&gt; from two years ago detailing a scam with almost the same details but from a different company. This has confirmed to me that it is indeed a scam, which is disappointing given the current job market. I have been looking for a job for a while now and it&amp;#39;s unfortunate that people are trying to take advantage of that, especially now. I wanted to post this in case anyone else had received this email and to let them know it&amp;#39;s not legitimate.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzqc27,honorarymexican,15,/r/datascience/comments/hzqc27/caution_job_offer_scam_from_booz_allen_hamilton/,https://www.reddit.com/r/datascience/comments/hzqc27/caution_job_offer_scam_from_booz_allen_hamilton/,1595981752.0
r/datascience,"I have a dataset and I’d like to engineer some new features from this dataset.

I then want to put these new features in to a DataFrame and train my model. 

For example, I want to create a feature which looks at the last k datapoints and sums them up (cumulative sum). 

How do I choose k? How do I optimise this?",t2_14h1nx,Creating new features; how to optimise parameters?,discussion,t3_i02tk6,1.0,1,Discussion,1,1596066029.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a dataset and I’d like to engineer some new features from this dataset.&lt;/p&gt;

&lt;p&gt;I then want to put these new features in to a DataFrame and train my model. &lt;/p&gt;

&lt;p&gt;For example, I want to create a feature which looks at the last k datapoints and sums them up (cumulative sum). &lt;/p&gt;

&lt;p&gt;How do I choose k? How do I optimise this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",i02tk6,BasslineButty,3,/r/datascience/comments/i02tk6/creating_new_features_how_to_optimise_parameters/,https://www.reddit.com/r/datascience/comments/i02tk6/creating_new_features_how_to_optimise_parameters/,1596037229.0
r/datascience,"Obviously, a lot of people have been affected by COVID related changes in business. 

So for those laid off, be it because COVID or some other reason:

How long has it taken you to find a new role? Are you still looking?",t2_nscej,"Data Scientists who got laid off, how long has it taken you to find new jobs?",,t3_hztet0,0.82,7,Job Search,7,1596022591.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Obviously, a lot of people have been affected by COVID related changes in business. &lt;/p&gt;

&lt;p&gt;So for those laid off, be it because COVID or some other reason:&lt;/p&gt;

&lt;p&gt;How long has it taken you to find a new role? Are you still looking?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hztet0,tonym9428,9,/r/datascience/comments/hztet0/data_scientists_who_got_laid_off_how_long_has_it/,https://www.reddit.com/r/datascience/comments/hztet0/data_scientists_who_got_laid_off_how_long_has_it/,1595993791.0
r/datascience,"Hi folks, I need your advice.

I came across a very poor quality paper recently, it was oublished in a reviewed journal. I don't want to tell which one was it, as I feel that wouldn't be a great thing to do. The paper itself was written by a professor from a more or less well respected business school. The analysis however is not only poor (underreporting results, which are just a correlation r value plus a line on a graph), it is exactly the type which makes a lot of people look at quantitative social science and political science as a child's playground.

The paper is based on a classification algorithm, which is so poorly documented, that you can only get any kind of accuracy from one single graph (nothing in the text), which actually shows that almost half of the cases were classified with an error so large, that it could span across three categories. The classification is based on a range, where classes span 5 units of measurement. The error for ~46% of classified data points is at least 5.5, so theoretically this is as ambigous as it gets. The algorithm is only documented in 4 pages, so there is literally nothing to go on. The first paper cites the short paper, and links to a google drive for the source code, but the link throws a 404, despite the paper coming out a week ago.

I have nothing against the author, I have nothing in making them retract the paper. I've been working in data modelling for years now, and linear models are my specialty, so I'm fairly certain I'm right. I'm also active academically, and as a person who tries to legitimize quantitative social sciences, I think papers like this hurt us a great deal.

Is it a dick move if I voice my concerns to the journal?

EDIT: wow this blew up. Thank you for the comments, I will read them until they come. I wrote to the managing editors, phrased a letter, and told them otherwise that I have nothing to gain or lose from this, so it really is their domain to decide. They were very chill about it, and asked for a few weeks time.",t2_126r72,Is writing a publisher about a very poor quality published paper considered a 'dick move'?,discussion,t3_hzb04b,0.96,189,Discussion,189,1595954132.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi folks, I need your advice.&lt;/p&gt;

&lt;p&gt;I came across a very poor quality paper recently, it was oublished in a reviewed journal. I don&amp;#39;t want to tell which one was it, as I feel that wouldn&amp;#39;t be a great thing to do. The paper itself was written by a professor from a more or less well respected business school. The analysis however is not only poor (underreporting results, which are just a correlation r value plus a line on a graph), it is exactly the type which makes a lot of people look at quantitative social science and political science as a child&amp;#39;s playground.&lt;/p&gt;

&lt;p&gt;The paper is based on a classification algorithm, which is so poorly documented, that you can only get any kind of accuracy from one single graph (nothing in the text), which actually shows that almost half of the cases were classified with an error so large, that it could span across three categories. The classification is based on a range, where classes span 5 units of measurement. The error for ~46% of classified data points is at least 5.5, so theoretically this is as ambigous as it gets. The algorithm is only documented in 4 pages, so there is literally nothing to go on. The first paper cites the short paper, and links to a google drive for the source code, but the link throws a 404, despite the paper coming out a week ago.&lt;/p&gt;

&lt;p&gt;I have nothing against the author, I have nothing in making them retract the paper. I&amp;#39;ve been working in data modelling for years now, and linear models are my specialty, so I&amp;#39;m fairly certain I&amp;#39;m right. I&amp;#39;m also active academically, and as a person who tries to legitimize quantitative social sciences, I think papers like this hurt us a great deal.&lt;/p&gt;

&lt;p&gt;Is it a dick move if I voice my concerns to the journal?&lt;/p&gt;

&lt;p&gt;EDIT: wow this blew up. Thank you for the comments, I will read them until they come. I wrote to the managing editors, phrased a letter, and told them otherwise that I have nothing to gain or lose from this, so it really is their domain to decide. They were very chill about it, and asked for a few weeks time.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzb04b,FKKGYM,62,/r/datascience/comments/hzb04b/is_writing_a_publisher_about_a_very_poor_quality/,https://www.reddit.com/r/datascience/comments/hzb04b/is_writing_a_publisher_about_a_very_poor_quality/,1595925332.0
r/datascience,"Growing up, I had a high understanding of, and test scores in, history, literature, etc., but I was always in the middle or back of the pack when it came to math.

Since developing my career, I have been getting more and more exposed to statistics and data. I am able to grasp programming concepts and SQL, and am able to understand database schemas/structures fairly well. However, when it comes to even basic statistics (regression, for example), I just seem to shut down.

When I see formulas or equations that contain letters, I don't know how to explain it, but I just get a complete mental block. If you give me percentages, fractions, proportions, even geometry, I am able to quickly work out solutions - normally faster than the average colleague that I work with. However, I just shut down as soon as I see letters or symbols or Greek letters in a formula. I can't seem to keep track of all the universal variables or assigned variables, and I quickly lose track of the logic in whatever formula or problem I'm working on.

I did learn early on in life that I was much better at ""word problems"" than I was at strict formulas, as I was able to understand the logic in the problem and translate it to a formula a bit more easily than just looking at a formula.

Anyway, I work on a dual project manager/insights role in a healthcare marketing department, adjacent to an advanced analytics team and a team of developers. The more I develop my career, the more this ""mental block"" seems to hinder me. I was hoping this community might have some suggestions or resources I could ingest/read/watch that could help me overcome this block so that I can have a better understanding of statistics and data science.",t2_7j2fgpx,Help with overcomimg my mental block upon seeing advanced formulas so that I can learn more about statistics and data?,,t3_hzz6u3,0.6,1,,1,1596051531.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Growing up, I had a high understanding of, and test scores in, history, literature, etc., but I was always in the middle or back of the pack when it came to math.&lt;/p&gt;

&lt;p&gt;Since developing my career, I have been getting more and more exposed to statistics and data. I am able to grasp programming concepts and SQL, and am able to understand database schemas/structures fairly well. However, when it comes to even basic statistics (regression, for example), I just seem to shut down.&lt;/p&gt;

&lt;p&gt;When I see formulas or equations that contain letters, I don&amp;#39;t know how to explain it, but I just get a complete mental block. If you give me percentages, fractions, proportions, even geometry, I am able to quickly work out solutions - normally faster than the average colleague that I work with. However, I just shut down as soon as I see letters or symbols or Greek letters in a formula. I can&amp;#39;t seem to keep track of all the universal variables or assigned variables, and I quickly lose track of the logic in whatever formula or problem I&amp;#39;m working on.&lt;/p&gt;

&lt;p&gt;I did learn early on in life that I was much better at &amp;quot;word problems&amp;quot; than I was at strict formulas, as I was able to understand the logic in the problem and translate it to a formula a bit more easily than just looking at a formula.&lt;/p&gt;

&lt;p&gt;Anyway, I work on a dual project manager/insights role in a healthcare marketing department, adjacent to an advanced analytics team and a team of developers. The more I develop my career, the more this &amp;quot;mental block&amp;quot; seems to hinder me. I was hoping this community might have some suggestions or resources I could ingest/read/watch that could help me overcome this block so that I can have a better understanding of statistics and data science.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzz6u3,poultryexterior,19,/r/datascience/comments/hzz6u3/help_with_overcomimg_my_mental_block_upon_seeing/,https://www.reddit.com/r/datascience/comments/hzz6u3/help_with_overcomimg_my_mental_block_upon_seeing/,1596022731.0
r/datascience,"Hi everyone. I work as a data analyst in marketing and I'm looking for opinion/suggestions on methods to determine the number of advertisements we should send an individual. It's a count issue and I don't see them here often, but they're constantly in industry.

The question is how many mailers do we send to optimise response?

I've looked at poisson regression, but are the mailers independent? Is meeting this assumption that important in industry?

Linear programming?

Any suggestions are welcome.",t2_5503u,Applied Work Issue - Direct Marketing Letters,discussion,t3_hzyuua,0.67,1,Discussion,1,1596049908.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone. I work as a data analyst in marketing and I&amp;#39;m looking for opinion/suggestions on methods to determine the number of advertisements we should send an individual. It&amp;#39;s a count issue and I don&amp;#39;t see them here often, but they&amp;#39;re constantly in industry.&lt;/p&gt;

&lt;p&gt;The question is how many mailers do we send to optimise response?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve looked at poisson regression, but are the mailers independent? Is meeting this assumption that important in industry?&lt;/p&gt;

&lt;p&gt;Linear programming?&lt;/p&gt;

&lt;p&gt;Any suggestions are welcome.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzyuua,Polus43,1,/r/datascience/comments/hzyuua/applied_work_issue_direct_marketing_letters/,https://www.reddit.com/r/datascience/comments/hzyuua/applied_work_issue_direct_marketing_letters/,1596021108.0
r/datascience,,t2_44mbtmjy,Latest from Carnegie Mellon and Facebook Researchers: 3D Human Shape and Pose from a Single Low-Resolution Image with Self-Supervised Learning,projects,t3_hzu4tq,0.67,2,Projects,2,1596025671.0,,hzu4tq,MLtinkerer,0,/r/datascience/comments/hzu4tq/latest_from_carnegie_mellon_and_facebook/,/r/LatestInML/comments/hztvin/latest_from_carnegie_mellon_and_facebook/,1595996871.0
r/datascience,"Hi all, 

I am a data science intern working on machine metric data. I am trying to understand the methods to predict maintenance of the machine - when will a machine be down and how much time will it be down? 

For the latter, I have historical data with down time and dates. The data is not present for every date and there are gaps. I tried grouping it by a week instead of a day and get a TS. Unfortunately the AR model isn't fitting the data properly because of the imbalance the data has. Tried using several lags to fit the model. Any help regarding this or some online sources is appreciated. 

Also, the 1 st problem statement of predicting if the machine is going to be down. How to use the categorical variables such as date, day or hour in a day to classify?",t2_3p0yts5p,Predictive Maintenance,discussion,t3_hzowcz,0.71,4,Discussion,4,1596005300.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, &lt;/p&gt;

&lt;p&gt;I am a data science intern working on machine metric data. I am trying to understand the methods to predict maintenance of the machine - when will a machine be down and how much time will it be down? &lt;/p&gt;

&lt;p&gt;For the latter, I have historical data with down time and dates. The data is not present for every date and there are gaps. I tried grouping it by a week instead of a day and get a TS. Unfortunately the AR model isn&amp;#39;t fitting the data properly because of the imbalance the data has. Tried using several lags to fit the model. Any help regarding this or some online sources is appreciated. &lt;/p&gt;

&lt;p&gt;Also, the 1 st problem statement of predicting if the machine is going to be down. How to use the categorical variables such as date, day or hour in a day to classify?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzowcz,vamsisachin27,17,/r/datascience/comments/hzowcz/predictive_maintenance/,https://www.reddit.com/r/datascience/comments/hzowcz/predictive_maintenance/,1595976500.0
r/datascience,"Hello everyone,

I work as a data-lead at a moderately (medium/large) sized civil office. My team and I have been tasked with the development of a data warehouse from scratch. The data we mainly work with are mostly stored on-prem. The data is not big the sense that they are long and frequently measured, but rather big in the sense that they are varied and ""wide"". 

What is both a blessing and a curse for us is that we are (almost) free to choose our data architecture (that is, what kind of database, ETL tool esc.)

The team consists of data scientists who all are experienced and very capable in R. So the team is set up to use R as a weapon of choice. For what it's worth, R has been my weapon of choice for more than a decade now. 

With the introduction of tidyverse and dbplyr to R - it is my opinion that R can now serve a go-to ETL tool for building a data warehouse. 

What I would like to ask this community is: Is there anyone here who has experience building a data warehouse (or a virtual data warehouse) using R as the main ETL tool? What are the pros-and-cons? What pitfalls could lie ahead that I am not seeing - me being very biased towards using R? Has anyone, for example, used data-lakes for storing raw data and then used R to transform and load data into a structured (relations) database structure?

I'd be very grateful to hear from the community your thoughts on the matter.",t2_4hpv3,R as an ETL tool for building a data warehouse,discussion,t3_hzdht8,0.88,16,Discussion,16,1595966849.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I work as a data-lead at a moderately (medium/large) sized civil office. My team and I have been tasked with the development of a data warehouse from scratch. The data we mainly work with are mostly stored on-prem. The data is not big the sense that they are long and frequently measured, but rather big in the sense that they are varied and &amp;quot;wide&amp;quot;. &lt;/p&gt;

&lt;p&gt;What is both a blessing and a curse for us is that we are (almost) free to choose our data architecture (that is, what kind of database, ETL tool esc.)&lt;/p&gt;

&lt;p&gt;The team consists of data scientists who all are experienced and very capable in R. So the team is set up to use R as a weapon of choice. For what it&amp;#39;s worth, R has been my weapon of choice for more than a decade now. &lt;/p&gt;

&lt;p&gt;With the introduction of tidyverse and dbplyr to R - it is my opinion that R can now serve a go-to ETL tool for building a data warehouse. &lt;/p&gt;

&lt;p&gt;What I would like to ask this community is: Is there anyone here who has experience building a data warehouse (or a virtual data warehouse) using R as the main ETL tool? What are the pros-and-cons? What pitfalls could lie ahead that I am not seeing - me being very biased towards using R? Has anyone, for example, used data-lakes for storing raw data and then used R to transform and load data into a structured (relations) database structure?&lt;/p&gt;

&lt;p&gt;I&amp;#39;d be very grateful to hear from the community your thoughts on the matter.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzdht8,olipalli,36,/r/datascience/comments/hzdht8/r_as_an_etl_tool_for_building_a_data_warehouse/,https://www.reddit.com/r/datascience/comments/hzdht8/r_as_an_etl_tool_for_building_a_data_warehouse/,1595938049.0
r/datascience,I have a problem and I am look for some resources on methodologies. Currently I have a dataset of 300k items and some features for each item. I want to find items in a second data set that are most similar to the items in the first dataset. What approach should I be looking at?,t2_1n8owavv,Identify rows from dataset A that are most similar to rows in dataset B.,projects,t3_hzp374,0.67,2,Projects,2,1596005979.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a problem and I am look for some resources on methodologies. Currently I have a dataset of 300k items and some features for each item. I want to find items in a second data set that are most similar to the items in the first dataset. What approach should I be looking at?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzp374,DS_throwitaway,10,/r/datascience/comments/hzp374/identify_rows_from_dataset_a_that_are_most/,https://www.reddit.com/r/datascience/comments/hzp374/identify_rows_from_dataset_a_that_are_most/,1595977179.0
r/datascience,"We're analyzing some creatives from past advertising campaigns and are looking for the best way to approach. Currently we've broken down each creative into 20+ objective characteristics, for example:

&amp;#x200B;

* CTA button (Y/N)
* Exclusive discount mentioned (Y/N)
* etc

For each campaign we have two main data points: CTR and conversions.

What's the best way to find patterns from this data? We're looking to find out how each feature affects CTR/conversions.

If this is a much bigger question than I'm making it out to be, does anyone have any good resources to read up on?",t2_16duoe,Creative Analysis - Best way to approach?,discussion,t3_hzfjvt,0.72,3,Discussion,3,1595975048.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We&amp;#39;re analyzing some creatives from past advertising campaigns and are looking for the best way to approach. Currently we&amp;#39;ve broken down each creative into 20+ objective characteristics, for example:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CTA button (Y/N)&lt;/li&gt;
&lt;li&gt;Exclusive discount mentioned (Y/N)&lt;/li&gt;
&lt;li&gt;etc&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For each campaign we have two main data points: CTR and conversions.&lt;/p&gt;

&lt;p&gt;What&amp;#39;s the best way to find patterns from this data? We&amp;#39;re looking to find out how each feature affects CTR/conversions.&lt;/p&gt;

&lt;p&gt;If this is a much bigger question than I&amp;#39;m making it out to be, does anyone have any good resources to read up on?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hzfjvt,dann2g,7,/r/datascience/comments/hzfjvt/creative_analysis_best_way_to_approach/,https://www.reddit.com/r/datascience/comments/hzfjvt/creative_analysis_best_way_to_approach/,1595946248.0
r/datascience,"I’m getting an degree in analytics and I’m curious if your corporate cultures consider data scientists as candidates for management and upper management?

I work as a data scientist for the federal government and can say that most federal agencies treat their data scientist like support staff and promote lawyers or MBAs for management. 

What is it like in your field?",t2_hxu5r,Is Data Science Changing Corporate Culture?,career,t3_hysmf4,0.95,206,Career,206,1595886662.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m getting an degree in analytics and I’m curious if your corporate cultures consider data scientists as candidates for management and upper management?&lt;/p&gt;

&lt;p&gt;I work as a data scientist for the federal government and can say that most federal agencies treat their data scientist like support staff and promote lawyers or MBAs for management. &lt;/p&gt;

&lt;p&gt;What is it like in your field?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hysmf4,GOBBlutheCompany,52,/r/datascience/comments/hysmf4/is_data_science_changing_corporate_culture/,https://www.reddit.com/r/datascience/comments/hysmf4/is_data_science_changing_corporate_culture/,1595857862.0
r/datascience,"Just a student studying and interested in data science, just wanted to know, what do you like about working in data science? What are your favourite and not so favourite parts?",t2_1qgzjjjl,Good parts about being a data scientist,discussion,t3_hz231g,0.91,18,Discussion,18,1595916636.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just a student studying and interested in data science, just wanted to know, what do you like about working in data science? What are your favourite and not so favourite parts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hz231g,acolyte17,26,/r/datascience/comments/hz231g/good_parts_about_being_a_data_scientist/,https://www.reddit.com/r/datascience/comments/hz231g/good_parts_about_being_a_data_scientist/,1595887836.0
r/datascience,"Background: I joined a company where my expectation of what I would be working turned out to be very different from what I have past experience in. In my past role, I worked closely with engineers building machine learning and deep learning models for domain-specific problems like text classification, image recognition, etc. The challenge was that out of the box deep learning models never worked well because the data was extremely domain-specific. It was challenging and a lot of fun. My title in this company was ""Data Scientist"".  


Recently, I changed jobs to a company where my title is still ""Data Scientist"" but the role is completely different. I do very little ML and focus more on product analytics. I have never worked on product analytics before and sometimes when I read other teammates' ""product recommendations"" I feel like I don't understand how they come up with these recommendations. Everyone is so focused on ""telling a story"" which sometimes seems so far-fetched. Sometimes, I show my team lead some data and say there isn't any obvious trend, but he picks out one graph and then asks me to run with it and tell a compelling story. I don't feel comfortable doing that at all. It's like every analysis that I do has to have a product recommendation. Is this how product analytics is? I don't have a background in this field so don't have anything to compare it against.   


Question: My question to everyone who works in product analytics. What do you do day-to-day and what are some best practices to follow to have some success in this field?",t2_2sdhd98j,Product Analytics advice,career,t3_hyy1sw,0.96,17,Career,17,1595903890.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Background: I joined a company where my expectation of what I would be working turned out to be very different from what I have past experience in. In my past role, I worked closely with engineers building machine learning and deep learning models for domain-specific problems like text classification, image recognition, etc. The challenge was that out of the box deep learning models never worked well because the data was extremely domain-specific. It was challenging and a lot of fun. My title in this company was &amp;quot;Data Scientist&amp;quot;.  &lt;/p&gt;

&lt;p&gt;Recently, I changed jobs to a company where my title is still &amp;quot;Data Scientist&amp;quot; but the role is completely different. I do very little ML and focus more on product analytics. I have never worked on product analytics before and sometimes when I read other teammates&amp;#39; &amp;quot;product recommendations&amp;quot; I feel like I don&amp;#39;t understand how they come up with these recommendations. Everyone is so focused on &amp;quot;telling a story&amp;quot; which sometimes seems so far-fetched. Sometimes, I show my team lead some data and say there isn&amp;#39;t any obvious trend, but he picks out one graph and then asks me to run with it and tell a compelling story. I don&amp;#39;t feel comfortable doing that at all. It&amp;#39;s like every analysis that I do has to have a product recommendation. Is this how product analytics is? I don&amp;#39;t have a background in this field so don&amp;#39;t have anything to compare it against.   &lt;/p&gt;

&lt;p&gt;Question: My question to everyone who works in product analytics. What do you do day-to-day and what are some best practices to follow to have some success in this field?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hyy1sw,SpiritAuror,4,/r/datascience/comments/hyy1sw/product_analytics_advice/,https://www.reddit.com/r/datascience/comments/hyy1sw/product_analytics_advice/,1595875090.0
r/datascience,"Hello, all 

Looking for some ideas from the experienced members of DS community regarding how I should go about data prep and which model would be relevant for my current task. 

Problem - Predicting city level market share of my company's product for upcoming quarters. 

Data - Historical city level store sales data containing sales numbers of my product and also competing products of the same category, over the last 10 years. 

Where I need help - What is the best way to prepare data for modeling (I'm currently thinking of aggregating avg. at city level) and how to define target? (I'm currently thinking of taking ratio of our product's sales to total sales for that zip across all the data). But since I want to predict market share for next quarter, how should I do prepare the data?   


Thanks in advance!",t2_85eksdy,Ideas for data prep &amp; model suggestions,projects,t3_hz825c,0.33,0,Projects,0,1595939421.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, all &lt;/p&gt;

&lt;p&gt;Looking for some ideas from the experienced members of DS community regarding how I should go about data prep and which model would be relevant for my current task. &lt;/p&gt;

&lt;p&gt;Problem - Predicting city level market share of my company&amp;#39;s product for upcoming quarters. &lt;/p&gt;

&lt;p&gt;Data - Historical city level store sales data containing sales numbers of my product and also competing products of the same category, over the last 10 years. &lt;/p&gt;

&lt;p&gt;Where I need help - What is the best way to prepare data for modeling (I&amp;#39;m currently thinking of aggregating avg. at city level) and how to define target? (I&amp;#39;m currently thinking of taking ratio of our product&amp;#39;s sales to total sales for that zip across all the data). But since I want to predict market share for next quarter, how should I do prepare the data?   &lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hz825c,KrishnarajaWadiyar4,3,/r/datascience/comments/hz825c/ideas_for_data_prep_model_suggestions/,https://www.reddit.com/r/datascience/comments/hz825c/ideas_for_data_prep_model_suggestions/,1595910621.0
r/datascience,"Hi! 

I’m relatively new to data/analytics. I found myself at a company with a data science program still in its infancy. A few people have told me this is great opportunity, because I can get tons of experience and pave my own path. The flip side is there aren’t other data professionals around and I’m finding that to be challenging when it comes to the intricacies of data work. 

If you were in my position, what would you do - if your goal was career growth? Would you stick around, push the envelope with taking on new tools and projects, or jump ship? 

Thanks in advance for any insight!",t2_cdiejit,How would you navigate in a company with a fledgeling data science program?,career,t3_hz2xyx,0.67,2,Career,2,1595919577.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! &lt;/p&gt;

&lt;p&gt;I’m relatively new to data/analytics. I found myself at a company with a data science program still in its infancy. A few people have told me this is great opportunity, because I can get tons of experience and pave my own path. The flip side is there aren’t other data professionals around and I’m finding that to be challenging when it comes to the intricacies of data work. &lt;/p&gt;

&lt;p&gt;If you were in my position, what would you do - if your goal was career growth? Would you stick around, push the envelope with taking on new tools and projects, or jump ship? &lt;/p&gt;

&lt;p&gt;Thanks in advance for any insight!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hz2xyx,nocturnalhustler,13,/r/datascience/comments/hz2xyx/how_would_you_navigate_in_a_company_with_a/,https://www.reddit.com/r/datascience/comments/hz2xyx/how_would_you_navigate_in_a_company_with_a/,1595890777.0
r/datascience," Hi ! I have a question for deep learning practitioners who are familiar with AWS products.

In my workplace, we are assessing two options : using Amazon SageMaker or having an EC2 instance with GPU.

We mainly need the computing power (GPU) and nothing more. We would like to have full control over which version is each package since our app needs specific versions for some packages and won't work otherwise. We are about to train a complex model with many components and loss functions.

Which is more adapted for our case cost-wise and from an ease-of-use point of view ?

Thank you in advance for your help.",t2_jwo6n,AWS Sagemaker vs EC2 for deep learning,tooling,t3_hyr66l,1.0,6,Tooling,6,1595881003.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi ! I have a question for deep learning practitioners who are familiar with AWS products.&lt;/p&gt;

&lt;p&gt;In my workplace, we are assessing two options : using Amazon SageMaker or having an EC2 instance with GPU.&lt;/p&gt;

&lt;p&gt;We mainly need the computing power (GPU) and nothing more. We would like to have full control over which version is each package since our app needs specific versions for some packages and won&amp;#39;t work otherwise. We are about to train a complex model with many components and loss functions.&lt;/p&gt;

&lt;p&gt;Which is more adapted for our case cost-wise and from an ease-of-use point of view ?&lt;/p&gt;

&lt;p&gt;Thank you in advance for your help.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hyr66l,chou404,8,/r/datascience/comments/hyr66l/aws_sagemaker_vs_ec2_for_deep_learning/,https://www.reddit.com/r/datascience/comments/hyr66l/aws_sagemaker_vs_ec2_for_deep_learning/,1595852203.0
r/datascience,"I'm trying to come up with a proof of concept for my PhD which includes some DL applications for brain MRI's. However, before I collect hundreds of MRI's and process them, I would like to develop some proof of concept. I already have on Knee MRI's as I could find a sufficiently large datasets but I'm having problems finding such datasets for brain MRI.

Another option could perhaps be to simulate the data using Pydicom...?

Anyone know the location of a large MRI brain dataset??

EDIT: A lot of great resources here! Be sure to link to this thread if you ever see a question about this again! Thank you!",t2_6nzxn9rl,Can't find a decently sized brain MRI dataset,discussion,t3_hy46e7,0.95,121,Discussion,121,1595785167.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to come up with a proof of concept for my PhD which includes some DL applications for brain MRI&amp;#39;s. However, before I collect hundreds of MRI&amp;#39;s and process them, I would like to develop some proof of concept. I already have on Knee MRI&amp;#39;s as I could find a sufficiently large datasets but I&amp;#39;m having problems finding such datasets for brain MRI.&lt;/p&gt;

&lt;p&gt;Another option could perhaps be to simulate the data using Pydicom...?&lt;/p&gt;

&lt;p&gt;Anyone know the location of a large MRI brain dataset??&lt;/p&gt;

&lt;p&gt;EDIT: A lot of great resources here! Be sure to link to this thread if you ever see a question about this again! Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hy46e7,helpamonkpls,24,/r/datascience/comments/hy46e7/cant_find_a_decently_sized_brain_mri_dataset/,https://www.reddit.com/r/datascience/comments/hy46e7/cant_find_a_decently_sized_brain_mri_dataset/,1595756367.0
r/datascience,"I’m about to take over a team that is data-science heavy. It’s an in-house innovation cell for a large technical consulting firm (we do big jobs like payroll, HR programmes for govt. departments and big firms, some cyber security etc.). 

I’m a generalist Project Manager and continuous improvement specialist (Agile, lean, PRINCE etc). 

What do you wish someone like me, knew about someone like you?",t2_6z1r8mec,Data scientists - What do you wish your non-specialist manager knew about your work?,discussion,t3_hyffxo,0.78,5,Discussion,5,1595828548.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m about to take over a team that is data-science heavy. It’s an in-house innovation cell for a large technical consulting firm (we do big jobs like payroll, HR programmes for govt. departments and big firms, some cyber security etc.). &lt;/p&gt;

&lt;p&gt;I’m a generalist Project Manager and continuous improvement specialist (Agile, lean, PRINCE etc). &lt;/p&gt;

&lt;p&gt;What do you wish someone like me, knew about someone like you?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hyffxo,jimmy-tar,16,/r/datascience/comments/hyffxo/data_scientists_what_do_you_wish_your/,https://www.reddit.com/r/datascience/comments/hyffxo/data_scientists_what_do_you_wish_your/,1595799748.0
r/datascience,"I'm having trouble finding literature on my particular problem.  

I'm familiar with Kaplan-Meier survival curves, which measure the probability that failure has not  occurred by time t. Normally, survival curves like this can handle variable start dates just fine, since the time to failure is assumed to follow some constant distribution. 

The system I am modeling has a deadline as well as variable start dates. For example, if the deadline is May 1st, samples could be 'born' on March 1st, or April 1st, or any date in  between. However, they cannot 'survive' past May 1st. Therefore, the possible range of survival time differs depending on start date. Samples born on April 1st cannot possible survive longer than 30 days, where samples born on March 1st can.

My first  thought was that I need to create a two dimensional survival 'triangle'  with all possible birth dates and time to failures. However, I've never heard of this method. Can anyone help point me in the right direction? Is there any way to create survival curves for samples that have different ranges?",t2_i8ujh,Survival Curves with Deadlines and Variable Start Dates,discussion,t3_hybuem,0.88,6,Discussion,6,1595816579.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m having trouble finding literature on my particular problem.  &lt;/p&gt;

&lt;p&gt;I&amp;#39;m familiar with Kaplan-Meier survival curves, which measure the probability that failure has not  occurred by time t. Normally, survival curves like this can handle variable start dates just fine, since the time to failure is assumed to follow some constant distribution. &lt;/p&gt;

&lt;p&gt;The system I am modeling has a deadline as well as variable start dates. For example, if the deadline is May 1st, samples could be &amp;#39;born&amp;#39; on March 1st, or April 1st, or any date in  between. However, they cannot &amp;#39;survive&amp;#39; past May 1st. Therefore, the possible range of survival time differs depending on start date. Samples born on April 1st cannot possible survive longer than 30 days, where samples born on March 1st can.&lt;/p&gt;

&lt;p&gt;My first  thought was that I need to create a two dimensional survival &amp;#39;triangle&amp;#39;  with all possible birth dates and time to failures. However, I&amp;#39;ve never heard of this method. Can anyone help point me in the right direction? Is there any way to create survival curves for samples that have different ranges?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hybuem,suspicious_gardener,19,/r/datascience/comments/hybuem/survival_curves_with_deadlines_and_variable_start/,https://www.reddit.com/r/datascience/comments/hybuem/survival_curves_with_deadlines_and_variable_start/,1595787779.0
r/datascience,"Hello, 

Just wondering how you professionals decided on a specific area of data science to pursue... I am caught between so many possibilities.",t2_2ich5u4y,How did you find your domain?,discussion,t3_hyew08,1.0,5,Discussion,5,1595826684.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, &lt;/p&gt;

&lt;p&gt;Just wondering how you professionals decided on a specific area of data science to pursue... I am caught between so many possibilities.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hyew08,Stutoucan12,11,/r/datascience/comments/hyew08/how_did_you_find_your_domain/,https://www.reddit.com/r/datascience/comments/hyew08/how_did_you_find_your_domain/,1595797884.0
r/datascience,I want to save a variable value in a Databricks notebook even when I change clusters or the cluster is detached. What is the best way to achieve this?,t2_l571ioo,Databricks: Save a variable value even when cluster is off,projects,t3_hykzgl,1.0,1,Projects,1,1595850355.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to save a variable value in a Databricks notebook even when I change clusters or the cluster is detached. What is the best way to achieve this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hykzgl,rapp17,4,/r/datascience/comments/hykzgl/databricks_save_a_variable_value_even_when/,https://www.reddit.com/r/datascience/comments/hykzgl/databricks_save_a_variable_value_even_when/,1595821555.0
r/datascience,"I am something of an amateur genealogist. In genealogy, when researching a family history and/or ancestors, as you go further back in time, you sometimes (or eventually) hit what’s called a 'brick wall'. That's the term for when you are unable to proceed any further in determining who somebody was, who their parents were, where or when they were born or died, etc. This is often the result of insufficient record keeping. As you can imagine, as you go further back in time, record keeping becomes more and more of a problem. 

As a result of a brick wall I’ve hit, I’ve decided to try to attack my ‘brick wall’ in something of a different angle - with data science/analytics. I’m not a data scientist. I have some experience with web analytics (implementation, analyzing, and reporting), but certainly not at the level of the posts that I see in this sub. 

My hypothesis is that I can use known social relationships/networks/interactions in a specific region within the U.S. across 70-80 years (multiple generations) to try to answer some of my questions, the main one being, “of this selection of candidates, who is most likely (and to what likelihood) to be this person’s father and mother?”

The data that I have includes (1) the entirety of the Federal Census records for three counties where all family are known to have lived, (2) church birth records, if/when available for churches within those counties, (3) marriage indexes (which do not include birthdates) for many or most marriages within those three counties, and (4) an incomplete, but sizable, collection of tax records.

What I’m thinking is that of the people who interacted with each other, whether that’s as bondsmen in a marriage, witnesses at birth/marriage, people who lived near each other, or people who were in some other way a part of each other’s social network - their parents also interacted with each other in some or similar ways. Friends of family span across multiple generations. Person A is best buds with Person B because, in part, their parents were best buds. I have seen this several times earlier/later in my own family tree, and it’s pretty interesting to see this insight. 

So, I wanted to reach out to ask for any suggestions/advice anybody might have about how I should go about this. I would appreciate if you can comment or PM. I’m willing to learn what I need to, in order to accomplish this task, even if it takes some time.",t2_jsq5y,Genealogy Project,projects,t3_hyjm1l,0.67,1,Projects,1,1595844516.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am something of an amateur genealogist. In genealogy, when researching a family history and/or ancestors, as you go further back in time, you sometimes (or eventually) hit what’s called a &amp;#39;brick wall&amp;#39;. That&amp;#39;s the term for when you are unable to proceed any further in determining who somebody was, who their parents were, where or when they were born or died, etc. This is often the result of insufficient record keeping. As you can imagine, as you go further back in time, record keeping becomes more and more of a problem. &lt;/p&gt;

&lt;p&gt;As a result of a brick wall I’ve hit, I’ve decided to try to attack my ‘brick wall’ in something of a different angle - with data science/analytics. I’m not a data scientist. I have some experience with web analytics (implementation, analyzing, and reporting), but certainly not at the level of the posts that I see in this sub. &lt;/p&gt;

&lt;p&gt;My hypothesis is that I can use known social relationships/networks/interactions in a specific region within the U.S. across 70-80 years (multiple generations) to try to answer some of my questions, the main one being, “of this selection of candidates, who is most likely (and to what likelihood) to be this person’s father and mother?”&lt;/p&gt;

&lt;p&gt;The data that I have includes (1) the entirety of the Federal Census records for three counties where all family are known to have lived, (2) church birth records, if/when available for churches within those counties, (3) marriage indexes (which do not include birthdates) for many or most marriages within those three counties, and (4) an incomplete, but sizable, collection of tax records.&lt;/p&gt;

&lt;p&gt;What I’m thinking is that of the people who interacted with each other, whether that’s as bondsmen in a marriage, witnesses at birth/marriage, people who lived near each other, or people who were in some other way a part of each other’s social network - their parents also interacted with each other in some or similar ways. Friends of family span across multiple generations. Person A is best buds with Person B because, in part, their parents were best buds. I have seen this several times earlier/later in my own family tree, and it’s pretty interesting to see this insight. &lt;/p&gt;

&lt;p&gt;So, I wanted to reach out to ask for any suggestions/advice anybody might have about how I should go about this. I would appreciate if you can comment or PM. I’m willing to learn what I need to, in order to accomplish this task, even if it takes some time.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hyjm1l,heelstoo,0,/r/datascience/comments/hyjm1l/genealogy_project/,https://www.reddit.com/r/datascience/comments/hyjm1l/genealogy_project/,1595815716.0
r/datascience,"I am just starting off my career after getting my degree. I often hear about LinkedIn being an ultimate tool for networking and career development. But did it really give someone a professional advantage in the Data Science field?

I mean is it worth your time regularly updating your profile and looking for connections? 

Also, I’m not sure about this question, but I’m gonna ask it anyway: doesn’t it look too needy when a person has a complete and “shining” profile?

By the way, how did you get your first connections?",t2_2prjmxtg,Is LinkedIn really important for a career in DS?,discussion,t3_hxsdx5,0.95,198,Discussion,198,1595733297.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am just starting off my career after getting my degree. I often hear about LinkedIn being an ultimate tool for networking and career development. But did it really give someone a professional advantage in the Data Science field?&lt;/p&gt;

&lt;p&gt;I mean is it worth your time regularly updating your profile and looking for connections? &lt;/p&gt;

&lt;p&gt;Also, I’m not sure about this question, but I’m gonna ask it anyway: doesn’t it look too needy when a person has a complete and “shining” profile?&lt;/p&gt;

&lt;p&gt;By the way, how did you get your first connections?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxsdx5,zef16,99,/r/datascience/comments/hxsdx5/is_linkedin_really_important_for_a_career_in_ds/,https://www.reddit.com/r/datascience/comments/hxsdx5/is_linkedin_really_important_for_a_career_in_ds/,1595704497.0
r/datascience,"Hi!

Like many, I am intrigued with the concept of “data science.” But then reality strikes, and I remember to be a competent data scientist one must be a statistician, ML engineer, data engineer, and business analyst rolled into 1 human. Not to mention the ever evolving tech stack requiring continuous study. My whole life I’ve always felt equipped to face challenges head on... but this one feels like tsunami. For those of you on the inside (actual data scientists), is this depiction accurate? Also, what have you done to become more secure in your role as a data scientist, despite the “tsunami” level of requirements?

Really appreciate any insight!",t2_cdiejit,Ongoing battle with imposter syndrome in data science,career,t3_hxyzd2,0.97,26,Career,26,1595759028.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi!&lt;/p&gt;

&lt;p&gt;Like many, I am intrigued with the concept of “data science.” But then reality strikes, and I remember to be a competent data scientist one must be a statistician, ML engineer, data engineer, and business analyst rolled into 1 human. Not to mention the ever evolving tech stack requiring continuous study. My whole life I’ve always felt equipped to face challenges head on... but this one feels like tsunami. For those of you on the inside (actual data scientists), is this depiction accurate? Also, what have you done to become more secure in your role as a data scientist, despite the “tsunami” level of requirements?&lt;/p&gt;

&lt;p&gt;Really appreciate any insight!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxyzd2,nocturnalhustler,51,/r/datascience/comments/hxyzd2/ongoing_battle_with_imposter_syndrome_in_data/,https://www.reddit.com/r/datascience/comments/hxyzd2/ongoing_battle_with_imposter_syndrome_in_data/,1595730228.0
r/datascience,,t2_ucebw,What soft skills are invaluable for Data Scientists?,discussion,t3_hye59h,0.4,0,Discussion,0,1595824170.0,,hye59h,Megatheorist,6,/r/datascience/comments/hye59h/what_soft_skills_are_invaluable_for_data/,https://www.reddit.com/r/datascience/comments/hye59h/what_soft_skills_are_invaluable_for_data/,1595795370.0
r/datascience,,t2_70xl2ua6,What’s the difference between Data science and Data engineering?,discussion,t3_hyavp2,0.44,0,Discussion,0,1595813337.0,,hyavp2,DrDockian,3,/r/datascience/comments/hyavp2/whats_the_difference_between_data_science_and/,https://www.reddit.com/r/datascience/comments/hyavp2/whats_the_difference_between_data_science_and/,1595784537.0
r/datascience,"I am trying to parallelize a piece of code over multiple GPU using `torch.multiprocessing.pool`. 

The code below hangs or keeps running forever without any errors when using `set_start_method('spawn', force=True)` in `torch.multiprocessing.pool`.

Code:
```
import numpy as np
import torch
from torch.multiprocessing import Pool, set_start_method

X = np.array([[1, 3, 2, 3], [2, 3, 5, 6], [1, 2, 3, 4]])
X = torch.DoubleTensor(X)

def X_power_func(j):
    X_power = X.cuda()**j
    return X_power

if __name__ == '__main__':
    set_start_method('spawn', force=True)
    with Pool(processes = 2) as p:   # Parallelizing over 2 GPUs
    results = p.map(X_power_func, range(4))

results
```

When I removed `set_start_method('spawn', force=True)`, the code ran properly and gave me the results, but this only works for when I run the code once. When I ran the code again in subsequent runs, I get the error `RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method`.

Any help would really be appreciated!",t2_zmqho4m,PyTorch: How to parallelize over multiple GPU using torch.multiprocessing.pool,discussion,t3_hxlou1,0.94,78,Discussion,78,1595707745.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to parallelize a piece of code over multiple GPU using &lt;code&gt;torch.multiprocessing.pool&lt;/code&gt;. &lt;/p&gt;

&lt;p&gt;The code below hangs or keeps running forever without any errors when using &lt;code&gt;set_start_method(&amp;#39;spawn&amp;#39;, force=True)&lt;/code&gt; in &lt;code&gt;torch.multiprocessing.pool&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Code:
```
import numpy as np
import torch
from torch.multiprocessing import Pool, set_start_method&lt;/p&gt;

&lt;p&gt;X = np.array([[1, 3, 2, 3], [2, 3, 5, 6], [1, 2, 3, 4]])
X = torch.DoubleTensor(X)&lt;/p&gt;

&lt;p&gt;def X_power_func(j):
    X_power = X.cuda()**j
    return X_power&lt;/p&gt;

&lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == &amp;#39;&lt;strong&gt;main&lt;/strong&gt;&amp;#39;:
    set_start_method(&amp;#39;spawn&amp;#39;, force=True)
    with Pool(processes = 2) as p:   # Parallelizing over 2 GPUs
    results = p.map(X_power_func, range(4))&lt;/p&gt;

&lt;p&gt;results
```&lt;/p&gt;

&lt;p&gt;When I removed &lt;code&gt;set_start_method(&amp;#39;spawn&amp;#39;, force=True)&lt;/code&gt;, the code ran properly and gave me the results, but this only works for when I run the code once. When I ran the code again in subsequent runs, I get the error &lt;code&gt;RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the &amp;#39;spawn&amp;#39; start method&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Any help would really be appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxlou1,leockl,20,/r/datascience/comments/hxlou1/pytorch_how_to_parallelize_over_multiple_gpu/,https://www.reddit.com/r/datascience/comments/hxlou1/pytorch_how_to_parallelize_over_multiple_gpu/,1595678945.0
r/datascience,"Hello, I have studied business analytics as my major and quantitative finance as my minor, but am unaware of positions where I could put both skills into use. Surprisingly, this seems to be a rare combination to study. Likewise, the only positions I have found so far have been credit risk modeling positions, which do not sound that interesting to me.

I'm especially interested about equities, and have built an extensive portfolio of projects where I used my data science skills to analyze the stock market and such (no ""predicting stock prices"" kind of stuff). My math skills are not good enough to become a quant I think, and I'm not that interested in derivatives and such. I'm also not sure whether positions like these exist, or are they just hidden jobs that do not have ads on the internet, and would like to hear your opinion on which positions I should look for and where.

If it matters, I'm looking for positions in Europe and not in the US due to a lack of a visa.",t2_g3joc,In which jobs could I put my skills in quantitative finance to use,career,t3_hxuttn,0.78,5,Career,5,1595742156.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I have studied business analytics as my major and quantitative finance as my minor, but am unaware of positions where I could put both skills into use. Surprisingly, this seems to be a rare combination to study. Likewise, the only positions I have found so far have been credit risk modeling positions, which do not sound that interesting to me.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m especially interested about equities, and have built an extensive portfolio of projects where I used my data science skills to analyze the stock market and such (no &amp;quot;predicting stock prices&amp;quot; kind of stuff). My math skills are not good enough to become a quant I think, and I&amp;#39;m not that interested in derivatives and such. I&amp;#39;m also not sure whether positions like these exist, or are they just hidden jobs that do not have ads on the internet, and would like to hear your opinion on which positions I should look for and where.&lt;/p&gt;

&lt;p&gt;If it matters, I&amp;#39;m looking for positions in Europe and not in the US due to a lack of a visa.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxuttn,epskkz,2,/r/datascience/comments/hxuttn/in_which_jobs_could_i_put_my_skills_in/,https://www.reddit.com/r/datascience/comments/hxuttn/in_which_jobs_could_i_put_my_skills_in/,1595713356.0
r/datascience,"Hey team, we're kicking off a women in data science meetup in my hometown, and we're starting to put together a list of possible topics for events - does anyone have any suggestions? We're keen to cover a mix of technical topics and less technical themes / real world applications of DS",t2_gb0gi,Topics for a data science meetup,network,t3_hy225w,0.36,0,Networking,0,1595773520.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey team, we&amp;#39;re kicking off a women in data science meetup in my hometown, and we&amp;#39;re starting to put together a list of possible topics for events - does anyone have any suggestions? We&amp;#39;re keen to cover a mix of technical topics and less technical themes / real world applications of DS&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hy225w,gavch298,1,/r/datascience/comments/hy225w/topics_for_a_data_science_meetup/,https://www.reddit.com/r/datascience/comments/hy225w/topics_for_a_data_science_meetup/,1595744720.0
r/datascience,I am going to be starting my first data science job shortly. Any advice?,t2_a8bujs3,Any advice on how to plan your first 90 days in your first data science position?,career,t3_hxe3qn,0.9,73,Career,73,1595668838.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am going to be starting my first data science job shortly. Any advice?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxe3qn,immunobio,48,/r/datascience/comments/hxe3qn/any_advice_on_how_to_plan_your_first_90_days_in/,https://www.reddit.com/r/datascience/comments/hxe3qn/any_advice_on_how_to_plan_your_first_90_days_in/,1595640038.0
r/datascience,"How would you compare these platforms in terms of usability, pricing, scaling, ML ops capabilities? Have you heard any good or bad anecdotes about them?

Please note we are acquiring software for data analyst team that are not your expert coders (the ones that go for Databricks). This is more for people who want something out of the box, easy to use but still with some coding ability.

P.S. SAS not being open source scares me a bit in terms of long run pricing power",t2_duwi1h3,"How does SAS compare to DataRobot, H2O, KNIME, RapidMiner?",discussion,t3_hxwzx1,0.67,1,Discussion,1,1595750536.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How would you compare these platforms in terms of usability, pricing, scaling, ML ops capabilities? Have you heard any good or bad anecdotes about them?&lt;/p&gt;

&lt;p&gt;Please note we are acquiring software for data analyst team that are not your expert coders (the ones that go for Databricks). This is more for people who want something out of the box, easy to use but still with some coding ability.&lt;/p&gt;

&lt;p&gt;P.S. SAS not being open source scares me a bit in terms of long run pricing power&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxwzx1,Electric_pokemon,8,/r/datascience/comments/hxwzx1/how_does_sas_compare_to_datarobot_h2o_knime/,https://www.reddit.com/r/datascience/comments/hxwzx1/how_does_sas_compare_to_datarobot_h2o_knime/,1595721736.0
r/datascience,"I am a market analyst and really enjoy the technical/data aspect of my job. This includes creating dashboards, troubleshooting, cleaning data, and using BI tools. I find that my critical thinking skills are really challenged when it comes to data analysis and insight generation.

I'd like to keep working with data, but don't think I have the qualifications to take on engineering or developer roles.

Are there any data-driven jobs that require minimal data analysis?",t2_1ogb1rrl,Are there data-driven jobs that require minimal data analysis?,,t3_hxrm3s,0.43,0,Job Search,0,1595730652.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a market analyst and really enjoy the technical/data aspect of my job. This includes creating dashboards, troubleshooting, cleaning data, and using BI tools. I find that my critical thinking skills are really challenged when it comes to data analysis and insight generation.&lt;/p&gt;

&lt;p&gt;I&amp;#39;d like to keep working with data, but don&amp;#39;t think I have the qualifications to take on engineering or developer roles.&lt;/p&gt;

&lt;p&gt;Are there any data-driven jobs that require minimal data analysis?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxrm3s,Anxious_Effort,13,/r/datascience/comments/hxrm3s/are_there_datadriven_jobs_that_require_minimal/,https://www.reddit.com/r/datascience/comments/hxrm3s/are_there_datadriven_jobs_that_require_minimal/,1595701852.0
r/datascience,"There are currently two courses available on Coursera for AWS and Azure. I would really appreciate some advice as to which one I should learn first.

I have seen Azure pop up as a requirement for many Data Science positions lately but I am not entirely sure how a company decides which platform to use and whether learning one offers a more comprehensive advantage than the other in terms of analytical capabilities, ease of use, etc.",t2_55x8eunu,"Azure vs. AWS, Which one to learn?",education,t3_hxuohq,0.25,0,Education,0,1595741609.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;There are currently two courses available on Coursera for AWS and Azure. I would really appreciate some advice as to which one I should learn first.&lt;/p&gt;

&lt;p&gt;I have seen Azure pop up as a requirement for many Data Science positions lately but I am not entirely sure how a company decides which platform to use and whether learning one offers a more comprehensive advantage than the other in terms of analytical capabilities, ease of use, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxuohq,payamv2,5,/r/datascience/comments/hxuohq/azure_vs_aws_which_one_to_learn/,https://www.reddit.com/r/datascience/comments/hxuohq/azure_vs_aws_which_one_to_learn/,1595712809.0
r/datascience,"I've been referring to an article on feature selection and need help in understanding how an ROC curve has been plotted.

Dataset used: Iris

One of the ways for feature selection, mentioned in the article is :    Visual ways to rank features

The example below plots the ROC curve of various features.

\##########################################

    from sklearn.datasets import load_iris
    import matplotlib.pyplot as plt
    from sklearn.metrics import auc
    import numpy as np# loading dataset
    data = load_iris()
    X, y = data.data, data.targety_ = y == 2plt.figure(figsize=(13,7))
    for col in range(X.shape[1]):
        tpr,fpr = [],[]
        for threshold in np.linspace(min(X[:,col]),max(X[:,col]),100):
            detP = X[:,col] &lt; threshold
            tpr.append(sum(detP &amp; y_)/sum(y_))# TP/P, aka recall
            fpr.append(sum(detP &amp; (~y_))/sum((~y_)))# FP/N
            
        if auc(fpr,tpr) &lt; .5:
            aux = tpr
            tpr = fpr
            fpr = aux
        plt.plot(fpr,tpr,label=data.feature_names[col] + ', auc = '\
            + str(np.round(auc(fpr,tpr),decimals=3)))plt.title('ROC curve - Iris features')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

\##########################################

I want to understand this bit:

    for threshold in np.linspace(min(X[:,col]),max(X[:,col]),100):
        detP = X[:,col] &lt; threshold
        tpr.append(sum(detP &amp; y_)/sum(y_))         # TP/P, aka recall
        fpr.append(sum(detP &amp; (~y_))/sum((~y_)))   # FP/N

&amp;#x200B;

How can one calculate True Positivity Rate (TPR) &amp; FPR by checking if values of a discrete variable (features) are above a threshold which has been calculated by dividing the range (Max-Min) of the feature in 100 equidistant points?

Here is the resultant ROC curve

https://i.postimg.cc/KYgrPJMR/ROC-Curve-Iris-features.png",t2_osdur,Iris dataset - Plotting ROC curve for feature ranking / feature selection and interpreting it,discussion,t3_hxqtz0,0.4,0,Discussion,0,1595727927.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been referring to an article on feature selection and need help in understanding how an ROC curve has been plotted.&lt;/p&gt;

&lt;p&gt;Dataset used: Iris&lt;/p&gt;

&lt;p&gt;One of the ways for feature selection, mentioned in the article is :    Visual ways to rank features&lt;/p&gt;

&lt;p&gt;The example below plots the ROC curve of various features.&lt;/p&gt;

&lt;p&gt;##########################################&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from sklearn.datasets import load_iris
import matplotlib.pyplot as plt
from sklearn.metrics import auc
import numpy as np# loading dataset
data = load_iris()
X, y = data.data, data.targety_ = y == 2plt.figure(figsize=(13,7))
for col in range(X.shape[1]):
    tpr,fpr = [],[]
    for threshold in np.linspace(min(X[:,col]),max(X[:,col]),100):
        detP = X[:,col] &amp;lt; threshold
        tpr.append(sum(detP &amp;amp; y_)/sum(y_))# TP/P, aka recall
        fpr.append(sum(detP &amp;amp; (~y_))/sum((~y_)))# FP/N

    if auc(fpr,tpr) &amp;lt; .5:
        aux = tpr
        tpr = fpr
        fpr = aux
    plt.plot(fpr,tpr,label=data.feature_names[col] + &amp;#39;, auc = &amp;#39;\
        + str(np.round(auc(fpr,tpr),decimals=3)))plt.title(&amp;#39;ROC curve - Iris features&amp;#39;)
plt.xlabel(&amp;#39;False Positive Rate&amp;#39;)
plt.ylabel(&amp;#39;True Positive Rate&amp;#39;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;##########################################&lt;/p&gt;

&lt;p&gt;I want to understand this bit:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for threshold in np.linspace(min(X[:,col]),max(X[:,col]),100):
    detP = X[:,col] &amp;lt; threshold
    tpr.append(sum(detP &amp;amp; y_)/sum(y_))         # TP/P, aka recall
    fpr.append(sum(detP &amp;amp; (~y_))/sum((~y_)))   # FP/N
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;How can one calculate True Positivity Rate (TPR) &amp;amp; FPR by checking if values of a discrete variable (features) are above a threshold which has been calculated by dividing the range (Max-Min) of the feature in 100 equidistant points?&lt;/p&gt;

&lt;p&gt;Here is the resultant ROC curve&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://i.postimg.cc/KYgrPJMR/ROC-Curve-Iris-features.png""&gt;https://i.postimg.cc/KYgrPJMR/ROC-Curve-Iris-features.png&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxqtz0,rahul_ahuja,3,/r/datascience/comments/hxqtz0/iris_dataset_plotting_roc_curve_for_feature/,https://www.reddit.com/r/datascience/comments/hxqtz0/iris_dataset_plotting_roc_curve_for_feature/,1595699127.0
r/datascience,"I'm working for a historical museum this summer. Since I'm a stats major, my boss said I could do any data science/stats project I can think of. Would really like to do something interesting/challenging/beneficial to the museum but I don't know where to start. Maybe something related to fundraising or marketing/visitor outreach? Would b super grateful for any suggestions. Decently experienced with R. Thanks!",t2_y46sv,Help! Can't think of project idea for museum,projects,t3_hx6tdl,0.86,51,Projects,51,1595642970.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working for a historical museum this summer. Since I&amp;#39;m a stats major, my boss said I could do any data science/stats project I can think of. Would really like to do something interesting/challenging/beneficial to the museum but I don&amp;#39;t know where to start. Maybe something related to fundraising or marketing/visitor outreach? Would b super grateful for any suggestions. Decently experienced with R. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hx6tdl,JBizzle07,23,/r/datascience/comments/hx6tdl/help_cant_think_of_project_idea_for_museum/,https://www.reddit.com/r/datascience/comments/hx6tdl/help_cant_think_of_project_idea_for_museum/,1595614170.0
r/datascience,,t2_3hn41pel,Analysis utilities,projects,t3_hxhunn,0.81,6,Projects,6,1595685806.0,,hxhunn,idan_huji,0,/r/datascience/comments/hxhunn/analysis_utilities/,/r/Python/comments/hxhsdp/analysis_utilities/,1595657006.0
r/datascience,"Hi there, I'm working as an Optometrist. I'm wondering if there are any Optometry related projects?

I recently was playing around with contact lens sales data to see what my fitting habits were like over the year. I want to share this project but the original data is private. As you can tell, I'm new to the field.",t2_2y6bv37n,Optometry related project ideas?,projects,t3_hxifkv,1.0,4,Projects,4,1595689009.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there, I&amp;#39;m working as an Optometrist. I&amp;#39;m wondering if there are any Optometry related projects?&lt;/p&gt;

&lt;p&gt;I recently was playing around with contact lens sales data to see what my fitting habits were like over the year. I want to share this project but the original data is private. As you can tell, I&amp;#39;m new to the field.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxifkv,BlackDefence,2,/r/datascience/comments/hxifkv/optometry_related_project_ideas/,https://www.reddit.com/r/datascience/comments/hxifkv/optometry_related_project_ideas/,1595660209.0
r/datascience,"Which is more appropriate? Windows or Linux?

Edit: Thanks for everyone's input - looks like it's a dual boot.  I have heard Nvidia GPUs don't play well with Linux.  Does that mean I should go with an AMD GPU?",t2_k0wt9,Building a data science workstation - what are pros and cons between Linux and Windows?,,t3_hxcj04,0.82,13,,13,1595662660.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Which is more appropriate? Windows or Linux?&lt;/p&gt;

&lt;p&gt;Edit: Thanks for everyone&amp;#39;s input - looks like it&amp;#39;s a dual boot.  I have heard Nvidia GPUs don&amp;#39;t play well with Linux.  Does that mean I should go with an AMD GPU?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxcj04,kw_hipster,44,/r/datascience/comments/hxcj04/building_a_data_science_workstation_what_are_pros/,https://www.reddit.com/r/datascience/comments/hxcj04/building_a_data_science_workstation_what_are_pros/,1595633860.0
r/datascience,My current options are Pandas and Jupyter Notebook.,t2_syghp,What are the best open source projects related to Data Science to contribute?,discussion,t3_hxo6uk,0.44,0,Discussion,0,1595718409.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My current options are Pandas and Jupyter Notebook.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxo6uk,cloud1997,2,/r/datascience/comments/hxo6uk/what_are_the_best_open_source_projects_related_to/,https://www.reddit.com/r/datascience/comments/hxo6uk/what_are_the_best_open_source_projects_related_to/,1595689609.0
r/datascience,"Planning to buy a new Laptop within 70-80k INR Max

Required Specs:
i7 9th or 10th gen
Min 8gb Ram but 16gb preferred 
Good GPU (not much knowledge about GPU)

Will be used for Machine Learning / Deep Learning / Artificial Intelligence

Please suggest!",t2_10xc56,Lazy on Laptops,discussion,t3_hxqzxl,0.25,0,Discussion,0,1595728509.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Planning to buy a new Laptop within 70-80k INR Max&lt;/p&gt;

&lt;p&gt;Required Specs:
i7 9th or 10th gen
Min 8gb Ram but 16gb preferred 
Good GPU (not much knowledge about GPU)&lt;/p&gt;

&lt;p&gt;Will be used for Machine Learning / Deep Learning / Artificial Intelligence&lt;/p&gt;

&lt;p&gt;Please suggest!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxqzxl,arnabdafadar,6,/r/datascience/comments/hxqzxl/lazy_on_laptops/,https://www.reddit.com/r/datascience/comments/hxqzxl/lazy_on_laptops/,1595699709.0
r/datascience,"I’d like to see a debate on this as I’ve heard both phrases used, but without much context to back them up.  What do you think, and why?

Edit: There have been lots of good ideas and suggestions in this threads, thank you all for your input! I’m still leaning towards “no data is better than bad data”, but less strongly than I was before - thanks to all who took the time to write!

[View Poll](https://www.reddit.com/poll/hwx7p1)",t2_oum4y,"Is any data is better than no data, or is no data better than bad data?",discussion,t3_hwx7p1,0.87,126,Discussion,126,1595603051.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’d like to see a debate on this as I’ve heard both phrases used, but without much context to back them up.  What do you think, and why?&lt;/p&gt;

&lt;p&gt;Edit: There have been lots of good ideas and suggestions in this threads, thank you all for your input! I’m still leaning towards “no data is better than bad data”, but less strongly than I was before - thanks to all who took the time to write!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.reddit.com/poll/hwx7p1""&gt;View Poll&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hwx7p1,_-Mia-_,186,/r/datascience/comments/hwx7p1/is_any_data_is_better_than_no_data_or_is_no_data/,https://www.reddit.com/r/datascience/comments/hwx7p1/is_any_data_is_better_than_no_data_or_is_no_data/,1595574251.0
r/datascience,,t2_zfavb,Paper: Bringing NHS data analysis into the 21st century,career,t3_hxjut9,0.67,1,Career,1,1595697334.0,,hxjut9,petenolan,1,/r/datascience/comments/hxjut9/paper_bringing_nhs_data_analysis_into_the_21st/,https://journals.sagepub.com/doi/full/10.1177/0141076820930666,1595668534.0
r/datascience,,t2_3ucsssgu,Person standing at varying distance from camera dataset [P] [R],discussion,t3_hxi9ce,0.67,1,Discussion,1,1595688049.0,,hxi9ce,Shinigami0108,0,/r/datascience/comments/hxi9ce/person_standing_at_varying_distance_from_camera/,/r/MachineLearning/comments/hxi930/person_standing_at_varying_distance_from_camera/,1595659249.0
r/datascience,"Sometime soon I'm going to flesh out my personal GitHub with the school projects and work projects I've done, for my own sake and for the sake of job applications. 

However, I want to make sure I know how intellectual property stuff works. I know that my company owns the work I do on company time or company machinery. Does that mean I can't put that code in a GitHub (even if it is super basic cleaning and analysis)? Also, if I contribute ""company code"" to a personal GitHub, does that somehow make the whole GitHub company property?

Anyone that has experience with this in the past, please help. We don't have a company GitHub because I'm the only person who codes and I'm still barely competent and haven't figured out GitHub yet. 

Obviously, I know to avoid putting in passwords or any proprietary information or datasets, and PPI.",t2_161wju,GitHub and IP.,,t3_hxaprf,0.7,5,,5,1595655780.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sometime soon I&amp;#39;m going to flesh out my personal GitHub with the school projects and work projects I&amp;#39;ve done, for my own sake and for the sake of job applications. &lt;/p&gt;

&lt;p&gt;However, I want to make sure I know how intellectual property stuff works. I know that my company owns the work I do on company time or company machinery. Does that mean I can&amp;#39;t put that code in a GitHub (even if it is super basic cleaning and analysis)? Also, if I contribute &amp;quot;company code&amp;quot; to a personal GitHub, does that somehow make the whole GitHub company property?&lt;/p&gt;

&lt;p&gt;Anyone that has experience with this in the past, please help. We don&amp;#39;t have a company GitHub because I&amp;#39;m the only person who codes and I&amp;#39;m still barely competent and haven&amp;#39;t figured out GitHub yet. &lt;/p&gt;

&lt;p&gt;Obviously, I know to avoid putting in passwords or any proprietary information or datasets, and PPI.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hxaprf,senorgraves,18,/r/datascience/comments/hxaprf/github_and_ip/,https://www.reddit.com/r/datascience/comments/hxaprf/github_and_ip/,1595626980.0
r/datascience,,t2_ucebw,What's the most interesting data set you've ever used?,discussion,t3_hwiir9,0.97,285,Discussion,285,1595549806.0,,hwiir9,Megatheorist,173,/r/datascience/comments/hwiir9/whats_the_most_interesting_data_set_youve_ever/,https://www.reddit.com/r/datascience/comments/hwiir9/whats_the_most_interesting_data_set_youve_ever/,1595521006.0
r/datascience,"I have a small dataset (200 samples and 22 features) and I am trying to solve a binary classification problem. All my features are continuous and lie on a scale of 0-1.

I computed the correlation among my features using the [pandas dataframe correlation method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html). Then, I found all the pairs of features that had a correlation of more than 0.95, and I was left with about 20 pairs.

Now my question is, from these pairs, how do I decide which features to drop?

There is a [same question on Stackoverflow](https://stackoverflow.com/questions/29294983/how-to-calculate-correlation-between-all-columns-and-remove-highly-correlated-on) and the top voted answer as well as the [approach shared by Chris Albon in his blog post](https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/) (also the second most voted answer in that SO post) drops one of the highly correlated features randomly. 

I don't feel confident about randomly dropping features without taking into account the correlation of the features with other features. 

Is there a more convincing/reliable way on how to decide which of the 2 features to drop?",t2_nis5p,How to remove correlated features?,discussion,t3_hx04uf,0.82,7,Discussion,7,1595619146.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a small dataset (200 samples and 22 features) and I am trying to solve a binary classification problem. All my features are continuous and lie on a scale of 0-1.&lt;/p&gt;

&lt;p&gt;I computed the correlation among my features using the &lt;a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html""&gt;pandas dataframe correlation method&lt;/a&gt;. Then, I found all the pairs of features that had a correlation of more than 0.95, and I was left with about 20 pairs.&lt;/p&gt;

&lt;p&gt;Now my question is, from these pairs, how do I decide which features to drop?&lt;/p&gt;

&lt;p&gt;There is a &lt;a href=""https://stackoverflow.com/questions/29294983/how-to-calculate-correlation-between-all-columns-and-remove-highly-correlated-on""&gt;same question on Stackoverflow&lt;/a&gt; and the top voted answer as well as the &lt;a href=""https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/""&gt;approach shared by Chris Albon in his blog post&lt;/a&gt; (also the second most voted answer in that SO post) drops one of the highly correlated features randomly. &lt;/p&gt;

&lt;p&gt;I don&amp;#39;t feel confident about randomly dropping features without taking into account the correlation of the features with other features. &lt;/p&gt;

&lt;p&gt;Is there a more convincing/reliable way on how to decide which of the 2 features to drop?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hx04uf,iCHAIT,28,/r/datascience/comments/hx04uf/how_to_remove_correlated_features/,https://www.reddit.com/r/datascience/comments/hx04uf/how_to_remove_correlated_features/,1595590346.0
r/datascience,"I've been using xgboost for a while now, which does the job just fine. It has supporting packages like [xgbfi](https://github.com/Far0n/xgbfi) and [xgboostExplainer](https://github.com/AppliedDataSciencePartners/xgboostExplainer) that give insight into what the model is doing. I was wondering what other packages may exist for other platforms like lightgbm or catboost.",t2_i8ujh,Which Gradient Boosting Platforms Have the Best 'Explainer' Packages/Functions?,discussion,t3_hx0us5,0.72,3,Discussion,3,1595622386.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been using xgboost for a while now, which does the job just fine. It has supporting packages like &lt;a href=""https://github.com/Far0n/xgbfi""&gt;xgbfi&lt;/a&gt; and &lt;a href=""https://github.com/AppliedDataSciencePartners/xgboostExplainer""&gt;xgboostExplainer&lt;/a&gt; that give insight into what the model is doing. I was wondering what other packages may exist for other platforms like lightgbm or catboost.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hx0us5,suspicious_gardener,9,/r/datascience/comments/hx0us5/which_gradient_boosting_platforms_have_the_best/,https://www.reddit.com/r/datascience/comments/hx0us5/which_gradient_boosting_platforms_have_the_best/,1595593586.0
r/datascience,"So I am a huge football statistics nerd and I somehow got the opportunity to interview the head of football data at the NFL. Super exciting! But I am really struggling to think of good data related questions for him. I think it's the equivalent of stage fright for an actor, but it's not good. Any help overcoming this fear or thinking of interesting questions would be dope.",t2_4d4vn7le,Pre-Meeting Idol Panic,discussion,t3_hx2h8k,0.5,0,Discussion,0,1595628755.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I am a huge football statistics nerd and I somehow got the opportunity to interview the head of football data at the NFL. Super exciting! But I am really struggling to think of good data related questions for him. I think it&amp;#39;s the equivalent of stage fright for an actor, but it&amp;#39;s not good. Any help overcoming this fear or thinking of interesting questions would be dope.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hx2h8k,em-lead-2021,5,/r/datascience/comments/hx2h8k/premeeting_idol_panic/,https://www.reddit.com/r/datascience/comments/hx2h8k/premeeting_idol_panic/,1595599955.0
r/datascience,"I’m thinking in a corporate and/or corporate marketing context. It seems like analytics is more interpreting the data and data science is actually building out the databases. Is that correct? Analytics is more sales and marketing and data science is more engineering?

But then I see some “analytics” positions seem to require both data interpretation and coding languages and the like. 

Are these skills equal in value but different? Or is data science more valuable than the other? Is the person who contains both skill sets rare?",t2_1clo5jzo,What’s the difference between data science and “data analytics”?,discussion,t3_hw6nwh,0.96,226,Discussion,226,1595496597.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m thinking in a corporate and/or corporate marketing context. It seems like analytics is more interpreting the data and data science is actually building out the databases. Is that correct? Analytics is more sales and marketing and data science is more engineering?&lt;/p&gt;

&lt;p&gt;But then I see some “analytics” positions seem to require both data interpretation and coding languages and the like. &lt;/p&gt;

&lt;p&gt;Are these skills equal in value but different? Or is data science more valuable than the other? Is the person who contains both skill sets rare?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hw6nwh,SeveralSpace,111,/r/datascience/comments/hw6nwh/whats_the_difference_between_data_science_and/,https://www.reddit.com/r/datascience/comments/hw6nwh/whats_the_difference_between_data_science_and/,1595467797.0
r/datascience,"The company *(anonymous for now)* said I would be helping them to answer many questions, but primarily this one:

**- How are people engaging with us?**

They have multiple locations across the US and thousands of people interacting with them weekly.

I'd LOVE some advice from people who have set up a data science process at a company before, or have any general tips!",t2_owa77ti,"Has anyone here created a data science process for a company before? I just accepted my first job as a Data Analyst and the company (details inside) admits they don't know what to do with data science, but the goal is to learn how people are engaging with them.",discussion,t3_hwndtq,1.0,8,Discussion,8,1595564762.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The company &lt;em&gt;(anonymous for now)&lt;/em&gt; said I would be helping them to answer many questions, but primarily this one:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;- How are people engaging with us?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;They have multiple locations across the US and thousands of people interacting with them weekly.&lt;/p&gt;

&lt;p&gt;I&amp;#39;d LOVE some advice from people who have set up a data science process at a company before, or have any general tips!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hwndtq,PhazonLink215,31,/r/datascience/comments/hwndtq/has_anyone_here_created_a_data_science_process/,https://www.reddit.com/r/datascience/comments/hwndtq/has_anyone_here_created_a_data_science_process/,1595535962.0
r/datascience,"My neck and shoulder are killing me from the long hours staring at a computer screen. Part of this is my less than ideal work from home space. So please tell me, what items do you have in your workspace to help keep away the tech neck? My heating pad can only do so much.",t2_1o0ku8e5,How do you stay comfortable at work all day?,fun,t3_hwello,0.75,6,Fun/Trivia,6,1595535323.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My neck and shoulder are killing me from the long hours staring at a computer screen. Part of this is my less than ideal work from home space. So please tell me, what items do you have in your workspace to help keep away the tech neck? My heating pad can only do so much.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hwello,100proofattitudepowe,22,/r/datascience/comments/hwello/how_do_you_stay_comfortable_at_work_all_day/,https://www.reddit.com/r/datascience/comments/hwello/how_do_you_stay_comfortable_at_work_all_day/,1595506523.0
r/datascience,"Hello everyone,

Im trying to do a project about Churn prediction in the Energy Sector. I recently finished my masters in Electrical and Computers Engineering wiht major in Automation and minor in Renewable Energy and Automotive Electronic.

Can someone help me find a good dataset to explore? The one that i found isn't very complete and it misses some features that i found interesting to explore.

If possible, can you suggest articles/literature to read? The material that i found doesnt focus in the energy sector and its 
particularities, it only focus in the machine learning part to apply different methods to predict if there is churn or not.

Thank you for your attention, I hope you can help me.",t2_6jg4a,Churn prediction in the Energy Sector,projects,t3_hwcsxx,1.0,8,Projects,8,1595525991.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;Im trying to do a project about Churn prediction in the Energy Sector. I recently finished my masters in Electrical and Computers Engineering wiht major in Automation and minor in Renewable Energy and Automotive Electronic.&lt;/p&gt;

&lt;p&gt;Can someone help me find a good dataset to explore? The one that i found isn&amp;#39;t very complete and it misses some features that i found interesting to explore.&lt;/p&gt;

&lt;p&gt;If possible, can you suggest articles/literature to read? The material that i found doesnt focus in the energy sector and its 
particularities, it only focus in the machine learning part to apply different methods to predict if there is churn or not.&lt;/p&gt;

&lt;p&gt;Thank you for your attention, I hope you can help me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hwcsxx,D1yzz,3,/r/datascience/comments/hwcsxx/churn_prediction_in_the_energy_sector/,https://www.reddit.com/r/datascience/comments/hwcsxx/churn_prediction_in_the_energy_sector/,1595497191.0
r/datascience,"I am looking for software to use for monitoring multiple individual data sources, which I would like to display in tables and graphs with the ability to log errors.

an example would be :

User a produces 5 different products at a varied number of each per day. If for some reason the person cannot produce a product an alarm or warning should be raised. 

I would like to be able to generate graphs indicating various metrics ranging from upper and lower bounds as well as cumulative production over a desired amount of time.

Any idea where to start looking?",t2_6nztgdl,Data monitoring platform,projects,t3_hweepm,1.0,6,Projects,6,1595534510.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am looking for software to use for monitoring multiple individual data sources, which I would like to display in tables and graphs with the ability to log errors.&lt;/p&gt;

&lt;p&gt;an example would be :&lt;/p&gt;

&lt;p&gt;User a produces 5 different products at a varied number of each per day. If for some reason the person cannot produce a product an alarm or warning should be raised. &lt;/p&gt;

&lt;p&gt;I would like to be able to generate graphs indicating various metrics ranging from upper and lower bounds as well as cumulative production over a desired amount of time.&lt;/p&gt;

&lt;p&gt;Any idea where to start looking?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hweepm,Challa1201,3,/r/datascience/comments/hweepm/data_monitoring_platform/,https://www.reddit.com/r/datascience/comments/hweepm/data_monitoring_platform/,1595505710.0
r/datascience,"I am a CS phd doing a data science internship for a big tech company and have a question on survival analysis. For those who have used survival analysis at a company before, how exactly do you report results? When I read papers, the authors will end up spending a lot of time on c-index and less about the predicting the remaining days until an event (churn for my case) for an individual subject. In industry, I feel like c-index doesn't add too much value, but having the ability to predict individual durations does.",t2_2wut64kh,Survival analysis in industry,discussion,t3_hvtw5a,0.96,78,Discussion,78,1595453751.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a CS phd doing a data science internship for a big tech company and have a question on survival analysis. For those who have used survival analysis at a company before, how exactly do you report results? When I read papers, the authors will end up spending a lot of time on c-index and less about the predicting the remaining days until an event (churn for my case) for an individual subject. In industry, I feel like c-index doesn&amp;#39;t add too much value, but having the ability to predict individual durations does.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvtw5a,SmartSpray,41,/r/datascience/comments/hvtw5a/survival_analysis_in_industry/,https://www.reddit.com/r/datascience/comments/hvtw5a/survival_analysis_in_industry/,1595424951.0
r/datascience,I just finished a coding interview for a data science position and am left feeling like I did terrible. This interview was using python and answering two algorithm questions. I couldn't use any built-in libraries and all implementation had to be from scratch. After I was expected to give Big O and  Big Theta and optimize. It felt like more of a software engineering interview than data science. I haven't done a coding interview in years is this the normal for data science positions now?,t2_1n8owavv,Big O and Big Theta During Interview,career,t3_hw2kd1,0.87,16,Career,16,1595482077.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just finished a coding interview for a data science position and am left feeling like I did terrible. This interview was using python and answering two algorithm questions. I couldn&amp;#39;t use any built-in libraries and all implementation had to be from scratch. After I was expected to give Big O and  Big Theta and optimize. It felt like more of a software engineering interview than data science. I haven&amp;#39;t done a coding interview in years is this the normal for data science positions now?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hw2kd1,DS_throwitaway,33,/r/datascience/comments/hw2kd1/big_o_and_big_theta_during_interview/,https://www.reddit.com/r/datascience/comments/hw2kd1/big_o_and_big_theta_during_interview/,1595453277.0
r/datascience,"I've accepted a FT offer at a big bank, and the team I'll be in develops models to analyze probability of default, loss given default etc. for CRE and commercial loans. Since my background is in engineering, I figured I'd work on developing my own simplified credit risk model so I don't show up and go full retard. I'm understand the concepts behind most credit risk models but mostly theoretically and I think at a pretty superficial level. I'm looking to get my hands dirty.

Anyone aware of any databases containing CRE or commercial loan-level data? If not, possibly consumer or small business loan data? I'm willing to pay a reasonable consumer price if the data is good. I know this may be a long shot since lenders usually keep this this type of stuff in house, but any help would be appreciated.",t2_22d5w1r0,Are there any loan-level datasets with default information available for commercial loans?,projects,t3_hw7ofv,1.0,6,Projects,6,1595500659.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve accepted a FT offer at a big bank, and the team I&amp;#39;ll be in develops models to analyze probability of default, loss given default etc. for CRE and commercial loans. Since my background is in engineering, I figured I&amp;#39;d work on developing my own simplified credit risk model so I don&amp;#39;t show up and go full retard. I&amp;#39;m understand the concepts behind most credit risk models but mostly theoretically and I think at a pretty superficial level. I&amp;#39;m looking to get my hands dirty.&lt;/p&gt;

&lt;p&gt;Anyone aware of any databases containing CRE or commercial loan-level data? If not, possibly consumer or small business loan data? I&amp;#39;m willing to pay a reasonable consumer price if the data is good. I know this may be a long shot since lenders usually keep this this type of stuff in house, but any help would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hw7ofv,toastyavocadoes,5,/r/datascience/comments/hw7ofv/are_there_any_loanlevel_datasets_with_default/,https://www.reddit.com/r/datascience/comments/hw7ofv/are_there_any_loanlevel_datasets_with_default/,1595471859.0
r/datascience,"When Implementing custom loss function how to make it invariant to the `batch size`. For example lets say `dice loss` is being implemented. The formula does not clarify how to deal with the `batch size`. It is worth noting that according to this formula, the value of `loss` will increase if the `batch size` is increased. The obvious intuition would be to normalize the `loss` value using `batch size`. I have two question in this context.

1. Is it theoretically valid to normalize the `loss` using the `batch size`?
2. How to normalize? 

* For example, In case of image the `tensor` at hand is `4D`. The `dice score` / `loss` can be calculated for _each image_ and _each class_ resulting into a `2D` tensor.

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Now the aggregated `loss` can be calculated as the sum of all elements in the `2D` tensor divided by `batch size`.

* Alternatively, we can ignore the `batch size` from the beginning and generate per class `loss` in a `1D` `tensor`. Finally sum the elements and divide by `batch size` to get the aggregated `loss` value.

**Is there any fundamental difference between these two approaches? Which one is correct (if any)?**

---
This question has been posted with formulas on [Data Science Stack Exchange](https://datascience.stackexchange.com/q/78151/76199).

A related discussion in [GitHub](https://github.com/NifTK/NiftyNet/issues/22)",t2_ltvm6,Implementation of custom loss function invariant to batch size,discussion,t3_hwbcba,1.0,2,Discussion,2,1595517715.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When Implementing custom loss function how to make it invariant to the &lt;code&gt;batch size&lt;/code&gt;. For example lets say &lt;code&gt;dice loss&lt;/code&gt; is being implemented. The formula does not clarify how to deal with the &lt;code&gt;batch size&lt;/code&gt;. It is worth noting that according to this formula, the value of &lt;code&gt;loss&lt;/code&gt; will increase if the &lt;code&gt;batch size&lt;/code&gt; is increased. The obvious intuition would be to normalize the &lt;code&gt;loss&lt;/code&gt; value using &lt;code&gt;batch size&lt;/code&gt;. I have two question in this context.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Is it theoretically valid to normalize the &lt;code&gt;loss&lt;/code&gt; using the &lt;code&gt;batch size&lt;/code&gt;?&lt;/li&gt;
&lt;li&gt;How to normalize? &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;For example, In case of image the &lt;code&gt;tensor&lt;/code&gt; at hand is &lt;code&gt;4D&lt;/code&gt;. The &lt;code&gt;dice score&lt;/code&gt; / &lt;code&gt;loss&lt;/code&gt; can be calculated for &lt;em&gt;each image&lt;/em&gt; and &lt;em&gt;each class&lt;/em&gt; resulting into a &lt;code&gt;2D&lt;/code&gt; tensor.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Now the aggregated &lt;code&gt;loss&lt;/code&gt; can be calculated as the sum of all elements in the &lt;code&gt;2D&lt;/code&gt; tensor divided by &lt;code&gt;batch size&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Alternatively, we can ignore the &lt;code&gt;batch size&lt;/code&gt; from the beginning and generate per class &lt;code&gt;loss&lt;/code&gt; in a &lt;code&gt;1D&lt;/code&gt; &lt;code&gt;tensor&lt;/code&gt;. Finally sum the elements and divide by &lt;code&gt;batch size&lt;/code&gt; to get the aggregated &lt;code&gt;loss&lt;/code&gt; value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Is there any fundamental difference between these two approaches? Which one is correct (if any)?&lt;/strong&gt;&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;This question has been posted with formulas on &lt;a href=""https://datascience.stackexchange.com/q/78151/76199""&gt;Data Science Stack Exchange&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A related discussion in &lt;a href=""https://github.com/NifTK/NiftyNet/issues/22""&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hwbcba,digital-idiot,7,/r/datascience/comments/hwbcba/implementation_of_custom_loss_function_invariant/,https://www.reddit.com/r/datascience/comments/hwbcba/implementation_of_custom_loss_function_invariant/,1595488915.0
r/datascience,"Hello everyone! 

Today I was on a meetup and the speaker mentioned he used Random Forest Classifier with Sigmoid... And I don't know how it works! Do you know any source or paper that references it and uses this?

Is it used? How is that it might be better than the normal rf? 

Thanks.",t2_11ggjx7,Random Forest + Sigmoid?,discussion,t3_hw5dyp,1.0,3,Discussion,3,1595491702.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone! &lt;/p&gt;

&lt;p&gt;Today I was on a meetup and the speaker mentioned he used Random Forest Classifier with Sigmoid... And I don&amp;#39;t know how it works! Do you know any source or paper that references it and uses this?&lt;/p&gt;

&lt;p&gt;Is it used? How is that it might be better than the normal rf? &lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hw5dyp,saikjuan,3,/r/datascience/comments/hw5dyp/random_forest_sigmoid/,https://www.reddit.com/r/datascience/comments/hw5dyp/random_forest_sigmoid/,1595462902.0
r/datascience,"I currently work as an industrial engineer at a CPG company, and am tracking a KPI to increase our weight shipped (which leads to reduced costs). Some of the factors that influence this are: the type of products we're shipping, the type of equipment we're using to ship the products, and how well we're filling our trailers (% max weight). 

I have alot of detailed data where I can pull these measurements together but I want to determine out of these factors what has the most influence on our weight KPI. 

Wondering what the fastest/easiest way to pull this together would be (and what language to use) - would a simple multiple regression work? 

Appreciate your help in advance! Sorry if this question is super basic.",t2_n99lz,"Newbie to data science - want to determine what factors have the greatest influence on a KPI, what would be the fastest/easiest way to do this?",projects,t3_hw2d5r,0.75,4,Projects,4,1595481400.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I currently work as an industrial engineer at a CPG company, and am tracking a KPI to increase our weight shipped (which leads to reduced costs). Some of the factors that influence this are: the type of products we&amp;#39;re shipping, the type of equipment we&amp;#39;re using to ship the products, and how well we&amp;#39;re filling our trailers (% max weight). &lt;/p&gt;

&lt;p&gt;I have alot of detailed data where I can pull these measurements together but I want to determine out of these factors what has the most influence on our weight KPI. &lt;/p&gt;

&lt;p&gt;Wondering what the fastest/easiest way to pull this together would be (and what language to use) - would a simple multiple regression work? &lt;/p&gt;

&lt;p&gt;Appreciate your help in advance! Sorry if this question is super basic.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hw2d5r,tacotime_,11,/r/datascience/comments/hw2d5r/newbie_to_data_science_want_to_determine_what/,https://www.reddit.com/r/datascience/comments/hw2d5r/newbie_to_data_science_want_to_determine_what/,1595452600.0
r/datascience,"I recently watched a kurzgasagt video on solar flare ups that could send huge EMP blasts to Earth with little to no warning. So be it nature or attack I want to protect my data and external hard drives from EMP blasts. I live in NJ , USA I have about 1TB of movies approximately 180 movies and counting all 1080 quality. In the event of a global outage I would like to have a few of my electronics secure. I went on eBay I just purchased (6) 1/8 x 12” x 24” 99.9% lead sheet on eBay , cost me about $300 i don’t care I just put it on credit lol. So I need help securing it should I use lead solder to seal it? Any suggestions where to ask this if not here?",t2_2vevifsf,Protecting data from solar flares with a lead box ?,discussion,t3_hw0s48,0.7,4,Discussion,4,1595476404.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I recently watched a kurzgasagt video on solar flare ups that could send huge EMP blasts to Earth with little to no warning. So be it nature or attack I want to protect my data and external hard drives from EMP blasts. I live in NJ , USA I have about 1TB of movies approximately 180 movies and counting all 1080 quality. In the event of a global outage I would like to have a few of my electronics secure. I went on eBay I just purchased (6) 1/8 x 12” x 24” 99.9% lead sheet on eBay , cost me about $300 i don’t care I just put it on credit lol. So I need help securing it should I use lead solder to seal it? Any suggestions where to ask this if not here?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hw0s48,cellardoorProgrammer,13,/r/datascience/comments/hw0s48/protecting_data_from_solar_flares_with_a_lead_box/,https://www.reddit.com/r/datascience/comments/hw0s48/protecting_data_from_solar_flares_with_a_lead_box/,1595447604.0
r/datascience,"So I’ve been looking for jobs for the past 4 months, thanks COVID! I recently had an interview and as the title suggests, I didn’t make it. But one of the feedback was that my responses were high level and not detailed. How do I work on this? 

The other feedback was that I lacked product centric experience, which is true because all my experience is more around marketing analytics. 

Thank you!",t2_1gouw6ih,Feedback from interview. How to interpret it.,,t3_hvztjx,0.86,5,Job Search,5,1595473410.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I’ve been looking for jobs for the past 4 months, thanks COVID! I recently had an interview and as the title suggests, I didn’t make it. But one of the feedback was that my responses were high level and not detailed. How do I work on this? &lt;/p&gt;

&lt;p&gt;The other feedback was that I lacked product centric experience, which is true because all my experience is more around marketing analytics. &lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvztjx,math_stat_gal,22,/r/datascience/comments/hvztjx/feedback_from_interview_how_to_interpret_it/,https://www.reddit.com/r/datascience/comments/hvztjx/feedback_from_interview_how_to_interpret_it/,1595444610.0
r/datascience,"I'm creating a survey which I need to host online, and will later analyze and visualize the results. I'm most comfortable working with data in Python, and am working on a deadline, so was hoping to get some website recommendations that allow you to easily access the data in a workable format. Google Forms, Typeform, something else? Thanks in advance for any recs!",t2_15kgnd,Best website for survey data analysis?,discussion,t3_hw1kky,1.0,3,Discussion,3,1595478860.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m creating a survey which I need to host online, and will later analyze and visualize the results. I&amp;#39;m most comfortable working with data in Python, and am working on a deadline, so was hoping to get some website recommendations that allow you to easily access the data in a workable format. Google Forms, Typeform, something else? Thanks in advance for any recs!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hw1kky,fitzgerrymander,6,/r/datascience/comments/hw1kky/best_website_for_survey_data_analysis/,https://www.reddit.com/r/datascience/comments/hw1kky/best_website_for_survey_data_analysis/,1595450060.0
r/datascience,"Since moving into the DS field roughly 4 years ago, and having worked on/for a handful of different teams/companies, I think one of the best skills I've picked up is being able to tell people what CAN'T be done.

It sounds pessimistic on face value, but in industry I find it to be a very practical skill. In my experience, upper management or outside departments have an overinflated perception of the capabilities of data science in general, but also data science capabilities within the organization. 

I've found this to be true working for very large corporations as well as non-profits. In my opinion, being able to honestly and succinctly articulate the realistic capabilities of the team can drastically improve efficiency and reduce wasted time/energy. 

Again, in my experience, explaining in blunt terms what can/ can't be done to non-technical or not-very-technical is the way to go. I typically start out very broad and explain why what their asking is a bad idea. If that doesn't work, I get more technical and also try to put it into a dollars/man-hours cost benefit type of analysis. Typically once you explain technically why it can't be done OR why it doesn't make sense in terms of money or time, then people start to understand better.

Using this type of strategy from the very outset is the best way to go. The last thing you want to do is overpromise and underperform.

An example, since this is a bit ambiguous, I was working on a team and we were contacted by another department to ""create an algorithm that sorts our emails into various categories."" They had heard from someone that text classification could save them time... Or something like that is what I gathered. Our team knew it was a BS request right off the bat, but my boss was overruled by a superior within the company. We had several (useless) meetings with them where they spilled out their reasons why they needed this to be done.

Long story short, it turns out that they only had 500 emails and there were no real defined categories to put them into. It wasn't until we explained to them that 1) this model would take longer than just going thru the emails by hand 2) would likely not be very accurate and 3) basically cost a teams worth of hours to complete. Ultimately common sense prevailed and they did it by hand.",t2_376wzl68,One of the useful skills that I've learned,discussion,t3_hvc6qs,0.96,259,Discussion,259,1595382855.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Since moving into the DS field roughly 4 years ago, and having worked on/for a handful of different teams/companies, I think one of the best skills I&amp;#39;ve picked up is being able to tell people what CAN&amp;#39;T be done.&lt;/p&gt;

&lt;p&gt;It sounds pessimistic on face value, but in industry I find it to be a very practical skill. In my experience, upper management or outside departments have an overinflated perception of the capabilities of data science in general, but also data science capabilities within the organization. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve found this to be true working for very large corporations as well as non-profits. In my opinion, being able to honestly and succinctly articulate the realistic capabilities of the team can drastically improve efficiency and reduce wasted time/energy. &lt;/p&gt;

&lt;p&gt;Again, in my experience, explaining in blunt terms what can/ can&amp;#39;t be done to non-technical or not-very-technical is the way to go. I typically start out very broad and explain why what their asking is a bad idea. If that doesn&amp;#39;t work, I get more technical and also try to put it into a dollars/man-hours cost benefit type of analysis. Typically once you explain technically why it can&amp;#39;t be done OR why it doesn&amp;#39;t make sense in terms of money or time, then people start to understand better.&lt;/p&gt;

&lt;p&gt;Using this type of strategy from the very outset is the best way to go. The last thing you want to do is overpromise and underperform.&lt;/p&gt;

&lt;p&gt;An example, since this is a bit ambiguous, I was working on a team and we were contacted by another department to &amp;quot;create an algorithm that sorts our emails into various categories.&amp;quot; They had heard from someone that text classification could save them time... Or something like that is what I gathered. Our team knew it was a BS request right off the bat, but my boss was overruled by a superior within the company. We had several (useless) meetings with them where they spilled out their reasons why they needed this to be done.&lt;/p&gt;

&lt;p&gt;Long story short, it turns out that they only had 500 emails and there were no real defined categories to put them into. It wasn&amp;#39;t until we explained to them that 1) this model would take longer than just going thru the emails by hand 2) would likely not be very accurate and 3) basically cost a teams worth of hours to complete. Ultimately common sense prevailed and they did it by hand.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvc6qs,Ryankinsey1,32,/r/datascience/comments/hvc6qs/one_of_the_useful_skills_that_ive_learned/,https://www.reddit.com/r/datascience/comments/hvc6qs/one_of_the_useful_skills_that_ive_learned/,1595354055.0
r/datascience,"I just recently started my Masters Program in Computer Science, and I'm doing the Data Science Focus (Coursera UIUC MOOC) , but I'm having some difficulty locking down what I really want to do, once I graduate. To be honest, 50% of the reason I'm doing this degree is because I keep hearing Data Science is the ""in"" topic of the decade, but the other 50% is because I have always been interested in artificial intelligence since I was young, and I know Data Science exists partially in the domain of Artificial Intelligence, Machine Learning, etc   


I know I'm relatively new and don't have as much information about the field as I will once I'm done with my degree, but I like to have at least an idea of what direction I should be moving in. Should I find a specialization inside of Data Science that interests me now, and only pick classes pertaining to that? Or should I just pick what's easy to get the degree and on the side study on my own the stuff that interests me? I try to look up what data scientists really do on job boards, but it seems so...obtuse, like the companies don't know what they want. What are the actual different roles that can be achieved with this degree and what do they specialize in?  


I appreciate any help that you all can give me, and I apologize if this isn't the right place to post this.",t2_2tqw0dof,Role/Focus/Specialization in the Industry,career,t3_hw2sn5,1.0,1,Career,1,1595482857.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just recently started my Masters Program in Computer Science, and I&amp;#39;m doing the Data Science Focus (Coursera UIUC MOOC) , but I&amp;#39;m having some difficulty locking down what I really want to do, once I graduate. To be honest, 50% of the reason I&amp;#39;m doing this degree is because I keep hearing Data Science is the &amp;quot;in&amp;quot; topic of the decade, but the other 50% is because I have always been interested in artificial intelligence since I was young, and I know Data Science exists partially in the domain of Artificial Intelligence, Machine Learning, etc   &lt;/p&gt;

&lt;p&gt;I know I&amp;#39;m relatively new and don&amp;#39;t have as much information about the field as I will once I&amp;#39;m done with my degree, but I like to have at least an idea of what direction I should be moving in. Should I find a specialization inside of Data Science that interests me now, and only pick classes pertaining to that? Or should I just pick what&amp;#39;s easy to get the degree and on the side study on my own the stuff that interests me? I try to look up what data scientists really do on job boards, but it seems so...obtuse, like the companies don&amp;#39;t know what they want. What are the actual different roles that can be achieved with this degree and what do they specialize in?  &lt;/p&gt;

&lt;p&gt;I appreciate any help that you all can give me, and I apologize if this isn&amp;#39;t the right place to post this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hw2sn5,zdsatta,4,/r/datascience/comments/hw2sn5/rolefocusspecialization_in_the_industry/,https://www.reddit.com/r/datascience/comments/hw2sn5/rolefocusspecialization_in_the_industry/,1595454057.0
r/datascience,"I work for a mid-sized manufacturing company in the semi-conductor industry and they want me to work as a BI analyst which is a completely new field for me. What they are especially interested in is KPIs and dashboards. For this reason it is planned to introduce Power BI (which should be connected to Microsoft Dynamics, NAV). However, I totally hate Microsoft products in general because of the catastrophic UI/UX and I wonder if Power BI is the best tool. I may have the chance to suggest a different software. What do you think is the best software for BI/dashboards? Or would you say Power BI is excellent software?",t2_5dsf80f5,Experience with Power BI and Possible Alternatives,tooling,t3_hvxwd1,0.67,1,Tooling,1,1595467310.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work for a mid-sized manufacturing company in the semi-conductor industry and they want me to work as a BI analyst which is a completely new field for me. What they are especially interested in is KPIs and dashboards. For this reason it is planned to introduce Power BI (which should be connected to Microsoft Dynamics, NAV). However, I totally hate Microsoft products in general because of the catastrophic UI/UX and I wonder if Power BI is the best tool. I may have the chance to suggest a different software. What do you think is the best software for BI/dashboards? Or would you say Power BI is excellent software?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvxwd1,Timm218,5,/r/datascience/comments/hvxwd1/experience_with_power_bi_and_possible_alternatives/,https://www.reddit.com/r/datascience/comments/hvxwd1/experience_with_power_bi_and_possible_alternatives/,1595438510.0
r/datascience,"Just want to get people’s thoughts on attending the NYR Conference put on by Lander Analytics - https://rstats.ai/nyr/.

I primarily use R for work, but am unsure about paying $250 for an online conference - especially when the talks will be online later for free. I would like to chat/“meet” people from other companies though. Thanks for any comments!",t2_xp32j,NYR Conference - worth it? Virtual,,t3_hvtic5,0.67,1,,1,1595452236.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just want to get people’s thoughts on attending the NYR Conference put on by Lander Analytics - &lt;a href=""https://rstats.ai/nyr/""&gt;https://rstats.ai/nyr/&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I primarily use R for work, but am unsure about paying $250 for an online conference - especially when the talks will be online later for free. I would like to chat/“meet” people from other companies though. Thanks for any comments!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvtic5,DCEmergencyVehicle,2,/r/datascience/comments/hvtic5/nyr_conference_worth_it_virtual/,https://www.reddit.com/r/datascience/comments/hvtic5/nyr_conference_worth_it_virtual/,1595423436.0
r/datascience,"Hello. This is a genuine question from a professional video editor with absolutely no knowledge of data science, and this may be the wrong sub altogether. I have noticed that when the new case numbers (in California for example) show a slowing rate of decline, depicted by a noticeably less steep angle, two or more times in a short space of time (less than a week), this seem to come before a rapid rise in case numbers. I may add an image in the comments to show what I mean but for now hopefully I can describe this without an image. The new case numbers go up and down each day - which is understandable but when the graph shows a pronounced gentle slope down, “braking” I call it- as opposed to a sharp and steep drop (like an inverted skinny V) I seem to then see a big and significant rise in case numbers in the following weeks. I’ve seen a couple of very steep and sharp drops of new case numbers close together which looks to be a precursor to the new case numbers going on the wane (dropping &amp; continuing to drop) for a while. First question; what is the gentle slope down called, if anything, and second, is there any logic or reason to what I feel like I am seeing? Thanks for indulging a rank amateur. Edit: the downward slopes I mention do not coincide with the well known weekend reporting drop. Just to stop the numerous people making the same point there.",t2_ju6ublp,A question for data scientists from a curious observer of covid new case stats.,discussion,t3_hv8mfp,0.92,60,Discussion,60,1595371696.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello. This is a genuine question from a professional video editor with absolutely no knowledge of data science, and this may be the wrong sub altogether. I have noticed that when the new case numbers (in California for example) show a slowing rate of decline, depicted by a noticeably less steep angle, two or more times in a short space of time (less than a week), this seem to come before a rapid rise in case numbers. I may add an image in the comments to show what I mean but for now hopefully I can describe this without an image. The new case numbers go up and down each day - which is understandable but when the graph shows a pronounced gentle slope down, “braking” I call it- as opposed to a sharp and steep drop (like an inverted skinny V) I seem to then see a big and significant rise in case numbers in the following weeks. I’ve seen a couple of very steep and sharp drops of new case numbers close together which looks to be a precursor to the new case numbers going on the wane (dropping &amp;amp; continuing to drop) for a while. First question; what is the gentle slope down called, if anything, and second, is there any logic or reason to what I feel like I am seeing? Thanks for indulging a rank amateur. Edit: the downward slopes I mention do not coincide with the well known weekend reporting drop. Just to stop the numerous people making the same point there.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hv8mfp,SierraDriftr,33,/r/datascience/comments/hv8mfp/a_question_for_data_scientists_from_a_curious/,https://www.reddit.com/r/datascience/comments/hv8mfp/a_question_for_data_scientists_from_a_curious/,1595342896.0
r/datascience,"Ideas for EDA on Sales Data

Hello everyone, 

I was recently asked to look at the data provided by a publishing company. They have a chain of bookstores in my country and the data includes Book Title, Volumes Sold, Pricing, Name of the Publisher and the Year the sales were made.

They asked me to do an EDA and this being my first experience with Sales Data, I would appreciate some guidance as to where I should begin, what to look for and the type of insight that will be useful to them. I specifically asked them these questions and they honestly had no clue!",t2_55x8eunu,Ideas for EDA on Sales Data!,discussion,t3_hvrwsy,0.57,1,Discussion,1,1595445182.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Ideas for EDA on Sales Data&lt;/p&gt;

&lt;p&gt;Hello everyone, &lt;/p&gt;

&lt;p&gt;I was recently asked to look at the data provided by a publishing company. They have a chain of bookstores in my country and the data includes Book Title, Volumes Sold, Pricing, Name of the Publisher and the Year the sales were made.&lt;/p&gt;

&lt;p&gt;They asked me to do an EDA and this being my first experience with Sales Data, I would appreciate some guidance as to where I should begin, what to look for and the type of insight that will be useful to them. I specifically asked them these questions and they honestly had no clue!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvrwsy,payamv2,10,/r/datascience/comments/hvrwsy/ideas_for_eda_on_sales_data/,https://www.reddit.com/r/datascience/comments/hvrwsy/ideas_for_eda_on_sales_data/,1595416382.0
r/datascience,"Whatever you do, DS, DE, PM, BA, BI Dev... what's the most fun part of your job? The one you most enjoy (let's keep money / prestige aside and talk about the actual job fulfillment).

I think it's useful info as well, for someone trying to break into the field. Often these most enjoyable parts are what makes you keep at it, persevere and not quit when you're at your worst.

For example, it might sound stupid but I really enjoy the visual part of creating new reports. We have no standards in my company and I'm the only analytical person, so I have a free hand, I can spend hours playing with colours like a drooling idiot (as long as I manage everything on time).",t2_7odh6,What's your favourite part of the whole DS&amp;BI / analytics job?,discussion,t3_hvpt0x,0.5,0,Discussion,0,1595434055.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Whatever you do, DS, DE, PM, BA, BI Dev... what&amp;#39;s the most fun part of your job? The one you most enjoy (let&amp;#39;s keep money / prestige aside and talk about the actual job fulfillment).&lt;/p&gt;

&lt;p&gt;I think it&amp;#39;s useful info as well, for someone trying to break into the field. Often these most enjoyable parts are what makes you keep at it, persevere and not quit when you&amp;#39;re at your worst.&lt;/p&gt;

&lt;p&gt;For example, it might sound stupid but I really enjoy the visual part of creating new reports. We have no standards in my company and I&amp;#39;m the only analytical person, so I have a free hand, I can spend hours playing with colours like a drooling idiot (as long as I manage everything on time).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvpt0x,PanFiluta,2,/r/datascience/comments/hvpt0x/whats_your_favourite_part_of_the_whole_dsbi/,https://www.reddit.com/r/datascience/comments/hvpt0x/whats_your_favourite_part_of_the_whole_dsbi/,1595405255.0
r/datascience,"Is it legal to scrape LinkedIn or Facebook data?

I read somewhere else that it's illegal but I'm just writing a script to get a list of all my connections so I want to know if that's also considered illegal.",t2_2g19atlz,LinkedIn Scraping Data,projects,t3_hvfzwd,1.0,6,Projects,6,1595394734.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it legal to scrape LinkedIn or Facebook data?&lt;/p&gt;

&lt;p&gt;I read somewhere else that it&amp;#39;s illegal but I&amp;#39;m just writing a script to get a list of all my connections so I want to know if that&amp;#39;s also considered illegal.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvfzwd,DarkKnight2001135,21,/r/datascience/comments/hvfzwd/linkedin_scraping_data/,https://www.reddit.com/r/datascience/comments/hvfzwd/linkedin_scraping_data/,1595365934.0
r/datascience,"I have this amazing opportunity to contribute to an NLP project. We are in our initial phase of exploring these bunch of text documents and share our findings, etc.

I spent a week on it and I myself do feel like I have done some great analysis. But when it comes time to share my work, I always feel like maybe my work is too basic to show and it won’t interest the other experienced people much. 

Would really like to know other people’s experiences with this. 

This usually happens to me every time I share something lol.",t2_4xla0g72,Fear of sharing my work,career,t3_huxsto,0.95,142,Career,142,1595321968.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have this amazing opportunity to contribute to an NLP project. We are in our initial phase of exploring these bunch of text documents and share our findings, etc.&lt;/p&gt;

&lt;p&gt;I spent a week on it and I myself do feel like I have done some great analysis. But when it comes time to share my work, I always feel like maybe my work is too basic to show and it won’t interest the other experienced people much. &lt;/p&gt;

&lt;p&gt;Would really like to know other people’s experiences with this. &lt;/p&gt;

&lt;p&gt;This usually happens to me every time I share something lol.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",huxsto,michaelschrutebeesly,32,/r/datascience/comments/huxsto/fear_of_sharing_my_work/,https://www.reddit.com/r/datascience/comments/huxsto/fear_of_sharing_my_work/,1595293168.0
r/datascience,"Hi r/datascience! 

So recently I've been battling with an interesting modelling project. The task is to create a descriptive model to help determine drivers of a given outcome. Initially, I went with decision trees as these had a good visual element to them and worked well for a previous project whereby one could also determine a 'profile' or set of attributes via the decision paths to one of the leaf nodes leading to a likely outcome determined by the model.

However, I am now dealing with a problem which has many categorical features (hence partial dependency plots are not exactly something applicable) and is more akin to a multiclass problem (I could split it into one vs all binary classification, but would prefer not to). My current thinking is to use catboost (I tried decision trees on this multiclass problem in R and the optimization procedure is too slow for this), which gives good results, but alas it is an ensemble method. I could grab the first decision tree, yes, but it is not the full picture. I have tried Shapley values for this as well, and come up with building some groups of attributes that are influential by using the attributions from the Shapley values. I won't go into detail but rather ask the following question:

Suppose you have a model which yields good performance. Sure, you can retrieve some feature importance from it. But, suppose you want to build a profile let's call it (could be a profile of a lead, or product) of attributes from your features which are very likely to lead to this outcome, as determined by this model. How would you proceed in doing so? Do you know of any techniques, packages etc. which handle this problem? Do you propose any other models which are good with this? 

Thank you!",t2_2rqvgdnh,Feature importance is great. But what about a most influential profile of feature attributes?,projects,t3_hvf8xr,0.67,2,Projects,2,1595392392.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt;! &lt;/p&gt;

&lt;p&gt;So recently I&amp;#39;ve been battling with an interesting modelling project. The task is to create a descriptive model to help determine drivers of a given outcome. Initially, I went with decision trees as these had a good visual element to them and worked well for a previous project whereby one could also determine a &amp;#39;profile&amp;#39; or set of attributes via the decision paths to one of the leaf nodes leading to a likely outcome determined by the model.&lt;/p&gt;

&lt;p&gt;However, I am now dealing with a problem which has many categorical features (hence partial dependency plots are not exactly something applicable) and is more akin to a multiclass problem (I could split it into one vs all binary classification, but would prefer not to). My current thinking is to use catboost (I tried decision trees on this multiclass problem in R and the optimization procedure is too slow for this), which gives good results, but alas it is an ensemble method. I could grab the first decision tree, yes, but it is not the full picture. I have tried Shapley values for this as well, and come up with building some groups of attributes that are influential by using the attributions from the Shapley values. I won&amp;#39;t go into detail but rather ask the following question:&lt;/p&gt;

&lt;p&gt;Suppose you have a model which yields good performance. Sure, you can retrieve some feature importance from it. But, suppose you want to build a profile let&amp;#39;s call it (could be a profile of a lead, or product) of attributes from your features which are very likely to lead to this outcome, as determined by this model. How would you proceed in doing so? Do you know of any techniques, packages etc. which handle this problem? Do you propose any other models which are good with this? &lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvf8xr,IntriguingMuffin,5,/r/datascience/comments/hvf8xr/feature_importance_is_great_but_what_about_a_most/,https://www.reddit.com/r/datascience/comments/hvf8xr/feature_importance_is_great_but_what_about_a_most/,1595363592.0
r/datascience,"Recently, I've been getting more interested on the engineering and deployment side of data science, rather than the math and the algorithms of data science. I know that MLOps is growing in importance for data science ecosystem so I'm curious how I can get started in learning this. Thanks!",t2_5xux0a4p,How do I get started on learning ML Ops?,discussion,t3_hv9scg,0.76,6,Discussion,6,1595375479.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Recently, I&amp;#39;ve been getting more interested on the engineering and deployment side of data science, rather than the math and the algorithms of data science. I know that MLOps is growing in importance for data science ecosystem so I&amp;#39;m curious how I can get started in learning this. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hv9scg,___24601,12,/r/datascience/comments/hv9scg/how_do_i_get_started_on_learning_ml_ops/,https://www.reddit.com/r/datascience/comments/hv9scg/how_do_i_get_started_on_learning_ml_ops/,1595346679.0
r/datascience,"Hi,

I'm sure this is a situation many of you have come across before, and I was wondering what your thoughts were. Many times when I'm tuning my hyperparameters, I'll find that the model with the best CV error is actually very overfit when comparing the in-fold vs out-of-fold training error. For example, I just ran an xgboost model, and the parameters with the best CV error resulted in a out-of-fold logloss of 0.451, and an in-fold logloss of 0.405. That in-fold logloss is 11% lower than the out of fold, which seems excessive. If I created a model with these parameters, I would expect it to be overfit. However, I would also expect it to generalize well based on logloss criteria.

So, what are the general thoughts on how 'different' in-fold vs out-of-fold errors should be? I know there isn't a formula or any hard set rules - I was just wondering how people handled situations like this. I personally up the regularization parameters somewhat before creating my final model.",t2_i8ujh,Balancing Variance vs Raw CV Performance,discussion,t3_hvbzbb,0.81,3,Discussion,3,1595382199.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m sure this is a situation many of you have come across before, and I was wondering what your thoughts were. Many times when I&amp;#39;m tuning my hyperparameters, I&amp;#39;ll find that the model with the best CV error is actually very overfit when comparing the in-fold vs out-of-fold training error. For example, I just ran an xgboost model, and the parameters with the best CV error resulted in a out-of-fold logloss of 0.451, and an in-fold logloss of 0.405. That in-fold logloss is 11% lower than the out of fold, which seems excessive. If I created a model with these parameters, I would expect it to be overfit. However, I would also expect it to generalize well based on logloss criteria.&lt;/p&gt;

&lt;p&gt;So, what are the general thoughts on how &amp;#39;different&amp;#39; in-fold vs out-of-fold errors should be? I know there isn&amp;#39;t a formula or any hard set rules - I was just wondering how people handled situations like this. I personally up the regularization parameters somewhat before creating my final model.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvbzbb,suspicious_gardener,12,/r/datascience/comments/hvbzbb/balancing_variance_vs_raw_cv_performance/,https://www.reddit.com/r/datascience/comments/hvbzbb/balancing_variance_vs_raw_cv_performance/,1595353399.0
r/datascience,"Hello everyone, I am a junior data analyst for the sales team at my company. This is my first real Data analytics job so excuse my simple question. My team has been given the option to choose either Tableau or Power BI to present our data. Right now we have all our data and presentations/""dashboards"" in excel. I am just now looking into the merits or down falls of both. I was wondering if the wonderful people on this sub can share their experience with both tools.  


Some key points.   


I am the only one on my team who is familiar with any coding language(Python, VBA, SQL), so if the tool has a scripting language the closer to any of those the better as it will help me get up to speed faster.  


I am learning Power Query and M Language in excel right now, but I am kinda hating it as it is very finicky with our ugly data( a lot of our data is manual reporting). which tool can handle dirty data better?

&amp;#x200B;

I mainly report my data to 3 people but often send out to dozens of people. Is one tool better than the other at presenting to someone who might not have a paid user of that tool?  


Which tool is more sought after in the industry? I don't plan to leave this job any time soon, but learning the more popular tool is of higher importance to me.",t2_3wxhxt1i,Would you recommend Tableau or Power Bi?,discussion,t3_hv7nlv,0.67,3,Discussion,3,1595368198.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, I am a junior data analyst for the sales team at my company. This is my first real Data analytics job so excuse my simple question. My team has been given the option to choose either Tableau or Power BI to present our data. Right now we have all our data and presentations/&amp;quot;dashboards&amp;quot; in excel. I am just now looking into the merits or down falls of both. I was wondering if the wonderful people on this sub can share their experience with both tools.  &lt;/p&gt;

&lt;p&gt;Some key points.   &lt;/p&gt;

&lt;p&gt;I am the only one on my team who is familiar with any coding language(Python, VBA, SQL), so if the tool has a scripting language the closer to any of those the better as it will help me get up to speed faster.  &lt;/p&gt;

&lt;p&gt;I am learning Power Query and M Language in excel right now, but I am kinda hating it as it is very finicky with our ugly data( a lot of our data is manual reporting). which tool can handle dirty data better?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I mainly report my data to 3 people but often send out to dozens of people. Is one tool better than the other at presenting to someone who might not have a paid user of that tool?  &lt;/p&gt;

&lt;p&gt;Which tool is more sought after in the industry? I don&amp;#39;t plan to leave this job any time soon, but learning the more popular tool is of higher importance to me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hv7nlv,TrainquilOasis1423,25,/r/datascience/comments/hv7nlv/would_you_recommend_tableau_or_power_bi/,https://www.reddit.com/r/datascience/comments/hv7nlv/would_you_recommend_tableau_or_power_bi/,1595339398.0
r/datascience,"By 2021, about 70 percent of the U.S. executives would prefer job candidates having data skills. Precisely, the demand for data analysts will keep expanding as our world continues moving into digitization.

The conversation around data science and big data analytics significantly caused a major impact on organizations. Multiple companies are now focused on developing a data-driven business market. And to cater to the needs of the business, they will need multiple talented professionals with big data skills.

data science and big data analytics, data analytics career, Structured Query Language (SQL), data analytics, big data analysts, Python or R,  Machine Learning

[http://newsdailyarticles.com/tech/top-7-tech-skills-every-data-analysts-will-need-in-2020](http://newsdailyarticles.com/tech/top-7-tech-skills-every-data-analysts-will-need-in-2020)",t2_3kiwj7vi,Top 7 Tech Skills Every Data Analysts Will Need in 2020,career,t3_hvrlmd,0.13,0,Career,0,1595443615.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;By 2021, about 70 percent of the U.S. executives would prefer job candidates having data skills. Precisely, the demand for data analysts will keep expanding as our world continues moving into digitization.&lt;/p&gt;

&lt;p&gt;The conversation around data science and big data analytics significantly caused a major impact on organizations. Multiple companies are now focused on developing a data-driven business market. And to cater to the needs of the business, they will need multiple talented professionals with big data skills.&lt;/p&gt;

&lt;p&gt;data science and big data analytics, data analytics career, Structured Query Language (SQL), data analytics, big data analysts, Python or R,  Machine Learning&lt;/p&gt;

&lt;p&gt;&lt;a href=""http://newsdailyarticles.com/tech/top-7-tech-skills-every-data-analysts-will-need-in-2020""&gt;http://newsdailyarticles.com/tech/top-7-tech-skills-every-data-analysts-will-need-in-2020&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hvrlmd,DASCA01,1,/r/datascience/comments/hvrlmd/top_7_tech_skills_every_data_analysts_will_need/,https://www.reddit.com/r/datascience/comments/hvrlmd/top_7_tech_skills_every_data_analysts_will_need/,1595414815.0
r/datascience,,t2_cfuc8,Distributed Computing and SQL,fun,t3_hudog1,0.96,1025,Fun/Trivia,1025,1595242782.0,,hudog1,EvanstonNU,62,/r/datascience/comments/hudog1/distributed_computing_and_sql/,https://mamg.makeameme.org/when-you-advertise-2c8984af95.jpg,1595213982.0
r/datascience,"I'm working on a dataset where users define their availabilities in a calendar.

I fear simply adding each day as a separate column in the final dataset won't be very pertinent, because I'm more interested in the profile that in the specific dates.

The obvious answer is to do a kind of clustering or embedding. But I haven't done it on this kind of data before and my first bibliographic forrays were not very fruitful.

Have you done something like this before ? Do you have any pointers or bibliographic references ?",t2_g40yp,Embedding of calendar type data,discussion,t3_hv3u95,0.81,3,Discussion,3,1595349549.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working on a dataset where users define their availabilities in a calendar.&lt;/p&gt;

&lt;p&gt;I fear simply adding each day as a separate column in the final dataset won&amp;#39;t be very pertinent, because I&amp;#39;m more interested in the profile that in the specific dates.&lt;/p&gt;

&lt;p&gt;The obvious answer is to do a kind of clustering or embedding. But I haven&amp;#39;t done it on this kind of data before and my first bibliographic forrays were not very fruitful.&lt;/p&gt;

&lt;p&gt;Have you done something like this before ? Do you have any pointers or bibliographic references ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hv3u95,Loddd,1,/r/datascience/comments/hv3u95/embedding_of_calendar_type_data/,https://www.reddit.com/r/datascience/comments/hv3u95/embedding_of_calendar_type_data/,1595320749.0
r/datascience,"Hi,

I know the question is kinda dumb but I am trying to learn a skill/strategy that is usually not taught in school/books/moocs.

I have heard a lot that one of the best ways of learning is to ""learn it on the job"" specially when it comes to machine learning and data science (given their rapid changes).

I, however, have a hard time understanding how should I learn on the job? Assume you are given a deep model that you have not worked with / studied before, or working on a data pipeline that you have not worked with before.

How do you go about actually get the project done, while also learning it well? How do you prioritize? How do you divide your time into learning, doing, searching, etc? If you have any other strategies please do share it as well.

&amp;#x200B;

Any practical advice / resource is highly appreciated.",t2_40ktirg1,"How to ""learn on the job""?",career,t3_hux01h,0.77,11,Career,11,1595318847.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I know the question is kinda dumb but I am trying to learn a skill/strategy that is usually not taught in school/books/moocs.&lt;/p&gt;

&lt;p&gt;I have heard a lot that one of the best ways of learning is to &amp;quot;learn it on the job&amp;quot; specially when it comes to machine learning and data science (given their rapid changes).&lt;/p&gt;

&lt;p&gt;I, however, have a hard time understanding how should I learn on the job? Assume you are given a deep model that you have not worked with / studied before, or working on a data pipeline that you have not worked with before.&lt;/p&gt;

&lt;p&gt;How do you go about actually get the project done, while also learning it well? How do you prioritize? How do you divide your time into learning, doing, searching, etc? If you have any other strategies please do share it as well.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any practical advice / resource is highly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hux01h,007ara,5,/r/datascience/comments/hux01h/how_to_learn_on_the_job/,https://www.reddit.com/r/datascience/comments/hux01h/how_to_learn_on_the_job/,1595290047.0
r/datascience,"I know data science is a broad career and can applies to different job sectors. Tech. Business. Gov. Etc. 

What role typically can allow for remote work? I don’t know too much as I’m still in school.",t2_d2e64,What data scientist job allows remote?,discussion,t3_hv1ghz,0.56,1,Discussion,1,1595337293.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know data science is a broad career and can applies to different job sectors. Tech. Business. Gov. Etc. &lt;/p&gt;

&lt;p&gt;What role typically can allow for remote work? I don’t know too much as I’m still in school.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hv1ghz,ryaznx,6,/r/datascience/comments/hv1ghz/what_data_scientist_job_allows_remote/,https://www.reddit.com/r/datascience/comments/hv1ghz/what_data_scientist_job_allows_remote/,1595308493.0
r/datascience,"I'm interested in learning more about GIS as it pertains to working with data analytics/science.  I'm interested in taking some classes.  Seems like there's a lot of options from free to paid MOOC and self-paced courses, including some directly from ESRI.  Anybody have any advice on this?

Edit:  Thanks everyone for the replies.  Very helpful.  I should have been more detailed in my post.  I am interested in performing data analytics for real estate.  I guess I don't know enough to really be asking the right questions potentially.  I have take some introductory courses for Python and R.  I'm definitely interested in using Python and R geospatial packages for data analysis.  But do you not really need to know ArcGIS or QGIS for that?  Or do you just need to understand GIS fundamentals?  So does that mean I should just learn Python or R geared for GIS packages?  Or should I also look into courses for ArcGIS or QGIS on top of that?  Or just need some sort of GIS primer instead?",t2_14hkulaw,GIS,education,t3_huop3m,1.0,11,Education,11,1595292459.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m interested in learning more about GIS as it pertains to working with data analytics/science.  I&amp;#39;m interested in taking some classes.  Seems like there&amp;#39;s a lot of options from free to paid MOOC and self-paced courses, including some directly from ESRI.  Anybody have any advice on this?&lt;/p&gt;

&lt;p&gt;Edit:  Thanks everyone for the replies.  Very helpful.  I should have been more detailed in my post.  I am interested in performing data analytics for real estate.  I guess I don&amp;#39;t know enough to really be asking the right questions potentially.  I have take some introductory courses for Python and R.  I&amp;#39;m definitely interested in using Python and R geospatial packages for data analysis.  But do you not really need to know ArcGIS or QGIS for that?  Or do you just need to understand GIS fundamentals?  So does that mean I should just learn Python or R geared for GIS packages?  Or should I also look into courses for ArcGIS or QGIS on top of that?  Or just need some sort of GIS primer instead?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",huop3m,HFWalling,13,/r/datascience/comments/huop3m/gis/,https://www.reddit.com/r/datascience/comments/huop3m/gis/,1595263659.0
r/datascience,"Long story short, I just got laid off from a really high paying oil and gas engineering job. Tried to enjoy unemployment, but I got bored VERY fast and ended up finding another job that's still in oil and gas but on the environmental side that pays half as much. Boo. I'm not into that, but the company is nice (like a person is nice).  


Anyways, I was also accepted into Oregon State's MS in Data Analytics and I am dying to apply these things I'm learning to real life. I am hoping I can create my own ""internship"" through my existing employer instead of quitting and doing my degree fulltime. I think it will work out because the data are there (they actually collect quite a bit of data in the field) and I can see what can be done with it and they aren't touching it at all. Like lots of equipment failure stats (could pinpoint failing pipe parts for O&amp;G companies for example), cost-saving analysis REALLY needs to be done (tons of inefficiencies), and really the list goes on. I think could create tangible results for the company from a business building and money-saving standpoint. 

For context, the CEO seems to be VERY paranoid about technology. There is another partner in the company who I work under (and probably why he hired me) is more of the tech guy and he kind of has the last say in things but it's mostly catering to the CEO's anti-tech fears.... though we DO have decent systems for running ArcMaps, there are better ways of going about it. All 18 employees of us are doing the same kind of work and have to SHARE 3 computers that run ArcMaps. Let me tell you the frustration I feel waiting an hour and  to be the next ""first"" person to get in on one. UGH.  And just to be clear, finding inefficiencies and automating anything possible was a HUGE part of my last job, as well as data mining and some analytics, so seeing all these things and not being able to do anything about it is beyond frustrating. 

&amp;#x200B;

TL;DR - My new employer is missing out on a lot of revenue and has a lot of wasteful spending.  I think I can ask to create a new role for myself while I do my Masters Degree in Data Analytics and apply what I learn as I go to real-life scenarios. I already see opportunity in the company but the CEO is paranoid about tech. Has anyone gone this route? Done something similar? How do you prove it's needed without being cockblocked or stepping on someone else's toes?",t2_3zu9y,Convincing my employer to let me do data analytics?,career,t3_hulhfv,0.79,13,Career,13,1595281460.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Long story short, I just got laid off from a really high paying oil and gas engineering job. Tried to enjoy unemployment, but I got bored VERY fast and ended up finding another job that&amp;#39;s still in oil and gas but on the environmental side that pays half as much. Boo. I&amp;#39;m not into that, but the company is nice (like a person is nice).  &lt;/p&gt;

&lt;p&gt;Anyways, I was also accepted into Oregon State&amp;#39;s MS in Data Analytics and I am dying to apply these things I&amp;#39;m learning to real life. I am hoping I can create my own &amp;quot;internship&amp;quot; through my existing employer instead of quitting and doing my degree fulltime. I think it will work out because the data are there (they actually collect quite a bit of data in the field) and I can see what can be done with it and they aren&amp;#39;t touching it at all. Like lots of equipment failure stats (could pinpoint failing pipe parts for O&amp;amp;G companies for example), cost-saving analysis REALLY needs to be done (tons of inefficiencies), and really the list goes on. I think could create tangible results for the company from a business building and money-saving standpoint. &lt;/p&gt;

&lt;p&gt;For context, the CEO seems to be VERY paranoid about technology. There is another partner in the company who I work under (and probably why he hired me) is more of the tech guy and he kind of has the last say in things but it&amp;#39;s mostly catering to the CEO&amp;#39;s anti-tech fears.... though we DO have decent systems for running ArcMaps, there are better ways of going about it. All 18 employees of us are doing the same kind of work and have to SHARE 3 computers that run ArcMaps. Let me tell you the frustration I feel waiting an hour and  to be the next &amp;quot;first&amp;quot; person to get in on one. UGH.  And just to be clear, finding inefficiencies and automating anything possible was a HUGE part of my last job, as well as data mining and some analytics, so seeing all these things and not being able to do anything about it is beyond frustrating. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;TL;DR - My new employer is missing out on a lot of revenue and has a lot of wasteful spending.  I think I can ask to create a new role for myself while I do my Masters Degree in Data Analytics and apply what I learn as I go to real-life scenarios. I already see opportunity in the company but the CEO is paranoid about tech. Has anyone gone this route? Done something similar? How do you prove it&amp;#39;s needed without being cockblocked or stepping on someone else&amp;#39;s toes?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hulhfv,tashibum,14,/r/datascience/comments/hulhfv/convincing_my_employer_to_let_me_do_data_analytics/,https://www.reddit.com/r/datascience/comments/hulhfv/convincing_my_employer_to_let_me_do_data_analytics/,1595252660.0
r/datascience,"My job wants me to do what seems like a pretty daunting task and I'm having a hard time wrapping my noodle around how to do it. I'm not much of a data guy so any compass you can provide that could put me in the right direction would be super, super appreciated, and may save me from getting fired.  

Without too many specifics, my company often works with other companies. We would like to do a better job monitoring companies in general in order to become predictive about when they turn up in the news, and in turn, get a greater context of our relationship with them. 

A workflow I'm envisioning: There are third-party databases/platforms that do media listening. Those platforms can be piped into (integrated, I guess?) a custom and/or inhouse created product. Machine learning counts mention of all entities and when specific entities are mentioned at an increased frequency, they are automatically cross-referenced with a master client list (also piped into the platform) to know if we work for a specific entity that is getting increased attention mentioned. A word cloud and/or other visualizations are created to determine the type of conversation around the entities on the client list with increased mentions. This is all accessible through some sort of dashboard that anyone can access in realtime. 

A separate pipe can also do the same thing with social media to build a broad context for topics as they develop. 

I imagine there are large financial institutions that have some sort of monitoring system like this already set up although I don't know of any. If any geopolitical or large development will trigger information they need to know, it predicts it will be an issue before it is an issue. Knowing nothing about data or machine learning, what would be the best way to attack this? Am I even approaching the right group of people? Do systems like this already exist? I am very, very lost (cringe face)",t2_xx3eo,"I'm a lot puppy with daunting task, am I in the right spot? Can someone be starting compass for me?",education,t3_huseg9,0.5,0,Education,0,1595303662.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My job wants me to do what seems like a pretty daunting task and I&amp;#39;m having a hard time wrapping my noodle around how to do it. I&amp;#39;m not much of a data guy so any compass you can provide that could put me in the right direction would be super, super appreciated, and may save me from getting fired.  &lt;/p&gt;

&lt;p&gt;Without too many specifics, my company often works with other companies. We would like to do a better job monitoring companies in general in order to become predictive about when they turn up in the news, and in turn, get a greater context of our relationship with them. &lt;/p&gt;

&lt;p&gt;A workflow I&amp;#39;m envisioning: There are third-party databases/platforms that do media listening. Those platforms can be piped into (integrated, I guess?) a custom and/or inhouse created product. Machine learning counts mention of all entities and when specific entities are mentioned at an increased frequency, they are automatically cross-referenced with a master client list (also piped into the platform) to know if we work for a specific entity that is getting increased attention mentioned. A word cloud and/or other visualizations are created to determine the type of conversation around the entities on the client list with increased mentions. This is all accessible through some sort of dashboard that anyone can access in realtime. &lt;/p&gt;

&lt;p&gt;A separate pipe can also do the same thing with social media to build a broad context for topics as they develop. &lt;/p&gt;

&lt;p&gt;I imagine there are large financial institutions that have some sort of monitoring system like this already set up although I don&amp;#39;t know of any. If any geopolitical or large development will trigger information they need to know, it predicts it will be an issue before it is an issue. Knowing nothing about data or machine learning, what would be the best way to attack this? Am I even approaching the right group of people? Do systems like this already exist? I am very, very lost (cringe face)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",huseg9,gfnofxc22,7,/r/datascience/comments/huseg9/im_a_lot_puppy_with_daunting_task_am_i_in_the/,https://www.reddit.com/r/datascience/comments/huseg9/im_a_lot_puppy_with_daunting_task_am_i_in_the/,1595274862.0
r/datascience,"You landed your dream job, you love every minute... or so you thought. You find yourself disliking your department, or specific projects -- you can't wait for them to be over.

During this period of time, before you decide on jumping out the window, what is your last hope of bringing the fun back to DS?",t2_5e34w9d2,How do you make Data Science fun again?,discussion,t3_humhpt,0.5,0,Discussion,0,1595285100.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;You landed your dream job, you love every minute... or so you thought. You find yourself disliking your department, or specific projects -- you can&amp;#39;t wait for them to be over.&lt;/p&gt;

&lt;p&gt;During this period of time, before you decide on jumping out the window, what is your last hope of bringing the fun back to DS?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",humhpt,expatwithajetpack,8,/r/datascience/comments/humhpt/how_do_you_make_data_science_fun_again/,https://www.reddit.com/r/datascience/comments/humhpt/how_do_you_make_data_science_fun_again/,1595256300.0
r/datascience,"I work in a small data science team (5-ish people) at a large, non-tech company. We work with very large data sources and have solid infrastructure, but the technical skills of the team are very low. The team is all data scientists (myself included) with decent theoretical knowledge, but minimal experience with good coding/development practices.

I've worked as a (junior) software engineer in the past, and although I consider my knowledge to be pretty modest, it far exceeds that of the rest of the team. I'd like to introduce better practies to my current team, such as code reviews and writing tests, but I've never worked anywhere that had a great approach to development so I'm not sure how to go about it.

We mainly work on projects individually, that are usually unique and have little in common, so there's not much standardisation that can be done. We use git, but basically just commit straight to master, and most of our work is analsyis rather than anything that's productionised. It's rare for multiple people to work on the same codebase and even rarer to do so at the same time. We don't really use development methodologies like scrum/kanban, as we mostly work independently so people just manage their own work.

Any thoughts on where the best place to start would be? I'm not sure where to begin given the nature of our work and the low technical proficiency of the team. I want to help the rest of the team improve their coding, increase knowledge sharing, and generally work more efficiently. Thanks!",t2_15z0ih,How to introduce good engineering practices to a corporate data science team?,career,t3_htynsr,0.98,266,Career,266,1595184905.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work in a small data science team (5-ish people) at a large, non-tech company. We work with very large data sources and have solid infrastructure, but the technical skills of the team are very low. The team is all data scientists (myself included) with decent theoretical knowledge, but minimal experience with good coding/development practices.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve worked as a (junior) software engineer in the past, and although I consider my knowledge to be pretty modest, it far exceeds that of the rest of the team. I&amp;#39;d like to introduce better practies to my current team, such as code reviews and writing tests, but I&amp;#39;ve never worked anywhere that had a great approach to development so I&amp;#39;m not sure how to go about it.&lt;/p&gt;

&lt;p&gt;We mainly work on projects individually, that are usually unique and have little in common, so there&amp;#39;s not much standardisation that can be done. We use git, but basically just commit straight to master, and most of our work is analsyis rather than anything that&amp;#39;s productionised. It&amp;#39;s rare for multiple people to work on the same codebase and even rarer to do so at the same time. We don&amp;#39;t really use development methodologies like scrum/kanban, as we mostly work independently so people just manage their own work.&lt;/p&gt;

&lt;p&gt;Any thoughts on where the best place to start would be? I&amp;#39;m not sure where to begin given the nature of our work and the low technical proficiency of the team. I want to help the rest of the team improve their coding, increase knowledge sharing, and generally work more efficiently. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htynsr,OptimalPlay,33,/r/datascience/comments/htynsr/how_to_introduce_good_engineering_practices_to_a/,https://www.reddit.com/r/datascience/comments/htynsr/how_to_introduce_good_engineering_practices_to_a/,1595156105.0
r/datascience,"I’m sure like most people in this subreddit, I feel as though I have a decent grasp of a few different engines/languages, however I primarily use R. I feel as though if I were to be given a task, I have no doubts I could complete whatever it was in R; I don’t know all of the in’s and outs of R, but I feel as though I know enough resources to figure it out. The more and more I learn about R and the things I can do in R, the more and more I realize simply how much there is to learn (different packages, etc).

I feel as though I’m “proficient”, however at the same time it’s weird saying that as it almost feels like I know more of the “what” and “where” to look to solve error codes as opposed to just being able to solve them off the top of my head. Same with using different packages; I know where to look to find what I need moreso than what I have memorized off the top of my head. My question for those who consider themselves proficient in these languages: is this common for you as well? Am I still much more novice than I am proficient? For context, I’ve used R most days for the last year or so, so I do consider myself to have a solid grasp of it, I just feel like Ive almost learned how to manage error codes/problems more efficiently since I began more than I have memorized all of the intricate codes.",t2_4jo7xlko,Proficiency in Data Science Tools,tooling,t3_hunp1z,0.67,1,Tooling,1,1595289220.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m sure like most people in this subreddit, I feel as though I have a decent grasp of a few different engines/languages, however I primarily use R. I feel as though if I were to be given a task, I have no doubts I could complete whatever it was in R; I don’t know all of the in’s and outs of R, but I feel as though I know enough resources to figure it out. The more and more I learn about R and the things I can do in R, the more and more I realize simply how much there is to learn (different packages, etc).&lt;/p&gt;

&lt;p&gt;I feel as though I’m “proficient”, however at the same time it’s weird saying that as it almost feels like I know more of the “what” and “where” to look to solve error codes as opposed to just being able to solve them off the top of my head. Same with using different packages; I know where to look to find what I need moreso than what I have memorized off the top of my head. My question for those who consider themselves proficient in these languages: is this common for you as well? Am I still much more novice than I am proficient? For context, I’ve used R most days for the last year or so, so I do consider myself to have a solid grasp of it, I just feel like Ive almost learned how to manage error codes/problems more efficiently since I began more than I have memorized all of the intricate codes.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hunp1z,hungrygreg97,1,/r/datascience/comments/hunp1z/proficiency_in_data_science_tools/,https://www.reddit.com/r/datascience/comments/hunp1z/proficiency_in_data_science_tools/,1595260420.0
r/datascience,"Trying to write a one-pager for a memo and was hoping to get some feedback about it. Please let me know if I missed something or misunderstood something?

The Data Science workflow starts with a business problem or objective that needs to be resolved. The data science team takes the problem at hand, and works through different stages to explore, clean and analyze the data to produce ML models that can solve business

1.   Data Cleaning turns the source “raw data” into a “clean” form. This takes a significant amount of time because most raw data is unclean, meaning steps need to be taken to improve the quality and develop it into a format that machines can interpret and learn from.

2.   Feature Engineering: Feature engineering is the process of taking a dataset and identifying explanatory variables  or “ features” that can be used to train a machine learning model for predictive analytics. Often, this involves merging data spread across multiple tables and gathered into a single table with rows containing the observations and features in the columns. This step is generally the most intensive part of the workflow, from a human perspective, as it requires a careful understanding of the problem and domain knowledge.

3.   Model Selection, Model Training and Deployment Model selection plays a crucial role in building good machine learning models. ML model selection requires selecting the best hyperparameters and algorithmic selection. A lot of model selection is now performed through automated software packages. Models are tested by exposing them to new data, providing an unbiased estimate of its performance.

4.   Exploratory Analysis Throughout the life of the data science project, the data science team will constantly sidestep from the main modeling pipeline to explore the data, try out various hypotheses.",t2_duwi1h3,Data Science Workflow - did I get this right?,education,t3_huama9,0.92,17,Education,17,1595230464.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Trying to write a one-pager for a memo and was hoping to get some feedback about it. Please let me know if I missed something or misunderstood something?&lt;/p&gt;

&lt;p&gt;The Data Science workflow starts with a business problem or objective that needs to be resolved. The data science team takes the problem at hand, and works through different stages to explore, clean and analyze the data to produce ML models that can solve business&lt;/p&gt;

&lt;p&gt;1.   Data Cleaning turns the source “raw data” into a “clean” form. This takes a significant amount of time because most raw data is unclean, meaning steps need to be taken to improve the quality and develop it into a format that machines can interpret and learn from.&lt;/p&gt;

&lt;p&gt;2.   Feature Engineering: Feature engineering is the process of taking a dataset and identifying explanatory variables  or “ features” that can be used to train a machine learning model for predictive analytics. Often, this involves merging data spread across multiple tables and gathered into a single table with rows containing the observations and features in the columns. This step is generally the most intensive part of the workflow, from a human perspective, as it requires a careful understanding of the problem and domain knowledge.&lt;/p&gt;

&lt;p&gt;3.   Model Selection, Model Training and Deployment Model selection plays a crucial role in building good machine learning models. ML model selection requires selecting the best hyperparameters and algorithmic selection. A lot of model selection is now performed through automated software packages. Models are tested by exposing them to new data, providing an unbiased estimate of its performance.&lt;/p&gt;

&lt;p&gt;4.   Exploratory Analysis Throughout the life of the data science project, the data science team will constantly sidestep from the main modeling pipeline to explore the data, try out various hypotheses.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",huama9,Electric_pokemon,7,/r/datascience/comments/huama9/data_science_workflow_did_i_get_this_right/,https://www.reddit.com/r/datascience/comments/huama9/data_science_workflow_did_i_get_this_right/,1595201664.0
r/datascience,"Hi,

I have experience in feature engineering mostly in a manufacturing domain.

I’m not aware of any conferences or societies around this topic specifically.  Does anyone know of any or are interested in the idea of creating one like a Feature Engineering Society?

My opinion is that feature engineering is one of the most important and vast layers of data science and ML.  A conference like this would help to expand the knowledge and collaboration. 


Thanks,
Alex
SeasonWarez",t2_5alo63z6,“Feature Engineering Society”,network,t3_huaqmy,0.78,5,Networking,5,1595230893.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I have experience in feature engineering mostly in a manufacturing domain.&lt;/p&gt;

&lt;p&gt;I’m not aware of any conferences or societies around this topic specifically.  Does anyone know of any or are interested in the idea of creating one like a Feature Engineering Society?&lt;/p&gt;

&lt;p&gt;My opinion is that feature engineering is one of the most important and vast layers of data science and ML.  A conference like this would help to expand the knowledge and collaboration. &lt;/p&gt;

&lt;p&gt;Thanks,
Alex
SeasonWarez&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",huaqmy,seasonwarez,14,/r/datascience/comments/huaqmy/feature_engineering_society/,https://www.reddit.com/r/datascience/comments/huaqmy/feature_engineering_society/,1595202093.0
r/datascience,"I wanted to hear what others think about automated feature engineering and their experience dealing with Featuretools?

I have personally always thought that automation was going to play a big role in data cleaning as well as picking ML models, but feature engineering was supposed to be the place where domain knowledge and critical thinking plays the most significant role (and cannot be automated).",t2_duwi1h3,Automated Feature Engineering?,education,t3_hu8v0w,0.8,3,Education,3,1595223998.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I wanted to hear what others think about automated feature engineering and their experience dealing with Featuretools?&lt;/p&gt;

&lt;p&gt;I have personally always thought that automation was going to play a big role in data cleaning as well as picking ML models, but feature engineering was supposed to be the place where domain knowledge and critical thinking plays the most significant role (and cannot be automated).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hu8v0w,Electric_pokemon,8,/r/datascience/comments/hu8v0w/automated_feature_engineering/,https://www.reddit.com/r/datascience/comments/hu8v0w/automated_feature_engineering/,1595195198.0
r/datascience,Im a newbie and learning Data Science and since its a very broad field I wonder how much do Data Science professionals look for solutions of another people works?,t2_oxk1j,How much of Data Science work is to look for solutions from works of other people on the Internet?,discussion,t3_huc44f,0.75,2,Discussion,2,1595236339.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im a newbie and learning Data Science and since its a very broad field I wonder how much do Data Science professionals look for solutions of another people works?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",huc44f,PinstripePride97,7,/r/datascience/comments/huc44f/how_much_of_data_science_work_is_to_look_for/,https://www.reddit.com/r/datascience/comments/huc44f/how_much_of_data_science_work_is_to_look_for/,1595207539.0
r/datascience,"My company is transitioning to using Oracle Cloud for hosting external docs, as a result this affects my team because our vendor invoices will now be through something called S2P. I've been tasked with researching new ways to do reporting for our team where multiple users can interact with data and edit fields to show what has been approved, rejected, etc. in S2P. I'm currently troubleshooting with Power BI to see if it will fulfill what we need. I'm running into an issue with Power BI, however, because even though I've successfully tested that we can host a data source through Service, any forum I find on the topic will say that only the Owner can edit fields (ex: a record in Excel). 

Is there a work-around to this in Power BI? My past experience has been primarily in school so I'm still fairly new to using this, I would really like to find a solution for my team as they were previously using Access on a VPN which could be a nightmare. I'm also curious if there's a better avenue other than using Power BI so I'm open to any suggestions. Unfortunately this isn't something we can just throw into a Shared drive (too clunky/slow for multiple users who are editing) nor can we just host this type of data on something like Google Sheets.",t2_14vhpn,Building a new reporting tool for multiple users,tooling,t3_hu84wo,0.8,3,Tooling,3,1595221520.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My company is transitioning to using Oracle Cloud for hosting external docs, as a result this affects my team because our vendor invoices will now be through something called S2P. I&amp;#39;ve been tasked with researching new ways to do reporting for our team where multiple users can interact with data and edit fields to show what has been approved, rejected, etc. in S2P. I&amp;#39;m currently troubleshooting with Power BI to see if it will fulfill what we need. I&amp;#39;m running into an issue with Power BI, however, because even though I&amp;#39;ve successfully tested that we can host a data source through Service, any forum I find on the topic will say that only the Owner can edit fields (ex: a record in Excel). &lt;/p&gt;

&lt;p&gt;Is there a work-around to this in Power BI? My past experience has been primarily in school so I&amp;#39;m still fairly new to using this, I would really like to find a solution for my team as they were previously using Access on a VPN which could be a nightmare. I&amp;#39;m also curious if there&amp;#39;s a better avenue other than using Power BI so I&amp;#39;m open to any suggestions. Unfortunately this isn&amp;#39;t something we can just throw into a Shared drive (too clunky/slow for multiple users who are editing) nor can we just host this type of data on something like Google Sheets.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hu84wo,BayerVelt,4,/r/datascience/comments/hu84wo/building_a_new_reporting_tool_for_multiple_users/,https://www.reddit.com/r/datascience/comments/hu84wo/building_a_new_reporting_tool_for_multiple_users/,1595192720.0
r/datascience,"Hey all,

As part of my work, I'm tasked with suggesting / finding imputation techniques to use with Spark (pyspark), and so far I've found [Petrozziello et al. 2018](https://www.researchgate.net/publication/328400525_Distributed_Neural_Networks_for_Missing_Big_Data_Imputation), [Kaliamoorthy et al. 2018](https://sci-hub.tw/10.1007/978-981-13-1813-9_3), and [Montesdeoca et al. 2019](https://www.scitepress.org/Papers/2019/77384/77384.pdf). 

In general, I was wondering what makes these able to be scaled to Big Data, and not an approach like MICE.",t2_1dcgyvco,What factors go into an imputation method being appropriate for Big Data uses?,education,t3_hu8kxo,0.75,2,Education,2,1595223025.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all,&lt;/p&gt;

&lt;p&gt;As part of my work, I&amp;#39;m tasked with suggesting / finding imputation techniques to use with Spark (pyspark), and so far I&amp;#39;ve found &lt;a href=""https://www.researchgate.net/publication/328400525_Distributed_Neural_Networks_for_Missing_Big_Data_Imputation""&gt;Petrozziello et al. 2018&lt;/a&gt;, &lt;a href=""https://sci-hub.tw/10.1007/978-981-13-1813-9_3""&gt;Kaliamoorthy et al. 2018&lt;/a&gt;, and &lt;a href=""https://www.scitepress.org/Papers/2019/77384/77384.pdf""&gt;Montesdeoca et al. 2019&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;In general, I was wondering what makes these able to be scaled to Big Data, and not an approach like MICE.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hu8kxo,ZealousRedLobster,2,/r/datascience/comments/hu8kxo/what_factors_go_into_an_imputation_method_being/,https://www.reddit.com/r/datascience/comments/hu8kxo/what_factors_go_into_an_imputation_method_being/,1595194225.0
r/datascience,"I follow this amazing course done by [mlcourse.ai](https://mlcourse.ai), but I have a problem interpreting one cross-validation scheme for LTV prediction and no one seems to explain to me why this is done in such a way.

I know that time-series data should be ordered such that we don't introduce any data leaks from the future in our training set. I am also familiarized with the 'rolling cross-validation' for time-series data, but here I don't understand why if we order data points via date-time we make training set for one month and we have to SKIP one month in order to get validation set? What is the point of skipping months?

Here is the video and an explanation of this scheme starts from 23:10:[https://youtu.be/B8yIaIEMyIc](https://youtu.be/B8yIaIEMyIc)

&amp;#x200B;

@ EDIT   
There is a notebook in the video description if you want to familiarize with the dataset a bit. ",t2_124xcawu,Problem interpreting this LTV cross-validation scheme,discussion,t3_hu5t37,1.0,2,Discussion,2,1595213615.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I follow this amazing course done by &lt;a href=""https://mlcourse.ai""&gt;mlcourse.ai&lt;/a&gt;, but I have a problem interpreting one cross-validation scheme for LTV prediction and no one seems to explain to me why this is done in such a way.&lt;/p&gt;

&lt;p&gt;I know that time-series data should be ordered such that we don&amp;#39;t introduce any data leaks from the future in our training set. I am also familiarized with the &amp;#39;rolling cross-validation&amp;#39; for time-series data, but here I don&amp;#39;t understand why if we order data points via date-time we make training set for one month and we have to SKIP one month in order to get validation set? What is the point of skipping months?&lt;/p&gt;

&lt;p&gt;Here is the video and an explanation of this scheme starts from 23:10:&lt;a href=""https://youtu.be/B8yIaIEMyIc""&gt;https://youtu.be/B8yIaIEMyIc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;@ EDIT&lt;br/&gt;
There is a notebook in the video description if you want to familiarize with the dataset a bit. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hu5t37,maybenexttime82,9,/r/datascience/comments/hu5t37/problem_interpreting_this_ltv_crossvalidation/,https://www.reddit.com/r/datascience/comments/hu5t37/problem_interpreting_this_ltv_crossvalidation/,1595184815.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 19 Jul 2020 - 26 Jul 2020,,t3_htzdso,0.9,7,Discussion,7,1595188830.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htzdso,datascience-bot,171,/r/datascience/comments/htzdso/weekly_entering_transitioning_thread_19_jul_2020/,https://www.reddit.com/r/datascience/comments/htzdso/weekly_entering_transitioning_thread_19_jul_2020/,1595160030.0
r/datascience,"I'm currently working on a project to identify and extract specific identifiers from text documents. The current process the documents go through a third party RPA vendor that uses machine learning (some custom NER I think) to extract the identifiers. 

Currently they are only able to extract the identifiers 26% of the time. We opted to just build a rules based regex since the identifiers are specific alpha numeric patterns (Always a specific length, always start with one of four unique patterns, always contains a specific letter, etc..). The initial POC showed we were extracting the identifier 74% of the time. 

Leadership is pretty hooked on being able to say they are using ML. Should we be combing outputs or build our own NER on top of the regex pattern? Initial thoughts are the pattern appears to be working pretty well and I don't want to over engineer a solution.",t2_1n8owavv,Regex or NER or Other ideas?,projects,t3_hu3eaw,1.0,2,Projects,2,1595205397.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently working on a project to identify and extract specific identifiers from text documents. The current process the documents go through a third party RPA vendor that uses machine learning (some custom NER I think) to extract the identifiers. &lt;/p&gt;

&lt;p&gt;Currently they are only able to extract the identifiers 26% of the time. We opted to just build a rules based regex since the identifiers are specific alpha numeric patterns (Always a specific length, always start with one of four unique patterns, always contains a specific letter, etc..). The initial POC showed we were extracting the identifier 74% of the time. &lt;/p&gt;

&lt;p&gt;Leadership is pretty hooked on being able to say they are using ML. Should we be combing outputs or build our own NER on top of the regex pattern? Initial thoughts are the pattern appears to be working pretty well and I don&amp;#39;t want to over engineer a solution.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hu3eaw,DS_throwitaway,4,/r/datascience/comments/hu3eaw/regex_or_ner_or_other_ideas/,https://www.reddit.com/r/datascience/comments/hu3eaw/regex_or_ner_or_other_ideas/,1595176597.0
r/datascience,"Hi, I am working on predicting wich customers will churn and need some help.

I am having doubts on how to approach the creation of the data set. Even asking the question is somewhat difficult to explain for me.

&amp;#x200B;

We have 250,000 clients, 1,500 churn every month, that is, approximately 0.6% per month churn . It is very unbalanced.

I have the data for 18 months, that means that I have 18 times the database of 250,000 clients (4.5M rows) and marked the 27,000 clients who have churned those 18 months (1,500 churn \* 18 months).

Of those 4.5 million records, there are many repeat customers, since if they did not churn , they will remain in the database the following month.

My question is how do I build the dataset. I suppose I have to select the 27,000 cases that churned as the class to be predicted, but how do I go about selecting the records for the classes that did not churn?

I was thinking of transforming the non-churn class to unique registers, but what register do I take? The last record, the first, random?

What other approach would youfollow or have you followed in similar cases?

&amp;#x200B;

I also found in kaggle someone with a similar question, but without answers, maybe if my question is not understood you can read a different wording.

[https://www.kaggle.com/blastchar/telco-customer-churn/discussion/63281](https://www.kaggle.com/blastchar/telco-customer-churn/discussion/63281)

&amp;#x200B;

Thank you!",t2_573vvx2f,How do you build your data set to predict customer churn?,discussion,t3_htp9vl,0.91,52,Discussion,52,1595139151.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I am working on predicting wich customers will churn and need some help.&lt;/p&gt;

&lt;p&gt;I am having doubts on how to approach the creation of the data set. Even asking the question is somewhat difficult to explain for me.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;We have 250,000 clients, 1,500 churn every month, that is, approximately 0.6% per month churn . It is very unbalanced.&lt;/p&gt;

&lt;p&gt;I have the data for 18 months, that means that I have 18 times the database of 250,000 clients (4.5M rows) and marked the 27,000 clients who have churned those 18 months (1,500 churn * 18 months).&lt;/p&gt;

&lt;p&gt;Of those 4.5 million records, there are many repeat customers, since if they did not churn , they will remain in the database the following month.&lt;/p&gt;

&lt;p&gt;My question is how do I build the dataset. I suppose I have to select the 27,000 cases that churned as the class to be predicted, but how do I go about selecting the records for the classes that did not churn?&lt;/p&gt;

&lt;p&gt;I was thinking of transforming the non-churn class to unique registers, but what register do I take? The last record, the first, random?&lt;/p&gt;

&lt;p&gt;What other approach would youfollow or have you followed in similar cases?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I also found in kaggle someone with a similar question, but without answers, maybe if my question is not understood you can read a different wording.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.kaggle.com/blastchar/telco-customer-churn/discussion/63281""&gt;https://www.kaggle.com/blastchar/telco-customer-churn/discussion/63281&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htp9vl,seba_sm,21,/r/datascience/comments/htp9vl/how_do_you_build_your_data_set_to_predict/,https://www.reddit.com/r/datascience/comments/htp9vl/how_do_you_build_your_data_set_to_predict/,1595110351.0
r/datascience,"Hi,

I am working in a company as data analyst / database manager and I would like to slowly shift to ""real"" data science.

I have very solid SQL (T-SQL to be precise) skills, Excel from A to Z and also its VBA scripting language I am able to programm Web Crawler / Web Scrapers, and other useful automation staff. About analysis,  I am no statistician (I studied economy) but I am a statistic enthusiast and at work I regularly use techniques like multiple regression, logistic regression to build scoring for customer groups etc,.. Other than that, the ""regular"" statistics (T-test for difference between groups, variation analysis, etc....) is also something I use.

I would describe myself more expert in the Database side  of the job though (50% of my working time I write queries in SQL).

What would be the next usefull skill I should learn? Time is not a problem, but the things I would like to learn should help me slowly switch to a proper ""data science"" role. I would love to learn techniques that are relevant for marketing purposes.

Any suggestion is highly appreciated! Thanks!

Edit: forgot to add -&gt; I have some experience in SPSS and can use R but I am not a huge expert in R. I can use R for the techniques I mentioned above and some easy stuff.",t2_5l4q82cj,What skills should I learn next?,career,t3_htjqsi,0.92,117,Career,117,1595119656.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I am working in a company as data analyst / database manager and I would like to slowly shift to &amp;quot;real&amp;quot; data science.&lt;/p&gt;

&lt;p&gt;I have very solid SQL (T-SQL to be precise) skills, Excel from A to Z and also its VBA scripting language I am able to programm Web Crawler / Web Scrapers, and other useful automation staff. About analysis,  I am no statistician (I studied economy) but I am a statistic enthusiast and at work I regularly use techniques like multiple regression, logistic regression to build scoring for customer groups etc,.. Other than that, the &amp;quot;regular&amp;quot; statistics (T-test for difference between groups, variation analysis, etc....) is also something I use.&lt;/p&gt;

&lt;p&gt;I would describe myself more expert in the Database side  of the job though (50% of my working time I write queries in SQL).&lt;/p&gt;

&lt;p&gt;What would be the next usefull skill I should learn? Time is not a problem, but the things I would like to learn should help me slowly switch to a proper &amp;quot;data science&amp;quot; role. I would love to learn techniques that are relevant for marketing purposes.&lt;/p&gt;

&lt;p&gt;Any suggestion is highly appreciated! Thanks!&lt;/p&gt;

&lt;p&gt;Edit: forgot to add -&amp;gt; I have some experience in SPSS and can use R but I am not a huge expert in R. I can use R for the techniques I mentioned above and some easy stuff.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htjqsi,Beavisx_K_90,51,/r/datascience/comments/htjqsi/what_skills_should_i_learn_next/,https://www.reddit.com/r/datascience/comments/htjqsi/what_skills_should_i_learn_next/,1595090856.0
r/datascience,"I am looking around for people with a analytics or data science background working in the recruitment industry, say with firms like Kelly Services, Randstad, etc. for some insight into how they use data for their recruiting/staffing practices. For instance, I am interested in understanding whether they are generally interested in people with a background in labour econometrics. Thank you, any leads will be appreciated!",t2_6i16800p,What are the skills that a data scientist should have in the recruitment/staffing industry?,career,t3_htvrk4,0.91,9,Career,9,1595167399.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am looking around for people with a analytics or data science background working in the recruitment industry, say with firms like Kelly Services, Randstad, etc. for some insight into how they use data for their recruiting/staffing practices. For instance, I am interested in understanding whether they are generally interested in people with a background in labour econometrics. Thank you, any leads will be appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htvrk4,circumbhoos,4,/r/datascience/comments/htvrk4/what_are_the_skills_that_a_data_scientist_should/,https://www.reddit.com/r/datascience/comments/htvrk4/what_are_the_skills_that_a_data_scientist_should/,1595138599.0
r/datascience,"Python and R are the most popular languages for data science and obviously they are still worth learning.  But [this article](https://towardsdatascience.com/why-python-is-not-the-programming-language-of-the-future-30ddc5339b66) says that either rust, go, or julia will replace python in the future.  Does this apply to data science or just software engineering?  Are there any good data science or machine learning libraries for rust, go, or julia?",t2_3x306odo,Language to Surpass Python for Data Science,discussion,t3_hu0e3f,0.5,0,Discussion,0,1595193684.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Python and R are the most popular languages for data science and obviously they are still worth learning.  But &lt;a href=""https://towardsdatascience.com/why-python-is-not-the-programming-language-of-the-future-30ddc5339b66""&gt;this article&lt;/a&gt; says that either rust, go, or julia will replace python in the future.  Does this apply to data science or just software engineering?  Are there any good data science or machine learning libraries for rust, go, or julia?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hu0e3f,battle-obsessed,12,/r/datascience/comments/hu0e3f/language_to_surpass_python_for_data_science/,https://www.reddit.com/r/datascience/comments/hu0e3f/language_to_surpass_python_for_data_science/,1595164884.0
r/datascience,"IS Datacamp a good resource for learning Data Science? 

If not, are there other better resources you would recommend? Thanks!",t2_wi45w,Thoughts on Datacamp?,career,t3_hu13u0,0.5,0,Career,0,1595196714.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;IS Datacamp a good resource for learning Data Science? &lt;/p&gt;

&lt;p&gt;If not, are there other better resources you would recommend? Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hu13u0,bjj17,10,/r/datascience/comments/hu13u0/thoughts_on_datacamp/,https://www.reddit.com/r/datascience/comments/hu13u0/thoughts_on_datacamp/,1595167914.0
r/datascience,"Hi, 

I got an interview with a health insurance company soon and the problems they are working on deals with predicting when a patient is due to fill their prescription drugs and pricing risks (for drugs). I want to wow them by thinking of a few approaches to such problems. 

Can you recommend a few commonly accepted tools/approaches for such problems and I can dig deeper? 

Thanks",t2_33bizuj,common approaches for pricing risk problems?,discussion,t3_htno1d,0.86,9,Discussion,9,1595133304.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, &lt;/p&gt;

&lt;p&gt;I got an interview with a health insurance company soon and the problems they are working on deals with predicting when a patient is due to fill their prescription drugs and pricing risks (for drugs). I want to wow them by thinking of a few approaches to such problems. &lt;/p&gt;

&lt;p&gt;Can you recommend a few commonly accepted tools/approaches for such problems and I can dig deeper? &lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htno1d,engineheat,9,/r/datascience/comments/htno1d/common_approaches_for_pricing_risk_problems/,https://www.reddit.com/r/datascience/comments/htno1d/common_approaches_for_pricing_risk_problems/,1595104504.0
r/datascience,"Hi, this question is probably being asked many times. I just graduated, learned basics of R, Python, SQL, and a bit of statistical modeling such regression, time series, monte carlo, linear optimization, together with calculus sequence, stats/probs sequence and a bit of business such as economics, finance, and accounting. I’d like to start as data analyst/data scientist but feel a bit lost. Udemy seems like plug and chug, rushed towards next topic and I miss projects... yet I’m unable to envision where to start on my own and miss skills, what to do, where to get data from, questions to ask... I’m lost in this big world of data and overwhelming amount of information and I need to be swift and precise. At the same time, I’m a career changer in early 30’s, I can’t just stare in ceiling and hope for best, as there is nobody that can support me. People, what’s your take on this situation? I live in Chicago, there are lots of positions but job requirements are long...",t2_4jzthfp5,Filling gaps in technical skills and entering the field?(Late bloomer in search of advice),career,t3_htgon3,0.92,21,Career,21,1595108029.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, this question is probably being asked many times. I just graduated, learned basics of R, Python, SQL, and a bit of statistical modeling such regression, time series, monte carlo, linear optimization, together with calculus sequence, stats/probs sequence and a bit of business such as economics, finance, and accounting. I’d like to start as data analyst/data scientist but feel a bit lost. Udemy seems like plug and chug, rushed towards next topic and I miss projects... yet I’m unable to envision where to start on my own and miss skills, what to do, where to get data from, questions to ask... I’m lost in this big world of data and overwhelming amount of information and I need to be swift and precise. At the same time, I’m a career changer in early 30’s, I can’t just stare in ceiling and hope for best, as there is nobody that can support me. People, what’s your take on this situation? I live in Chicago, there are lots of positions but job requirements are long...&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htgon3,thats-fascinating,19,/r/datascience/comments/htgon3/filling_gaps_in_technical_skills_and_entering_the/,https://www.reddit.com/r/datascience/comments/htgon3/filling_gaps_in_technical_skills_and_entering_the/,1595079229.0
r/datascience,"So I have lets say 1000+ names of cyber security companies and I need to find jobs they advertise. Rather than manually visiting the website I want to setup a solution which does

Input: Website address + Text to search

Expected output: career pages which shows keywords like ""Sr. Security Engineer"" etc. Then I can manually visit those pages to explore more. 

&amp;#x200B;

Option 2:

The tool automatically gives me direct link to the career page of the company so I don't need to google each of them and reach the site. 

I have a 150mb connection and a decent PC at home so I think I do have the resources. Also do companies restrict crawling on their websites ?

Is there any tool which can help me with the requirement?",t2_n7oc1vv,web scraping for jobs,tooling,t3_htvayb,0.5,0,Tooling,0,1595164929.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have lets say 1000+ names of cyber security companies and I need to find jobs they advertise. Rather than manually visiting the website I want to setup a solution which does&lt;/p&gt;

&lt;p&gt;Input: Website address + Text to search&lt;/p&gt;

&lt;p&gt;Expected output: career pages which shows keywords like &amp;quot;Sr. Security Engineer&amp;quot; etc. Then I can manually visit those pages to explore more. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Option 2:&lt;/p&gt;

&lt;p&gt;The tool automatically gives me direct link to the career page of the company so I don&amp;#39;t need to google each of them and reach the site. &lt;/p&gt;

&lt;p&gt;I have a 150mb connection and a decent PC at home so I think I do have the resources. Also do companies restrict crawling on their websites ?&lt;/p&gt;

&lt;p&gt;Is there any tool which can help me with the requirement?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htvayb,anjan42,5,/r/datascience/comments/htvayb/web_scraping_for_jobs/,https://www.reddit.com/r/datascience/comments/htvayb/web_scraping_for_jobs/,1595136129.0
r/datascience,"Hi everyone,

I'm one of the developers that have been working on a package that enables faster hyperparameter tuning for machine learning models. We recognized that sklearn's GridSearchCV is too slow, especially for today's larger models and datasets, so we're introducing [tune-sklearn](https://github.com/ray-project/tune-sklearn). Just 1 line of code to superpower Grid/Random Search with

* Bayesian Optimization
* Early Stopping
* Distributed Execution using Ray Tune
* GPU support

Check out our blog post here and let us know what you think!

[https://medium.com/distributed-computing-with-ray/gridsearchcv-2-0-new-and-improved-ee56644cbabf](https://medium.com/distributed-computing-with-ray/gridsearchcv-2-0-new-and-improved-ee56644cbabf)

&amp;#x200B;

Installing [tune-sklearn](https://github.com/ray-project/tune-sklearn):

`pip install tune-sklearn scikit-optimize ray[tune]` or `pip install tune-sklearn scikit-optimize ""ray[tune]""` depending on your os.

Quick Example:

    from tune_sklearn import TuneSearchCV
    
    # Other imports
    import scipy
    from sklearn.datasets import make_classification
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import SGDClassifier
    
    # Set training and validation sets
    X, y = make_classification(n_samples=11000, n_features=1000, n_informative=50, 
                               n_redundant=0, n_classes=10, class_sep=2.5)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000)
    
    # Example parameter distributions to tune from SGDClassifier
    # Note the use of tuples instead if Bayesian optimization is desired
    param_dists = {
       'alpha': (1e-4, 1e-1),
       'epsilon': (1e-2, 1e-1)
    }
    
    tune_search = TuneSearchCV(SGDClassifier(),
       param_distributions=param_dists,
       n_iter=2,
       early_stopping=True,
       max_iters=10,
       search_optimization=""bayesian""
    )
    
    tune_search.fit(X_train, y_train)
    print(tune_search.best_params_) 

Additional Links:

* Documentation: [https://docs.ray.io/en/master/tune/api\_docs/sklearn.html](https://docs.ray.io/en/master/tune/api_docs/sklearn.html)
* Github: [https://github.com/ray-project/tune-sklearn](https://github.com/ray-project/tune-sklearn)",t2_ht3qy,GridSearchCV 2.0 - Up to 10x faster than sklearn,projects,t3_ht26ec,0.99,448,Projects,448,1595043039.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m one of the developers that have been working on a package that enables faster hyperparameter tuning for machine learning models. We recognized that sklearn&amp;#39;s GridSearchCV is too slow, especially for today&amp;#39;s larger models and datasets, so we&amp;#39;re introducing &lt;a href=""https://github.com/ray-project/tune-sklearn""&gt;tune-sklearn&lt;/a&gt;. Just 1 line of code to superpower Grid/Random Search with&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bayesian Optimization&lt;/li&gt;
&lt;li&gt;Early Stopping&lt;/li&gt;
&lt;li&gt;Distributed Execution using Ray Tune&lt;/li&gt;
&lt;li&gt;GPU support&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Check out our blog post here and let us know what you think!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://medium.com/distributed-computing-with-ray/gridsearchcv-2-0-new-and-improved-ee56644cbabf""&gt;https://medium.com/distributed-computing-with-ray/gridsearchcv-2-0-new-and-improved-ee56644cbabf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Installing &lt;a href=""https://github.com/ray-project/tune-sklearn""&gt;tune-sklearn&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pip install tune-sklearn scikit-optimize ray[tune]&lt;/code&gt; or &lt;code&gt;pip install tune-sklearn scikit-optimize &amp;quot;ray[tune]&amp;quot;&lt;/code&gt; depending on your os.&lt;/p&gt;

&lt;p&gt;Quick Example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from tune_sklearn import TuneSearchCV

# Other imports
import scipy
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier

# Set training and validation sets
X, y = make_classification(n_samples=11000, n_features=1000, n_informative=50, 
                           n_redundant=0, n_classes=10, class_sep=2.5)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000)

# Example parameter distributions to tune from SGDClassifier
# Note the use of tuples instead if Bayesian optimization is desired
param_dists = {
   &amp;#39;alpha&amp;#39;: (1e-4, 1e-1),
   &amp;#39;epsilon&amp;#39;: (1e-2, 1e-1)
}

tune_search = TuneSearchCV(SGDClassifier(),
   param_distributions=param_dists,
   n_iter=2,
   early_stopping=True,
   max_iters=10,
   search_optimization=&amp;quot;bayesian&amp;quot;
)

tune_search.fit(X_train, y_train)
print(tune_search.best_params_) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Additional Links:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Documentation: &lt;a href=""https://docs.ray.io/en/master/tune/api_docs/sklearn.html""&gt;https://docs.ray.io/en/master/tune/api_docs/sklearn.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github: &lt;a href=""https://github.com/ray-project/tune-sklearn""&gt;https://github.com/ray-project/tune-sklearn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ht26ec,inventormc,60,/r/datascience/comments/ht26ec/gridsearchcv_20_up_to_10x_faster_than_sklearn/,https://www.reddit.com/r/datascience/comments/ht26ec/gridsearchcv_20_up_to_10x_faster_than_sklearn/,1595014239.0
r/datascience,"I work in fin tech and would like to build some sort of simulation program to assess how different inputs will impact net revenue. For example, if we create new policies based on ML shoes, how would those have impacted our loss and revenue metrics. 

While we can and do run online experiments, it would be desirable to simulate these impacts ahead of time. 

Aside from something like reinforcement learning, I was thinking that Monte Carlo simulations might be the best approach. Anyone do something similar before or have suggestions?",t2_8qco4,Building a risk simulation,projects,t3_htu2xq,0.67,1,Projects,1,1595158960.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work in fin tech and would like to build some sort of simulation program to assess how different inputs will impact net revenue. For example, if we create new policies based on ML shoes, how would those have impacted our loss and revenue metrics. &lt;/p&gt;

&lt;p&gt;While we can and do run online experiments, it would be desirable to simulate these impacts ahead of time. &lt;/p&gt;

&lt;p&gt;Aside from something like reinforcement learning, I was thinking that Monte Carlo simulations might be the best approach. Anyone do something similar before or have suggestions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htu2xq,maxismyboxersname,1,/r/datascience/comments/htu2xq/building_a_risk_simulation/,https://www.reddit.com/r/datascience/comments/htu2xq/building_a_risk_simulation/,1595130160.0
r/datascience,"
The problem is that we often have a scenario where a piece of work will
involve multiple steps, they're to be delivered in a pretty short space
of time, and changes are often requested later on (""*_can you filter by x%
instead of y% for z?*"", or whatever).

What has been done previously is that an issue is created for a piece of
analysis and everything is done there - the problem is that it's really damn
hard to manage all the commentary / defining scope / seeing what needs to be
done when everything is in one place (imo). So - instead of this - each
subtask of a particular piece of a project is broken out into a separate
issue, each with a particular deliverable.

This makes sense - but where it becomes a bit trickier is when I might want
to be able to borrow a bit of code from one issue to another, if they're all
siloed this makes things harder to do. So, I guess I would want to merge them
into the ""main issue"" repeatedly, I'm not really sure though.

So - in this scenario I have something like

```
├── master
│   ├── analysis_project
│   │   ├── task_1
│   │   └── task_2
│   │   └── task_3
│   │   └── task_4
│   │   └── task_5
...
```

And I'm asking - if you were to do something along these lines how would you
approach it?

You could have a branch off `analysis_project`, and just use the issues on
github to document the work being done on the tasks, but not actually have
branches for them.

Or, you could have a branch for `task_1`, `task_2`, `task_3` etc and when you
feel the task is complete (or near enough ish) merge it back into
`analysis_project`? How would you handle changes to the tasks in this setup?

Maybe there's an established workflow? That'd be nice.


# Edit

In response to a comment below the following context was given. 


________________


notebooks are used a lot but generally I try and use notebooks as a
luxurious `breakpoint()`, as soon as there's code that's code a reasonable
structure it's going into a module.

&gt; How you perform your analysis and reporting is going to have a huge influence

Yeah. So, a common scenario is that something will spin up very quickly (eg
&lt;24 hours notice and the project is live) and can have delivery within 2
weeks or so. Typically there can be exploratory stuff, data cleaning /
processing and then plotting/analyis of the data. Not expecting anything to
seem too unusual there, but what I don't know really is the way to structure
things for this.

Say the work comes in and it's `X Analysis`, then there's a story (issue)
created `Analysis of Y for X`, which contains an outline of the work that
needs to be done there might be a story created as:

```

Story S1

need to generate analysis for X, some data is located at &lt;somewhere&gt; and 
needs to be integrated into &lt;something&gt;, after which X needs EDA of &lt;y1 y2
y3&gt;, dead line for this is &lt;date&gt;.
```

Now - work could procede in a few ways afaik (there might be others too,
perhaps better!)

* 1 - create a branch `b0` for `S1`, and carry out all work within this branch
* 2 - Break the story out into separate tasks, and write up work for each of those tasks on the github issue, but keep all code within branch `b0`
* 3 - Break the story out into separate tasks, and write up work for each of those tasks on the github issue, for each task create a branch, so `b1 : gather data initial checks`, `b2 : integrate data into &lt;something&gt;`, `b3 : eda of &lt;y1 y2 y3&gt;`, once each task is completed merge into `b0`

Of the above I'm pretty sure that I don't like `1`, having *everything* on a single branch. For `2` and `3` I'm not too sure. `3` feels as though it would be the most ""textbook"", but there are scenarios where things are moving quickly and having *everything* on separate branches feels as though it might start getting a bit confusing, and if the client requests changes in something that's already been merged into `b0` then I guess I'd have to re-open, work on it, then merge it back in 🤔I'm not too sure really.",t2_4i904031,How do you manage workflow with git branches for an analysis project? All work on one branch or multiple?,discussion,t3_htfhxo,0.86,5,Discussion,5,1595102568.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The problem is that we often have a scenario where a piece of work will
involve multiple steps, they&amp;#39;re to be delivered in a pretty short space
of time, and changes are often requested later on (&amp;quot;&lt;em&gt;_can you filter by x%
instead of y% for z?&lt;/em&gt;&amp;quot;, or whatever).&lt;/p&gt;

&lt;p&gt;What has been done previously is that an issue is created for a piece of
analysis and everything is done there - the problem is that it&amp;#39;s really damn
hard to manage all the commentary / defining scope / seeing what needs to be
done when everything is in one place (imo). So - instead of this - each
subtask of a particular piece of a project is broken out into a separate
issue, each with a particular deliverable.&lt;/p&gt;

&lt;p&gt;This makes sense - but where it becomes a bit trickier is when I might want
to be able to borrow a bit of code from one issue to another, if they&amp;#39;re all
siloed this makes things harder to do. So, I guess I would want to merge them
into the &amp;quot;main issue&amp;quot; repeatedly, I&amp;#39;m not really sure though.&lt;/p&gt;

&lt;p&gt;So - in this scenario I have something like&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
├── master
│   ├── analysis_project
│   │   ├── task_1
│   │   └── task_2
│   │   └── task_3
│   │   └── task_4
│   │   └── task_5
...
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;And I&amp;#39;m asking - if you were to do something along these lines how would you
approach it?&lt;/p&gt;

&lt;p&gt;You could have a branch off &lt;code&gt;analysis_project&lt;/code&gt;, and just use the issues on
github to document the work being done on the tasks, but not actually have
branches for them.&lt;/p&gt;

&lt;p&gt;Or, you could have a branch for &lt;code&gt;task_1&lt;/code&gt;, &lt;code&gt;task_2&lt;/code&gt;, &lt;code&gt;task_3&lt;/code&gt; etc and when you
feel the task is complete (or near enough ish) merge it back into
&lt;code&gt;analysis_project&lt;/code&gt;? How would you handle changes to the tasks in this setup?&lt;/p&gt;

&lt;p&gt;Maybe there&amp;#39;s an established workflow? That&amp;#39;d be nice.&lt;/p&gt;

&lt;h1&gt;Edit&lt;/h1&gt;

&lt;p&gt;In response to a comment below the following context was given. &lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;notebooks are used a lot but generally I try and use notebooks as a
luxurious &lt;code&gt;breakpoint()&lt;/code&gt;, as soon as there&amp;#39;s code that&amp;#39;s code a reasonable
structure it&amp;#39;s going into a module.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;How you perform your analysis and reporting is going to have a huge influence&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Yeah. So, a common scenario is that something will spin up very quickly (eg
&amp;lt;24 hours notice and the project is live) and can have delivery within 2
weeks or so. Typically there can be exploratory stuff, data cleaning /
processing and then plotting/analyis of the data. Not expecting anything to
seem too unusual there, but what I don&amp;#39;t know really is the way to structure
things for this.&lt;/p&gt;

&lt;p&gt;Say the work comes in and it&amp;#39;s &lt;code&gt;X Analysis&lt;/code&gt;, then there&amp;#39;s a story (issue)
created &lt;code&gt;Analysis of Y for X&lt;/code&gt;, which contains an outline of the work that
needs to be done there might be a story created as:&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Story S1&lt;/p&gt;

&lt;p&gt;need to generate analysis for X, some data is located at &amp;lt;somewhere&amp;gt; and 
needs to be integrated into &amp;lt;something&amp;gt;, after which X needs EDA of &amp;lt;y1 y2
y3&amp;gt;, dead line for this is &amp;lt;date&amp;gt;.
```&lt;/p&gt;

&lt;p&gt;Now - work could procede in a few ways afaik (there might be others too,
perhaps better!)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1 - create a branch &lt;code&gt;b0&lt;/code&gt; for &lt;code&gt;S1&lt;/code&gt;, and carry out all work within this branch&lt;/li&gt;
&lt;li&gt;2 - Break the story out into separate tasks, and write up work for each of those tasks on the github issue, but keep all code within branch &lt;code&gt;b0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;3 - Break the story out into separate tasks, and write up work for each of those tasks on the github issue, for each task create a branch, so &lt;code&gt;b1 : gather data initial checks&lt;/code&gt;, &lt;code&gt;b2 : integrate data into &amp;lt;something&amp;gt;&lt;/code&gt;, &lt;code&gt;b3 : eda of &amp;lt;y1 y2 y3&amp;gt;&lt;/code&gt;, once each task is completed merge into &lt;code&gt;b0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Of the above I&amp;#39;m pretty sure that I don&amp;#39;t like &lt;code&gt;1&lt;/code&gt;, having &lt;em&gt;everything&lt;/em&gt; on a single branch. For &lt;code&gt;2&lt;/code&gt; and &lt;code&gt;3&lt;/code&gt; I&amp;#39;m not too sure. &lt;code&gt;3&lt;/code&gt; feels as though it would be the most &amp;quot;textbook&amp;quot;, but there are scenarios where things are moving quickly and having &lt;em&gt;everything&lt;/em&gt; on separate branches feels as though it might start getting a bit confusing, and if the client requests changes in something that&amp;#39;s already been merged into &lt;code&gt;b0&lt;/code&gt; then I guess I&amp;#39;d have to re-open, work on it, then merge it back in 🤔I&amp;#39;m not too sure really.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htfhxo,thatusername8346,14,/r/datascience/comments/htfhxo/how_do_you_manage_workflow_with_git_branches_for/,https://www.reddit.com/r/datascience/comments/htfhxo/how_do_you_manage_workflow_with_git_branches_for/,1595073768.0
r/datascience,I currently work as a database manager and analyst at a nonprofit. My analyst skills/experience are limited to prospect research and budget related analytics that are related to the nonprofit world. I have some experience working with Tableau and a decent amount of knowledge around SQL databases.  I would like to make the move to the for profit industry as an analyst and I think my skillset would be most transferable to the finance world. I would like to gain some certificates to further my knowledge but have no clue where to start in terms of proper certificates or courses to take. Any advice would be much appreciated!,t2_haazr7y,Could Use Some Career Advice,career,t3_htk15f,0.67,1,Career,1,1595120691.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I currently work as a database manager and analyst at a nonprofit. My analyst skills/experience are limited to prospect research and budget related analytics that are related to the nonprofit world. I have some experience working with Tableau and a decent amount of knowledge around SQL databases.  I would like to make the move to the for profit industry as an analyst and I think my skillset would be most transferable to the finance world. I would like to gain some certificates to further my knowledge but have no clue where to start in terms of proper certificates or courses to take. Any advice would be much appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htk15f,Caritas86,4,/r/datascience/comments/htk15f/could_use_some_career_advice/,https://www.reddit.com/r/datascience/comments/htk15f/could_use_some_career_advice/,1595091891.0
r/datascience,Curious what roles people have seen fellow DS move into outside of the typical managerial ladder.,t2_8tfjx,What roles have you seen DS move into?,discussion,t3_htamw4,0.75,4,Discussion,4,1595075301.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Curious what roles people have seen fellow DS move into outside of the typical managerial ladder.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",htamw4,boogieforward,2,/r/datascience/comments/htamw4/what_roles_have_you_seen_ds_move_into/,https://www.reddit.com/r/datascience/comments/htamw4/what_roles_have_you_seen_ds_move_into/,1595046501.0
r/datascience,"In a clustering problem I am using the gower distance, which results in a dissimilarity matrix.

Then I'm using k-medoids to clusterize.

So now if I read the medoids that result from k-medoids, then take the rows of the medoids from the dissimilarity matrix, and finally sum the cluster labels from that corresponding medoid in that row , what do I  obtain?

The total sum of the dissimilarity of that cluster?

Meaning this could be used as the within distance sum of that cluster?

My goal would be to use that sum as the elbow method.

Example below:

Dissimilarity Matrix

||row1|row2|row3|row4|row5|row6|row7|row8|row9|row10|
|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|
|row 1|0|0,0723|0,0736|0,0743|0,0825|0,0485|0,0549|0,0401|0,0799|0,0534|
|row 2|0,0723|0|0,0504|0,0494|0,0573|0,0473|0,0535|0,0638|0,0564|0,0524|
|row 3|**0,0736**|0,0504|**0**|**0,0520**|0,0719|**0,0502**|0,0561|0,0667|0,0564|0,0524|
|row 4|0,0743|0,0494|0,0520|0|0,0322|0,0610|0,0547|0,0649|0,0693|0,0653|
|row 5|0,0825|0,0573|0,0719|0,0322|0|0,0692|0,0629|0,0580|0,0732|0,0687|
|row 6|0,0485|0,0473|0,0502|0,0610|0,0692|0|0,0298|0,0635|0,0561|0,0404|
|row 7|0,0549|**0,0535**|0,0561|0,0547|**0,0629**|0,0298|**0**|**0,0581**|**0,0742**|**0,0349**|
|row 8|0,0401|0,0638|0,0667|0,0649|0,0580|0,0635|0,0581|0|0,0794|0,0486|
|row 9|0,0799|0,0564|0,0564|0,0693|0,0732|0,0561|0,0742|0,0794|0|0,0794|
|row 10|0,0534|0,0524|0,0524|0,0653|0,0687|0,0404|0,0349|0,0486|0,0794|0|

Medoid 1 = row 1 + row 3 + row 4+ row 6 = 0,1759

Medoid 2 = row 2 + row 5 + row 7 + row 8 + row 9 + row 10 = 0,2836

Total Dissimilarity = 0,4594

This would be the total dissimilarity for 2 clusters, then I would do the same for 3 clusters, 4, etc.",t2_719vr9ao,Using the dissimilarity matrix obtained through the gower distance as an evaluation metric.,discussion,t3_ht12p9,0.9,14,Discussion,14,1595039444.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In a clustering problem I am using the gower distance, which results in a dissimilarity matrix.&lt;/p&gt;

&lt;p&gt;Then I&amp;#39;m using k-medoids to clusterize.&lt;/p&gt;

&lt;p&gt;So now if I read the medoids that result from k-medoids, then take the rows of the medoids from the dissimilarity matrix, and finally sum the cluster labels from that corresponding medoid in that row , what do I  obtain?&lt;/p&gt;

&lt;p&gt;The total sum of the dissimilarity of that cluster?&lt;/p&gt;

&lt;p&gt;Meaning this could be used as the within distance sum of that cluster?&lt;/p&gt;

&lt;p&gt;My goal would be to use that sum as the elbow method.&lt;/p&gt;

&lt;p&gt;Example below:&lt;/p&gt;

&lt;p&gt;Dissimilarity Matrix&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=""left""&gt;&lt;/th&gt;
&lt;th align=""left""&gt;row1&lt;/th&gt;
&lt;th align=""left""&gt;row2&lt;/th&gt;
&lt;th align=""left""&gt;row3&lt;/th&gt;
&lt;th align=""left""&gt;row4&lt;/th&gt;
&lt;th align=""left""&gt;row5&lt;/th&gt;
&lt;th align=""left""&gt;row6&lt;/th&gt;
&lt;th align=""left""&gt;row7&lt;/th&gt;
&lt;th align=""left""&gt;row8&lt;/th&gt;
&lt;th align=""left""&gt;row9&lt;/th&gt;
&lt;th align=""left""&gt;row10&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 1&lt;/td&gt;
&lt;td align=""left""&gt;0&lt;/td&gt;
&lt;td align=""left""&gt;0,0723&lt;/td&gt;
&lt;td align=""left""&gt;0,0736&lt;/td&gt;
&lt;td align=""left""&gt;0,0743&lt;/td&gt;
&lt;td align=""left""&gt;0,0825&lt;/td&gt;
&lt;td align=""left""&gt;0,0485&lt;/td&gt;
&lt;td align=""left""&gt;0,0549&lt;/td&gt;
&lt;td align=""left""&gt;0,0401&lt;/td&gt;
&lt;td align=""left""&gt;0,0799&lt;/td&gt;
&lt;td align=""left""&gt;0,0534&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 2&lt;/td&gt;
&lt;td align=""left""&gt;0,0723&lt;/td&gt;
&lt;td align=""left""&gt;0&lt;/td&gt;
&lt;td align=""left""&gt;0,0504&lt;/td&gt;
&lt;td align=""left""&gt;0,0494&lt;/td&gt;
&lt;td align=""left""&gt;0,0573&lt;/td&gt;
&lt;td align=""left""&gt;0,0473&lt;/td&gt;
&lt;td align=""left""&gt;0,0535&lt;/td&gt;
&lt;td align=""left""&gt;0,0638&lt;/td&gt;
&lt;td align=""left""&gt;0,0564&lt;/td&gt;
&lt;td align=""left""&gt;0,0524&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 3&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0,0736&lt;/strong&gt;&lt;/td&gt;
&lt;td align=""left""&gt;0,0504&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0,0520&lt;/strong&gt;&lt;/td&gt;
&lt;td align=""left""&gt;0,0719&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0,0502&lt;/strong&gt;&lt;/td&gt;
&lt;td align=""left""&gt;0,0561&lt;/td&gt;
&lt;td align=""left""&gt;0,0667&lt;/td&gt;
&lt;td align=""left""&gt;0,0564&lt;/td&gt;
&lt;td align=""left""&gt;0,0524&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 4&lt;/td&gt;
&lt;td align=""left""&gt;0,0743&lt;/td&gt;
&lt;td align=""left""&gt;0,0494&lt;/td&gt;
&lt;td align=""left""&gt;0,0520&lt;/td&gt;
&lt;td align=""left""&gt;0&lt;/td&gt;
&lt;td align=""left""&gt;0,0322&lt;/td&gt;
&lt;td align=""left""&gt;0,0610&lt;/td&gt;
&lt;td align=""left""&gt;0,0547&lt;/td&gt;
&lt;td align=""left""&gt;0,0649&lt;/td&gt;
&lt;td align=""left""&gt;0,0693&lt;/td&gt;
&lt;td align=""left""&gt;0,0653&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 5&lt;/td&gt;
&lt;td align=""left""&gt;0,0825&lt;/td&gt;
&lt;td align=""left""&gt;0,0573&lt;/td&gt;
&lt;td align=""left""&gt;0,0719&lt;/td&gt;
&lt;td align=""left""&gt;0,0322&lt;/td&gt;
&lt;td align=""left""&gt;0&lt;/td&gt;
&lt;td align=""left""&gt;0,0692&lt;/td&gt;
&lt;td align=""left""&gt;0,0629&lt;/td&gt;
&lt;td align=""left""&gt;0,0580&lt;/td&gt;
&lt;td align=""left""&gt;0,0732&lt;/td&gt;
&lt;td align=""left""&gt;0,0687&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 6&lt;/td&gt;
&lt;td align=""left""&gt;0,0485&lt;/td&gt;
&lt;td align=""left""&gt;0,0473&lt;/td&gt;
&lt;td align=""left""&gt;0,0502&lt;/td&gt;
&lt;td align=""left""&gt;0,0610&lt;/td&gt;
&lt;td align=""left""&gt;0,0692&lt;/td&gt;
&lt;td align=""left""&gt;0&lt;/td&gt;
&lt;td align=""left""&gt;0,0298&lt;/td&gt;
&lt;td align=""left""&gt;0,0635&lt;/td&gt;
&lt;td align=""left""&gt;0,0561&lt;/td&gt;
&lt;td align=""left""&gt;0,0404&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 7&lt;/td&gt;
&lt;td align=""left""&gt;0,0549&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0,0535&lt;/strong&gt;&lt;/td&gt;
&lt;td align=""left""&gt;0,0561&lt;/td&gt;
&lt;td align=""left""&gt;0,0547&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0,0629&lt;/strong&gt;&lt;/td&gt;
&lt;td align=""left""&gt;0,0298&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0,0581&lt;/strong&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0,0742&lt;/strong&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;strong&gt;0,0349&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 8&lt;/td&gt;
&lt;td align=""left""&gt;0,0401&lt;/td&gt;
&lt;td align=""left""&gt;0,0638&lt;/td&gt;
&lt;td align=""left""&gt;0,0667&lt;/td&gt;
&lt;td align=""left""&gt;0,0649&lt;/td&gt;
&lt;td align=""left""&gt;0,0580&lt;/td&gt;
&lt;td align=""left""&gt;0,0635&lt;/td&gt;
&lt;td align=""left""&gt;0,0581&lt;/td&gt;
&lt;td align=""left""&gt;0&lt;/td&gt;
&lt;td align=""left""&gt;0,0794&lt;/td&gt;
&lt;td align=""left""&gt;0,0486&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 9&lt;/td&gt;
&lt;td align=""left""&gt;0,0799&lt;/td&gt;
&lt;td align=""left""&gt;0,0564&lt;/td&gt;
&lt;td align=""left""&gt;0,0564&lt;/td&gt;
&lt;td align=""left""&gt;0,0693&lt;/td&gt;
&lt;td align=""left""&gt;0,0732&lt;/td&gt;
&lt;td align=""left""&gt;0,0561&lt;/td&gt;
&lt;td align=""left""&gt;0,0742&lt;/td&gt;
&lt;td align=""left""&gt;0,0794&lt;/td&gt;
&lt;td align=""left""&gt;0&lt;/td&gt;
&lt;td align=""left""&gt;0,0794&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;row 10&lt;/td&gt;
&lt;td align=""left""&gt;0,0534&lt;/td&gt;
&lt;td align=""left""&gt;0,0524&lt;/td&gt;
&lt;td align=""left""&gt;0,0524&lt;/td&gt;
&lt;td align=""left""&gt;0,0653&lt;/td&gt;
&lt;td align=""left""&gt;0,0687&lt;/td&gt;
&lt;td align=""left""&gt;0,0404&lt;/td&gt;
&lt;td align=""left""&gt;0,0349&lt;/td&gt;
&lt;td align=""left""&gt;0,0486&lt;/td&gt;
&lt;td align=""left""&gt;0,0794&lt;/td&gt;
&lt;td align=""left""&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;Medoid 1 = row 1 + row 3 + row 4+ row 6 = 0,1759&lt;/p&gt;

&lt;p&gt;Medoid 2 = row 2 + row 5 + row 7 + row 8 + row 9 + row 10 = 0,2836&lt;/p&gt;

&lt;p&gt;Total Dissimilarity = 0,4594&lt;/p&gt;

&lt;p&gt;This would be the total dissimilarity for 2 clusters, then I would do the same for 3 clusters, 4, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ht12p9,rpinto02,9,/r/datascience/comments/ht12p9/using_the_dissimilarity_matrix_obtained_through/,https://www.reddit.com/r/datascience/comments/ht12p9/using_the_dissimilarity_matrix_obtained_through/,1595010644.0
r/datascience,"As I've gotten more comfortable with programming, I feel I got the syntax down. However to truly take the training wheels off, I need to start thinking more about efficiency and memory usage.

Something I think has helped me is using more list/dictionary comprehension. Particularly when adding new columns to a data frame. For example:

`lst = []`

`for n in range(0,10):`  
`lst.append(n*2)`

`df['new'] = lst`

vs.

`df['new'] = [n*2 for n in range(0,10)]`",t2_51b0m,What sort of best practices made your code more efficient?,discussion,t3_ht2o0m,1.0,8,Discussion,8,1595044593.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As I&amp;#39;ve gotten more comfortable with programming, I feel I got the syntax down. However to truly take the training wheels off, I need to start thinking more about efficiency and memory usage.&lt;/p&gt;

&lt;p&gt;Something I think has helped me is using more list/dictionary comprehension. Particularly when adding new columns to a data frame. For example:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;lst = []&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;for n in range(0,10):&lt;/code&gt;&lt;br/&gt;
&lt;code&gt;lst.append(n*2)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;df[&amp;#39;new&amp;#39;] = lst&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;vs.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;df[&amp;#39;new&amp;#39;] = [n*2 for n in range(0,10)]&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ht2o0m,LegendaryPeanut,7,/r/datascience/comments/ht2o0m/what_sort_of_best_practices_made_your_code_more/,https://www.reddit.com/r/datascience/comments/ht2o0m/what_sort_of_best_practices_made_your_code_more/,1595015793.0
r/datascience,"As for the timeline, the company had posted a DS job a few months ago on LinkedIn. A week ago, I sent in my resume because a friend was willing to refer me.

I just got an email yesterday that the company had a leading candidate in mind but still wanted to chat on the phone.

Has anyone been in this situation before or on the other end? It's a bit unclear to me whether I am still interviewing for this position, the company just wants to keep my info on file, or if they might be considering me for another role. Besides standard interview prep, is there anything I should do?

Thanks!",t2_dov66,Company has a leading candidate but still wants to interview?,,t3_hsx6el,0.85,14,Job Search,14,1595026835.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As for the timeline, the company had posted a DS job a few months ago on LinkedIn. A week ago, I sent in my resume because a friend was willing to refer me.&lt;/p&gt;

&lt;p&gt;I just got an email yesterday that the company had a leading candidate in mind but still wanted to chat on the phone.&lt;/p&gt;

&lt;p&gt;Has anyone been in this situation before or on the other end? It&amp;#39;s a bit unclear to me whether I am still interviewing for this position, the company just wants to keep my info on file, or if they might be considering me for another role. Besides standard interview prep, is there anything I should do?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hsx6el,shim12,14,/r/datascience/comments/hsx6el/company_has_a_leading_candidate_but_still_wants/,https://www.reddit.com/r/datascience/comments/hsx6el/company_has_a_leading_candidate_but_still_wants/,1594998035.0
r/datascience,"I'm working on a 2-dimensional dataset for segmentation (inputs are geo-locations, just latitudes and longitudes) and I want to use K-means (or other clustering algorithm if it's more relevant) but at the same time to be able to specify minimum and maximum number of units in clusters, as well as the maximum distance between cluster center and outermost point in that cluster. Is anyone aware of any such implementation in R or Python? 

If not, does anyone have an idea how to do this?",t2_9uw05,Geo-location clustering with size and unit count constraints,discussion,t3_hsx70c,0.87,11,Discussion,11,1595026895.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working on a 2-dimensional dataset for segmentation (inputs are geo-locations, just latitudes and longitudes) and I want to use K-means (or other clustering algorithm if it&amp;#39;s more relevant) but at the same time to be able to specify minimum and maximum number of units in clusters, as well as the maximum distance between cluster center and outermost point in that cluster. Is anyone aware of any such implementation in R or Python? &lt;/p&gt;

&lt;p&gt;If not, does anyone have an idea how to do this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hsx70c,zGiorgi,9,/r/datascience/comments/hsx70c/geolocation_clustering_with_size_and_unit_count/,https://www.reddit.com/r/datascience/comments/hsx70c/geolocation_clustering_with_size_and_unit_count/,1594998095.0
r/datascience,"For those who work in predictive analytics, time series analysis, forecasting, outlier detection, or related fields, how are you going to handle this dumpster fire of a year when modeling?

Will you handle 2020 data 'as-is' without adjustment and add a footnote to any reports? Or somehow modify?

I suppose there are strategies to adjust or impute data depending on the use case, and that's what I'm most curious about. What is your organization specifically doing, or going to do in the future, to offset the disruptive force of Covid and the global lockdowns on your predictive models or business KPIs?",t2_pr6lcu2,How are you handling 2020 in your predictive models?,discussion,t3_hsjxte,0.98,186,Discussion,186,1594967573.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For those who work in predictive analytics, time series analysis, forecasting, outlier detection, or related fields, how are you going to handle this dumpster fire of a year when modeling?&lt;/p&gt;

&lt;p&gt;Will you handle 2020 data &amp;#39;as-is&amp;#39; without adjustment and add a footnote to any reports? Or somehow modify?&lt;/p&gt;

&lt;p&gt;I suppose there are strategies to adjust or impute data depending on the use case, and that&amp;#39;s what I&amp;#39;m most curious about. What is your organization specifically doing, or going to do in the future, to offset the disruptive force of Covid and the global lockdowns on your predictive models or business KPIs?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hsjxte,most_humblest_ever,66,/r/datascience/comments/hsjxte/how_are_you_handling_2020_in_your_predictive/,https://www.reddit.com/r/datascience/comments/hsjxte/how_are_you_handling_2020_in_your_predictive/,1594938773.0
r/datascience,"So for complicated reasons, we had to use a small random sample from a dataset to build a supervised binary classifier model. Because the dataset itself is easy to classify, the model performance is quite high (at 90’s %), therefore performance is not an issue. We did a sample size calculation and it came back with 94% confidence level with 7% margin of error.

Are there any academic papers out there where we can reference to about small sample sizes used in model building to get the paper through to be published in a peer reviewed journal?",t2_zmqho4m,Any academic paper to reference for small sample sizes used to build a model?,discussion,t3_hsskaq,0.82,20,Discussion,20,1595006236.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So for complicated reasons, we had to use a small random sample from a dataset to build a supervised binary classifier model. Because the dataset itself is easy to classify, the model performance is quite high (at 90’s %), therefore performance is not an issue. We did a sample size calculation and it came back with 94% confidence level with 7% margin of error.&lt;/p&gt;

&lt;p&gt;Are there any academic papers out there where we can reference to about small sample sizes used in model building to get the paper through to be published in a peer reviewed journal?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hsskaq,leockl,39,/r/datascience/comments/hsskaq/any_academic_paper_to_reference_for_small_sample/,https://www.reddit.com/r/datascience/comments/hsskaq/any_academic_paper_to_reference_for_small_sample/,1594977436.0
r/datascience,"Hi data science reddit. My family is torn up fighting over my brothers recent career decision and I need your advice.

My brother is 30 years old. He is an oil &amp; gas reservoir engineer with 5 years experience working at Royal Dutch Shell. He’s about to lose his job because his sector/industry has been hit hard by COVID19 and as a result his company is going through a massive wave of layoffs.

For as long as I can remember he has been infatuated with computer science/ coding, and it’s always been a regret of his that he did not pursue this career path when he was younger. He doesn’t have any formal training or experience in this, although he is somewhat of an amateur coder (self-taught in python and some stuff like that) but I really have no clue how good he is at this stuff.

This lay-off has got him thinking about a career shift. His plan is to enroll in a 3 year undergrad computer science program and get a bachelors degree so he can become a data scientist.

My mom doesn’t support his decision to go back to school and they won’t stop fighting about it. I’m trying keep the peace between them and stay neutral, but I’m leaning more towards my mom’s POV. The idea of going back to school and starting his career from scratch as a 34 year old fresh grad looking for entry level work in data science seems radical to me, at the very least questionable. Am I wrong? Is this a good idea?

I suggested as an alternative that he enroll in a 2 year master’s program instead. I don’t know if this is a good idea either TBH but at least it would be 1 less year and it seems more practical to me that he pursue an advanced degree and possibly compete for more senior positions, given his age. But he seems to think that even if he earned a masters degree he still lacks the work experience to compete at a more senior level, so might as well get the bachelors degree. He also says that he wants to get a full education in computer science starting with the fundamentals, which he would not get from a masters program.

1. Is it too late for my brother to become a data scientist? (I know it’s never too late for anything and I’d love for my brother to follow his dream and all that, but if we’re being practical about this- is it too late?)

2. If not, what is the best way for my brother to break into this industry?

Thanks in advance r/datasience. Eagerly awaiting your advice!",t2_ff9i1,Family Feud; Need Advice on Data Science Career Shift,,t3_ht6lhc,0.5,0,Job Search,0,1595058088.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi data science reddit. My family is torn up fighting over my brothers recent career decision and I need your advice.&lt;/p&gt;

&lt;p&gt;My brother is 30 years old. He is an oil &amp;amp; gas reservoir engineer with 5 years experience working at Royal Dutch Shell. He’s about to lose his job because his sector/industry has been hit hard by COVID19 and as a result his company is going through a massive wave of layoffs.&lt;/p&gt;

&lt;p&gt;For as long as I can remember he has been infatuated with computer science/ coding, and it’s always been a regret of his that he did not pursue this career path when he was younger. He doesn’t have any formal training or experience in this, although he is somewhat of an amateur coder (self-taught in python and some stuff like that) but I really have no clue how good he is at this stuff.&lt;/p&gt;

&lt;p&gt;This lay-off has got him thinking about a career shift. His plan is to enroll in a 3 year undergrad computer science program and get a bachelors degree so he can become a data scientist.&lt;/p&gt;

&lt;p&gt;My mom doesn’t support his decision to go back to school and they won’t stop fighting about it. I’m trying keep the peace between them and stay neutral, but I’m leaning more towards my mom’s POV. The idea of going back to school and starting his career from scratch as a 34 year old fresh grad looking for entry level work in data science seems radical to me, at the very least questionable. Am I wrong? Is this a good idea?&lt;/p&gt;

&lt;p&gt;I suggested as an alternative that he enroll in a 2 year master’s program instead. I don’t know if this is a good idea either TBH but at least it would be 1 less year and it seems more practical to me that he pursue an advanced degree and possibly compete for more senior positions, given his age. But he seems to think that even if he earned a masters degree he still lacks the work experience to compete at a more senior level, so might as well get the bachelors degree. He also says that he wants to get a full education in computer science starting with the fundamentals, which he would not get from a masters program.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Is it too late for my brother to become a data scientist? (I know it’s never too late for anything and I’d love for my brother to follow his dream and all that, but if we’re being practical about this- is it too late?)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If not, what is the best way for my brother to break into this industry?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thanks in advance &lt;a href=""/r/datasience""&gt;r/datasience&lt;/a&gt;. Eagerly awaiting your advice!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ht6lhc,theshihab,37,/r/datascience/comments/ht6lhc/family_feud_need_advice_on_data_science_career/,https://www.reddit.com/r/datascience/comments/ht6lhc/family_feud_need_advice_on_data_science_career/,1595029288.0
r/datascience,"hey guys, 

I'm just using Association Rules for a project and wondering how useful/popular these actually are in industry.  Thanks!",t2_4yqkvgto,Association Rules in Text Mining (Industry Relevance),discussion,t3_hsyxz8,0.8,3,Discussion,3,1595032638.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;hey guys, &lt;/p&gt;

&lt;p&gt;I&amp;#39;m just using Association Rules for a project and wondering how useful/popular these actually are in industry.  Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hsyxz8,lil_faucet,0,/r/datascience/comments/hsyxz8/association_rules_in_text_mining_industry/,https://www.reddit.com/r/datascience/comments/hsyxz8/association_rules_in_text_mining_industry/,1595003838.0
r/datascience,,t2_ucebw,What kind of math and statistics do you actually use in a daily basis at work?,discussion,t3_hsb1u4,0.98,307,Discussion,307,1594940115.0,,hsb1u4,Megatheorist,199,/r/datascience/comments/hsb1u4/what_kind_of_math_and_statistics_do_you_actually/,https://www.reddit.com/r/datascience/comments/hsb1u4/what_kind_of_math_and_statistics_do_you_actually/,1594911315.0
r/datascience,"Hey guys, what are your methods for development of a project and managing a small data science team? What principles do you follow?",t2_5e34w9d2,Data science project management,discussion,t3_ht1xhk,0.67,1,Discussion,1,1595042224.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, what are your methods for development of a project and managing a small data science team? What principles do you follow?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ht1xhk,expatwithajetpack,4,/r/datascience/comments/ht1xhk/data_science_project_management/,https://www.reddit.com/r/datascience/comments/ht1xhk/data_science_project_management/,1595013424.0
r/datascience,"I get kudos for my work, presentations, etc. I am told that the work is quite good and respected. But I can't shake the disappointment that the analyses are not clearly linked to any particular policy changes or strategic initiatives. I idealize stakeholders telling me precisely how the analysis results relate to action, but I'm concerned that expectation is futile.",t2_apemm,How important is it for the results of your analysis to be actionable by your stakeholders?,discussion,t3_hsfldn,0.96,24,Discussion,24,1594954046.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I get kudos for my work, presentations, etc. I am told that the work is quite good and respected. But I can&amp;#39;t shake the disappointment that the analyses are not clearly linked to any particular policy changes or strategic initiatives. I idealize stakeholders telling me precisely how the analysis results relate to action, but I&amp;#39;m concerned that expectation is futile.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hsfldn,WhosaWhatsa,19,/r/datascience/comments/hsfldn/how_important_is_it_for_the_results_of_your/,https://www.reddit.com/r/datascience/comments/hsfldn/how_important_is_it_for_the_results_of_your/,1594925246.0
r/datascience,"I see that about half the job descriptions want knowledge of Tableau and such, and as I do scientific research for the most part in linux, I have never used these tools. What kind of analysis do you do with them that cannot be done or harder to do with python/R?",t2_1o3lq7ck,How much do you rely on Tableau and similar tools?,discussion,t3_hsgmtu,0.75,6,Discussion,6,1594956957.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I see that about half the job descriptions want knowledge of Tableau and such, and as I do scientific research for the most part in linux, I have never used these tools. What kind of analysis do you do with them that cannot be done or harder to do with python/R?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hsgmtu,timberhilly,13,/r/datascience/comments/hsgmtu/how_much_do_you_rely_on_tableau_and_similar_tools/,https://www.reddit.com/r/datascience/comments/hsgmtu/how_much_do_you_rely_on_tableau_and_similar_tools/,1594928157.0
r/datascience,,t2_5xux0a4p,New Professional ML Engineer Certification from Google Cloud (beta),career,t3_hrta2c,0.96,297,Career,297,1594867226.0,,hrta2c,___24601,47,/r/datascience/comments/hrta2c/new_professional_ml_engineer_certification_from/,https://cloud.google.com/certification/machine-learning-engineer,1594838426.0
r/datascience,"Not sure if this is the right place to post but I'm looking for someone to have a quick look at my clustering set-up. I'm in over my head doing stuff I haven't studied for writing about a subject that is wayyy off track from my masters. But I'm committed now since I find it interesting.  
&amp;nbsp;  
I'll try to keep in short. I found [this](https://www.researchgate.net/publication/327298996_Hardcore_Gamer_Profiling_Results_from_an_unsupervised_learning_approach_to_playing_behavior_on_the_Steam_platform) paper and want to replicate what they did but instead of using k-means I want to use DBSCAN. The data is retrieved from the Steam platform and they aim to cluster players on their behaviour, i.e. how likely is it for someone that only plays AAA games to also play Indie or F2P games.    
&amp;nbsp;  
 [This](https://imgur.com/a/uRUCmQY) is the dataset that I'm working with and what I presume they used in the paper as well. For now I'm only trying to find out if using DBSCAN, with best practice parameters, will give me the same clusters as they got.  
&amp;nbsp;  
Things I'm currently having trouble with:  
&amp;nbsp;  
1) How should I imagine multidimensional clustering to take place? Like, I can, in my mind, visualize how clustering works on up to three axis but anything more than that I don't get. This gives me a bit of trouble because I want to make sense of the features that are chosen for the clustering. Is this even something I'm supposed to get?  
&amp;nbsp;  
2) Does the 'appid' feature in my dataset make sense to use in clustering? Something about the numbers feels off as they're not all the same length but my understanding is not good enough to pinpoint what exactly my problem with it is.  
&amp;nbsp;   
3) I tried using DBSCAN but apparently it is not optimized for large datasets, instead I used HDBSCAN which, after running for twelve hours finally gave me a result. Has anyone worked with HDBSCAN in combination with a dataset the size of mine and can give me some pointers on how to set my parameters?  
&amp;nbsp;  
Like I said, not sure if this is Data Sciencey enough for this subreddit but didn't really know where else to post.",t2_epbv0,Looking for feedback on clustering set-up,discussion,t3_hsa0hp,1.0,5,Discussion,5,1594936356.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Not sure if this is the right place to post but I&amp;#39;m looking for someone to have a quick look at my clustering set-up. I&amp;#39;m in over my head doing stuff I haven&amp;#39;t studied for writing about a subject that is wayyy off track from my masters. But I&amp;#39;m committed now since I find it interesting.&lt;br/&gt;
&amp;nbsp;&lt;br/&gt;
I&amp;#39;ll try to keep in short. I found &lt;a href=""https://www.researchgate.net/publication/327298996_Hardcore_Gamer_Profiling_Results_from_an_unsupervised_learning_approach_to_playing_behavior_on_the_Steam_platform""&gt;this&lt;/a&gt; paper and want to replicate what they did but instead of using k-means I want to use DBSCAN. The data is retrieved from the Steam platform and they aim to cluster players on their behaviour, i.e. how likely is it for someone that only plays AAA games to also play Indie or F2P games.&lt;br/&gt;
&amp;nbsp;&lt;br/&gt;
 &lt;a href=""https://imgur.com/a/uRUCmQY""&gt;This&lt;/a&gt; is the dataset that I&amp;#39;m working with and what I presume they used in the paper as well. For now I&amp;#39;m only trying to find out if using DBSCAN, with best practice parameters, will give me the same clusters as they got.&lt;br/&gt;
&amp;nbsp;&lt;br/&gt;
Things I&amp;#39;m currently having trouble with:&lt;br/&gt;
&amp;nbsp;&lt;br/&gt;
1) How should I imagine multidimensional clustering to take place? Like, I can, in my mind, visualize how clustering works on up to three axis but anything more than that I don&amp;#39;t get. This gives me a bit of trouble because I want to make sense of the features that are chosen for the clustering. Is this even something I&amp;#39;m supposed to get?&lt;br/&gt;
&amp;nbsp;&lt;br/&gt;
2) Does the &amp;#39;appid&amp;#39; feature in my dataset make sense to use in clustering? Something about the numbers feels off as they&amp;#39;re not all the same length but my understanding is not good enough to pinpoint what exactly my problem with it is.&lt;br/&gt;
&amp;nbsp;&lt;br/&gt;
3) I tried using DBSCAN but apparently it is not optimized for large datasets, instead I used HDBSCAN which, after running for twelve hours finally gave me a result. Has anyone worked with HDBSCAN in combination with a dataset the size of mine and can give me some pointers on how to set my parameters?&lt;br/&gt;
&amp;nbsp;&lt;br/&gt;
Like I said, not sure if this is Data Sciencey enough for this subreddit but didn&amp;#39;t really know where else to post.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hsa0hp,xDav,17,/r/datascience/comments/hsa0hp/looking_for_feedback_on_clustering_setup/,https://www.reddit.com/r/datascience/comments/hsa0hp/looking_for_feedback_on_clustering_setup/,1594907556.0
r/datascience,"I'm currently working on a regression problem in which the model inputs are images, and the desired output is a ""rating"" in the range \[0,1\]. Each image in the dataset has been labelled once by employees of the client, in a quick ""eye ball"" sort of measurement. Consequently, there is considerable noise in the labels. The Bayes error for this problem is likely not zero, but I'm certain it's considerably lower than that of the workers.

  
I'd like to somehow compare the performance of my model to that of the workers in estimating the *actual* ground truth, or some proxy thereof.

  
One idea I've had is having workers relabel parts of the dataset, and comparing the error of the new labels against the error of the model, assuming the old labels as ground truth. If I'm not mistaken, this test has the possibility of showing that the model is at least as good as the workers, but I don't think it can show that the model outperforms the workers.

  
Sorry if this is a bit vague. I can't really divulge too many specifics, but I'll try to answer any clarifying questions if you have them.",t2_osi5d,Comparing model and human performance,discussion,t3_hs78n3,1.0,4,Discussion,4,1594924270.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently working on a regression problem in which the model inputs are images, and the desired output is a &amp;quot;rating&amp;quot; in the range [0,1]. Each image in the dataset has been labelled once by employees of the client, in a quick &amp;quot;eye ball&amp;quot; sort of measurement. Consequently, there is considerable noise in the labels. The Bayes error for this problem is likely not zero, but I&amp;#39;m certain it&amp;#39;s considerably lower than that of the workers.&lt;/p&gt;

&lt;p&gt;I&amp;#39;d like to somehow compare the performance of my model to that of the workers in estimating the &lt;em&gt;actual&lt;/em&gt; ground truth, or some proxy thereof.&lt;/p&gt;

&lt;p&gt;One idea I&amp;#39;ve had is having workers relabel parts of the dataset, and comparing the error of the new labels against the error of the model, assuming the old labels as ground truth. If I&amp;#39;m not mistaken, this test has the possibility of showing that the model is at least as good as the workers, but I don&amp;#39;t think it can show that the model outperforms the workers.&lt;/p&gt;

&lt;p&gt;Sorry if this is a bit vague. I can&amp;#39;t really divulge too many specifics, but I&amp;#39;ll try to answer any clarifying questions if you have them.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hs78n3,Purerushh,7,/r/datascience/comments/hs78n3/comparing_model_and_human_performance/,https://www.reddit.com/r/datascience/comments/hs78n3/comparing_model_and_human_performance/,1594895470.0
r/datascience,"I may have an opportunity to transition from a hands-on data scientist role at a local company, into a role at a large Indian consultancy firm where I would act as the interface between local clients in my home country and the data science teams in India. It does genuinely appear to be very much of a quite senior DS lead role, rather than mainly sales. Understanding client needs, participating in PoC development, identifying applicable methods, guiding iterative delivery, quality assurance, communicating results to clients, and measuring impact.

Does anyone have any experience working in or interacting with this type of role? What are the pros and cons, and potential pitfalls? I feel my ability to deliver will largely be determined by the quality of the teams in India, which on the one hand makes me nervous (due to western prejudices?), and on the other hand makes me think I can do much more with a team than I can on my own in my current role.",t2_ewqpu,Senior role in outsourcing company?,career,t3_hs7xdg,1.0,3,Career,3,1594927737.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I may have an opportunity to transition from a hands-on data scientist role at a local company, into a role at a large Indian consultancy firm where I would act as the interface between local clients in my home country and the data science teams in India. It does genuinely appear to be very much of a quite senior DS lead role, rather than mainly sales. Understanding client needs, participating in PoC development, identifying applicable methods, guiding iterative delivery, quality assurance, communicating results to clients, and measuring impact.&lt;/p&gt;

&lt;p&gt;Does anyone have any experience working in or interacting with this type of role? What are the pros and cons, and potential pitfalls? I feel my ability to deliver will largely be determined by the quality of the teams in India, which on the one hand makes me nervous (due to western prejudices?), and on the other hand makes me think I can do much more with a team than I can on my own in my current role.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hs7xdg,drop_panda,7,/r/datascience/comments/hs7xdg/senior_role_in_outsourcing_company/,https://www.reddit.com/r/datascience/comments/hs7xdg/senior_role_in_outsourcing_company/,1594898937.0
r/datascience,"Started an ai startup in the middle of COVID pandemic and we were able to get VC funding! To give back, Im having a virtual meetup event on Meetup. Come and lets talk of you wanna hear how we did it. Nothing to sell here. Just giving advice. There will be guest speakers who have previously sold companies as well as INVESTORS in attendance! [https://www.meetup.com/meetup-group-aYMKMziu/events/271913112/](https://www.meetup.com/meetup-group-aYMKMziu/events/271913112/)",t2_33tsikaa,Starting a startup in the middle of a pandemic,education,t3_hs0at4,0.78,10,Education,10,1594890681.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Started an ai startup in the middle of COVID pandemic and we were able to get VC funding! To give back, Im having a virtual meetup event on Meetup. Come and lets talk of you wanna hear how we did it. Nothing to sell here. Just giving advice. There will be guest speakers who have previously sold companies as well as INVESTORS in attendance! &lt;a href=""https://www.meetup.com/meetup-group-aYMKMziu/events/271913112/""&gt;https://www.meetup.com/meetup-group-aYMKMziu/events/271913112/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hs0at4,BeBetterThanEver,16,/r/datascience/comments/hs0at4/starting_a_startup_in_the_middle_of_a_pandemic/,https://www.reddit.com/r/datascience/comments/hs0at4/starting_a_startup_in_the_middle_of_a_pandemic/,1594861881.0
r/datascience,I've noticed that most Data Scientists in my team end up using XGB for all our models in production (except ones which need deep learning). Is this the case in most teams? We work more with structured data.,t2_85eksdy,Is XGBoost mostly used in your work for all non-deep learning model?,discussion,t3_hrjc02,0.97,176,Discussion,176,1594827563.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve noticed that most Data Scientists in my team end up using XGB for all our models in production (except ones which need deep learning). Is this the case in most teams? We work more with structured data.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrjc02,KrishnarajaWadiyar4,139,/r/datascience/comments/hrjc02/is_xgboost_mostly_used_in_your_work_for_all/,https://www.reddit.com/r/datascience/comments/hrjc02/is_xgboost_mostly_used_in_your_work_for_all/,1594798763.0
r/datascience,I'm searching for something like [this](http://www.pnrjournal.com/viewimage.asp?img=JPharmNegativeResults_2010_1_2_61_75708_f1.jpg) that incorporates a much wider variety of tests. Kind of like a cheat sheet for choosing the right method.,t2_3tonbxla,What is the best existing decision tree/flow chart for choosing the right analysis method?,discussion,t3_hrvsiv,0.85,17,Discussion,17,1594874942.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m searching for something like &lt;a href=""http://www.pnrjournal.com/viewimage.asp?img=JPharmNegativeResults_2010_1_2_61_75708_f1.jpg""&gt;this&lt;/a&gt; that incorporates a much wider variety of tests. Kind of like a cheat sheet for choosing the right method.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrvsiv,AntiTrollBott,4,/r/datascience/comments/hrvsiv/what_is_the_best_existing_decision_treeflow_chart/,https://www.reddit.com/r/datascience/comments/hrvsiv/what_is_the_best_existing_decision_treeflow_chart/,1594846142.0
r/datascience,"Today I messed up by focusing on one part of the project (a prediction model for a business for the UK) for two days, where that extra granular level was not required. I ended up doing the analysis at local authority level rather than country level - a tonne more data and for not much benefit. 

I explained the situation but ultimately the mistake is down to me, which I corrected already. 

Whilst everything is back on track now, I learnt a very important lesson today - if in doubt about project scope, and getting conflicting priorities from different people, - verify first. Working in a pandemic and remote, its not the easiest to adjust to a new job where you joined remotely. 

What are some other golden rules from projects going wrong (or right!) that the community has picked up over the years, across both soft and technical skills?",t2_1szwqlis,Stories of projects that almost went downhill and lessons learned?,career,t3_hs02t2,0.72,3,Career,3,1594889795.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Today I messed up by focusing on one part of the project (a prediction model for a business for the UK) for two days, where that extra granular level was not required. I ended up doing the analysis at local authority level rather than country level - a tonne more data and for not much benefit. &lt;/p&gt;

&lt;p&gt;I explained the situation but ultimately the mistake is down to me, which I corrected already. &lt;/p&gt;

&lt;p&gt;Whilst everything is back on track now, I learnt a very important lesson today - if in doubt about project scope, and getting conflicting priorities from different people, - verify first. Working in a pandemic and remote, its not the easiest to adjust to a new job where you joined remotely. &lt;/p&gt;

&lt;p&gt;What are some other golden rules from projects going wrong (or right!) that the community has picked up over the years, across both soft and technical skills?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hs02t2,ak111444777,2,/r/datascience/comments/hs02t2/stories_of_projects_that_almost_went_downhill_and/,https://www.reddit.com/r/datascience/comments/hs02t2/stories_of_projects_that_almost_went_downhill_and/,1594860995.0
r/datascience,"I am assigned to multiple projects in my DS role. Every single one of them is always held up at some point due to office politics. For example, the stakeholder on a current project is asking me to perform a simple review of work done on some data by an outside vendor. My manager doesn’t want me to do it and thinks that the vendor should do it. Nothing in the vendor contract states that they should be performing this review. And I do not mind doing it, I actually would like to do it as work has been somewhat slow recently. What’s the big deal with just letting me do some work? It’s something I can get done in like 2 hours, whereas if the vendor does it we will most likely have to wait at least a week or two to hear back from them. 

Does anyone else experience this?",t2_128a70,Is it common for the DS process to be held up by office politics?,discussion,t3_hro98h,0.87,25,Discussion,25,1594851055.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am assigned to multiple projects in my DS role. Every single one of them is always held up at some point due to office politics. For example, the stakeholder on a current project is asking me to perform a simple review of work done on some data by an outside vendor. My manager doesn’t want me to do it and thinks that the vendor should do it. Nothing in the vendor contract states that they should be performing this review. And I do not mind doing it, I actually would like to do it as work has been somewhat slow recently. What’s the big deal with just letting me do some work? It’s something I can get done in like 2 hours, whereas if the vendor does it we will most likely have to wait at least a week or two to hear back from them. &lt;/p&gt;

&lt;p&gt;Does anyone else experience this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hro98h,thekid153,24,/r/datascience/comments/hro98h/is_it_common_for_the_ds_process_to_be_held_up_by/,https://www.reddit.com/r/datascience/comments/hro98h/is_it_common_for_the_ds_process_to_be_held_up_by/,1594822255.0
r/datascience,"From understanding and implementing it, I feel like it's so different from your regular data algos and projects.",t2_163jio,Does anyone work with recommender systems IRL? Why is it so hard to understand and implement IRL?,discussion,t3_hrzcq6,0.67,2,Discussion,2,1594887058.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;From understanding and implementing it, I feel like it&amp;#39;s so different from your regular data algos and projects.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrzcq6,THE_REAL_ODB,17,/r/datascience/comments/hrzcq6/does_anyone_work_with_recommender_systems_irl_why/,https://www.reddit.com/r/datascience/comments/hrzcq6/does_anyone_work_with_recommender_systems_irl_why/,1594858258.0
r/datascience,"I am currently working on this [kaggle challenge](https://www.kaggle.com/c/ashrae-energy-prediction). The data tables can get quite large (3GB+) and my laptop's computing power is insufficient. I am thinking about trying to use pyspark and AWS.

What would be the workflow with Jupyter notebooks, pyspark and AWS?

When I am working off my computer I usually use Jupyter notebooks for EDA and code experimentation and then consolidate longer final code into spyder IDE.

What would the tools and workflow looking like with pyspark and AWS?",t2_k0wt9,"What is an efficient workflow using pyspark, AWS and Jupyter notebooks?",discussion,t3_hs2cbj,0.57,1,Discussion,1,1594898929.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently working on this &lt;a href=""https://www.kaggle.com/c/ashrae-energy-prediction""&gt;kaggle challenge&lt;/a&gt;. The data tables can get quite large (3GB+) and my laptop&amp;#39;s computing power is insufficient. I am thinking about trying to use pyspark and AWS.&lt;/p&gt;

&lt;p&gt;What would be the workflow with Jupyter notebooks, pyspark and AWS?&lt;/p&gt;

&lt;p&gt;When I am working off my computer I usually use Jupyter notebooks for EDA and code experimentation and then consolidate longer final code into spyder IDE.&lt;/p&gt;

&lt;p&gt;What would the tools and workflow looking like with pyspark and AWS?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hs2cbj,kw_hipster,12,/r/datascience/comments/hs2cbj/what_is_an_efficient_workflow_using_pyspark_aws/,https://www.reddit.com/r/datascience/comments/hs2cbj/what_is_an_efficient_workflow_using_pyspark_aws/,1594870129.0
r/datascience,"Hi all, I work for a small organization where I am a one person data science team and have been in this position for a couple of years. They are currently looking at an automated data science platform that does automatic feature engineering and model testing to ""scale up my work"". On one hand, it would allow me to cover many more projects than I am now, but I am concerned that it will make me reliant on automated methods and will blunt my career/skill progression. Anyone have any advice on how to deal with this?

EDIT: You all have made some really great points. I think this has a lot to do with my perspective and how I decide to use these tools. I think I am placing too much importance on the need to write my own code base for every step and implement everything on my own, which obviously is not scalable.  ",t2_25w85e,Company wants to use automated data science platform. Where does that leave my career progression?,career,t3_hrr9q9,0.67,3,Career,3,1594860986.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I work for a small organization where I am a one person data science team and have been in this position for a couple of years. They are currently looking at an automated data science platform that does automatic feature engineering and model testing to &amp;quot;scale up my work&amp;quot;. On one hand, it would allow me to cover many more projects than I am now, but I am concerned that it will make me reliant on automated methods and will blunt my career/skill progression. Anyone have any advice on how to deal with this?&lt;/p&gt;

&lt;p&gt;EDIT: You all have made some really great points. I think this has a lot to do with my perspective and how I decide to use these tools. I think I am placing too much importance on the need to write my own code base for every step and implement everything on my own, which obviously is not scalable.  &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrr9q9,pc_4_life,10,/r/datascience/comments/hrr9q9/company_wants_to_use_automated_data_science/,https://www.reddit.com/r/datascience/comments/hrr9q9/company_wants_to_use_automated_data_science/,1594832186.0
r/datascience,"For those of you who were self-taught or had to prove their knowledge of the field, what types of projects did you undertake that were the most impactful during the job procurement process?",t2_2a4d4wz8,What data science projects got you your first job?,projects,t3_hr0a91,0.95,336,Projects,336,1594757207.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For those of you who were self-taught or had to prove their knowledge of the field, what types of projects did you undertake that were the most impactful during the job procurement process?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hr0a91,productive_guy123,90,/r/datascience/comments/hr0a91/what_data_science_projects_got_you_your_first_job/,https://www.reddit.com/r/datascience/comments/hr0a91/what_data_science_projects_got_you_your_first_job/,1594728407.0
r/datascience,"Hi all, I'm not a data scientist but trying to create topics for open-ended comments we collect on a weekly survey (the exact question is : why is this your favorite brand?). I don't think it's a problem with my code as topics are indeed generated, they just don't make **any** sense. Keywords are represented in multiple topics. I even tried using bigrams/trigrams - creating ngrams of the default text without removing stopwords or lemmatizing creates topics that are just as useless, but if I do remove words then I have ngrams that are not accurate because those words don't actually appear together.

&amp;#x200B;

Right now I've asked my team to hand code the topics, but I need a more sustainable way going forward. Is there a better way to generate distinct topics?  Or should I just focus on categorizing going forward based on what the team comes up with this time?

&amp;#x200B;

Generic code below (edit: had to remove comments to stop the automatic markdown conversion to headers).

```import pandas as pd, warnings, os, string, re, itertools, language_check, spacy
from pprint import pprint
from itertools import groupby  
from nltk import sent_tokenize
from nltk.tokenize import word_tokenize

import gensim, gensim.models
from gensim.corpora import Dictionary
from gensim.models import LdaMulticore

tool = language_check.LanguageTool('en-US')
nlp = spacy.load(""en_core_web_sm"")
warnings.filterwarnings(""ignore"")

def remove_punct(word):
 return word.translate(str.maketrans('', '', string.punctuation)).replace('  ',' ')

def convert_triples(txt):
    x = re.sub(r'(?i)(.)\1{2,}', r'\1\1', txt, re.IGNORECASE)
    x = re.sub(r'(.)\1{2,}', r'\1\1', x, re.IGNORECASE)
 return x

def spellcheck(txt):
    matches = tool.check(txt)
    matches = [m for m in matches
 if m.category not in ['Redundant Phrases', 'Capitalization', 'Redundancy', 'Plain English']
 and m.locqualityissuetype not in ['style', 'uncategorized']
 and (m.ruleId!='MORFOLOGIK_RULE_EN_US' and m.msg!='Possible spelling mistake found')
 and len(m.replacements)&gt;0]
 if len(matches)&gt;0:
 #x = tool.correct(txt, matches)
        x = language_check.correct(txt, matches)
 return x
 else : 
 return txt

def spacy_tokenize(txtobj):
 if len(txtobj)==0: return []
 else:
        tokens = [token.lower_ for token in nlp(txtobj, disable=[""parser"", ""ner""])]
        tokens = [remove_punct(t) for t in tokens if remove_punct(t) not in stop_n
 and len(remove_punct(t))&lt;30
 and not remove_punct(t).isnumeric()
 and remove_punct(t)]
        tokens = [t for t in tokens if t not in stop_n and not t.isnumeric()
 and t and t!='' and t!=' ' and len(t)&gt;0 and t not in list(string.punctuation)]
        tokens = [t[0] for t in groupby(tokens)]
 return tokens

def spacy_lemmatize(txtobj):
 if len(txtobj)==0: return []
 else:
 return [token.lemma_ for token in nlp(txtobj, disable=[""parser"", ""ner""])]

folder = '/path'
oe = pd.read_csv(os.path.join(folder, 'file_name.csv'), sep='|', encoding='utf-8')

stop = pd.read_csv(os.path.join(folder, 'stopwords.csv'), header=0)
stop_o = stop.stopwords.tolist()
stop_o.extend(list(string.ascii_lowercase))
stop_o.extend(list(string.punctuation))
stop_o.extend(list(string.digits))
stop_o.extend([';','.','/',',','+','n/a','#',""'"", '""', '’', '“', '‘','&amp;', ""n't"", '10', '100', 'like', 'love', 'nan','ton','-PRON-'])
stop_o = list(set(stop_o))
ignore = ['good','great','best','better','everywhere','few','many','least', 'help','have','find', 'years','less','little','never'
            ,'name','high','newer','small','young','everything','everywhere', 'anywhere']
stop_n = [s for s in stop_o if s not in ignore] #stop words minus descriptive words that are actually helpful
common_terms = ignore+[""of"", ""with"", ""without"", ""and"", ""or"", ""the"", ""a"", ""to"", ""in"", ""on"", ""an"", ""than""]

oe['Q5_clean'] = oe['Q5'].astype(str).str.replace('  ',' ')
oe['Q5_clean'] = oe.apply(lambda row: convert_triples(row['Q5_clean']),axis=1)
oe.loc[oe['Q5_clean'].notna(), 'Q5_clean'] = oe.apply(lambda row: spellcheck(row['Q5_clean']),axis=1)
oe['Q5_clean'] = oe['Q5_clean'].str.strip()
oe.loc[oe['Q5_clean'].notna(), 'Q5_tokens'] = oe.apply(lambda row: spacy_tokenize(row['Q5_clean']),axis=1)
oe['Q5_valid'] = oe.Q5_tokens.astype(bool)
oe['Q5_lemmas'] = oe['Q5_tokens'].apply(' '.join)
oe.loc[oe['Q5_clean'].notna(), 'Q5_lemmas'] = oe.apply(lambda row: spacy_lemmatize(row['Q5_lemmas']),axis=1)
oe['Q5_lemmas'] = oe['Q5_lemmas'].apply(' '.join)

Q5 = list(oe[oe.Q5_valid]['Q5_lemmas'].unique())
Q5_sent_toks = [word_tokenize(f) for f in Q5]

dictionary = Dictionary(Q5_sent_toks)
dictionary.filter_extremes(no_below=3, no_above=0.95)
bow_corpus = [dictionary.doc2bow(s) for s in Q5_sent_toks]

tfidf = gensim.models.TfidfModel(dictionary=dictionary, normalize=True)
tfidf_corpus = tfidf[bow_corpus]

tf_idf_lda_model = LdaMulticore(corpus=tfidf_corpus, id2word=dictionary, num_topics=8, random_state=100,
 chunksize=1000, passes=20, iterations = 10, minimum_probability=0.52, workers=2)
top_topics_tf = tf_idf_lda_model.top_topics(tfidf_corpus)
pprint(top_topics_tf)```",t2_ywa5s,Requesting help on topic modelling (NLP),projects,t3_hrtil1,0.5,0,Projects,0,1594867976.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;m not a data scientist but trying to create topics for open-ended comments we collect on a weekly survey (the exact question is : why is this your favorite brand?). I don&amp;#39;t think it&amp;#39;s a problem with my code as topics are indeed generated, they just don&amp;#39;t make &lt;strong&gt;any&lt;/strong&gt; sense. Keywords are represented in multiple topics. I even tried using bigrams/trigrams - creating ngrams of the default text without removing stopwords or lemmatizing creates topics that are just as useless, but if I do remove words then I have ngrams that are not accurate because those words don&amp;#39;t actually appear together.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Right now I&amp;#39;ve asked my team to hand code the topics, but I need a more sustainable way going forward. Is there a better way to generate distinct topics?  Or should I just focus on categorizing going forward based on what the team comes up with this time?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Generic code below (edit: had to remove comments to stop the automatic markdown conversion to headers).&lt;/p&gt;

&lt;p&gt;```import pandas as pd, warnings, os, string, re, itertools, language_check, spacy
from pprint import pprint
from itertools import groupby&lt;br/&gt;
from nltk import sent_tokenize
from nltk.tokenize import word_tokenize&lt;/p&gt;

&lt;p&gt;import gensim, gensim.models
from gensim.corpora import Dictionary
from gensim.models import LdaMulticore&lt;/p&gt;

&lt;p&gt;tool = language_check.LanguageTool(&amp;#39;en-US&amp;#39;)
nlp = spacy.load(&amp;quot;en_core_web_sm&amp;quot;)
warnings.filterwarnings(&amp;quot;ignore&amp;quot;)&lt;/p&gt;

&lt;p&gt;def remove_punct(word):
 return word.translate(str.maketrans(&amp;#39;&amp;#39;, &amp;#39;&amp;#39;, string.punctuation)).replace(&amp;#39;  &amp;#39;,&amp;#39; &amp;#39;)&lt;/p&gt;

&lt;p&gt;def convert_triples(txt):
    x = re.sub(r&amp;#39;(?i)(.)\1{2,}&amp;#39;, r&amp;#39;\1\1&amp;#39;, txt, re.IGNORECASE)
    x = re.sub(r&amp;#39;(.)\1{2,}&amp;#39;, r&amp;#39;\1\1&amp;#39;, x, re.IGNORECASE)
 return x&lt;/p&gt;

&lt;p&gt;def spellcheck(txt):
    matches = tool.check(txt)
    matches = [m for m in matches
 if m.category not in [&amp;#39;Redundant Phrases&amp;#39;, &amp;#39;Capitalization&amp;#39;, &amp;#39;Redundancy&amp;#39;, &amp;#39;Plain English&amp;#39;]
 and m.locqualityissuetype not in [&amp;#39;style&amp;#39;, &amp;#39;uncategorized&amp;#39;]
 and (m.ruleId!=&amp;#39;MORFOLOGIK_RULE_EN_US&amp;#39; and m.msg!=&amp;#39;Possible spelling mistake found&amp;#39;)
 and len(m.replacements)&amp;gt;0]
 if len(matches)&amp;gt;0:
 #x = tool.correct(txt, matches)
        x = language_check.correct(txt, matches)
 return x
 else : 
 return txt&lt;/p&gt;

&lt;p&gt;def spacy&lt;em&gt;tokenize(txtobj):
 if len(txtobj)==0: return []
 else:
        tokens = [token.lower&lt;/em&gt; for token in nlp(txtobj, disable=[&amp;quot;parser&amp;quot;, &amp;quot;ner&amp;quot;])]
        tokens = [remove_punct(t) for t in tokens if remove_punct(t) not in stop_n
 and len(remove_punct(t))&amp;lt;30
 and not remove_punct(t).isnumeric()
 and remove_punct(t)]
        tokens = [t for t in tokens if t not in stop_n and not t.isnumeric()
 and t and t!=&amp;#39;&amp;#39; and t!=&amp;#39; &amp;#39; and len(t)&amp;gt;0 and t not in list(string.punctuation)]
        tokens = [t[0] for t in groupby(tokens)]
 return tokens&lt;/p&gt;

&lt;p&gt;def spacy&lt;em&gt;lemmatize(txtobj):
 if len(txtobj)==0: return []
 else:
 return [token.lemma&lt;/em&gt; for token in nlp(txtobj, disable=[&amp;quot;parser&amp;quot;, &amp;quot;ner&amp;quot;])]&lt;/p&gt;

&lt;p&gt;folder = &amp;#39;/path&amp;#39;
oe = pd.read_csv(os.path.join(folder, &amp;#39;file_name.csv&amp;#39;), sep=&amp;#39;|&amp;#39;, encoding=&amp;#39;utf-8&amp;#39;)&lt;/p&gt;

&lt;p&gt;stop = pd.read_csv(os.path.join(folder, &amp;#39;stopwords.csv&amp;#39;), header=0)
stop_o = stop.stopwords.tolist()
stop_o.extend(list(string.ascii_lowercase))
stop_o.extend(list(string.punctuation))
stop_o.extend(list(string.digits))
stop_o.extend([&amp;#39;;&amp;#39;,&amp;#39;.&amp;#39;,&amp;#39;/&amp;#39;,&amp;#39;,&amp;#39;,&amp;#39;+&amp;#39;,&amp;#39;n/a&amp;#39;,&amp;#39;#&amp;#39;,&amp;quot;&amp;#39;&amp;quot;, &amp;#39;&amp;quot;&amp;#39;, &amp;#39;’&amp;#39;, &amp;#39;“&amp;#39;, &amp;#39;‘&amp;#39;,&amp;#39;&amp;amp;&amp;#39;, &amp;quot;n&amp;#39;t&amp;quot;, &amp;#39;10&amp;#39;, &amp;#39;100&amp;#39;, &amp;#39;like&amp;#39;, &amp;#39;love&amp;#39;, &amp;#39;nan&amp;#39;,&amp;#39;ton&amp;#39;,&amp;#39;-PRON-&amp;#39;])
stop_o = list(set(stop_o))
ignore = [&amp;#39;good&amp;#39;,&amp;#39;great&amp;#39;,&amp;#39;best&amp;#39;,&amp;#39;better&amp;#39;,&amp;#39;everywhere&amp;#39;,&amp;#39;few&amp;#39;,&amp;#39;many&amp;#39;,&amp;#39;least&amp;#39;, &amp;#39;help&amp;#39;,&amp;#39;have&amp;#39;,&amp;#39;find&amp;#39;, &amp;#39;years&amp;#39;,&amp;#39;less&amp;#39;,&amp;#39;little&amp;#39;,&amp;#39;never&amp;#39;
            ,&amp;#39;name&amp;#39;,&amp;#39;high&amp;#39;,&amp;#39;newer&amp;#39;,&amp;#39;small&amp;#39;,&amp;#39;young&amp;#39;,&amp;#39;everything&amp;#39;,&amp;#39;everywhere&amp;#39;, &amp;#39;anywhere&amp;#39;]
stop_n = [s for s in stop_o if s not in ignore] #stop words minus descriptive words that are actually helpful
common_terms = ignore+[&amp;quot;of&amp;quot;, &amp;quot;with&amp;quot;, &amp;quot;without&amp;quot;, &amp;quot;and&amp;quot;, &amp;quot;or&amp;quot;, &amp;quot;the&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;to&amp;quot;, &amp;quot;in&amp;quot;, &amp;quot;on&amp;quot;, &amp;quot;an&amp;quot;, &amp;quot;than&amp;quot;]&lt;/p&gt;

&lt;p&gt;oe[&amp;#39;Q5_clean&amp;#39;] = oe[&amp;#39;Q5&amp;#39;].astype(str).str.replace(&amp;#39;  &amp;#39;,&amp;#39; &amp;#39;)
oe[&amp;#39;Q5_clean&amp;#39;] = oe.apply(lambda row: convert_triples(row[&amp;#39;Q5_clean&amp;#39;]),axis=1)
oe.loc[oe[&amp;#39;Q5_clean&amp;#39;].notna(), &amp;#39;Q5_clean&amp;#39;] = oe.apply(lambda row: spellcheck(row[&amp;#39;Q5_clean&amp;#39;]),axis=1)
oe[&amp;#39;Q5_clean&amp;#39;] = oe[&amp;#39;Q5_clean&amp;#39;].str.strip()
oe.loc[oe[&amp;#39;Q5_clean&amp;#39;].notna(), &amp;#39;Q5_tokens&amp;#39;] = oe.apply(lambda row: spacy_tokenize(row[&amp;#39;Q5_clean&amp;#39;]),axis=1)
oe[&amp;#39;Q5_valid&amp;#39;] = oe.Q5_tokens.astype(bool)
oe[&amp;#39;Q5_lemmas&amp;#39;] = oe[&amp;#39;Q5_tokens&amp;#39;].apply(&amp;#39; &amp;#39;.join)
oe.loc[oe[&amp;#39;Q5_clean&amp;#39;].notna(), &amp;#39;Q5_lemmas&amp;#39;] = oe.apply(lambda row: spacy_lemmatize(row[&amp;#39;Q5_lemmas&amp;#39;]),axis=1)
oe[&amp;#39;Q5_lemmas&amp;#39;] = oe[&amp;#39;Q5_lemmas&amp;#39;].apply(&amp;#39; &amp;#39;.join)&lt;/p&gt;

&lt;p&gt;Q5 = list(oe[oe.Q5_valid][&amp;#39;Q5_lemmas&amp;#39;].unique())
Q5_sent_toks = [word_tokenize(f) for f in Q5]&lt;/p&gt;

&lt;p&gt;dictionary = Dictionary(Q5_sent_toks)
dictionary.filter_extremes(no_below=3, no_above=0.95)
bow_corpus = [dictionary.doc2bow(s) for s in Q5_sent_toks]&lt;/p&gt;

&lt;p&gt;tfidf = gensim.models.TfidfModel(dictionary=dictionary, normalize=True)
tfidf_corpus = tfidf[bow_corpus]&lt;/p&gt;

&lt;p&gt;tf_idf_lda_model = LdaMulticore(corpus=tfidf_corpus, id2word=dictionary, num_topics=8, random_state=100,
 chunksize=1000, passes=20, iterations = 10, minimum_probability=0.52, workers=2)
top_topics_tf = tf_idf_lda_model.top_topics(tfidf_corpus)
pprint(top_topics_tf)```&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrtil1,dontsaybye,12,/r/datascience/comments/hrtil1/requesting_help_on_topic_modelling_nlp/,https://www.reddit.com/r/datascience/comments/hrtil1/requesting_help_on_topic_modelling_nlp/,1594839176.0
r/datascience,"* Can you access ""production"" data on your laptop? or do you have to use a VM? What about for end consumers of data?
* Do you have pseudonymized or ""dev"" data that is easier to query and use than non-anonymous, ""production"" data?
* Do you have super accounts to access databases?
* Do you feel your company's data policy strikes the right balance b/w enablement and security?

With any answer it'd be interesting to hear how many employees the company has, as I'm sure there's a correlation.",t2_6pkco,data access &amp; security: what is your company's approach?,discussion,t3_hrrfq4,0.67,1,Discussion,1,1594861515.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;ul&gt;
&lt;li&gt;Can you access &amp;quot;production&amp;quot; data on your laptop? or do you have to use a VM? What about for end consumers of data?&lt;/li&gt;
&lt;li&gt;Do you have pseudonymized or &amp;quot;dev&amp;quot; data that is easier to query and use than non-anonymous, &amp;quot;production&amp;quot; data?&lt;/li&gt;
&lt;li&gt;Do you have super accounts to access databases?&lt;/li&gt;
&lt;li&gt;Do you feel your company&amp;#39;s data policy strikes the right balance b/w enablement and security?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With any answer it&amp;#39;d be interesting to hear how many employees the company has, as I&amp;#39;m sure there&amp;#39;s a correlation.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrrfq4,andersdellosnubes,4,/r/datascience/comments/hrrfq4/data_access_security_what_is_your_companys/,https://www.reddit.com/r/datascience/comments/hrrfq4/data_access_security_what_is_your_companys/,1594832715.0
r/datascience,"Hi guys!

This might be a long post, so thank you for taking the time to read this :)

I just graduated with a Sociology degree from a college in U.S, but discovered the field of data science in my senior year. I know a lot of people have told me that I might not need to go back to school, I can learn on my own to get a data science job with SQL, Python, but because I am from South East Asia (data science jobs are not very big here), I am hoping to go to college again to get a degree to be able to get a job abroad to work in the future. It's much easier to get a job abroad/work visa in e.g Canada, Australia etc if I graduate from there. I am wondering if anyone can give me any advice on countries/universities that would offer a second bachelors, masters or diploma that would allow me to learn more? I am hoping to avoid the U.S. because the work visa is a bit difficult to obtain.

I have been stuck on trying to find schools and been quite stressed about it... The amount of money that I can afford to spend on the whole degree (including accommodation, fees, tuition etc) is USD $60k-65k... since I have already spent a fortune on my current undergrad...

Thank you so much! &lt;3",t2_2qavizjk,Second bachelors or masters?,education,t3_hrre3l,0.6,1,Education,1,1594861363.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys!&lt;/p&gt;

&lt;p&gt;This might be a long post, so thank you for taking the time to read this :)&lt;/p&gt;

&lt;p&gt;I just graduated with a Sociology degree from a college in U.S, but discovered the field of data science in my senior year. I know a lot of people have told me that I might not need to go back to school, I can learn on my own to get a data science job with SQL, Python, but because I am from South East Asia (data science jobs are not very big here), I am hoping to go to college again to get a degree to be able to get a job abroad to work in the future. It&amp;#39;s much easier to get a job abroad/work visa in e.g Canada, Australia etc if I graduate from there. I am wondering if anyone can give me any advice on countries/universities that would offer a second bachelors, masters or diploma that would allow me to learn more? I am hoping to avoid the U.S. because the work visa is a bit difficult to obtain.&lt;/p&gt;

&lt;p&gt;I have been stuck on trying to find schools and been quite stressed about it... The amount of money that I can afford to spend on the whole degree (including accommodation, fees, tuition etc) is USD $60k-65k... since I have already spent a fortune on my current undergrad...&lt;/p&gt;

&lt;p&gt;Thank you so much! &amp;lt;3&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrre3l,lewu058,5,/r/datascience/comments/hrre3l/second_bachelors_or_masters/,https://www.reddit.com/r/datascience/comments/hrre3l/second_bachelors_or_masters/,1594832563.0
r/datascience,"Hi all,

I would like to ask for advice on how to use recommendation letter from my post graduate professor. A few months ago I graduated from my master program of computer/data science from my university and I am looking for a job in the data science field. In the last semester, I have the privilege to work with the professors from the school's computer science department and are publishing a paper to ICML this year. The professor seems happy about my work and agree to write an recommendation letter for me, he even said he was willing to have one of his colleagues who is famous in the field to sign on the recommendation letter. So I start thinking what the best way to utilize this opportunity is to help on my current job search. 

There are two options that I can think of right now as below:

* Ask the professor to write the recommendation letter on my LinkedIn profile

The benefit of this option is that the letter can be viewed publicly by recruiters and HR managers and the value of the letter can be re-used and last long. However, I will not get the endorsement from my professor's famous colleague.

* Ask the professor to write the recommendation letter to a specific company that I apply for

In this solution, I will be able to get the signature from my professor and the famous person's name on the letter which increase the letter's value, but I can only use it once. If I didn't admitted to the company, the letter basically goes useless.

I am relatively inexperienced on this recommendation letter subject and open to any suggestion and advice, if you see any other better way to utilize the professor's recommendation letter, feel free to let me know.

I'd really appreciate.

Thank you!",t2_56yq5mhu,What is the best way to make the most of the recommendation from professor,career,t3_hrr5kd,0.43,0,Career,0,1594860616.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I would like to ask for advice on how to use recommendation letter from my post graduate professor. A few months ago I graduated from my master program of computer/data science from my university and I am looking for a job in the data science field. In the last semester, I have the privilege to work with the professors from the school&amp;#39;s computer science department and are publishing a paper to ICML this year. The professor seems happy about my work and agree to write an recommendation letter for me, he even said he was willing to have one of his colleagues who is famous in the field to sign on the recommendation letter. So I start thinking what the best way to utilize this opportunity is to help on my current job search. &lt;/p&gt;

&lt;p&gt;There are two options that I can think of right now as below:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ask the professor to write the recommendation letter on my LinkedIn profile&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The benefit of this option is that the letter can be viewed publicly by recruiters and HR managers and the value of the letter can be re-used and last long. However, I will not get the endorsement from my professor&amp;#39;s famous colleague.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ask the professor to write the recommendation letter to a specific company that I apply for&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this solution, I will be able to get the signature from my professor and the famous person&amp;#39;s name on the letter which increase the letter&amp;#39;s value, but I can only use it once. If I didn&amp;#39;t admitted to the company, the letter basically goes useless.&lt;/p&gt;

&lt;p&gt;I am relatively inexperienced on this recommendation letter subject and open to any suggestion and advice, if you see any other better way to utilize the professor&amp;#39;s recommendation letter, feel free to let me know.&lt;/p&gt;

&lt;p&gt;I&amp;#39;d really appreciate.&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrr5kd,sylvao08,1,/r/datascience/comments/hrr5kd/what_is_the_best_way_to_make_the_most_of_the/,https://www.reddit.com/r/datascience/comments/hrr5kd/what_is_the_best_way_to_make_the_most_of_the/,1594831816.0
r/datascience,I was recently wondering to utilize the pandemic time and work from home to do some certifications and was wondering if the AWS machine learning speciality certification is valuable in our Industry or just a good to have. Will really appreciate all your reviews/suggestions as I am looking to do this certification or any other which adds value to my profile with 3+ years experience in Data Science,t2_w7si0x,Reviews of AWS machine learning speciality certification,career,t3_hrpw0b,1.0,1,Career,1,1594856540.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was recently wondering to utilize the pandemic time and work from home to do some certifications and was wondering if the AWS machine learning speciality certification is valuable in our Industry or just a good to have. Will really appreciate all your reviews/suggestions as I am looking to do this certification or any other which adds value to my profile with 3+ years experience in Data Science&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrpw0b,kineticker,8,/r/datascience/comments/hrpw0b/reviews_of_aws_machine_learning_speciality/,https://www.reddit.com/r/datascience/comments/hrpw0b/reviews_of_aws_machine_learning_speciality/,1594827740.0
r/datascience,"Sorry for the vague title, not quite sure how to frame this question. But basically I'm working on a classification problem atm, where samples are divided into groups, and we have class labels for those groups rather than the individual samples. At the moment we're handling this by aggregating features for each group and training on those, but it feels a bit ugly and like we're losing information by doing this- we have loads of features like x_percentile_10, x_median, x_percentile_90, y_std etc- it just feels like it would be better to train on all the data and avoid this. Are there any techniques for doing this or can you point me in the direction of the right things to google? Thanks",t2_zcfifuy,Learning on 'distributions' rather than individual samples?,discussion,t3_hrjz72,0.75,2,Discussion,2,1594831174.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sorry for the vague title, not quite sure how to frame this question. But basically I&amp;#39;m working on a classification problem atm, where samples are divided into groups, and we have class labels for those groups rather than the individual samples. At the moment we&amp;#39;re handling this by aggregating features for each group and training on those, but it feels a bit ugly and like we&amp;#39;re losing information by doing this- we have loads of features like x_percentile_10, x_median, x_percentile_90, y_std etc- it just feels like it would be better to train on all the data and avoid this. Are there any techniques for doing this or can you point me in the direction of the right things to google? Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrjz72,Data-5cientist,7,/r/datascience/comments/hrjz72/learning_on_distributions_rather_than_individual/,https://www.reddit.com/r/datascience/comments/hrjz72/learning_on_distributions_rather_than_individual/,1594802374.0
r/datascience,"I just got my ds degree and now I am exploring the career options in the field.

What is the best freelance platform for data scientists? 
Is this a viable alternative to a regular job?
What kind of experience is appreciated the most?

And most importantly, what is the best way to show people who are not qualified recruiters that you are good for the job?",t2_2prjmxtg,How is freelance data science market working?,discussion,t3_hqydnm,0.87,66,Discussion,66,1594747379.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just got my ds degree and now I am exploring the career options in the field.&lt;/p&gt;

&lt;p&gt;What is the best freelance platform for data scientists? 
Is this a viable alternative to a regular job?
What kind of experience is appreciated the most?&lt;/p&gt;

&lt;p&gt;And most importantly, what is the best way to show people who are not qualified recruiters that you are good for the job?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hqydnm,zef16,30,/r/datascience/comments/hqydnm/how_is_freelance_data_science_market_working/,https://www.reddit.com/r/datascience/comments/hqydnm/how_is_freelance_data_science_market_working/,1594718579.0
r/datascience,"This has happened more than once to me: I write my code, it works as intended per goals set by manager, I explain what I did to manager best I can, they don't understand it, and then says what we should do... which literally happens to be what I just did and showcased. I reiterate that that is what I had just accomplished, and then they understand. If they don't understand then, they understand later when it comes to production and they end up reverting back to something I wrote weeks prior. 

I don't think this my manager's fault. I think it is my fault. I generally have a hard time explaining things I do or what's going on in my head, especially if it is very complicated and there are parts that would take me a while to explain without walking through the math for them or writing them up first. Communication is so key in this field, but it is currently my shortcoming. It wasn't always the case, it just started happening when I shifted my field from something else to this field. Not sure if all the coding and grinding through books shuffled up my brain and made me lose my ability to speak properly lol. 

Does anyone have any real, practical tips that I can apply to help me get my points across better or just communicate what I need to better? I am open to trying anything. Thank you in advance.",t2_bdyv63,Failing to demonstrate my work well due to communication shortcomings,career,t3_hrazsq,1.0,6,Career,6,1594792764.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This has happened more than once to me: I write my code, it works as intended per goals set by manager, I explain what I did to manager best I can, they don&amp;#39;t understand it, and then says what we should do... which literally happens to be what I just did and showcased. I reiterate that that is what I had just accomplished, and then they understand. If they don&amp;#39;t understand then, they understand later when it comes to production and they end up reverting back to something I wrote weeks prior. &lt;/p&gt;

&lt;p&gt;I don&amp;#39;t think this my manager&amp;#39;s fault. I think it is my fault. I generally have a hard time explaining things I do or what&amp;#39;s going on in my head, especially if it is very complicated and there are parts that would take me a while to explain without walking through the math for them or writing them up first. Communication is so key in this field, but it is currently my shortcoming. It wasn&amp;#39;t always the case, it just started happening when I shifted my field from something else to this field. Not sure if all the coding and grinding through books shuffled up my brain and made me lose my ability to speak properly lol. &lt;/p&gt;

&lt;p&gt;Does anyone have any real, practical tips that I can apply to help me get my points across better or just communicate what I need to better? I am open to trying anything. Thank you in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hrazsq,itanorchi,16,/r/datascience/comments/hrazsq/failing_to_demonstrate_my_work_well_due_to/,https://www.reddit.com/r/datascience/comments/hrazsq/failing_to_demonstrate_my_work_well_due_to/,1594763964.0
r/datascience,"Hi, has anyone used or uses Data Science in the Pharma Industry? 

I have been working R&amp;D Pharma for more than a decade and for long time been interested in data science field. The thing is, as far as I know, it might be use in the bussiness side but have never seen it on the technical side (at least in my country). I was wondering if anybody has worked on projects or knows about data science being use in R&amp;D o another more thechnical side of the industry.

Thanks everyone!",t2_3c5y1iu9,Data science in Pharma Industry,discussion,t3_hr857i,0.91,8,Discussion,8,1594783791.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, has anyone used or uses Data Science in the Pharma Industry? &lt;/p&gt;

&lt;p&gt;I have been working R&amp;amp;D Pharma for more than a decade and for long time been interested in data science field. The thing is, as far as I know, it might be use in the bussiness side but have never seen it on the technical side (at least in my country). I was wondering if anybody has worked on projects or knows about data science being use in R&amp;amp;D o another more thechnical side of the industry.&lt;/p&gt;

&lt;p&gt;Thanks everyone!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hr857i,PracticalReader,7,/r/datascience/comments/hr857i/data_science_in_pharma_industry/,https://www.reddit.com/r/datascience/comments/hr857i/data_science_in_pharma_industry/,1594754991.0
r/datascience,"If this isn't the right subreddit to post this please point me towards a more appropriate one.

tldr: My team's codebase is a mess of unorganized and poorly documented jupyter notebooks/.py files and I am trying to figure out the best method/way of managing all of it in a more standardized way.

As the title states, how do you all manage your company/team's codebase/tools? I recently got hired in a healthcare company as a statistical modeling analyst and to say the least - their unorganized as hell when it comes to their code. In the past, the position I have was handled by one person and basically just held all their code/juptyer notebooks in their personal directory; I am talking about \~2.5 years worth of ad hoc analysis, analytic tools (finished and unfinished), jupyter notebooks that outline several major processes. There are also some major production tools he made that are stored in his folder without any real meaningful way of doing some version control.

Then about 8 months ago, they hired my co-worker (lets call him Bob) who didn't have any coding background and learned by just re-using the first guy's work. He accessed/still accesses it through the first guy's folder, but copied it over to his own personal folder and added a bunch of edits. Well, the first guy leaves to Google and he leaves this mess without much documentation (I am talking even without much comments within the notebooks, let alone a README file).

Fast-forward to a month ago, I come in and am shadowing Bob and he is jumping back and forth across multiple (read: almost a dozen) different folders at a time trying to find the right jupyter notebook to use, has at least 5 untitled jupyter notebooks opened at once doing several things (sometimes working on the same project across multiple notebooks), and overall just a very messy and poorly documented workflow. Outputs get put in not a standardized fashion, everything just seems like a mess. He even confuses himself sometimes on which notebook is working on what.

I myself am starting to build tools/automate parts of the job, but I don't want to fall in the same habit of just storing it all on my personal directory and have files (.py) floating around everywhere. Luckily this position gives me a lot of freedom to spend time improving on this aspect of the job. So to return back to the original reason for the post - what is the best way to go about this? Should I try pushing for a github for our team in order to organize everything? Or is there a better alternative? My background is astrophysics so I don't have much experience doing version control or managing codebases, but since I'm planning on being in the position for a while, I dont want to have a bajillion notebooks open at once.",t2_39fgc1dn,How do you manage your company's codebase?,discussion,t3_hr4qkf,0.86,9,Discussion,9,1594773149.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If this isn&amp;#39;t the right subreddit to post this please point me towards a more appropriate one.&lt;/p&gt;

&lt;p&gt;tldr: My team&amp;#39;s codebase is a mess of unorganized and poorly documented jupyter notebooks/.py files and I am trying to figure out the best method/way of managing all of it in a more standardized way.&lt;/p&gt;

&lt;p&gt;As the title states, how do you all manage your company/team&amp;#39;s codebase/tools? I recently got hired in a healthcare company as a statistical modeling analyst and to say the least - their unorganized as hell when it comes to their code. In the past, the position I have was handled by one person and basically just held all their code/juptyer notebooks in their personal directory; I am talking about ~2.5 years worth of ad hoc analysis, analytic tools (finished and unfinished), jupyter notebooks that outline several major processes. There are also some major production tools he made that are stored in his folder without any real meaningful way of doing some version control.&lt;/p&gt;

&lt;p&gt;Then about 8 months ago, they hired my co-worker (lets call him Bob) who didn&amp;#39;t have any coding background and learned by just re-using the first guy&amp;#39;s work. He accessed/still accesses it through the first guy&amp;#39;s folder, but copied it over to his own personal folder and added a bunch of edits. Well, the first guy leaves to Google and he leaves this mess without much documentation (I am talking even without much comments within the notebooks, let alone a README file).&lt;/p&gt;

&lt;p&gt;Fast-forward to a month ago, I come in and am shadowing Bob and he is jumping back and forth across multiple (read: almost a dozen) different folders at a time trying to find the right jupyter notebook to use, has at least 5 untitled jupyter notebooks opened at once doing several things (sometimes working on the same project across multiple notebooks), and overall just a very messy and poorly documented workflow. Outputs get put in not a standardized fashion, everything just seems like a mess. He even confuses himself sometimes on which notebook is working on what.&lt;/p&gt;

&lt;p&gt;I myself am starting to build tools/automate parts of the job, but I don&amp;#39;t want to fall in the same habit of just storing it all on my personal directory and have files (.py) floating around everywhere. Luckily this position gives me a lot of freedom to spend time improving on this aspect of the job. So to return back to the original reason for the post - what is the best way to go about this? Should I try pushing for a github for our team in order to organize everything? Or is there a better alternative? My background is astrophysics so I don&amp;#39;t have much experience doing version control or managing codebases, but since I&amp;#39;m planning on being in the position for a while, I dont want to have a bajillion notebooks open at once.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hr4qkf,nollange_,13,/r/datascience/comments/hr4qkf/how_do_you_manage_your_companys_codebase/,https://www.reddit.com/r/datascience/comments/hr4qkf/how_do_you_manage_your_companys_codebase/,1594744349.0
r/datascience,"Fresh thread for 2020 extensions...

1) Jupyter Debugger ; This seems to require a novel Xeus-Python kernel. When i use it, my other extensions do not work (like JupyterDash extension)

2) AI - code complete ; Is there a recommendation for an AI service for code completion which works in Jupyter Lab? I know the company Kite has a beta program for this but TBA

I don't use many extensions myself, but I hope there are some recommendations which increase quality-of-life.",t2_76gf1dkz,JupyterLab Extensions for 2020?,tooling,t3_hqzblu,0.8,13,Tooling,13,1594752583.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Fresh thread for 2020 extensions...&lt;/p&gt;

&lt;p&gt;1) Jupyter Debugger ; This seems to require a novel Xeus-Python kernel. When i use it, my other extensions do not work (like JupyterDash extension)&lt;/p&gt;

&lt;p&gt;2) AI - code complete ; Is there a recommendation for an AI service for code completion which works in Jupyter Lab? I know the company Kite has a beta program for this but TBA&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t use many extensions myself, but I hope there are some recommendations which increase quality-of-life.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hqzblu,shotihoti,12,/r/datascience/comments/hqzblu/jupyterlab_extensions_for_2020/,https://www.reddit.com/r/datascience/comments/hqzblu/jupyterlab_extensions_for_2020/,1594723783.0
r/datascience,"I've noticed that clustering seems to be one of the main focus areas of machine learning. After basic regression &amp; classification, clustering seems to be the area most people learn about next when they are learning the fundamentals. However, I've never used it. Nobody I know has ever used it either. We all know how most of the algorithms work (k means, dbscan, etc), but these algorithms never seem to fit into the data / problem we are trying to solve.

I was wondering if anyone has actually used these algorithms, what they used them for, and how well it worked out.",t2_i8ujh,Has Anyone Actually Used Clustering to Solve an Industry Problem?,discussion,t3_hqfvp4,0.97,337,Discussion,337,1594678062.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve noticed that clustering seems to be one of the main focus areas of machine learning. After basic regression &amp;amp; classification, clustering seems to be the area most people learn about next when they are learning the fundamentals. However, I&amp;#39;ve never used it. Nobody I know has ever used it either. We all know how most of the algorithms work (k means, dbscan, etc), but these algorithms never seem to fit into the data / problem we are trying to solve.&lt;/p&gt;

&lt;p&gt;I was wondering if anyone has actually used these algorithms, what they used them for, and how well it worked out.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hqfvp4,suspicious_gardener,187,/r/datascience/comments/hqfvp4/has_anyone_actually_used_clustering_to_solve_an/,https://www.reddit.com/r/datascience/comments/hqfvp4/has_anyone_actually_used_clustering_to_solve_an/,1594649262.0
r/datascience,"Hi, amateur data scientist here, and I've been tasked with building an automated categorization tool for supplier lists. In essence, it needs to take a vendor name, and output what category it falls into. Categories include, but are not limited too: Transportation, Legal, IT, Construction, Staffing, Manufacturing, or Maintenance &amp; Installation.

So far, I've considered two strategies.

* *Option A*
Using a google search API to scrape the top ten search results for that vendor, build or utilize an existing NLP algorithm to match the Google output with a category from a pre-built table of categories. 

* *Option B*
Build a table of supplier names and their associated categories using previous data, and then fuzzy match new supplier data as best I can with the pre-built table. This one is tricky as ""Delta Air Inc,"" ""D Airlines,"" ""Delta"" would all need to be matched to the same supplier, but not ""D Air""--that's an air conditioning company. Additionally, it would be added too as needed---if the supplier isn't present, either manually input their data or utilize something like *Option A*. 

Looking over the two options, I see now that they may be one and the same, but two different levels in the hierarchy of the tool. 

Either way, I wanted to see what the smart users of this subreddit would suggest. How would you tackle it? Any algorithms that could simplify things? Is there a tool out there you know about that accomplishes this very goal?",t2_srzxf,"Big-Picture Help for Project, Categorizing Supplier Names",discussion,t3_hr4ty4,1.0,1,Discussion,1,1594773460.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, amateur data scientist here, and I&amp;#39;ve been tasked with building an automated categorization tool for supplier lists. In essence, it needs to take a vendor name, and output what category it falls into. Categories include, but are not limited too: Transportation, Legal, IT, Construction, Staffing, Manufacturing, or Maintenance &amp;amp; Installation.&lt;/p&gt;

&lt;p&gt;So far, I&amp;#39;ve considered two strategies.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Option A&lt;/em&gt;
Using a google search API to scrape the top ten search results for that vendor, build or utilize an existing NLP algorithm to match the Google output with a category from a pre-built table of categories. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Option B&lt;/em&gt;
Build a table of supplier names and their associated categories using previous data, and then fuzzy match new supplier data as best I can with the pre-built table. This one is tricky as &amp;quot;Delta Air Inc,&amp;quot; &amp;quot;D Airlines,&amp;quot; &amp;quot;Delta&amp;quot; would all need to be matched to the same supplier, but not &amp;quot;D Air&amp;quot;--that&amp;#39;s an air conditioning company. Additionally, it would be added too as needed---if the supplier isn&amp;#39;t present, either manually input their data or utilize something like &lt;em&gt;Option A&lt;/em&gt;. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Looking over the two options, I see now that they may be one and the same, but two different levels in the hierarchy of the tool. &lt;/p&gt;

&lt;p&gt;Either way, I wanted to see what the smart users of this subreddit would suggest. How would you tackle it? Any algorithms that could simplify things? Is there a tool out there you know about that accomplishes this very goal?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hr4ty4,Marthorax,3,/r/datascience/comments/hr4ty4/bigpicture_help_for_project_categorizing_supplier/,https://www.reddit.com/r/datascience/comments/hr4ty4/bigpicture_help_for_project_categorizing_supplier/,1594744660.0
r/datascience,"Hoping to tap the hivemind of Reddit for this question.

For those of you who manage data science managers/people leaders, or are part of interview panels for data science managers: are there different expectations of technical aptitude between people manager candidates and ICs who apply for \[senior/principal\] data science roles?

Why I'm asking this question: I'm a people manager myself at a mid-sized company in the Bay Area, with a Masters in Data Science and 4+ years of leadership experience (in industry for 15). I am simply not as ""in the weeds"" as my team members are... nor is there an expectation by my leadership teams that I code or query every day; while this frustrates me, I continue to receive praise for helping my team do better work, asking the right questions, ensuring they are staying on track, etc. 

However, I have applied to other manager positions, and my technical interviews have been VERY technical: I've had a total of 10-15 technical-round interviews in the last 6-8 months. It's clear that I pass the leadership scrutiny test, but I continue to miss expectations on the technical front. In short, I'm rusty. 

I understand that teams and companies have different needs... but are companies really expecting senior managers and/or directors to be able to perform technically at the same level as ICs? Or is the truth of the matter that I--and others in my situation--simply have to review like crazy, even at this level? Are VPs asked technical questions as well? 

Hope that wasn't too rant-like. Would love to hear thoughts.

Updated for grammar/details",t2_2qz9deek,Directors/VPs &amp; up: How do your technical interviews differ between managers and ICs?,career,t3_hqnaqz,0.82,17,Career,17,1594701584.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hoping to tap the hivemind of Reddit for this question.&lt;/p&gt;

&lt;p&gt;For those of you who manage data science managers/people leaders, or are part of interview panels for data science managers: are there different expectations of technical aptitude between people manager candidates and ICs who apply for [senior/principal] data science roles?&lt;/p&gt;

&lt;p&gt;Why I&amp;#39;m asking this question: I&amp;#39;m a people manager myself at a mid-sized company in the Bay Area, with a Masters in Data Science and 4+ years of leadership experience (in industry for 15). I am simply not as &amp;quot;in the weeds&amp;quot; as my team members are... nor is there an expectation by my leadership teams that I code or query every day; while this frustrates me, I continue to receive praise for helping my team do better work, asking the right questions, ensuring they are staying on track, etc. &lt;/p&gt;

&lt;p&gt;However, I have applied to other manager positions, and my technical interviews have been VERY technical: I&amp;#39;ve had a total of 10-15 technical-round interviews in the last 6-8 months. It&amp;#39;s clear that I pass the leadership scrutiny test, but I continue to miss expectations on the technical front. In short, I&amp;#39;m rusty. &lt;/p&gt;

&lt;p&gt;I understand that teams and companies have different needs... but are companies really expecting senior managers and/or directors to be able to perform technically at the same level as ICs? Or is the truth of the matter that I--and others in my situation--simply have to review like crazy, even at this level? Are VPs asked technical questions as well? &lt;/p&gt;

&lt;p&gt;Hope that wasn&amp;#39;t too rant-like. Would love to hear thoughts.&lt;/p&gt;

&lt;p&gt;Updated for grammar/details&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hqnaqz,WhiskyTantrum,6,/r/datascience/comments/hqnaqz/directorsvps_up_how_do_your_technical_interviews/,https://www.reddit.com/r/datascience/comments/hqnaqz/directorsvps_up_how_do_your_technical_interviews/,1594672784.0
r/datascience,"Data scientists of Reddit, how much time do you spend engineering data to get into the right format for the machine learning? This could include, but isnt limited to,  scraping, cleaning, mining, reshaping and casting the data. I'm curious because I am an aspiring data scientist and I know how to do machine learning, but I'm not very good at data engineering. I also want to know whether it's worth doing the Coursera specialization on data engineering. 

 Do the data engineers at your company take care of all the formatting and give it to you in the perfect shape? Or do you end up having to do a lot of processing? Thanks in advance, have a great day.",t2_5fyi7l49,"On average, how much data engineering do data scientists do?",discussion,t3_hqwc57,0.67,4,Discussion,4,1594736531.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Data scientists of Reddit, how much time do you spend engineering data to get into the right format for the machine learning? This could include, but isnt limited to,  scraping, cleaning, mining, reshaping and casting the data. I&amp;#39;m curious because I am an aspiring data scientist and I know how to do machine learning, but I&amp;#39;m not very good at data engineering. I also want to know whether it&amp;#39;s worth doing the Coursera specialization on data engineering. &lt;/p&gt;

&lt;p&gt;Do the data engineers at your company take care of all the formatting and give it to you in the perfect shape? Or do you end up having to do a lot of processing? Thanks in advance, have a great day.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hqwc57,dhruvmk,11,/r/datascience/comments/hqwc57/on_average_how_much_data_engineering_do_data/,https://www.reddit.com/r/datascience/comments/hqwc57/on_average_how_much_data_engineering_do_data/,1594707731.0
r/datascience,,t2_cqcjmb5,Does a data scientist have as much autonomy as a programmer? Such as working from their personal laptop at any location?,career,t3_hqovss,0.6,2,Career,2,1594706640.0,,hqovss,LightK05,11,/r/datascience/comments/hqovss/does_a_data_scientist_have_as_much_autonomy_as_a/,https://www.reddit.com/r/datascience/comments/hqovss/does_a_data_scientist_have_as_much_autonomy_as_a/,1594677840.0
r/datascience,,t2_i994l,Analysis of all YouTube popular videos in US for 2019,projects,t3_hpzw0u,0.96,226,Projects,226,1594609335.0,,hpzw0u,ammar-,37,/r/datascience/comments/hpzw0u/analysis_of_all_youtube_popular_videos_in_us_for/,https://ammar-alyousfi.com/2020/youtube-trending-videos-analysis-2019-us?src=redditdatascience,1594580535.0
r/datascience,"Hi, I was tasked with cleaning up a very large excel file of data, so far I did the following for one of the main identifying columns:

-Extracted all unique values from the column

-Used stopwords from R to get rid of all stop words.

-Threw this semi cleaned data into a new csv

I am trying to figure out how to get keywords from each line, is there a recommended approach for this? Or would I have to go through 10,000+ lines and figure out which words in each line are keywords and which are not?",t2_ezj1w,Get keywords from a large excel file,tooling,t3_hqjsxp,1.0,1,Tooling,1,1594690573.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I was tasked with cleaning up a very large excel file of data, so far I did the following for one of the main identifying columns:&lt;/p&gt;

&lt;p&gt;-Extracted all unique values from the column&lt;/p&gt;

&lt;p&gt;-Used stopwords from R to get rid of all stop words.&lt;/p&gt;

&lt;p&gt;-Threw this semi cleaned data into a new csv&lt;/p&gt;

&lt;p&gt;I am trying to figure out how to get keywords from each line, is there a recommended approach for this? Or would I have to go through 10,000+ lines and figure out which words in each line are keywords and which are not?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hqjsxp,ihatenature,2,/r/datascience/comments/hqjsxp/get_keywords_from_a_large_excel_file/,https://www.reddit.com/r/datascience/comments/hqjsxp/get_keywords_from_a_large_excel_file/,1594661773.0
r/datascience,"Hi all,

I've run into an interesting problem: ingesting labeled data (coordinate pairs, with an additional label), and attempting to cluster that data, taking into account the spatial distance alongside the existing labels. This would be a trivial problem with tons of solutions if it weren't labeled, but I'm hitting my head against a wall trying to think of a way to cluster data based on spatial distance and additional data, in this case a label?

Thanks!",t2_ejpld,Clustering already-labeled data,discussion,t3_hqflt3,0.67,1,Discussion,1,1594677059.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve run into an interesting problem: ingesting labeled data (coordinate pairs, with an additional label), and attempting to cluster that data, taking into account the spatial distance alongside the existing labels. This would be a trivial problem with tons of solutions if it weren&amp;#39;t labeled, but I&amp;#39;m hitting my head against a wall trying to think of a way to cluster data based on spatial distance and additional data, in this case a label?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hqflt3,maniacalsounds,10,/r/datascience/comments/hqflt3/clustering_alreadylabeled_data/,https://www.reddit.com/r/datascience/comments/hqflt3/clustering_alreadylabeled_data/,1594648259.0
r/datascience,"Our data science team has created a pipeline that automates most of our EDA into a dashboard for our end user/customer. What's the next logical thing for a good data scientist and DS team to do?

Some ideas we have include:

* Talk to the business stakeholder for direction (but what if they don't know what they need?)
* Machine learning (sure, but why?)
* Statistical tests (again, why?)
* Adding logging and monitoring metrics to our dashboard on the backend.

&amp;#x200B;

BTWs, all the senior data scientists and PhD holders left a long time ago and a single PM typically takes care of talking with the business stakeholder. We're two scientists and a dev on a remote workers island.",t2_xvaf9,What now? How to steer a data science project towards value.,discussion,t3_hqfhe4,0.67,1,Discussion,1,1594676585.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Our data science team has created a pipeline that automates most of our EDA into a dashboard for our end user/customer. What&amp;#39;s the next logical thing for a good data scientist and DS team to do?&lt;/p&gt;

&lt;p&gt;Some ideas we have include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Talk to the business stakeholder for direction (but what if they don&amp;#39;t know what they need?)&lt;/li&gt;
&lt;li&gt;Machine learning (sure, but why?)&lt;/li&gt;
&lt;li&gt;Statistical tests (again, why?)&lt;/li&gt;
&lt;li&gt;Adding logging and monitoring metrics to our dashboard on the backend.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;BTWs, all the senior data scientists and PhD holders left a long time ago and a single PM typically takes care of talking with the business stakeholder. We&amp;#39;re two scientists and a dev on a remote workers island.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hqfhe4,sepa299,5,/r/datascience/comments/hqfhe4/what_now_how_to_steer_a_data_science_project/,https://www.reddit.com/r/datascience/comments/hqfhe4/what_now_how_to_steer_a_data_science_project/,1594647785.0
r/datascience,"I'm fresh out of a data science related masters program and often find myself doing a lot of googling at the start of a project to re-familiarize myself with a language, topic, or package. I'm wondering if anyone has some good cheat sheets or resources that I can compile for myself to maybe speed that re-familiarization process up a bit until it becomes second nature.",t2_q1o59,Data Science Cheat Sheets,education,t3_hq8dkr,0.64,4,Education,4,1594641528.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m fresh out of a data science related masters program and often find myself doing a lot of googling at the start of a project to re-familiarize myself with a language, topic, or package. I&amp;#39;m wondering if anyone has some good cheat sheets or resources that I can compile for myself to maybe speed that re-familiarization process up a bit until it becomes second nature.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hq8dkr,Sizzlehott,15,/r/datascience/comments/hq8dkr/data_science_cheat_sheets/,https://www.reddit.com/r/datascience/comments/hq8dkr/data_science_cheat_sheets/,1594612728.0
r/datascience, Trying to Predict Store Sales for the next 30 days by using: 1- Past 365 days of sales + Past 365 days of Traffic at store + past 365 Days of S&amp;P500 index ?,t2_3ftiaba8,Python Library for MultiVariate Timer Series ?,education,t3_hq47hq,0.63,2,Education,2,1594624470.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Trying to Predict Store Sales for the next 30 days by using: 1- Past 365 days of sales + Past 365 days of Traffic at store + past 365 Days of S&amp;amp;P500 index ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hq47hq,Zenith_N,2,/r/datascience/comments/hq47hq/python_library_for_multivariate_timer_series/,https://www.reddit.com/r/datascience/comments/hq47hq/python_library_for_multivariate_timer_series/,1594595670.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 12 Jul 2020 - 19 Jul 2020,,t3_hptb1j,0.9,7,Discussion,7,1594584030.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hptb1j,datascience-bot,129,/r/datascience/comments/hptb1j/weekly_entering_transitioning_thread_12_jul_2020/,https://www.reddit.com/r/datascience/comments/hptb1j/weekly_entering_transitioning_thread_12_jul_2020/,1594555230.0
r/datascience,"I've taken schooling for this my entire life to be honest. It's always been mathematical and statistical, and in my second bout of education, focused more on computing to apply this math.

But for data scientists we have to know so much spanning different fields. **From math, statistics, to optimization, to data structures, and algorithms, to your specific programming language gotchas, more advanced statistical + computing algorithms including ML/DL/ etc...**

How can someone possibly remember all of this and retain all the different sources of knowledge in memory? It's not like I have not been taught this and didn't know the specifics before. But it's never efficiently stored in memory. For some very common basics, I have to look up and remember how they work again.

1. So take linear regression for example something I've studied multiple times before. It's the most basic. I can right now tell you the general formula of the equation, and what it's trying to do. But if someone were to ask me right now to explain the internals of gradient descent (DESPITE taking multiple courses that taught/used this concept), I wouldn't be able to tell you. I can tell you the gist, and I have some visualization of my mind of the process, in that it's essentially trying to look for the direction of highest negative change.  For logistic regression, I can tell you its for classification and that it uses MLE to solve, but would have to look up again the implementation. For example, I don't remember how MLE works but know its related to probability.
2. If someone were to then ask me to explain something that involves more computing and computer science. So say something about bytes, binary representation, how it's used. I can give you the general gist that it's used to represent/store data in an efficient manner. But that's it. I can't give you more specifics to that, and would probably have to learn it all again with more details.
3. With data structures/algorithms, despite learning it before, I can give you a general gist of what they involve, but that's it. For example, a dictionary is cool because it allows easy key lookup because it uses hash representation. A list is ordered and is iterable, etc... I understand the general concept of time complexity but probably will struggle if asked to figure out whether something represents exponential time. Just the other day, had to refresh on the differences between hashable and mutable, etc...

My point is, there's just so many different fields we have to have working knowledge on. And don't even get me started with more http, web servers, etc...  It's something I haven't been taught and haven't had the chance to learn yet as I'm still trying to remember, learn, maintain everything else. How do people REMEMBER all of this? I had to look up the basics of hypothesis testing the other day, as I remembered its gist, but not how to implement it. Is this normal?",t2_cnkxw,"Does anyone else struggle with remembering, internalizing the basics?",discussion,t3_hpc6vz,0.96,283,Discussion,283,1594511327.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve taken schooling for this my entire life to be honest. It&amp;#39;s always been mathematical and statistical, and in my second bout of education, focused more on computing to apply this math.&lt;/p&gt;

&lt;p&gt;But for data scientists we have to know so much spanning different fields. &lt;strong&gt;From math, statistics, to optimization, to data structures, and algorithms, to your specific programming language gotchas, more advanced statistical + computing algorithms including ML/DL/ etc...&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;How can someone possibly remember all of this and retain all the different sources of knowledge in memory? It&amp;#39;s not like I have not been taught this and didn&amp;#39;t know the specifics before. But it&amp;#39;s never efficiently stored in memory. For some very common basics, I have to look up and remember how they work again.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;So take linear regression for example something I&amp;#39;ve studied multiple times before. It&amp;#39;s the most basic. I can right now tell you the general formula of the equation, and what it&amp;#39;s trying to do. But if someone were to ask me right now to explain the internals of gradient descent (DESPITE taking multiple courses that taught/used this concept), I wouldn&amp;#39;t be able to tell you. I can tell you the gist, and I have some visualization of my mind of the process, in that it&amp;#39;s essentially trying to look for the direction of highest negative change.  For logistic regression, I can tell you its for classification and that it uses MLE to solve, but would have to look up again the implementation. For example, I don&amp;#39;t remember how MLE works but know its related to probability.&lt;/li&gt;
&lt;li&gt;If someone were to then ask me to explain something that involves more computing and computer science. So say something about bytes, binary representation, how it&amp;#39;s used. I can give you the general gist that it&amp;#39;s used to represent/store data in an efficient manner. But that&amp;#39;s it. I can&amp;#39;t give you more specifics to that, and would probably have to learn it all again with more details.&lt;/li&gt;
&lt;li&gt;With data structures/algorithms, despite learning it before, I can give you a general gist of what they involve, but that&amp;#39;s it. For example, a dictionary is cool because it allows easy key lookup because it uses hash representation. A list is ordered and is iterable, etc... I understand the general concept of time complexity but probably will struggle if asked to figure out whether something represents exponential time. Just the other day, had to refresh on the differences between hashable and mutable, etc...&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;My point is, there&amp;#39;s just so many different fields we have to have working knowledge on. And don&amp;#39;t even get me started with more http, web servers, etc...  It&amp;#39;s something I haven&amp;#39;t been taught and haven&amp;#39;t had the chance to learn yet as I&amp;#39;m still trying to remember, learn, maintain everything else. How do people REMEMBER all of this? I had to look up the basics of hypothesis testing the other day, as I remembered its gist, but not how to implement it. Is this normal?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hpc6vz,Moontrix,71,/r/datascience/comments/hpc6vz/does_anyone_else_struggle_with_remembering/,https://www.reddit.com/r/datascience/comments/hpc6vz/does_anyone_else_struggle_with_remembering/,1594482527.0
r/datascience, Trying to Predict Store Sales for the next 30 days by using: 1- Past 365 days of sales + Past 365 days of Traffic at store + past 365 Days of S&amp;P500 index ?,t2_3ftiaba8,Python Library for MultiVariate Timer Series ?,education,t3_hpwwh5,0.5,0,Education,0,1594599060.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Trying to Predict Store Sales for the next 30 days by using: 1- Past 365 days of sales + Past 365 days of Traffic at store + past 365 Days of S&amp;amp;P500 index ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hpwwh5,Zenith_N,14,/r/datascience/comments/hpwwh5/python_library_for_multivariate_timer_series/,https://www.reddit.com/r/datascience/comments/hpwwh5/python_library_for_multivariate_timer_series/,1594570260.0
r/datascience,"I have slightly over 12 years of experience, pretty much all of it in the tech industry. I started as a Business Analyst 12+ years ago in a startup based out of the midwestern USA right after undergrad degree in Engineering. Data Scientist as a title didn't exist back then, but I still did a bunch of statistical modeling in SAS. 

Later, moved to the tech division of a Fortune 50 company in the Bay Area, again as a BA. Then moved to a FAANG company as a DS, which opened the door for other FAANGs, so I spent time in two more FAANGs in various roles before moving to a bay area unicorn. In this time I also finished a masters in my employer's dime.

Had promotions in every company I worked in, except for one in the middle because of my tenure being too short. Here are some tips to aspiring and current data scientists.

1. **Getting hired:** I'll admit, I got ridiculously lucky. I don't think the 21 year old me would get hired at a tech company right now. I didn't have a portfolio, no experience in DS/Analytics/Statistical Modeling, and no family connections in the industry. A friend who was a year ahead of me in college was already working for the startup as an Engineer and since he knew I was ""mathematically gifted"" (his words, not mine), he got me the job. I learned everything on the job from SQL, SAS (yes, I'm that old), and even Excel. However, with DS and ML becoming the new gold rush, companies, especially tech companies, doubly so for FAANGs are spoiled for choice. So it's important to stand out. I've done a lot of hiring for FAANGs, so I feel like I can pass on some advice. As with anything on the internet, please take this with a grain of salt because this is only based on my experience, and isn't meant to be universal. For folks who're fresh out of school/still in school - internships help a lot. But in the absence of industry experience, the thing I look for is your ability to solve open ended problems using DS/ML. Kaggle competitions like predicting the survivors of Titanic have been done a million times over and don't show anything that I haven't already seen. So pick a problem in a domain that you think is interesting and do something DS related, like building a cool Data Viz, or building a model to predict/explain something, etc. For the more experienced folks, highlight the impact of your previous work. This leads neatly into my second point.

2. **Impact not method:** Unless you’re working in the research arm of tech companies (MSR, Google Brain, FAIR), or in Academia, your boss’s boss likely doesn’t care about what method you used to solve the problem. Just what the impact to the company was. So stop focusing on methodology and start focusing on how you’re helping the business. Remember that you’ve not been hired to write SQL and Python, you’ve been hired to help do one of: (a) make more money for the company, (b) cut costs for the company - which also includes helping others in the company be more effective by building internal tools. However, it’s relatively unheard of to have an entry level DS being given an open ended problem and being asked to solve it, you will likely have to rely on your manager and/mentors to do that for you. But over time, the expectation is for you to become more and more independent. Which would require you to constantly learn new things and adapt to change. Keep in mind that this doesn't mean you should stop paying attention to using the right methodology for the right problem, but that when you're telling your story, focus on the impact.

3. **Getting promoted:** Unless you’re exceptionally talented or exceptionally lucky, promotions won’t happen without asking for it. Have open and honest conversations with your manager about the expectations for the next level and chart a course to get there. Ask for feedback and continuously improve. As you grow in your career, especially past the *Senior* level, your ability to influence your peers, and leaders matters a lot more than your technical competency. So identify areas where you can exercise that muscle. It’s very different muscle from being a technically capable data scientist. A mistake I see a lot of young Data Scientists making is relying on the idea that more work will get you promoted. It won’t, at least after a point. What it takes to go from L3 (entry level) DS to L4 (the very next level) is very different from what it takes to get to L5 (Senior) and above. 

4. **When moving companies, know the levels:** I got seriously burnt in my last role. I misunderstood their leveling system and took a role at a level below my expected level, became seriously resentful at seeing people with half my experience being in the level above me, eventually ended up leaving because I thought it was a clear case of bait and switch. So do your research, talk to people in the company if you can. levels.fyi is a great resource to understand level equivalence across companies.

5. **Find a mentor, then mentor others:** If your company has many Data Scientists, find someone who you look up to and ask them to be your mentor. Go prepared to your mentorship sessions, ask pointed questions and ask for their advice. More importantly follow-up with them and show how their advice helped you. Once you're comfortable enough, pass on the favor to those who come after you. If you're the only DS in a company - which I've seen cases of, find industry mentors. I've seen many forums for you to find DS mentors. If nothing works, reach out to people in the industry on LinkedIn asking for mentorship. More than half the time, they will accept.

6. **Strike a balance between technical skills and soft skills:** As I mentioned above, the further you get in your career, the less important your technical ability becomes. That doesn’t mean you can afford not to know the basics, it just means you’re valued more for your ability to influence your peers, stakeholders, and leaders than your ability to write beautiful code. So learning after a point has to span both the (almost orthogonal) axes of technical ability and soft skills. You cannot afford to be lax on learning new techniques because the world around us is changing. I started my job knowing only SQL and SAS. Then my toolkit was SQL, SAS and R. I only picked up Python ~2-3 years ago. I’m sure it’s not gonna end here. Learning is a lifelong endeavor in a field like this. At the same time, I was also learning to be a better negotiator, and a better leader. 

7. **Focus on quality of life:** Remember that I have had over 12 years to do this, and I’m not even half-way into my career. Careers span 30+ years. Learn to take a breather, take vacations, take breaks and disconnect from it all once in a while. An endless rat-race will leave you burned out and unable to focus. It happened to me 5-6 years into my career where I felt overwhelmed everyday. It’s not good for you in the long run. I know this point sounds contradictory to everything I’ve said above about constantly having to learn, but it really isn’t if you put it into a 30+ year time-span. You don’t have to be the best analyst, best machine learning engineer, the best story teller, and the best leader in year 2. You can pick and choose what you want to learn based on your environment and what’s needed immediately.

8. **Don’t gatekeep, don’t look down on others, help those who ask:** Nothing bothers me more than seeing young Data Scientists/ML Engineers looking down on Data Analysts, calling them SQL monkeys. A lot of them also look down on people who do sales and marketing. Remember, even in companies like FAANG, your ability to get paid ultimately depends on the marketing and sales people’s ability to sell the things you build. Work with everyone, help anyone who will ask, and be nice to everyone you come across. Being known as the person who is “nice to work with” will take you much farther than being a 10x engineer (a term I’ve come to loathe).

I’m happy to provide proof of my career to the mods, but also worried about getting doxxed. Feel free to ask me any questions, I’ll be happy to answer them (within reason).",t2_8j3b6,Career tips from an old timer,career,t3_howrzj,0.99,835,Career,835,1594442528.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have slightly over 12 years of experience, pretty much all of it in the tech industry. I started as a Business Analyst 12+ years ago in a startup based out of the midwestern USA right after undergrad degree in Engineering. Data Scientist as a title didn&amp;#39;t exist back then, but I still did a bunch of statistical modeling in SAS. &lt;/p&gt;

&lt;p&gt;Later, moved to the tech division of a Fortune 50 company in the Bay Area, again as a BA. Then moved to a FAANG company as a DS, which opened the door for other FAANGs, so I spent time in two more FAANGs in various roles before moving to a bay area unicorn. In this time I also finished a masters in my employer&amp;#39;s dime.&lt;/p&gt;

&lt;p&gt;Had promotions in every company I worked in, except for one in the middle because of my tenure being too short. Here are some tips to aspiring and current data scientists.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Getting hired:&lt;/strong&gt; I&amp;#39;ll admit, I got ridiculously lucky. I don&amp;#39;t think the 21 year old me would get hired at a tech company right now. I didn&amp;#39;t have a portfolio, no experience in DS/Analytics/Statistical Modeling, and no family connections in the industry. A friend who was a year ahead of me in college was already working for the startup as an Engineer and since he knew I was &amp;quot;mathematically gifted&amp;quot; (his words, not mine), he got me the job. I learned everything on the job from SQL, SAS (yes, I&amp;#39;m that old), and even Excel. However, with DS and ML becoming the new gold rush, companies, especially tech companies, doubly so for FAANGs are spoiled for choice. So it&amp;#39;s important to stand out. I&amp;#39;ve done a lot of hiring for FAANGs, so I feel like I can pass on some advice. As with anything on the internet, please take this with a grain of salt because this is only based on my experience, and isn&amp;#39;t meant to be universal. For folks who&amp;#39;re fresh out of school/still in school - internships help a lot. But in the absence of industry experience, the thing I look for is your ability to solve open ended problems using DS/ML. Kaggle competitions like predicting the survivors of Titanic have been done a million times over and don&amp;#39;t show anything that I haven&amp;#39;t already seen. So pick a problem in a domain that you think is interesting and do something DS related, like building a cool Data Viz, or building a model to predict/explain something, etc. For the more experienced folks, highlight the impact of your previous work. This leads neatly into my second point.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Impact not method:&lt;/strong&gt; Unless you’re working in the research arm of tech companies (MSR, Google Brain, FAIR), or in Academia, your boss’s boss likely doesn’t care about what method you used to solve the problem. Just what the impact to the company was. So stop focusing on methodology and start focusing on how you’re helping the business. Remember that you’ve not been hired to write SQL and Python, you’ve been hired to help do one of: (a) make more money for the company, (b) cut costs for the company - which also includes helping others in the company be more effective by building internal tools. However, it’s relatively unheard of to have an entry level DS being given an open ended problem and being asked to solve it, you will likely have to rely on your manager and/mentors to do that for you. But over time, the expectation is for you to become more and more independent. Which would require you to constantly learn new things and adapt to change. Keep in mind that this doesn&amp;#39;t mean you should stop paying attention to using the right methodology for the right problem, but that when you&amp;#39;re telling your story, focus on the impact.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Getting promoted:&lt;/strong&gt; Unless you’re exceptionally talented or exceptionally lucky, promotions won’t happen without asking for it. Have open and honest conversations with your manager about the expectations for the next level and chart a course to get there. Ask for feedback and continuously improve. As you grow in your career, especially past the &lt;em&gt;Senior&lt;/em&gt; level, your ability to influence your peers, and leaders matters a lot more than your technical competency. So identify areas where you can exercise that muscle. It’s very different muscle from being a technically capable data scientist. A mistake I see a lot of young Data Scientists making is relying on the idea that more work will get you promoted. It won’t, at least after a point. What it takes to go from L3 (entry level) DS to L4 (the very next level) is very different from what it takes to get to L5 (Senior) and above. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;When moving companies, know the levels:&lt;/strong&gt; I got seriously burnt in my last role. I misunderstood their leveling system and took a role at a level below my expected level, became seriously resentful at seeing people with half my experience being in the level above me, eventually ended up leaving because I thought it was a clear case of bait and switch. So do your research, talk to people in the company if you can. levels.fyi is a great resource to understand level equivalence across companies.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Find a mentor, then mentor others:&lt;/strong&gt; If your company has many Data Scientists, find someone who you look up to and ask them to be your mentor. Go prepared to your mentorship sessions, ask pointed questions and ask for their advice. More importantly follow-up with them and show how their advice helped you. Once you&amp;#39;re comfortable enough, pass on the favor to those who come after you. If you&amp;#39;re the only DS in a company - which I&amp;#39;ve seen cases of, find industry mentors. I&amp;#39;ve seen many forums for you to find DS mentors. If nothing works, reach out to people in the industry on LinkedIn asking for mentorship. More than half the time, they will accept.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Strike a balance between technical skills and soft skills:&lt;/strong&gt; As I mentioned above, the further you get in your career, the less important your technical ability becomes. That doesn’t mean you can afford not to know the basics, it just means you’re valued more for your ability to influence your peers, stakeholders, and leaders than your ability to write beautiful code. So learning after a point has to span both the (almost orthogonal) axes of technical ability and soft skills. You cannot afford to be lax on learning new techniques because the world around us is changing. I started my job knowing only SQL and SAS. Then my toolkit was SQL, SAS and R. I only picked up Python ~2-3 years ago. I’m sure it’s not gonna end here. Learning is a lifelong endeavor in a field like this. At the same time, I was also learning to be a better negotiator, and a better leader. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Focus on quality of life:&lt;/strong&gt; Remember that I have had over 12 years to do this, and I’m not even half-way into my career. Careers span 30+ years. Learn to take a breather, take vacations, take breaks and disconnect from it all once in a while. An endless rat-race will leave you burned out and unable to focus. It happened to me 5-6 years into my career where I felt overwhelmed everyday. It’s not good for you in the long run. I know this point sounds contradictory to everything I’ve said above about constantly having to learn, but it really isn’t if you put it into a 30+ year time-span. You don’t have to be the best analyst, best machine learning engineer, the best story teller, and the best leader in year 2. You can pick and choose what you want to learn based on your environment and what’s needed immediately.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Don’t gatekeep, don’t look down on others, help those who ask:&lt;/strong&gt; Nothing bothers me more than seeing young Data Scientists/ML Engineers looking down on Data Analysts, calling them SQL monkeys. A lot of them also look down on people who do sales and marketing. Remember, even in companies like FAANG, your ability to get paid ultimately depends on the marketing and sales people’s ability to sell the things you build. Work with everyone, help anyone who will ask, and be nice to everyone you come across. Being known as the person who is “nice to work with” will take you much farther than being a 10x engineer (a term I’ve come to loathe).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I’m happy to provide proof of my career to the mods, but also worried about getting doxxed. Feel free to ask me any questions, I’ll be happy to answer them (within reason).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",howrzj,analystdude,127,/r/datascience/comments/howrzj/career_tips_from_an_old_timer/,https://www.reddit.com/r/datascience/comments/howrzj/career_tips_from_an_old_timer/,1594413728.0
r/datascience,"Hi All,

&amp;#x200B;

About 4 years ago I took a career sidestep from an oil/gas science role to data science (with a data analyst stepping stone in the middle). I am now a senior data scientist with a mid-sized medical technology company in their R&amp;D division.

&amp;#x200B;

However, there are five slightly concerning issues with my current role/situation:

1) I am the only formally titled 'Data Scientist' in the company. (There are other's who easily have the knowledge and experience to be one but are put under the 'Stats' umbrella)

2) The company's DS capabilities are very much in their infancy. (But one of their key focuses is to change that)

3) It is the kind of company that doesn't seem to know what a data scientist does. (Although, thankfully, they have given me a huge amount of flexibility and autonomy to get things done)

4) The term 'Senior' in this company appears to be scaled differently to other companies I've been in. (I think everyone who has come in so far has at least a 'senior' role!)

5) I never had any formal data science learning/training and most of what I've learned has been on the job or what I'm picking up from ESL and PRML. (I come from a Maths/Natural Sciences background so I like to think I have the mind to pick DS/ML concepts up quickly)

&amp;#x200B;

So far my role has been more of a data engineering one and I've spent the past year consolidating the company's data, getting teams to move away from storing data in spreadsheets, and coordinating with the IT department to set up a data warehouse which has, so far, been very successful. I'm now in a position to start analysing data and building models to help the business. (Although I'm a little concerned about my lack in breath of knowledge of DS/ML)

&amp;#x200B;

I'm really enjoying the job and I have no plans to leave but I always like to have an escape route and I worry that I've managed to oversell myself into a senior DS role. I feel like I'm under-qualified to transition into another senior DS role (should anything happen to my role or the company) and that my current DE work has taken time away from my development.

&amp;#x200B;

So what is expected of a senior data scientist and what should I be focusing my development on for now? Should I be expanding my knowledgebase of modelling techniques? Or managerial skills? Or something else?

&amp;#x200B;

Thanks!",t2_57w7a,Expectations of a Senior Data Scientist,career,t3_hp821i,0.89,32,Career,32,1594493370.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All,&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;About 4 years ago I took a career sidestep from an oil/gas science role to data science (with a data analyst stepping stone in the middle). I am now a senior data scientist with a mid-sized medical technology company in their R&amp;amp;D division.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;However, there are five slightly concerning issues with my current role/situation:&lt;/p&gt;

&lt;p&gt;1) I am the only formally titled &amp;#39;Data Scientist&amp;#39; in the company. (There are other&amp;#39;s who easily have the knowledge and experience to be one but are put under the &amp;#39;Stats&amp;#39; umbrella)&lt;/p&gt;

&lt;p&gt;2) The company&amp;#39;s DS capabilities are very much in their infancy. (But one of their key focuses is to change that)&lt;/p&gt;

&lt;p&gt;3) It is the kind of company that doesn&amp;#39;t seem to know what a data scientist does. (Although, thankfully, they have given me a huge amount of flexibility and autonomy to get things done)&lt;/p&gt;

&lt;p&gt;4) The term &amp;#39;Senior&amp;#39; in this company appears to be scaled differently to other companies I&amp;#39;ve been in. (I think everyone who has come in so far has at least a &amp;#39;senior&amp;#39; role!)&lt;/p&gt;

&lt;p&gt;5) I never had any formal data science learning/training and most of what I&amp;#39;ve learned has been on the job or what I&amp;#39;m picking up from ESL and PRML. (I come from a Maths/Natural Sciences background so I like to think I have the mind to pick DS/ML concepts up quickly)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;So far my role has been more of a data engineering one and I&amp;#39;ve spent the past year consolidating the company&amp;#39;s data, getting teams to move away from storing data in spreadsheets, and coordinating with the IT department to set up a data warehouse which has, so far, been very successful. I&amp;#39;m now in a position to start analysing data and building models to help the business. (Although I&amp;#39;m a little concerned about my lack in breath of knowledge of DS/ML)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&amp;#39;m really enjoying the job and I have no plans to leave but I always like to have an escape route and I worry that I&amp;#39;ve managed to oversell myself into a senior DS role. I feel like I&amp;#39;m under-qualified to transition into another senior DS role (should anything happen to my role or the company) and that my current DE work has taken time away from my development.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;So what is expected of a senior data scientist and what should I be focusing my development on for now? Should I be expanding my knowledgebase of modelling techniques? Or managerial skills? Or something else?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hp821i,flunk09,15,/r/datascience/comments/hp821i/expectations_of_a_senior_data_scientist/,https://www.reddit.com/r/datascience/comments/hp821i/expectations_of_a_senior_data_scientist/,1594464570.0
r/datascience,"I have 2 tables of data, Table A represents Transaction info from one store, with 30 columns of useful data, and Table B represents Transaction info from a department in a different store with 8 columns of useful data. (By useful Data, I mean data that may need to be displayed on the timeline) Both tables have Date info in each Row. Does anyone have any recommendations for a good way to visualize a timeline where I could add information for each rows Date on the timeline?

I apologize if this is confusing. Any recommendations are greatly appreciated.",t2_cr3tdqt,Does anyone have any recommendations for visualizing a Timeline?,tooling,t3_hpgvx9,0.76,2,Tooling,2,1594527417.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have 2 tables of data, Table A represents Transaction info from one store, with 30 columns of useful data, and Table B represents Transaction info from a department in a different store with 8 columns of useful data. (By useful Data, I mean data that may need to be displayed on the timeline) Both tables have Date info in each Row. Does anyone have any recommendations for a good way to visualize a timeline where I could add information for each rows Date on the timeline?&lt;/p&gt;

&lt;p&gt;I apologize if this is confusing. Any recommendations are greatly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hpgvx9,GetOutNoWah,4,/r/datascience/comments/hpgvx9/does_anyone_have_any_recommendations_for/,https://www.reddit.com/r/datascience/comments/hpgvx9/does_anyone_have_any_recommendations_for/,1594498617.0
r/datascience,"Hello fellows!
I'm an undergrad experimenting with ML in Timeseries predictions right now. I collected data of tomatoes yielded per day in our home kitchen garden over 83 days, and decided to try and forecast it.

I used a simple linear regression model, feeding in 5 values as features and the next value as a the label. Please see the result [here](https://drive.google.com/file/d/18niGw7SnZ3QI2npQ7QMfFbDpH9rh7SPk/view?usp=drivesdk). The vertical red line at 60 is the training/testing split value. 

I have a few questions regarding this:
1)  Why does it seem that my predicted curve is leading the original data by roughly 5 time steps (same as my window size)?

2) What else should I try to achieve better results?

I hope i've made myself clear. Thanks a bunch!",t2_5t92ym0i,Time series prediction,education,t3_hpf2zb,0.67,2,Education,2,1594521192.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello fellows!
I&amp;#39;m an undergrad experimenting with ML in Timeseries predictions right now. I collected data of tomatoes yielded per day in our home kitchen garden over 83 days, and decided to try and forecast it.&lt;/p&gt;

&lt;p&gt;I used a simple linear regression model, feeding in 5 values as features and the next value as a the label. Please see the result &lt;a href=""https://drive.google.com/file/d/18niGw7SnZ3QI2npQ7QMfFbDpH9rh7SPk/view?usp=drivesdk""&gt;here&lt;/a&gt;. The vertical red line at 60 is the training/testing split value. &lt;/p&gt;

&lt;p&gt;I have a few questions regarding this:
1)  Why does it seem that my predicted curve is leading the original data by roughly 5 time steps (same as my window size)?&lt;/p&gt;

&lt;p&gt;2) What else should I try to achieve better results?&lt;/p&gt;

&lt;p&gt;I hope i&amp;#39;ve made myself clear. Thanks a bunch!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hpf2zb,_saan,20,/r/datascience/comments/hpf2zb/time_series_prediction/,https://www.reddit.com/r/datascience/comments/hpf2zb/time_series_prediction/,1594492392.0
r/datascience,"I've been lurking on this sub for a while now and all too often I see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience. That's great and all but I'd like to move the spotlight to the rest of us for just a minute. Cheers to my fellow mediocre data scientists who don't work at FAANG companies, aren't pursing a PhD, don't publish papers, haven't won Kaggle competitions, and don't spend every waking hour improving their portfolio.  Even though we're nothing special, we still deserve some appreciation every once in a while.

/rant I'll hand it back over to the smart people now",t2_hl45shh,Shout Out to All the Mediocre Data Scientists Out There,discussion,t3_hohvgq,0.98,2548,Discussion,2548,1594381531.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been lurking on this sub for a while now and all too often I see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience. That&amp;#39;s great and all but I&amp;#39;d like to move the spotlight to the rest of us for just a minute. Cheers to my fellow mediocre data scientists who don&amp;#39;t work at FAANG companies, aren&amp;#39;t pursing a PhD, don&amp;#39;t publish papers, haven&amp;#39;t won Kaggle competitions, and don&amp;#39;t spend every waking hour improving their portfolio.  Even though we&amp;#39;re nothing special, we still deserve some appreciation every once in a while.&lt;/p&gt;

&lt;p&gt;/rant I&amp;#39;ll hand it back over to the smart people now&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hohvgq,MrBurritoQuest,262,/r/datascience/comments/hohvgq/shout_out_to_all_the_mediocre_data_scientists_out/,https://www.reddit.com/r/datascience/comments/hohvgq/shout_out_to_all_the_mediocre_data_scientists_out/,1594352731.0
r/datascience,"Hi everyone.

&amp;#x200B;

I want to do a project but I'm not sure if it's really viable neither which path I should take to try and solve this.

&amp;#x200B;

I have a dataset with numerous incidents from different places and their risk classification. For example:

&gt;Incident: ""John stumbled and fell down the stairs""  
&gt;  
&gt;Risk: Severe  
&gt;  
&gt;Warehouse: A  
&gt;  
&gt;Date: 2020-07-11  
&gt;  
&gt;\---  
&gt;  
&gt;Incident: ""Mary left the door open""  
&gt;  
&gt;Risk: Low  
&gt;  
&gt;Warehouse: B  
&gt;  
&gt;Date: 2020-07-10 

&amp;#x200B;

My idea is to compile the incidents by warehouse by week and give a probability of incidents happening in each warehouse for every risk.

&amp;#x200B;

&gt;Warehouse A  
&gt;  
&gt;Probability of low risk incidents next week: 60%  
&gt;  
&gt;Probability of severe risk incidents next week: 30%

&amp;#x200B;

But I'm not really sure how to get around this problem. It's not really text classification because I know the classification of every report (risk). Is there a way to use this dataset and get any prediction for the next week?

&amp;#x200B;

Thanks in advance for any help!",t2_q6tp0gb,Predicting next week incidents using text analysis on incident reports,projects,t3_hpgifw,0.67,1,Projects,1,1594526132.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I want to do a project but I&amp;#39;m not sure if it&amp;#39;s really viable neither which path I should take to try and solve this.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have a dataset with numerous incidents from different places and their risk classification. For example:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Incident: &amp;quot;John stumbled and fell down the stairs&amp;quot;  &lt;/p&gt;

&lt;p&gt;Risk: Severe  &lt;/p&gt;

&lt;p&gt;Warehouse: A  &lt;/p&gt;

&lt;p&gt;Date: 2020-07-11  &lt;/p&gt;

&lt;p&gt;---  &lt;/p&gt;

&lt;p&gt;Incident: &amp;quot;Mary left the door open&amp;quot;  &lt;/p&gt;

&lt;p&gt;Risk: Low  &lt;/p&gt;

&lt;p&gt;Warehouse: B  &lt;/p&gt;

&lt;p&gt;Date: 2020-07-10 &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;My idea is to compile the incidents by warehouse by week and give a probability of incidents happening in each warehouse for every risk.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Warehouse A  &lt;/p&gt;

&lt;p&gt;Probability of low risk incidents next week: 60%  &lt;/p&gt;

&lt;p&gt;Probability of severe risk incidents next week: 30%&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;But I&amp;#39;m not really sure how to get around this problem. It&amp;#39;s not really text classification because I know the classification of every report (risk). Is there a way to use this dataset and get any prediction for the next week?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks in advance for any help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hpgifw,wardowardont,5,/r/datascience/comments/hpgifw/predicting_next_week_incidents_using_text/,https://www.reddit.com/r/datascience/comments/hpgifw/predicting_next_week_incidents_using_text/,1594497332.0
r/datascience,"Say I'm modelling whether a particular customer will purchase a product or not. What models can used to predict the probability that the customer purchases the product?

I used an XGBoost model for modelling this(using the predict_proba() function for getting the probability values). But the probability values I get are either very high or very low. Also, I'm not sure if the probability values from XGBoost are exacly interpretable as the probabilty in a real sense. Any ideas?",t2_pxg0g,Predicting probability of an event,discussion,t3_hpe6yh,0.5,0,Discussion,0,1594518128.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Say I&amp;#39;m modelling whether a particular customer will purchase a product or not. What models can used to predict the probability that the customer purchases the product?&lt;/p&gt;

&lt;p&gt;I used an XGBoost model for modelling this(using the predict_proba() function for getting the probability values). But the probability values I get are either very high or very low. Also, I&amp;#39;m not sure if the probability values from XGBoost are exacly interpretable as the probabilty in a real sense. Any ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hpe6yh,darkurama,11,/r/datascience/comments/hpe6yh/predicting_probability_of_an_event/,https://www.reddit.com/r/datascience/comments/hpe6yh/predicting_probability_of_an_event/,1594489328.0
r/datascience,"I have had trouble getting an internship before my final year of college this year. So I am really thinking about getting Masters Degree and one of the requirements are two professional recommendations. Since Target is a professional environment, I don’t see the problem, but I can see people arguing it is a retail environment. What’s your opinion?",t2_4cu8moke,"I work at Target, would I be able to use my co-workers for a professional recommendations?",career,t3_hpd8z5,0.5,0,Career,0,1594514953.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have had trouble getting an internship before my final year of college this year. So I am really thinking about getting Masters Degree and one of the requirements are two professional recommendations. Since Target is a professional environment, I don’t see the problem, but I can see people arguing it is a retail environment. What’s your opinion?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hpd8z5,SwoleJohll,10,/r/datascience/comments/hpd8z5/i_work_at_target_would_i_be_able_to_use_my/,https://www.reddit.com/r/datascience/comments/hpd8z5/i_work_at_target_would_i_be_able_to_use_my/,1594486153.0
r/datascience,"Hi, I’m a university student taking data analytics, but I really hate cleaning, organizing, and collecting data. What are some data-related jobs that don’t involve doing these? 

Thank you.

Sorry for mixing the terms “data entry” and “data cleaning/ organizing/ collecting” in my earlier post.",t2_3rjdpsxd,"Data-related careers that don’t involve cleaning, organizing, and collecting data",career,t3_hparpd,0.27,0,Career,0,1594506088.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I’m a university student taking data analytics, but I really hate cleaning, organizing, and collecting data. What are some data-related jobs that don’t involve doing these? &lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;

&lt;p&gt;Sorry for mixing the terms “data entry” and “data cleaning/ organizing/ collecting” in my earlier post.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hparpd,Dudeguybrochingo,32,/r/datascience/comments/hparpd/datarelated_careers_that_dont_involve_cleaning/,https://www.reddit.com/r/datascience/comments/hparpd/datarelated_careers_that_dont_involve_cleaning/,1594477288.0
r/datascience,"Boss treated me like shit on a project. He gave me menial tasks, disregarded my work, made me a gopher, publicly yelled at me, shut me down when I tried to say anything, treated me like a whopping boy, and had the gall to ask at the end of the project if we were cool in front of all his work buddies. Being a nonconfrontational Midwesterner, I said we're fine then I went home and wrote an email telling him I wanted to be treated with respect and that I wasn't happy with how he treated me during that project. 3 weeks passed and we had a meeting a few minutes ago to discuss my email. Basically, he doubled down on what he said saying that he can treat me however he likes. There's a hierarchy and I need to learn my place. 

Now the DS job pays well, is apart of a nice consulting company, the work is fine and stimulating usually, I get paid 125k in DC, and I basically get to work from home forever. 

Am I being entitled thinking I deserve to be treated better and should look for a new job or should I shut up and be happy with what I've got?

For perspective, I have my PhD in a STEM field, I was quite successful in my academic pursuits but decided to take the plunge in DS, I've worked as a DS for about 1.5 years and got promoted in 6 months at a previous company, and I'm constantly getting recruiters wanting to hire me.",t2_14ajrp,Am I entitled or should I quit?,,t3_hov10z,0.67,3,Job Search,3,1594436824.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Boss treated me like shit on a project. He gave me menial tasks, disregarded my work, made me a gopher, publicly yelled at me, shut me down when I tried to say anything, treated me like a whopping boy, and had the gall to ask at the end of the project if we were cool in front of all his work buddies. Being a nonconfrontational Midwesterner, I said we&amp;#39;re fine then I went home and wrote an email telling him I wanted to be treated with respect and that I wasn&amp;#39;t happy with how he treated me during that project. 3 weeks passed and we had a meeting a few minutes ago to discuss my email. Basically, he doubled down on what he said saying that he can treat me however he likes. There&amp;#39;s a hierarchy and I need to learn my place. &lt;/p&gt;

&lt;p&gt;Now the DS job pays well, is apart of a nice consulting company, the work is fine and stimulating usually, I get paid 125k in DC, and I basically get to work from home forever. &lt;/p&gt;

&lt;p&gt;Am I being entitled thinking I deserve to be treated better and should look for a new job or should I shut up and be happy with what I&amp;#39;ve got?&lt;/p&gt;

&lt;p&gt;For perspective, I have my PhD in a STEM field, I was quite successful in my academic pursuits but decided to take the plunge in DS, I&amp;#39;ve worked as a DS for about 1.5 years and got promoted in 6 months at a previous company, and I&amp;#39;m constantly getting recruiters wanting to hire me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hov10z,BBS_1990,17,/r/datascience/comments/hov10z/am_i_entitled_or_should_i_quit/,https://www.reddit.com/r/datascience/comments/hov10z/am_i_entitled_or_should_i_quit/,1594408024.0
r/datascience,Hi! So I recently started working with a tiny AI startup and my job is to figure out how to visualize their n-dimensional custom data structure in a compelling way. My boss said he wanted a visualization like [this](https://imgur.com/jDjfwAW) that can be embedded in a website and I could use some help being pointed in the right direction. Thanks!,t2_166yrv,Best practices for visualizing unstructured data?,projects,t3_hox45x,1.0,2,Projects,2,1594443671.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! So I recently started working with a tiny AI startup and my job is to figure out how to visualize their n-dimensional custom data structure in a compelling way. My boss said he wanted a visualization like &lt;a href=""https://imgur.com/jDjfwAW""&gt;this&lt;/a&gt; that can be embedded in a website and I could use some help being pointed in the right direction. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hox45x,gypR2G,9,/r/datascience/comments/hox45x/best_practices_for_visualizing_unstructured_data/,https://www.reddit.com/r/datascience/comments/hox45x/best_practices_for_visualizing_unstructured_data/,1594414871.0
r/datascience,"For a few months now, I've been having some sort of a career + future anxiety. I started with data science around 2 and a half years ago in my first year of bachelor's because I really liked data handing at the time. I loved working with messy data and I loved the feeling when I successfully visualised something. Then I learnt about Kaggle and to this day, I always do projects or analysis from there. I've even been able to build a small community of kagglers who support and lift each other.

With all that, I started applying for internships. I'd get rejected initially but I though that that's just part of the journey. I did get a lot of internships and have been able to meet a lot of people. I further moved to domains like machine learning and artificial intelligence and I've been able to get some research papers published as well. I see here, that recruiters love the candidates that can talk to non-tech people and explain their approach and results. I feel like I can do that, I love to write everything that I do as if I were explaining it to a 5 year old. I've also had the opportunity to work with researchers from all around the world.

Yet, I feel like I am not good at interviews and screenings. Or am I just aiming too high? After 2 and a half years dedicated to this field, I often get flustered with screening tasks, I am unable to help people with their doubts, it takes me ages to understand code etc. Most of the internships I have got are through connections and networking on linkedin. I just feel like I have been faking it. I'm not bragging but I have a really nice resume with good internships, good projects, research papers, but I feel like that's just a show because I really don't know stuff. Am I overreacting? Do you guys feel this? Did I choose a wrong career path? I'd rather know now when I'm 21 than later in life where changing careers might be impossible for me. Sorry for the rant but I really don't have anyone irl who understands this.",t2_154tfq,Is it imposter's syndrome or do I really not seem to know anything?,discussion,t3_hoaz2f,0.83,107,Discussion,107,1594356356.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For a few months now, I&amp;#39;ve been having some sort of a career + future anxiety. I started with data science around 2 and a half years ago in my first year of bachelor&amp;#39;s because I really liked data handing at the time. I loved working with messy data and I loved the feeling when I successfully visualised something. Then I learnt about Kaggle and to this day, I always do projects or analysis from there. I&amp;#39;ve even been able to build a small community of kagglers who support and lift each other.&lt;/p&gt;

&lt;p&gt;With all that, I started applying for internships. I&amp;#39;d get rejected initially but I though that that&amp;#39;s just part of the journey. I did get a lot of internships and have been able to meet a lot of people. I further moved to domains like machine learning and artificial intelligence and I&amp;#39;ve been able to get some research papers published as well. I see here, that recruiters love the candidates that can talk to non-tech people and explain their approach and results. I feel like I can do that, I love to write everything that I do as if I were explaining it to a 5 year old. I&amp;#39;ve also had the opportunity to work with researchers from all around the world.&lt;/p&gt;

&lt;p&gt;Yet, I feel like I am not good at interviews and screenings. Or am I just aiming too high? After 2 and a half years dedicated to this field, I often get flustered with screening tasks, I am unable to help people with their doubts, it takes me ages to understand code etc. Most of the internships I have got are through connections and networking on linkedin. I just feel like I have been faking it. I&amp;#39;m not bragging but I have a really nice resume with good internships, good projects, research papers, but I feel like that&amp;#39;s just a show because I really don&amp;#39;t know stuff. Am I overreacting? Do you guys feel this? Did I choose a wrong career path? I&amp;#39;d rather know now when I&amp;#39;m 21 than later in life where changing careers might be impossible for me. Sorry for the rant but I really don&amp;#39;t have anyone irl who understands this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hoaz2f,funusernameinnit,65,/r/datascience/comments/hoaz2f/is_it_imposters_syndrome_or_do_i_really_not_seem/,https://www.reddit.com/r/datascience/comments/hoaz2f/is_it_imposters_syndrome_or_do_i_really_not_seem/,1594327556.0
r/datascience,"Hey guys (sorry if this has been asked before) what are some nice cities with high salaries relative to the other high COL cities I listed?

I am about to graduate next year and feel I am a pretty competitive applicant, but I am having trouble deciding on what city would be good for me.

Thanks!",t2_16zp9o,Best cities for DS (other than SF/NYC),career,t3_hop5xd,0.67,2,Career,2,1594417403.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys (sorry if this has been asked before) what are some nice cities with high salaries relative to the other high COL cities I listed?&lt;/p&gt;

&lt;p&gt;I am about to graduate next year and feel I am a pretty competitive applicant, but I am having trouble deciding on what city would be good for me.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hop5xd,Massive_bull_worm,9,/r/datascience/comments/hop5xd/best_cities_for_ds_other_than_sfnyc/,https://www.reddit.com/r/datascience/comments/hop5xd/best_cities_for_ds_other_than_sfnyc/,1594388603.0
r/datascience,"I am doing Bachelor's in CS and have been interested in Data Science for sometime now and currently doing a ML course. While I found the programming part easy, I'm overwhelmed by the amount of mathematical formula there. It's scaring me. If I land a DA/DS position in future, would I be doing maths on the job?",t2_t1hv9,How much maths do you do on daily basis in your job as a Data Analyst / Data Scientist?,discussion,t3_hoqz1y,0.4,0,Discussion,0,1594423766.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am doing Bachelor&amp;#39;s in CS and have been interested in Data Science for sometime now and currently doing a ML course. While I found the programming part easy, I&amp;#39;m overwhelmed by the amount of mathematical formula there. It&amp;#39;s scaring me. If I land a DA/DS position in future, would I be doing maths on the job?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hoqz1y,Katsuga50,8,/r/datascience/comments/hoqz1y/how_much_maths_do_you_do_on_daily_basis_in_your/,https://www.reddit.com/r/datascience/comments/hoqz1y/how_much_maths_do_you_do_on_daily_basis_in_your/,1594394966.0
r/datascience,"I’m studying BCom Mathematical Sciences next year at university and I’m looking at all these different career paths. 

I saw that Family Guy meme format on this subreddit that made it look like the data analysts career path was inferior to that of a data scientist , machine learning engineer and data engineer.

Can someone please tell me why that is and maybe a brief explanation of the main differences in the job . Thank you !",t2_3mu3943r,Are data scientists seen as “better “ or “smarter “ than data analysts ?,career,t3_hop6rc,0.67,1,Career,1,1594417487.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m studying BCom Mathematical Sciences next year at university and I’m looking at all these different career paths. &lt;/p&gt;

&lt;p&gt;I saw that Family Guy meme format on this subreddit that made it look like the data analysts career path was inferior to that of a data scientist , machine learning engineer and data engineer.&lt;/p&gt;

&lt;p&gt;Can someone please tell me why that is and maybe a brief explanation of the main differences in the job . Thank you !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hop6rc,EthanBradbury17,8,/r/datascience/comments/hop6rc/are_data_scientists_seen_as_better_or_smarter/,https://www.reddit.com/r/datascience/comments/hop6rc/are_data_scientists_seen_as_better_or_smarter/,1594388687.0
r/datascience,"Hi everyone, the organisation I work for is creating its first-ever data-position '***Head of Data &amp; Analytics***'. There is a big data literacy/maturity deficit within the organisation and it would be this person's role to begin to change this. Salary is not massive so the role is open to someone who hasn't been in a senior data-position before but is up to the challenge. The organisation I work for is rather complex as it is a charity with social enterprises so it combines impact/social work, fundraising and commercial activity.

I've drafted the job role below, however, I'm hoping you kind people might be able to help me determine what skills/knowledge would be classed as essential to be able to do this and any other pointers in what the right candidate should look like (remember this is a low/mid salary position due to limited funding available).

\----

# Job Purpose

There has been identified a lack of clear data structure and process within the organisation and confirmation that data needs to be managed, retained, analysed and stored with greater control and routine. The role of the Data &amp; Analytics Lead would be to:

* To define, own and implement a group-wide data strategy and ensure the strategic vision for data architecture is met and maintained by working with the CEO (in line with their 3-year strategic vision) and a range of Stakeholders including Department Heads, Managers and Support Workers.
* To develop and promote a central database architecture that aids the organisation in achieving its strategic goals
* Work with various teams throughout the organisation to provide analysis and valuable insights to unlock opportunities, drive data-informed business decisions and to make a positive impact on our service users.

# Key Objectives/Responsibilities

**Infrastructure**

* Partner with leadership and peers to understand report requirements, map and document existing business processes, evaluating output requirements and formats and ensure consistency across teams
* Implement and administer the large CRM database initiative and provide database user support.

&amp;#x200B;

**Analysis**

* Effectively use data to tell stories, communicate key insights through internal reports, presentations and dashboards to drive business decisions.
* Define and share key business performance indicators with the leadership team.
* Analysis of our customer and donor base to help our retail and fundraising teams understand our supporters.
* Help get the most out of our website, content and social platforms - by understanding and helping in the optimization of customer journeys and marketing/advertising campaign performance

&amp;#x200B;

**Management**

* Help to drive the data strategy group-wide.
* Work with the with leadership &amp; management teams across the group to understand their requirements &amp; data sources, set priorities based on analysis and results to implement and optimise fundraising, impact and commercial processes and solutions
* Work with the leadership teams to build dashboards and KPI monitoring reports for providing insights to enable better planning and performance monitoring across the organisation.
* Work closely with various teams within the organisation to gain a holistic view of customers, trends and competitors

\----

I appreciate that this may be asking a lot from one person, especially on a low/mid-range salary but it is what we need and all we can afford. I'm hoping that it will be a great working experience for the person taking the role who will see it as an opportunity to develop their role and get their feet wet in a senior data position. With that, there will also be patience and expectation for a lot of on the job learning, that this will be a long process and the person filling the role won't magically be able to implement/fix everything listed above within their first year in the role. We see this as a two-year+ journey to data maturity.

&amp;#x200B;

**What are the bare minimum technical/non-technical skills/knowledge I should be looking for?**

&amp;#x200B;

Also for extra context the organisation is 6 years old, and is looking to implement salesforce but does not have a CRM/central database yet. 

&amp;#x200B;

Thank you!",t2_7t2l9,"Hiring the first data role, what skills are needed for role described?",discussion,t3_hol7ni,0.5,0,Discussion,0,1594398127.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, the organisation I work for is creating its first-ever data-position &amp;#39;&lt;strong&gt;&lt;em&gt;Head of Data &amp;amp; Analytics&lt;/em&gt;&lt;/strong&gt;&amp;#39;. There is a big data literacy/maturity deficit within the organisation and it would be this person&amp;#39;s role to begin to change this. Salary is not massive so the role is open to someone who hasn&amp;#39;t been in a senior data-position before but is up to the challenge. The organisation I work for is rather complex as it is a charity with social enterprises so it combines impact/social work, fundraising and commercial activity.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve drafted the job role below, however, I&amp;#39;m hoping you kind people might be able to help me determine what skills/knowledge would be classed as essential to be able to do this and any other pointers in what the right candidate should look like (remember this is a low/mid salary position due to limited funding available).&lt;/p&gt;

&lt;p&gt;----&lt;/p&gt;

&lt;h1&gt;Job Purpose&lt;/h1&gt;

&lt;p&gt;There has been identified a lack of clear data structure and process within the organisation and confirmation that data needs to be managed, retained, analysed and stored with greater control and routine. The role of the Data &amp;amp; Analytics Lead would be to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To define, own and implement a group-wide data strategy and ensure the strategic vision for data architecture is met and maintained by working with the CEO (in line with their 3-year strategic vision) and a range of Stakeholders including Department Heads, Managers and Support Workers.&lt;/li&gt;
&lt;li&gt;To develop and promote a central database architecture that aids the organisation in achieving its strategic goals&lt;/li&gt;
&lt;li&gt;Work with various teams throughout the organisation to provide analysis and valuable insights to unlock opportunities, drive data-informed business decisions and to make a positive impact on our service users.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;Key Objectives/Responsibilities&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Partner with leadership and peers to understand report requirements, map and document existing business processes, evaluating output requirements and formats and ensure consistency across teams&lt;/li&gt;
&lt;li&gt;Implement and administer the large CRM database initiative and provide database user support.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analysis&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Effectively use data to tell stories, communicate key insights through internal reports, presentations and dashboards to drive business decisions.&lt;/li&gt;
&lt;li&gt;Define and share key business performance indicators with the leadership team.&lt;/li&gt;
&lt;li&gt;Analysis of our customer and donor base to help our retail and fundraising teams understand our supporters.&lt;/li&gt;
&lt;li&gt;Help get the most out of our website, content and social platforms - by understanding and helping in the optimization of customer journeys and marketing/advertising campaign performance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Management&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Help to drive the data strategy group-wide.&lt;/li&gt;
&lt;li&gt;Work with the with leadership &amp;amp; management teams across the group to understand their requirements &amp;amp; data sources, set priorities based on analysis and results to implement and optimise fundraising, impact and commercial processes and solutions&lt;/li&gt;
&lt;li&gt;Work with the leadership teams to build dashboards and KPI monitoring reports for providing insights to enable better planning and performance monitoring across the organisation.&lt;/li&gt;
&lt;li&gt;Work closely with various teams within the organisation to gain a holistic view of customers, trends and competitors&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;----&lt;/p&gt;

&lt;p&gt;I appreciate that this may be asking a lot from one person, especially on a low/mid-range salary but it is what we need and all we can afford. I&amp;#39;m hoping that it will be a great working experience for the person taking the role who will see it as an opportunity to develop their role and get their feet wet in a senior data position. With that, there will also be patience and expectation for a lot of on the job learning, that this will be a long process and the person filling the role won&amp;#39;t magically be able to implement/fix everything listed above within their first year in the role. We see this as a two-year+ journey to data maturity.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What are the bare minimum technical/non-technical skills/knowledge I should be looking for?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Also for extra context the organisation is 6 years old, and is looking to implement salesforce but does not have a CRM/central database yet. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hol7ni,jboyd88,12,/r/datascience/comments/hol7ni/hiring_the_first_data_role_what_skills_are_needed/,https://www.reddit.com/r/datascience/comments/hol7ni/hiring_the_first_data_role_what_skills_are_needed/,1594369327.0
r/datascience,"Matt Tran, the owner of Engineered Truth on youtube, nowadays is working with a Congo dude to promote data science courses. He had multiple videos saying that even a bachelor's degree is not required to get a job as a data scientist since you can self learn online. He even went as far as saying that CS and Math degrees are worthless and you should just go to a data science Bootcamp to get a job as a data scientist, and now he is promoting his courses. 

Btw, this is the guy who threatened and blackmailed a college kid for criticizing him, so you know what kind of person he is. His videos seem to target audiences who are living in 3rd world countries. His courses cost 350 dollars and claiming that this is better than the MIT professor's course. 

I did more research and it turns out there are actually a lot of people who are scamming people from 3rd world countries with their low-quality data science courses claiming that they can become a data scientist with an above-average salary in just 3 months. They are basically preying on desperate people where regulations are almost non-existent, unlike the U.S or Canada. 

I know this may sound harsh, but do you personally think people who purchased these types of products are responsible for buying shitty courses?  Also, has the number of online courses scam gone up in the past few years with the rise of popularity in Data Science?",t2_6iinrmvs,Are there a lot of Online Course Scams in the Data Science Industry especially in 3rd world countries?,discussion,t3_hnt2kk,0.98,251,Discussion,251,1594283370.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Matt Tran, the owner of Engineered Truth on youtube, nowadays is working with a Congo dude to promote data science courses. He had multiple videos saying that even a bachelor&amp;#39;s degree is not required to get a job as a data scientist since you can self learn online. He even went as far as saying that CS and Math degrees are worthless and you should just go to a data science Bootcamp to get a job as a data scientist, and now he is promoting his courses. &lt;/p&gt;

&lt;p&gt;Btw, this is the guy who threatened and blackmailed a college kid for criticizing him, so you know what kind of person he is. His videos seem to target audiences who are living in 3rd world countries. His courses cost 350 dollars and claiming that this is better than the MIT professor&amp;#39;s course. &lt;/p&gt;

&lt;p&gt;I did more research and it turns out there are actually a lot of people who are scamming people from 3rd world countries with their low-quality data science courses claiming that they can become a data scientist with an above-average salary in just 3 months. They are basically preying on desperate people where regulations are almost non-existent, unlike the U.S or Canada. &lt;/p&gt;

&lt;p&gt;I know this may sound harsh, but do you personally think people who purchased these types of products are responsible for buying shitty courses?  Also, has the number of online courses scam gone up in the past few years with the rise of popularity in Data Science?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hnt2kk,owlwaves,86,/r/datascience/comments/hnt2kk/are_there_a_lot_of_online_course_scams_in_the/,https://www.reddit.com/r/datascience/comments/hnt2kk/are_there_a_lot_of_online_course_scams_in_the/,1594254570.0
r/datascience,"Took a new job, getting familiar with PL/SQL and some of the different stacks they have here. Find out they use massive tables with close to 300 columns for pretty much every reporting table on their Oracle database...

I'm Used to MS SQL and a well maintained EDW structure with tables having optimal indexed fields. Just trying to understand ***WHY***? I get that usually corporate data structures get this way due to legacy patch fixes and other 'office politics but this seems insane.",t2_lvpl8,Enterprise Tables with 100+ columns?,discussion,t3_ho8oar,0.67,4,Discussion,4,1594348939.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Took a new job, getting familiar with PL/SQL and some of the different stacks they have here. Find out they use massive tables with close to 300 columns for pretty much every reporting table on their Oracle database...&lt;/p&gt;

&lt;p&gt;I&amp;#39;m Used to MS SQL and a well maintained EDW structure with tables having optimal indexed fields. Just trying to understand &lt;strong&gt;&lt;em&gt;WHY&lt;/em&gt;&lt;/strong&gt;? I get that usually corporate data structures get this way due to legacy patch fixes and other &amp;#39;office politics but this seems insane.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ho8oar,MaCRo_OL,19,/r/datascience/comments/ho8oar/enterprise_tables_with_100_columns/,https://www.reddit.com/r/datascience/comments/ho8oar/enterprise_tables_with_100_columns/,1594320139.0
r/datascience,"Can someone who isnt working on AI/ML but everything else including data engineering, ETL, data modelling, data warehousing, data analysis, experiments, BI (reports, dashboards) etc call themselves a data scientist? 

If so, and you are an AI/ML type DS, does this offend you?",t2_37ginbo7,Can this role be called « data scientist »?,discussion,t3_hoi42j,0.33,0,Discussion,0,1594382575.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can someone who isnt working on AI/ML but everything else including data engineering, ETL, data modelling, data warehousing, data analysis, experiments, BI (reports, dashboards) etc call themselves a data scientist? &lt;/p&gt;

&lt;p&gt;If so, and you are an AI/ML type DS, does this offend you?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hoi42j,mango_sorbet13,4,/r/datascience/comments/hoi42j/can_this_role_be_called_data_scientist/,https://www.reddit.com/r/datascience/comments/hoi42j/can_this_role_be_called_data_scientist/,1594353775.0
r/datascience,"I recently went through a job search and in the process saved (bookmarked urls, saved tweets, saved reddit threads, youtube videos) that would be handy in the future job searches or during the job. I also have several code snippets/algorithms that i used to brush up on data structures/algos. 

I made wordpress blog but had to manually type out all the content. and not really best use of time.

What is the best way to save all these resources (and potentially share with other job hunters)? Has anyone faced this issue? 

\*\*note:  i want to be able to remind myself why i bookmarked something so that I later don't have to read through entire article to jog my memory.\*\*

Also, i this is a great community, I got and continue to get a lot of great resources from you all, thank you :)",t2_4m1ivn,Best tool/framework to save online technical resources for future use,discussion,t3_ho8y6z,1.0,2,Discussion,2,1594349807.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I recently went through a job search and in the process saved (bookmarked urls, saved tweets, saved reddit threads, youtube videos) that would be handy in the future job searches or during the job. I also have several code snippets/algorithms that i used to brush up on data structures/algos. &lt;/p&gt;

&lt;p&gt;I made wordpress blog but had to manually type out all the content. and not really best use of time.&lt;/p&gt;

&lt;p&gt;What is the best way to save all these resources (and potentially share with other job hunters)? Has anyone faced this issue? &lt;/p&gt;

&lt;p&gt;**note:  i want to be able to remind myself why i bookmarked something so that I later don&amp;#39;t have to read through entire article to jog my memory.**&lt;/p&gt;

&lt;p&gt;Also, i this is a great community, I got and continue to get a lot of great resources from you all, thank you :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ho8y6z,sang89,12,/r/datascience/comments/ho8y6z/best_toolframework_to_save_online_technical/,https://www.reddit.com/r/datascience/comments/ho8y6z/best_toolframework_to_save_online_technical/,1594321007.0
r/datascience,"We’ve had two data science positions open up at our company and my boss was interested in having me manage the eventual new hires. I’m hesitant because they are in a different time zone (3 hours behind, so I would have to adjust my working schedule) and I’m unsure if there will be a raise. They would be considered my direct reports and I would have a title change.

Anyone have any advice on how to navigate this and ask for more compensation?

EDIT: Since this post is trending a bit wanted to give a little more context:

* I would be in charge of their training and assignment of all future work, 1-1's, and performance reviews
* The 2 new hires are the first DS on the West Coast team. I would be leading them from the East Coast, and all of the work associated with the West Coast
* Would also most likely be interacting with middle management to scope out work",t2_fs03u,Should I demand a raise if my boss asked me to manage new hires?,career,t3_hnmu71,0.94,130,Career,130,1594262819.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We’ve had two data science positions open up at our company and my boss was interested in having me manage the eventual new hires. I’m hesitant because they are in a different time zone (3 hours behind, so I would have to adjust my working schedule) and I’m unsure if there will be a raise. They would be considered my direct reports and I would have a title change.&lt;/p&gt;

&lt;p&gt;Anyone have any advice on how to navigate this and ask for more compensation?&lt;/p&gt;

&lt;p&gt;EDIT: Since this post is trending a bit wanted to give a little more context:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I would be in charge of their training and assignment of all future work, 1-1&amp;#39;s, and performance reviews&lt;/li&gt;
&lt;li&gt;The 2 new hires are the first DS on the West Coast team. I would be leading them from the East Coast, and all of the work associated with the West Coast&lt;/li&gt;
&lt;li&gt;Would also most likely be interacting with middle management to scope out work&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hnmu71,jambery,40,/r/datascience/comments/hnmu71/should_i_demand_a_raise_if_my_boss_asked_me_to/,https://www.reddit.com/r/datascience/comments/hnmu71/should_i_demand_a_raise_if_my_boss_asked_me_to/,1594234019.0
r/datascience,"I hope this post doesn't violate the guidelines of this sub. I am trying for a job change as a Data Scientist for the last 8 months.  I am working under a manager who has indirectly told me that he will never promote me and after a few months, I might be reporting to my, now, juniors. I am stuck in a very bad situation.  I have more than 3 years of work experience and a master's degree in applied mathematics and computer science. I keep getting rejected from ALL the companies, be it big, medium or small. I have been to multiple on-site interviews but something always goes wrong. At this point, I am able to answer all the technical questions but that doesn't seem to be enough. I am proficient in machine learning algorithms, statistics, and some competitive programming which is enough for data science interviews. I am losing all hope that I'll be ever able to switch jobs. I have hands-on experience in developing machine learning pipelines and a master's degree. Data science is supposed to be a lucrative field. Why is everyone rejecting me? Any tip is highly appreciated.",t2_d1p28kh,Rejected from a lot of interviews. Losing all hope.,,t3_hnnwda,0.79,32,Job Search,32,1594265982.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I hope this post doesn&amp;#39;t violate the guidelines of this sub. I am trying for a job change as a Data Scientist for the last 8 months.  I am working under a manager who has indirectly told me that he will never promote me and after a few months, I might be reporting to my, now, juniors. I am stuck in a very bad situation.  I have more than 3 years of work experience and a master&amp;#39;s degree in applied mathematics and computer science. I keep getting rejected from ALL the companies, be it big, medium or small. I have been to multiple on-site interviews but something always goes wrong. At this point, I am able to answer all the technical questions but that doesn&amp;#39;t seem to be enough. I am proficient in machine learning algorithms, statistics, and some competitive programming which is enough for data science interviews. I am losing all hope that I&amp;#39;ll be ever able to switch jobs. I have hands-on experience in developing machine learning pipelines and a master&amp;#39;s degree. Data science is supposed to be a lucrative field. Why is everyone rejecting me? Any tip is highly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hnnwda,cpluscplus,66,/r/datascience/comments/hnnwda/rejected_from_a_lot_of_interviews_losing_all_hope/,https://www.reddit.com/r/datascience/comments/hnnwda/rejected_from_a_lot_of_interviews_losing_all_hope/,1594237182.0
r/datascience,"I posted my other video, ['How to Make Beautiful Graphs in R'](https://youtu.be/qnw1xDnt_Ec) about a week ago and it seemed to pick up decent reception in this subreddit

To continue with the ggplot2 series, I made a tutorial on [**'Making Gorgeous Animated Graphs in R'**](https://youtu.be/SnCi0s0e4Io) using the gganimate library with [decent looking graphs](https://imgur.com/a/9CHZCr7) and not the basic ggplot ones.

Please let me know if it helped, and if you have any recommendations for future content. And of course, [**subscribe**](https://www.youtube.com/channel/UCBV194XNr6CIQCCuw1v2rMQ?sub_confirmation=1) **if you're interested in this type of content :-)**

Thanks!",t2_7378bvlf,Make Gorgeous *Animated* Graphs in R [gganimate],education,t3_hnam46,0.98,329,Education,329,1594211867.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I posted my other video, &lt;a href=""https://youtu.be/qnw1xDnt_Ec""&gt;&amp;#39;How to Make Beautiful Graphs in R&amp;#39;&lt;/a&gt; about a week ago and it seemed to pick up decent reception in this subreddit&lt;/p&gt;

&lt;p&gt;To continue with the ggplot2 series, I made a tutorial on &lt;a href=""https://youtu.be/SnCi0s0e4Io""&gt;&lt;strong&gt;&amp;#39;Making Gorgeous Animated Graphs in R&amp;#39;&lt;/strong&gt;&lt;/a&gt; using the gganimate library with &lt;a href=""https://imgur.com/a/9CHZCr7""&gt;decent looking graphs&lt;/a&gt; and not the basic ggplot ones.&lt;/p&gt;

&lt;p&gt;Please let me know if it helped, and if you have any recommendations for future content. And of course, &lt;a href=""https://www.youtube.com/channel/UCBV194XNr6CIQCCuw1v2rMQ?sub_confirmation=1""&gt;&lt;strong&gt;subscribe&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;if you&amp;#39;re interested in this type of content :-)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hnam46,datasliceYT,22,/r/datascience/comments/hnam46/make_gorgeous_animated_graphs_in_r_gganimate/,https://www.reddit.com/r/datascience/comments/hnam46/make_gorgeous_animated_graphs_in_r_gganimate/,1594183067.0
r/datascience,"Really simple question. I understand the MAPE value as representing the average percent that the models predicted value is off compared to the actual value of the test data. In my situation, I'm seeing a MAPE value of 0.8762103.  


My question is whether I ought to read that as .087% or 8.7%?",t2_13wm53,Simple question about interpreting a MAPE (mean absolute percentage error) when validating an ARIMA (time series) model.,projects,t3_ho9d6f,0.17,0,Projects,0,1594351130.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Really simple question. I understand the MAPE value as representing the average percent that the models predicted value is off compared to the actual value of the test data. In my situation, I&amp;#39;m seeing a MAPE value of 0.8762103.  &lt;/p&gt;

&lt;p&gt;My question is whether I ought to read that as .087% or 8.7%?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ho9d6f,greendogufo,2,/r/datascience/comments/ho9d6f/simple_question_about_interpreting_a_mape_mean/,https://www.reddit.com/r/datascience/comments/ho9d6f/simple_question_about_interpreting_a_mape_mean/,1594322330.0
r/datascience,"Hello.

I'm sorry if people dislike lots of starters on this subreddit, but I don't know where else to ask. I feel very lost when it comes to statistics since many textbooks have complicated mathematical annotations (a little bit too much for ""laymen"" with basic knowledge) and are not very beginner friendly. I covered probability theory and hypothesis testing in my studies but didn't really take much from it. I also have a vague understanding of regression and classification but don't know the details.

Is there any one textbook that is free and also very good, where I can learn the most important basics for application in biotechnology/sciences in general? I'm not talking about applying statistics in Python but rather understanding the basics behind them. Basically a statistics book with few but helpful practical examples.

Thank you and kind regards",t2_2fohpkzi,Feeling lost in statistics,education,t3_ho9qdp,0.22,0,Education,0,1594352328.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m sorry if people dislike lots of starters on this subreddit, but I don&amp;#39;t know where else to ask. I feel very lost when it comes to statistics since many textbooks have complicated mathematical annotations (a little bit too much for &amp;quot;laymen&amp;quot; with basic knowledge) and are not very beginner friendly. I covered probability theory and hypothesis testing in my studies but didn&amp;#39;t really take much from it. I also have a vague understanding of regression and classification but don&amp;#39;t know the details.&lt;/p&gt;

&lt;p&gt;Is there any one textbook that is free and also very good, where I can learn the most important basics for application in biotechnology/sciences in general? I&amp;#39;m not talking about applying statistics in Python but rather understanding the basics behind them. Basically a statistics book with few but helpful practical examples.&lt;/p&gt;

&lt;p&gt;Thank you and kind regards&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ho9qdp,mikehawk1988,18,/r/datascience/comments/ho9qdp/feeling_lost_in_statistics/,https://www.reddit.com/r/datascience/comments/ho9qdp/feeling_lost_in_statistics/,1594323528.0
r/datascience,"Hey all, i have a general ML/DS question.  

Despite me being in school for CS and minoring in stats with a handful of machine learning, math, and statistics courses under my belt, i currently lack the ability to ""think like a data scientist"" (diagnosis upon my own observations...). How does one get there? Of course it doesnt happen over night but is there a general guideline on how to get there or advice on what one should do? Feeling really stuck these days...

I'm currently working as a Data Scientist Coop but can really see my flaws and areas that i need improvement. I feel as though my mindset and toolset right now as a ""data scientist"" is more like...script kitty/plug in and play...very narrow minded. I lack the ability to think creatively with the data I have to work with and really struggle to develop innovative or intelligent ideas/thoughts with the data. Also I definitely have a big case of imposter syndrome in this field so far.  I'm an undergrad rn.",t2_szwf3,How to Think Like a Data Scientist?,career,t3_hny0kc,0.58,2,Career,2,1594304166.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all, i have a general ML/DS question.  &lt;/p&gt;

&lt;p&gt;Despite me being in school for CS and minoring in stats with a handful of machine learning, math, and statistics courses under my belt, i currently lack the ability to &amp;quot;think like a data scientist&amp;quot; (diagnosis upon my own observations...). How does one get there? Of course it doesnt happen over night but is there a general guideline on how to get there or advice on what one should do? Feeling really stuck these days...&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently working as a Data Scientist Coop but can really see my flaws and areas that i need improvement. I feel as though my mindset and toolset right now as a &amp;quot;data scientist&amp;quot; is more like...script kitty/plug in and play...very narrow minded. I lack the ability to think creatively with the data I have to work with and really struggle to develop innovative or intelligent ideas/thoughts with the data. Also I definitely have a big case of imposter syndrome in this field so far.  I&amp;#39;m an undergrad rn.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hny0kc,c-kyi,5,/r/datascience/comments/hny0kc/how_to_think_like_a_data_scientist/,https://www.reddit.com/r/datascience/comments/hny0kc/how_to_think_like_a_data_scientist/,1594275366.0
r/datascience,"In a clustering problem I am using the gower distance, which results in a dissimilarity matrix.

Furthermore I'm using k-medoids to clusterize.

So now if I read the medoids that result from k-medoids, then take the rows of the medoids from the dissimilarity matrix, and finally sum the cluster labels from that corresponding medoid in that row , what do I obtain?

The inverse of the within cluster distance?",t2_719vr9ao,K-medoids within cluster distance sum with gower dissimilarity matrix,education,t3_hnlrqa,0.73,10,Education,10,1594259521.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In a clustering problem I am using the gower distance, which results in a dissimilarity matrix.&lt;/p&gt;

&lt;p&gt;Furthermore I&amp;#39;m using k-medoids to clusterize.&lt;/p&gt;

&lt;p&gt;So now if I read the medoids that result from k-medoids, then take the rows of the medoids from the dissimilarity matrix, and finally sum the cluster labels from that corresponding medoid in that row , what do I obtain?&lt;/p&gt;

&lt;p&gt;The inverse of the within cluster distance?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hnlrqa,rpinto02,1,/r/datascience/comments/hnlrqa/kmedoids_within_cluster_distance_sum_with_gower/,https://www.reddit.com/r/datascience/comments/hnlrqa/kmedoids_within_cluster_distance_sum_with_gower/,1594230721.0
r/datascience,"Hi all,

So for work I analyze course survey data for professors looking to potentially redesign their courses and take them from an in-person lecture based class to a fully online self-regulated learning based class. So I'm the person who is doing all the data wrangling and am doing it in R. This is my first time ever having a job or doing something like this for such a scale. Everybody else uses SPSS but I don't know how to use SPSS and I use my personal Mac for work and SPSS just does not want to work on my Mac. Besides, R is better (but I'm the only person on my team of people that knows how to use it) .... Anyways,

Right now we have a project where we are analyzing Fall 2018, Spring 2019, Fall 2019, and Spring 2020 course survey data (labeled FA18, SP19, FA19, and SP20 respectively) for four classes: a math class (MA 101), a business class (BUS 563), a computer science class (CSC 362), and a biochemistry class (BCH 231).

Within each semester, there are three surveys administered to the class uniformly across the semester-- one at the beginning (BGN), the middle (called MID), and the end (END -- really creative I know). We call these time points ""phases"". So now, for each of the four classes, I have a grand total of 12 surveys (4 semesters worth of data x 3 surveys administered total).

Let's talk about the surveys. I wish I could say each survey asks the exact same questions, but they don't. Stuff that exists in one of the MA 101 surveys might not exist in say, the BCH 231 survey and even for one particular course there are some questions that are only asked at a certain phase. This is to be expected though, however, I have a few tasks:

1. Download these course survey results (whether it's the BGN survey, MID survey, or END survey) from Qualtrics in SPSS, then bring the SPSS data into R (my boss just sends me the SPSS data hence why I worded it this way. I don't have access to Qualtrics and I don't use SPSS on my Mac since it acts all wonky). To bring in SPSS data I use the haven package which works fantastically :)
2. Clean this data. There are a lot of variables here, but these variables are literally questions with pre-defined labels. A common question we ask in any of these surveys is ""describe your interest in this subject matter before, during, or after \[depending on the phase\] of this course."" This question we just call ""Interest1"" or something. Things like that (if that makes any sense). So part of the data cleaning process involves me using the reshape package to go in and manually go through every single variable and either rename it or tell R to exclude it from the final data set. This is a very time consuming and tedious process might I add. The variables that come to mind are things like ""StudentIDNum"", ""ResponseID"", ""First Name"", ""Last Name"", ""Email Address"", ""Year in School"", ""Interest1"", etc. I also have to change missing values from -99 to N/A for each of these variables in all of this data. If someone could be as so kind to tell me how to do this that would be so wonderful :) This data is also mostly all Likert Scale data. So a lot of my data is just columns of integers between 1 and 5. Not all of it is though, but I would like it to be. Some of my data is like ""Definitely no"", ""sometimes no"", ""maybe"", ""sometimes yes"", and ""yes"". Know what I mean? I would also love to know how to convert variables with responses like this to integers between 1 and 5 please and thank you :)
3. Now once I have cleaned all my data and spit out a cleaned CSV file for each of the surveys administered for the students to take (which, might I add, don't always all have a 100% response rate -- again, to be expected though), my task is to then merge each of the three survey results into one combined data set for a given semester. From here, then I take each of these merged data sets for one semester, and put them all together so that way for a particular course, say MA 101, we have one massive combined data set that consists of a bunch of survey results across time: FA18\_BGN FA18\_MID FA18\_END SP19\_BGN SP19\_MID SP19\_END ... SP20\_BGN SP20\_MID SP20\_END. Something like that, does that make sense?
4. Now once I have one massive merged/combined data set for each of these four courses, then ultimately I have to merge all of these data sets into one super massive combined data set.

So ultimately my question is how do I do this? Do I just use the merge() function in R? This function can only take two data sets at a time though and also within this function there is the ""by ="" parameter which, to my best understanding, tells R by what variables do you want to merge by? I was doing by intersect(dataset 1, dataset 2) but apparently that's not what my boss wants. He wants literally all of it merged together whether someone responded to all three surveys in a given course or only did just one. And also because there isn't really likely an overlap between students across semesters for a given course or any of the other classes (save maybe for the MA 101 course and the CSC 362 course), how do I handle merging this? Should I tell my boss that what he wants isn't feasible?

I apologize for asking so many questions and sounding like a confused idiot, but well, that's exactly what I am. This is my first big boy stats job because I'm in grad school for statistics so I'm brand spanking new to it (background is pure math -- undergrad and masters in it) and just finished my first year. I've never really had to clean data sets before or do any of that kind of work and I'm working with some education and psychology researchers and people this summer which is why they all use SPSS. Because we have a work from home order though I'm using my Mac to do all my work on and I'm actually using my brand new one I just got. The MacBook Pro I was previously using (and had been using for the past 6 years) died about 4 weeks ago and since all the apple stores are closed between my summer courses and work I had to get a new one. I tried a work one for a bit but I couldn't download anything (R/R Studio) and I needed a new personal one anyways so I got this one. My old one had a trial of SPSS on it though and Jesus did that thing never want to freaking work. It always froze on me and made everything so slow. Plus I want to refine my R skills and get good at it (mostly I've just been using SAS this whole first year -- ew, but, well, apparently our school likes to use SAS for some reason idk).

But yeah, I don't know how to best join these data sets and account for the lack of complete responses, and I'm just feeling overwhelmed because nobody else on my team knows how to program in R well and I'm super new to all this statistics and data stuff so I'm just feeling super stressed about it all. This is why I'm turning to r/datascience to help. Thank you for taking the time to read all this and helping a poor grad student out! It really does mean a lot and I am very appreciative of your time. Thanks again.",t2_y17qqo9,[Q] How Do I Clean and Merge all this Course Survey Data in R?,career,t3_hnj11t,0.83,7,Career,7,1594250730.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;So for work I analyze course survey data for professors looking to potentially redesign their courses and take them from an in-person lecture based class to a fully online self-regulated learning based class. So I&amp;#39;m the person who is doing all the data wrangling and am doing it in R. This is my first time ever having a job or doing something like this for such a scale. Everybody else uses SPSS but I don&amp;#39;t know how to use SPSS and I use my personal Mac for work and SPSS just does not want to work on my Mac. Besides, R is better (but I&amp;#39;m the only person on my team of people that knows how to use it) .... Anyways,&lt;/p&gt;

&lt;p&gt;Right now we have a project where we are analyzing Fall 2018, Spring 2019, Fall 2019, and Spring 2020 course survey data (labeled FA18, SP19, FA19, and SP20 respectively) for four classes: a math class (MA 101), a business class (BUS 563), a computer science class (CSC 362), and a biochemistry class (BCH 231).&lt;/p&gt;

&lt;p&gt;Within each semester, there are three surveys administered to the class uniformly across the semester-- one at the beginning (BGN), the middle (called MID), and the end (END -- really creative I know). We call these time points &amp;quot;phases&amp;quot;. So now, for each of the four classes, I have a grand total of 12 surveys (4 semesters worth of data x 3 surveys administered total).&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s talk about the surveys. I wish I could say each survey asks the exact same questions, but they don&amp;#39;t. Stuff that exists in one of the MA 101 surveys might not exist in say, the BCH 231 survey and even for one particular course there are some questions that are only asked at a certain phase. This is to be expected though, however, I have a few tasks:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Download these course survey results (whether it&amp;#39;s the BGN survey, MID survey, or END survey) from Qualtrics in SPSS, then bring the SPSS data into R (my boss just sends me the SPSS data hence why I worded it this way. I don&amp;#39;t have access to Qualtrics and I don&amp;#39;t use SPSS on my Mac since it acts all wonky). To bring in SPSS data I use the haven package which works fantastically :)&lt;/li&gt;
&lt;li&gt;Clean this data. There are a lot of variables here, but these variables are literally questions with pre-defined labels. A common question we ask in any of these surveys is &amp;quot;describe your interest in this subject matter before, during, or after [depending on the phase] of this course.&amp;quot; This question we just call &amp;quot;Interest1&amp;quot; or something. Things like that (if that makes any sense). So part of the data cleaning process involves me using the reshape package to go in and manually go through every single variable and either rename it or tell R to exclude it from the final data set. This is a very time consuming and tedious process might I add. The variables that come to mind are things like &amp;quot;StudentIDNum&amp;quot;, &amp;quot;ResponseID&amp;quot;, &amp;quot;First Name&amp;quot;, &amp;quot;Last Name&amp;quot;, &amp;quot;Email Address&amp;quot;, &amp;quot;Year in School&amp;quot;, &amp;quot;Interest1&amp;quot;, etc. I also have to change missing values from -99 to N/A for each of these variables in all of this data. If someone could be as so kind to tell me how to do this that would be so wonderful :) This data is also mostly all Likert Scale data. So a lot of my data is just columns of integers between 1 and 5. Not all of it is though, but I would like it to be. Some of my data is like &amp;quot;Definitely no&amp;quot;, &amp;quot;sometimes no&amp;quot;, &amp;quot;maybe&amp;quot;, &amp;quot;sometimes yes&amp;quot;, and &amp;quot;yes&amp;quot;. Know what I mean? I would also love to know how to convert variables with responses like this to integers between 1 and 5 please and thank you :)&lt;/li&gt;
&lt;li&gt;Now once I have cleaned all my data and spit out a cleaned CSV file for each of the surveys administered for the students to take (which, might I add, don&amp;#39;t always all have a 100% response rate -- again, to be expected though), my task is to then merge each of the three survey results into one combined data set for a given semester. From here, then I take each of these merged data sets for one semester, and put them all together so that way for a particular course, say MA 101, we have one massive combined data set that consists of a bunch of survey results across time: FA18_BGN FA18_MID FA18_END SP19_BGN SP19_MID SP19_END ... SP20_BGN SP20_MID SP20_END. Something like that, does that make sense?&lt;/li&gt;
&lt;li&gt;Now once I have one massive merged/combined data set for each of these four courses, then ultimately I have to merge all of these data sets into one super massive combined data set.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So ultimately my question is how do I do this? Do I just use the merge() function in R? This function can only take two data sets at a time though and also within this function there is the &amp;quot;by =&amp;quot; parameter which, to my best understanding, tells R by what variables do you want to merge by? I was doing by intersect(dataset 1, dataset 2) but apparently that&amp;#39;s not what my boss wants. He wants literally all of it merged together whether someone responded to all three surveys in a given course or only did just one. And also because there isn&amp;#39;t really likely an overlap between students across semesters for a given course or any of the other classes (save maybe for the MA 101 course and the CSC 362 course), how do I handle merging this? Should I tell my boss that what he wants isn&amp;#39;t feasible?&lt;/p&gt;

&lt;p&gt;I apologize for asking so many questions and sounding like a confused idiot, but well, that&amp;#39;s exactly what I am. This is my first big boy stats job because I&amp;#39;m in grad school for statistics so I&amp;#39;m brand spanking new to it (background is pure math -- undergrad and masters in it) and just finished my first year. I&amp;#39;ve never really had to clean data sets before or do any of that kind of work and I&amp;#39;m working with some education and psychology researchers and people this summer which is why they all use SPSS. Because we have a work from home order though I&amp;#39;m using my Mac to do all my work on and I&amp;#39;m actually using my brand new one I just got. The MacBook Pro I was previously using (and had been using for the past 6 years) died about 4 weeks ago and since all the apple stores are closed between my summer courses and work I had to get a new one. I tried a work one for a bit but I couldn&amp;#39;t download anything (R/R Studio) and I needed a new personal one anyways so I got this one. My old one had a trial of SPSS on it though and Jesus did that thing never want to freaking work. It always froze on me and made everything so slow. Plus I want to refine my R skills and get good at it (mostly I&amp;#39;ve just been using SAS this whole first year -- ew, but, well, apparently our school likes to use SAS for some reason idk).&lt;/p&gt;

&lt;p&gt;But yeah, I don&amp;#39;t know how to best join these data sets and account for the lack of complete responses, and I&amp;#39;m just feeling overwhelmed because nobody else on my team knows how to program in R well and I&amp;#39;m super new to all this statistics and data stuff so I&amp;#39;m just feeling super stressed about it all. This is why I&amp;#39;m turning to &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt; to help. Thank you for taking the time to read all this and helping a poor grad student out! It really does mean a lot and I am very appreciative of your time. Thanks again.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hnj11t,Citizen_of_Danksburg,4,/r/datascience/comments/hnj11t/q_how_do_i_clean_and_merge_all_this_course_survey/,https://www.reddit.com/r/datascience/comments/hnj11t/q_how_do_i_clean_and_merge_all_this_course_survey/,1594221930.0
r/datascience,,t2_4an3hfer,The Day-to-Day,career,t3_hn07dc,0.98,181,Career,181,1594175578.0,,hn07dc,urban_citrus,43,/r/datascience/comments/hn07dc/the_daytoday/,https://twitter.com/DrewFustin/status/1280492738455244803?s=20,1594146778.0
r/datascience,"Hi people,

I have been searching on Google for the answer but since I'm pretty new to handling this much data, I hope someone more experienced can give me some advice.

Basically I have around 300-400GB of csv up on Google Drive right now that I want to analyze. I upload it there since I don't have enough space in my laptop. 

I am currently unemployed and this is sort of a passion project only (I can't aford AWS/Azure for it) so I'm only looking for free program that can help me interact with the data. So after looking around, I'm thinking about using Spark on Google Colab to deal with it.

I have never used or learnt Spark before, so can anyone tell me if this is even possible? I see the Disk storage in Colab is 100GB something so if I merge all my cvs into a single dataframe, will that exceed Colab storage? For now I guess I just want to run some simple multivariate regressions on those data so if there's better way to do it than merging every single csv together, I would appreciate the suggestion. Thank you",t2_114eam,How to interact with large volume of csv data on Google Drive (~3-400GB),tooling,t3_hnqk91,0.57,1,Tooling,1,1594274403.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi people,&lt;/p&gt;

&lt;p&gt;I have been searching on Google for the answer but since I&amp;#39;m pretty new to handling this much data, I hope someone more experienced can give me some advice.&lt;/p&gt;

&lt;p&gt;Basically I have around 300-400GB of csv up on Google Drive right now that I want to analyze. I upload it there since I don&amp;#39;t have enough space in my laptop. &lt;/p&gt;

&lt;p&gt;I am currently unemployed and this is sort of a passion project only (I can&amp;#39;t aford AWS/Azure for it) so I&amp;#39;m only looking for free program that can help me interact with the data. So after looking around, I&amp;#39;m thinking about using Spark on Google Colab to deal with it.&lt;/p&gt;

&lt;p&gt;I have never used or learnt Spark before, so can anyone tell me if this is even possible? I see the Disk storage in Colab is 100GB something so if I merge all my cvs into a single dataframe, will that exceed Colab storage? For now I guess I just want to run some simple multivariate regressions on those data so if there&amp;#39;s better way to do it than merging every single csv together, I would appreciate the suggestion. Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hnqk91,Namngonvl,11,/r/datascience/comments/hnqk91/how_to_interact_with_large_volume_of_csv_data_on/,https://www.reddit.com/r/datascience/comments/hnqk91/how_to_interact_with_large_volume_of_csv_data_on/,1594245603.0
r/datascience,Do they remain engineers or do they move on to a different position in DataScience? What's the common career path for someone who starts out as an associate data engineer?,t2_glb9l,What do most data engineers do after 5 years?,career,t3_hn7ksx,0.85,41,Career,41,1594200131.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do they remain engineers or do they move on to a different position in DataScience? What&amp;#39;s the common career path for someone who starts out as an associate data engineer?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hn7ksx,FlREBALL,22,/r/datascience/comments/hn7ksx/what_do_most_data_engineers_do_after_5_years/,https://www.reddit.com/r/datascience/comments/hn7ksx/what_do_most_data_engineers_do_after_5_years/,1594171331.0
r/datascience,"Have any of you experimented with ""private Consulting""? By this i mean offering analytics to smaller organizations or organizations seeking a one time analysis. I was thinking about this is an idea but hoping there was a proof of concept somewhere out there.

Thanks!",t2_g9nl2yr,Side Business,discussion,t3_hnmdw2,0.56,1,Discussion,1,1594261412.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Have any of you experimented with &amp;quot;private Consulting&amp;quot;? By this i mean offering analytics to smaller organizations or organizations seeking a one time analysis. I was thinking about this is an idea but hoping there was a proof of concept somewhere out there.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hnmdw2,NotSodiumFree,9,/r/datascience/comments/hnmdw2/side_business/,https://www.reddit.com/r/datascience/comments/hnmdw2/side_business/,1594232612.0
r/datascience,"  

Taking up certification courses on Udemy, Coursera, Udacity, and likes is great, but again, let your work speak, I am more ascribed to the school of “proof of work is better than words and branding”.

Prove that what you have learned is valuable and beneficial through solving real-world meaningful problems that positively impact our communities and derive value for businesses.

The data science models have no value without any real experiments or deployed solutions”. Focus on doing meaningful work that has real value to the business and it should be quantifiable through real experiments/deployed in a production system.

If hiring you is a good business decision, companies will line up to hire you and what determines that you are a good decision is simple: Profit. You are an asset of value if only your skills are valuable.

Please don’t get deluded, simple projects don’t demonstrate problem-solving. Everyone is doing them. These projects are simple or stupid or useless copy paste and not at all useful. Be different and build a track record of practical solutions and keep solving more complex projects.

Strive to become a rare combination of skilled, visible, different and valuable

The intersection of all these things with communication &amp; storytelling, creativity, critical and analytical thinking, practical built solutions, model deployment, and other skills do greatly count.",t2_3m1kf60u,The Value of Data Science Certifications,projects,t3_hmrj6a,0.88,209,Projects,209,1594143833.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Taking up certification courses on Udemy, Coursera, Udacity, and likes is great, but again, let your work speak, I am more ascribed to the school of “proof of work is better than words and branding”.&lt;/p&gt;

&lt;p&gt;Prove that what you have learned is valuable and beneficial through solving real-world meaningful problems that positively impact our communities and derive value for businesses.&lt;/p&gt;

&lt;p&gt;The data science models have no value without any real experiments or deployed solutions”. Focus on doing meaningful work that has real value to the business and it should be quantifiable through real experiments/deployed in a production system.&lt;/p&gt;

&lt;p&gt;If hiring you is a good business decision, companies will line up to hire you and what determines that you are a good decision is simple: Profit. You are an asset of value if only your skills are valuable.&lt;/p&gt;

&lt;p&gt;Please don’t get deluded, simple projects don’t demonstrate problem-solving. Everyone is doing them. These projects are simple or stupid or useless copy paste and not at all useful. Be different and build a track record of practical solutions and keep solving more complex projects.&lt;/p&gt;

&lt;p&gt;Strive to become a rare combination of skilled, visible, different and valuable&lt;/p&gt;

&lt;p&gt;The intersection of all these things with communication &amp;amp; storytelling, creativity, critical and analytical thinking, practical built solutions, model deployment, and other skills do greatly count.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hmrj6a,KennedyKWangari,94,/r/datascience/comments/hmrj6a/the_value_of_data_science_certifications/,https://www.reddit.com/r/datascience/comments/hmrj6a/the_value_of_data_science_certifications/,1594115033.0
r/datascience,"I'm curious if anyone has a process or tool for capturing and remembering 'macro' level market events? Example: My company makes widget\_x, and sometimes large externalities (things my company can't control) will happen. Things like:

* competitor launches widget\_y in the same market as widget\_x
* a new law / regulation is enacted that (may or may not) affect our market
* widget\_z (already in the market) changes in some fundamental way (e.g. new feature, price drop, etc.)
* Covid-19 
* All the buyers of widgets are suspending their normal routines (holiday, conference, etc.)  


I find it can be difficult to keep track of these types of events when trying to understand sources of variation in sales of widget\_x over different time periods. Often times my business partners know these things but I really only have access to these by literally asking them (and knowing what to ask for, which I know is part of my role as a data scientist). So what do y'all use / see being used? Spreadsheets? You keep track of it yourself? A table in a data warehouse that is maintained? Do your marketers, sales, or account teams keep track of it for you?  


tl;dr I'm wondering what's the best way to keep track of external market events for use in data science applications.",t2_12o149,Tracking 'macro' market events for a product market,discussion,t3_hn5ikq,1.0,3,Discussion,3,1594192652.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m curious if anyone has a process or tool for capturing and remembering &amp;#39;macro&amp;#39; level market events? Example: My company makes widget_x, and sometimes large externalities (things my company can&amp;#39;t control) will happen. Things like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;competitor launches widget_y in the same market as widget_x&lt;/li&gt;
&lt;li&gt;a new law / regulation is enacted that (may or may not) affect our market&lt;/li&gt;
&lt;li&gt;widget_z (already in the market) changes in some fundamental way (e.g. new feature, price drop, etc.)&lt;/li&gt;
&lt;li&gt;Covid-19 &lt;/li&gt;
&lt;li&gt;All the buyers of widgets are suspending their normal routines (holiday, conference, etc.)&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I find it can be difficult to keep track of these types of events when trying to understand sources of variation in sales of widget_x over different time periods. Often times my business partners know these things but I really only have access to these by literally asking them (and knowing what to ask for, which I know is part of my role as a data scientist). So what do y&amp;#39;all use / see being used? Spreadsheets? You keep track of it yourself? A table in a data warehouse that is maintained? Do your marketers, sales, or account teams keep track of it for you?  &lt;/p&gt;

&lt;p&gt;tl;dr I&amp;#39;m wondering what&amp;#39;s the best way to keep track of external market events for use in data science applications.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hn5ikq,nsala5,0,/r/datascience/comments/hn5ikq/tracking_macro_market_events_for_a_product_market/,https://www.reddit.com/r/datascience/comments/hn5ikq/tracking_macro_market_events_for_a_product_market/,1594163852.0
r/datascience,"Imagine that you've been having to do your own data analysis work because you don't have a data analyst on the team.  (This is probably annoying because you'd rather be doing data science.)

Luckily, you've been selected to be on an interview panel for a senior data analyst position. You're assessing how well interviewees understand the data analysis process.

* What questions would you ask to explore their data analysis process? What kind of an answer would tell you that they know what they're talking about?

* What details might they miss that would tell you that they're probably not qualified?

* What might you ask to figure out how useful this person will be to your job?  From a selfish perspective, what responses would you want to hear?",t2_3pnmt3n,Imagine you're part of an interview panel for a senior data analyst position. What questions would you ask to probe whether someone has a good understanding of the data analysis process?,discussion,t3_hmpni8,0.86,44,Discussion,44,1594134027.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Imagine that you&amp;#39;ve been having to do your own data analysis work because you don&amp;#39;t have a data analyst on the team.  (This is probably annoying because you&amp;#39;d rather be doing data science.)&lt;/p&gt;

&lt;p&gt;Luckily, you&amp;#39;ve been selected to be on an interview panel for a senior data analyst position. You&amp;#39;re assessing how well interviewees understand the data analysis process.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What questions would you ask to explore their data analysis process? What kind of an answer would tell you that they know what they&amp;#39;re talking about?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What details might they miss that would tell you that they&amp;#39;re probably not qualified?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What might you ask to figure out how useful this person will be to your job?  From a selfish perspective, what responses would you want to hear?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hmpni8,im_most_likely_lyin,29,/r/datascience/comments/hmpni8/imagine_youre_part_of_an_interview_panel_for_a/,https://www.reddit.com/r/datascience/comments/hmpni8/imagine_youre_part_of_an_interview_panel_for_a/,1594105227.0
r/datascience,"I'm building a kubeflow pipeline implementation that will train many sklearn models in parallel. As I built up these containers, I realize I'm basically building a generic model training pipeline. Inside of this I'd love to have the ability to submit an arbitrary dataset into it, this by itself is quite easy to do for a given trial, however...I want to build automatic parameter scaling into the system as well. I was looking around briefly to see if there was anything in sklearn that did a bit of automatic deduction in this regard but I didn't seem to find anything.

What I'm thinking about writing operates on the dtypes of a dataframe and will do things like separate strings as categorical variables, separate low-unique-count numeric columns as categorical (not ordinal), and then apply standard scaling to the remaining numeric columns. This would be configurable at runtime, but would establish a base upon which pipelines could begin tweaking data preprocessing. Part of this configuration is that you could skip scaling altogether if you so desired to test on raw values from a dataset.

Has anyone made anything like this before or could short-circuit my development to a solution that already exists? Thank you!",t2_9hjj5,Automatic Scaling and ML Pipelines,discussion,t3_hn368n,1.0,2,Discussion,2,1594184980.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m building a kubeflow pipeline implementation that will train many sklearn models in parallel. As I built up these containers, I realize I&amp;#39;m basically building a generic model training pipeline. Inside of this I&amp;#39;d love to have the ability to submit an arbitrary dataset into it, this by itself is quite easy to do for a given trial, however...I want to build automatic parameter scaling into the system as well. I was looking around briefly to see if there was anything in sklearn that did a bit of automatic deduction in this regard but I didn&amp;#39;t seem to find anything.&lt;/p&gt;

&lt;p&gt;What I&amp;#39;m thinking about writing operates on the dtypes of a dataframe and will do things like separate strings as categorical variables, separate low-unique-count numeric columns as categorical (not ordinal), and then apply standard scaling to the remaining numeric columns. This would be configurable at runtime, but would establish a base upon which pipelines could begin tweaking data preprocessing. Part of this configuration is that you could skip scaling altogether if you so desired to test on raw values from a dataset.&lt;/p&gt;

&lt;p&gt;Has anyone made anything like this before or could short-circuit my development to a solution that already exists? Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hn368n,kirinthos,2,/r/datascience/comments/hn368n/automatic_scaling_and_ml_pipelines/,https://www.reddit.com/r/datascience/comments/hn368n/automatic_scaling_and_ml_pipelines/,1594156180.0
r/datascience,"There are a lot of posts asking about data science certifications, and in all the discussions people seem more concerned with certifying they know something than knowing the thing. So I thought it'd be helpful to bring up Bryan Caplan's [The Case Against Education: Why the Education System Is a Waste of Time and Money.](https://www.amazon.com/Case-against-Education-System-Waste/dp/0691174652)

It really changed how I think about education and certifications. The big idea is that there are two ways to get ROI in education

1. Signaling: You're paying for a piece of paper verifying you know X,Y,Z
2. Human Capital: You're paying to increase the value of your output. 

Of course any sensible person would say education's a bit of signaling and HC, but for the most part we combine the two when talking about programs which makes it difficult to understand the relationship between the two. And in my opinion #2 should be the primary focus when cultivating skills and that #1 will follow naturally. When we lose site of that it allows certification mills charging an arm and a leg to flourish.

I'm hoping that in this community we can start distinguishing between the two when discussing the merits of various certs.",t2_2gln0h10,"If you deploy a model to production and no one's around, did it really happen?",education,t3_hmxefs,0.75,6,Education,6,1594166844.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;There are a lot of posts asking about data science certifications, and in all the discussions people seem more concerned with certifying they know something than knowing the thing. So I thought it&amp;#39;d be helpful to bring up Bryan Caplan&amp;#39;s &lt;a href=""https://www.amazon.com/Case-against-Education-System-Waste/dp/0691174652""&gt;The Case Against Education: Why the Education System Is a Waste of Time and Money.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It really changed how I think about education and certifications. The big idea is that there are two ways to get ROI in education&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Signaling: You&amp;#39;re paying for a piece of paper verifying you know X,Y,Z&lt;/li&gt;
&lt;li&gt;Human Capital: You&amp;#39;re paying to increase the value of your output. &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Of course any sensible person would say education&amp;#39;s a bit of signaling and HC, but for the most part we combine the two when talking about programs which makes it difficult to understand the relationship between the two. And in my opinion #2 should be the primary focus when cultivating skills and that #1 will follow naturally. When we lose site of that it allows certification mills charging an arm and a leg to flourish.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m hoping that in this community we can start distinguishing between the two when discussing the merits of various certs.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hmxefs,poopybutbaby,26,/r/datascience/comments/hmxefs/if_you_deploy_a_model_to_production_and_no_ones/,https://www.reddit.com/r/datascience/comments/hmxefs/if_you_deploy_a_model_to_production_and_no_ones/,1594138044.0
r/datascience,"I'm currently in my second full time position.  I got my first job as a data scientist as a return offer from my internship.  I got my second job as a machine learning engineer relying mostly on Leetcode and my previous work experience.  I did not apply to that many jobs for my second position, so i don't feel knowledgeable about the recruitment process.



How much Leetcode should I be doing to be successful in future roles?  Can I also get away with never doing Kaggle?",t2_2k1plfwa,How much should we do Leetcode and Kaggle for our 2nd/3rd data science jobs?,discussion,t3_hn6w11,0.4,0,Discussion,0,1594197545.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently in my second full time position.  I got my first job as a data scientist as a return offer from my internship.  I got my second job as a machine learning engineer relying mostly on Leetcode and my previous work experience.  I did not apply to that many jobs for my second position, so i don&amp;#39;t feel knowledgeable about the recruitment process.&lt;/p&gt;

&lt;p&gt;How much Leetcode should I be doing to be successful in future roles?  Can I also get away with never doing Kaggle?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hn6w11,memcpy94,9,/r/datascience/comments/hn6w11/how_much_should_we_do_leetcode_and_kaggle_for_our/,https://www.reddit.com/r/datascience/comments/hn6w11/how_much_should_we_do_leetcode_and_kaggle_for_our/,1594168745.0
r/datascience,"Hey folks. I'd like some honest advice on how best to approach a PhD that supplements our field. I left a PhD program in BME for personal reasons about 4 years ago. Life is back to normal, and it would be nice to have that ""PhD"" next to my name, but in a more relevant area of research. I don't think going back to that program would be advantageous.

1. Is it worth it given that I already have quite a bit of academic graduate experience?
2. If so, what's going to be helpful if I eventually work at a FAANG?
3. Any way to facilitate this while still working full time (even if it takes significantly longer)? There must be a lot of professors/advisors who could use someone with a strong math/stats/coding background and industry experience.

I know the answer is ""it depends"", but what would you do? Let me know if you need more info than what I've provided below:

&amp;#x200B;

* Professional background (in order):
   * 3.5 years ML/DS work in financial industry, mostly Sales/Marketing optimization and client retention
   * 2.5 years as a GRA in MRI research
   * 2 years as a GRA in plasma physics research
   * 3 years as a sysadmin
* Academic Background (in order):
   * Biomedical Eng M.S.
   * Physics M.S.
   * Biology B.S. / Psychology B.A
* Personal:
   * Pacific NW
   * early 30s
   * married, no kids

&amp;#x200B;

Edit: Thanks all, this gives me a little more to think about. I really do appreciate the time you put into your thoughtful responses.",t2_7p66t,Advice on whether to go for a PhD,career,t3_hn2sl4,0.5,0,Career,0,1594183765.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey folks. I&amp;#39;d like some honest advice on how best to approach a PhD that supplements our field. I left a PhD program in BME for personal reasons about 4 years ago. Life is back to normal, and it would be nice to have that &amp;quot;PhD&amp;quot; next to my name, but in a more relevant area of research. I don&amp;#39;t think going back to that program would be advantageous.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Is it worth it given that I already have quite a bit of academic graduate experience?&lt;/li&gt;
&lt;li&gt;If so, what&amp;#39;s going to be helpful if I eventually work at a FAANG?&lt;/li&gt;
&lt;li&gt;Any way to facilitate this while still working full time (even if it takes significantly longer)? There must be a lot of professors/advisors who could use someone with a strong math/stats/coding background and industry experience.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I know the answer is &amp;quot;it depends&amp;quot;, but what would you do? Let me know if you need more info than what I&amp;#39;ve provided below:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Professional background (in order):

&lt;ul&gt;
&lt;li&gt;3.5 years ML/DS work in financial industry, mostly Sales/Marketing optimization and client retention&lt;/li&gt;
&lt;li&gt;2.5 years as a GRA in MRI research&lt;/li&gt;
&lt;li&gt;2 years as a GRA in plasma physics research&lt;/li&gt;
&lt;li&gt;3 years as a sysadmin&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Academic Background (in order):

&lt;ul&gt;
&lt;li&gt;Biomedical Eng M.S.&lt;/li&gt;
&lt;li&gt;Physics M.S.&lt;/li&gt;
&lt;li&gt;Biology B.S. / Psychology B.A&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Personal:

&lt;ul&gt;
&lt;li&gt;Pacific NW&lt;/li&gt;
&lt;li&gt;early 30s&lt;/li&gt;
&lt;li&gt;married, no kids&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Edit: Thanks all, this gives me a little more to think about. I really do appreciate the time you put into your thoughtful responses.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hn2sl4,yeableskive,12,/r/datascience/comments/hn2sl4/advice_on_whether_to_go_for_a_phd/,https://www.reddit.com/r/datascience/comments/hn2sl4/advice_on_whether_to_go_for_a_phd/,1594154965.0
r/datascience,"I am doing a machine learning project where a random forest style algorithm gave me a good auc/f1 score. However, I tried and tweaked many different clustering algorithms and none of them seem to be showing anything useful. This leads me to the question:

1) is this a normal phenomenon? Good classification, poor clustering?

2) more importantly, suppose you had great clustering results (data was separable).  how can you use the results of clustering to assist and improve  classification tasks?

Thanks!",t2_3f0i9m72,"Strong classification results, weak clustering results",discussion,t3_hmwc24,0.84,4,Discussion,4,1594163485.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am doing a machine learning project where a random forest style algorithm gave me a good auc/f1 score. However, I tried and tweaked many different clustering algorithms and none of them seem to be showing anything useful. This leads me to the question:&lt;/p&gt;

&lt;p&gt;1) is this a normal phenomenon? Good classification, poor clustering?&lt;/p&gt;

&lt;p&gt;2) more importantly, suppose you had great clustering results (data was separable).  how can you use the results of clustering to assist and improve  classification tasks?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hmwc24,SQL_beginner,6,/r/datascience/comments/hmwc24/strong_classification_results_weak_clustering/,https://www.reddit.com/r/datascience/comments/hmwc24/strong_classification_results_weak_clustering/,1594134685.0
r/datascience,Never quite understood why,t2_6wjpihu8,why is naive bayes so popular for nlp,projects,t3_hmhg9v,0.92,71,Projects,71,1594101370.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Never quite understood why&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hmhg9v,uw_finest,21,/r/datascience/comments/hmhg9v/why_is_naive_bayes_so_popular_for_nlp/,https://www.reddit.com/r/datascience/comments/hmhg9v/why_is_naive_bayes_so_popular_for_nlp/,1594072570.0
r/datascience,"I'm building a map based on ""good"" investments. ""Good"" is defined by my boss' eyes, and he determines if the locations are ""good"" based on his knowledge of the area. This, in my eyes, is not feasible.

I rank the locations based on the following data ( they are all modelled over time, i.e. increase in price shows an area is becoming more desirable). 

1) Price  (higher = better)

2) Income (higher = better)

3) Volatility (stddev price, lower = better) 

4) Number of offers (lower = better, lower offers mean more permanent renters)

He doesn't give me any input as to what else I can add, just eyeballs the map I make and says if it's accurate. 

I've asked to ask what an investor would value in a map, and have also looked into what classifies as a safe secure investment. 

How do I solve this, or recommend that my boss use an alternative method to just eyeballing a map?",t2_5e34w9d2,My boss wants to build a model validated based on visual inspection. What do I do?,discussion,t3_hmsbxs,1.0,2,Discussion,2,1594147875.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m building a map based on &amp;quot;good&amp;quot; investments. &amp;quot;Good&amp;quot; is defined by my boss&amp;#39; eyes, and he determines if the locations are &amp;quot;good&amp;quot; based on his knowledge of the area. This, in my eyes, is not feasible.&lt;/p&gt;

&lt;p&gt;I rank the locations based on the following data ( they are all modelled over time, i.e. increase in price shows an area is becoming more desirable). &lt;/p&gt;

&lt;p&gt;1) Price  (higher = better)&lt;/p&gt;

&lt;p&gt;2) Income (higher = better)&lt;/p&gt;

&lt;p&gt;3) Volatility (stddev price, lower = better) &lt;/p&gt;

&lt;p&gt;4) Number of offers (lower = better, lower offers mean more permanent renters)&lt;/p&gt;

&lt;p&gt;He doesn&amp;#39;t give me any input as to what else I can add, just eyeballs the map I make and says if it&amp;#39;s accurate. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve asked to ask what an investor would value in a map, and have also looked into what classifies as a safe secure investment. &lt;/p&gt;

&lt;p&gt;How do I solve this, or recommend that my boss use an alternative method to just eyeballing a map?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hmsbxs,expatwithajetpack,9,/r/datascience/comments/hmsbxs/my_boss_wants_to_build_a_model_validated_based_on/,https://www.reddit.com/r/datascience/comments/hmsbxs/my_boss_wants_to_build_a_model_validated_based_on/,1594119075.0
r/datascience,"I'm currently doing a data science/business intelligence internship for my universities business intelligence unit and so far all we've done is data warehouse related tasks, with our current task being to create a mock datamart. We have to pull data from source tables, apply transformations and store the data into tables using the star schema data mart design. I understand that data science mostly consists of obtaining and cleaning data but this seems more like the role of a data engineer who sets up the data architecture &amp; infrastructure. Am I wrong in this assumption or is this indeed a core role of a data scientist or business intelligence analyst? 

As a note, this internship has been watered down to an extent due to issues with coranavirus and lockdown. These factors caused this part of the internship programme to be shortened thus requiring content to be cut that would otherwise have been covered.",t2_4csxm713,Am I doing the role of a data engineer or does data science/business intelligence entail datamart design?,discussion,t3_hme3mt,0.9,14,Discussion,14,1594091294.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently doing a data science/business intelligence internship for my universities business intelligence unit and so far all we&amp;#39;ve done is data warehouse related tasks, with our current task being to create a mock datamart. We have to pull data from source tables, apply transformations and store the data into tables using the star schema data mart design. I understand that data science mostly consists of obtaining and cleaning data but this seems more like the role of a data engineer who sets up the data architecture &amp;amp; infrastructure. Am I wrong in this assumption or is this indeed a core role of a data scientist or business intelligence analyst? &lt;/p&gt;

&lt;p&gt;As a note, this internship has been watered down to an extent due to issues with coranavirus and lockdown. These factors caused this part of the internship programme to be shortened thus requiring content to be cut that would otherwise have been covered.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hme3mt,42TowelsCo,5,/r/datascience/comments/hme3mt/am_i_doing_the_role_of_a_data_engineer_or_does/,https://www.reddit.com/r/datascience/comments/hme3mt/am_i_doing_the_role_of_a_data_engineer_or_does/,1594062494.0
r/datascience,"I'm starting a new job soon and have been offered a choice between a mac and windows machine. I currently use  a linux laptop but not sure this company will allow me to use ubuntu or not on the 'Windows machine'.

My preference would be for linux but since that may not be possible, mac would be the next option due to it being unix based. Just wondering what peoples thoughts are on this.

Will be working in the  cloud but tend to use laptop for local development using spark, etc, then pushing up to run in cloud.",t2_tugic,Job offered choice of laptop. Mac or Windows?,tooling,t3_hm5vak,0.71,10,Tooling,10,1594063461.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m starting a new job soon and have been offered a choice between a mac and windows machine. I currently use  a linux laptop but not sure this company will allow me to use ubuntu or not on the &amp;#39;Windows machine&amp;#39;.&lt;/p&gt;

&lt;p&gt;My preference would be for linux but since that may not be possible, mac would be the next option due to it being unix based. Just wondering what peoples thoughts are on this.&lt;/p&gt;

&lt;p&gt;Will be working in the  cloud but tend to use laptop for local development using spark, etc, then pushing up to run in cloud.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hm5vak,Fungie16,33,/r/datascience/comments/hm5vak/job_offered_choice_of_laptop_mac_or_windows/,https://www.reddit.com/r/datascience/comments/hm5vak/job_offered_choice_of_laptop_mac_or_windows/,1594034661.0
r/datascience,"Hi guys,

I've been interning now at a large organization for about a month, and my team is essentially trying to build a dashboard displaying some statistics etc. Everything is still in development, meaning that the data flow could change all the time, nothing is really reliable. I was given the task to make sense of data they had previously collected to make some predictions on a given metric. (sry for being that incredibly broad, just trying hard not to reveal the company) Well, okay so far, I started looking at the data and had the first bummer: 80% of the values are missing for most features, and even if they are not missing, you could not necessarily be sure if the data is right. (and they weren't willing to explain every little aspect of every feature collection process to sort that out, just for some features they were willing to) We then decided to concentrate on a subset of the data first with more reliable information, and I started doing the usual tests and drawing plots etc.. Unfortunately, I couldn't find a pattern in the data. Well, as expected, the ML algorithm didn't do so either, returning horrible scores (best MCC was 0.28). Now I'm kind of lost, not really knowing whether I failed or the data just didn't have the right information. 

Did anybody have the same experience? If so, how did you handle it? I now have to talk to the manager and see how it goes :( Any help is appreciated!",t2_3yasb3p,Intern struggling to find any useful information from given data,career,t3_hm5fzf,0.71,4,Career,4,1594061418.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been interning now at a large organization for about a month, and my team is essentially trying to build a dashboard displaying some statistics etc. Everything is still in development, meaning that the data flow could change all the time, nothing is really reliable. I was given the task to make sense of data they had previously collected to make some predictions on a given metric. (sry for being that incredibly broad, just trying hard not to reveal the company) Well, okay so far, I started looking at the data and had the first bummer: 80% of the values are missing for most features, and even if they are not missing, you could not necessarily be sure if the data is right. (and they weren&amp;#39;t willing to explain every little aspect of every feature collection process to sort that out, just for some features they were willing to) We then decided to concentrate on a subset of the data first with more reliable information, and I started doing the usual tests and drawing plots etc.. Unfortunately, I couldn&amp;#39;t find a pattern in the data. Well, as expected, the ML algorithm didn&amp;#39;t do so either, returning horrible scores (best MCC was 0.28). Now I&amp;#39;m kind of lost, not really knowing whether I failed or the data just didn&amp;#39;t have the right information. &lt;/p&gt;

&lt;p&gt;Did anybody have the same experience? If so, how did you handle it? I now have to talk to the manager and see how it goes :( Any help is appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hm5fzf,Klausstaler,5,/r/datascience/comments/hm5fzf/intern_struggling_to_find_any_useful_information/,https://www.reddit.com/r/datascience/comments/hm5fzf/intern_struggling_to_find_any_useful_information/,1594032618.0
r/datascience,"So I have a Macbook (not Pro or Air, the thin small model) Retina Display 12"" from 2017 that I have been using in school for a while now. I'm an Econ major about to finish my degree. My computer has a dual core  1,2 GHz Intel Core m3 and 8gb of memory.

I mostly use Stata, R, and Python for econometrics, but I have lately been doing data science as well (beyond the economics/econometrics frameworks) and hope to do some deep learning as well.

Being a student, I cannot really afford using AWS instances with high computing power so I plan on using my self owned hardware for the most part.

Lately I have realized these specs might not be enough, and I am considering purchasing a Macbook Pro 13"" with ""1.4GHz Quad-Core Processor with Turbo Boost up to 3.9GHz"", 256gb storage and 16gb RAM. Another option would be a Mac mini with ""3.6GHz Quad-Core Processor"", 256 gb and 16gb of RAM as well, in both cases paired with a decent monitor. Should I really consider this purchase or will my current mac be enough?

Please don't advise me to buy PCs since I really despise them (sorry!)",t2_4gex97w3,Is my Macbook 12in (2017) enough for data science?,discussion,t3_hmi6kv,0.39,0,Discussion,0,1594103696.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have a Macbook (not Pro or Air, the thin small model) Retina Display 12&amp;quot; from 2017 that I have been using in school for a while now. I&amp;#39;m an Econ major about to finish my degree. My computer has a dual core  1,2 GHz Intel Core m3 and 8gb of memory.&lt;/p&gt;

&lt;p&gt;I mostly use Stata, R, and Python for econometrics, but I have lately been doing data science as well (beyond the economics/econometrics frameworks) and hope to do some deep learning as well.&lt;/p&gt;

&lt;p&gt;Being a student, I cannot really afford using AWS instances with high computing power so I plan on using my self owned hardware for the most part.&lt;/p&gt;

&lt;p&gt;Lately I have realized these specs might not be enough, and I am considering purchasing a Macbook Pro 13&amp;quot; with &amp;quot;1.4GHz Quad-Core Processor with Turbo Boost up to 3.9GHz&amp;quot;, 256gb storage and 16gb RAM. Another option would be a Mac mini with &amp;quot;3.6GHz Quad-Core Processor&amp;quot;, 256 gb and 16gb of RAM as well, in both cases paired with a decent monitor. Should I really consider this purchase or will my current mac be enough?&lt;/p&gt;

&lt;p&gt;Please don&amp;#39;t advise me to buy PCs since I really despise them (sorry!)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hmi6kv,punkwalras,14,/r/datascience/comments/hmi6kv/is_my_macbook_12in_2017_enough_for_data_science/,https://www.reddit.com/r/datascience/comments/hmi6kv/is_my_macbook_12in_2017_enough_for_data_science/,1594074896.0
r/datascience,[https://www.forbes.com/sites/kalevleetaru/2019/03/07/how-data-scientists-turned-against-statistics/#1823ddcd257c](https://www.forbes.com/sites/kalevleetaru/2019/03/07/how-data-scientists-turned-against-statistics/#1823ddcd257c),t2_hsbcd,"Interesting article in Forbes on Data Science vs Statistics. As someone with a more conventional econometrics/statistics education, I found it very interesting and wanted to know what you folks think!",meta,t3_hlguz6,0.98,387,Meta,387,1593952881.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.forbes.com/sites/kalevleetaru/2019/03/07/how-data-scientists-turned-against-statistics/#1823ddcd257c""&gt;https://www.forbes.com/sites/kalevleetaru/2019/03/07/how-data-scientists-turned-against-statistics/#1823ddcd257c&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hlguz6,chandra381,139,/r/datascience/comments/hlguz6/interesting_article_in_forbes_on_data_science_vs/,https://www.reddit.com/r/datascience/comments/hlguz6/interesting_article_in_forbes_on_data_science_vs/,1593924081.0
r/datascience,Pretty much what the title says....what are some good sources to keep up with all the new development in data science? Where do you read the latest research papers or read about what is currently being worked on/talked about? Do you have any recommendations or favourites?,t2_4m6jgrsb,What is your go-to place (website/journal/etc) for keeping up with the latest news from the field?,discussion,t3_hlobwm,0.73,17,Discussion,17,1593991313.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Pretty much what the title says....what are some good sources to keep up with all the new development in data science? Where do you read the latest research papers or read about what is currently being worked on/talked about? Do you have any recommendations or favourites?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hlobwm,permadressed,14,/r/datascience/comments/hlobwm/what_is_your_goto_place_websitejournaletc_for/,https://www.reddit.com/r/datascience/comments/hlobwm/what_is_your_goto_place_websitejournaletc_for/,1593962513.0
r/datascience,,t2_5k25sp2s,At what age did you guys start learning data science? How many years did it take for you to land your first job and what did you do?,career,t3_hm6c6j,0.36,0,Career,0,1594065624.0,,hm6c6j,vitx777,8,/r/datascience/comments/hm6c6j/at_what_age_did_you_guys_start_learning_data/,https://www.reddit.com/r/datascience/comments/hm6c6j/at_what_age_did_you_guys_start_learning_data/,1594036824.0
r/datascience,"This is my third month as a Junior Data Scientist for a new startup. While the company is trying to gather as many customer data as possible, I do many many research on marketing to improve the site's conversion rate, promotion, etc. I help them solve AI/ML related problem by doing research for days or weeks. I also do social media analysis monthly and database management. I update small part of the data there. 

When I watch YouTube video of a day in a life, looks like most DS run, write, test lines of codes and manipulate data in a way. Well, they obviously working in a much larger company than mine. I just think, I'm doing so much marketing research and I don't think this improves my Data Science skills at all. I was thinking there would be long term project or something that will use my programming skills. Or maybe I'm wrong? What should I do then? Is this normal?",t2_k1a4t,Is it possible that your job won't include any coding but so much research?,career,t3_hm1nh7,0.57,1,Career,1,1594041827.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is my third month as a Junior Data Scientist for a new startup. While the company is trying to gather as many customer data as possible, I do many many research on marketing to improve the site&amp;#39;s conversion rate, promotion, etc. I help them solve AI/ML related problem by doing research for days or weeks. I also do social media analysis monthly and database management. I update small part of the data there. &lt;/p&gt;

&lt;p&gt;When I watch YouTube video of a day in a life, looks like most DS run, write, test lines of codes and manipulate data in a way. Well, they obviously working in a much larger company than mine. I just think, I&amp;#39;m doing so much marketing research and I don&amp;#39;t think this improves my Data Science skills at all. I was thinking there would be long term project or something that will use my programming skills. Or maybe I&amp;#39;m wrong? What should I do then? Is this normal?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hm1nh7,silveri5,1,/r/datascience/comments/hm1nh7/is_it_possible_that_your_job_wont_include_any/,https://www.reddit.com/r/datascience/comments/hm1nh7/is_it_possible_that_your_job_wont_include_any/,1594013027.0
r/datascience,"Hi folks -

I am possibly looking to find another DS job for multiple reasons. I have been reached approached by recruiters from Amazon, Facebook (several times), Netflix, Lyft, Microsoft, AirBnB and Pinterest (I failed my first invite from Google). My current interest is Netflix.

Can I get a review on my resume:[https://imgur.com/a/P85xCMZ](https://imgur.com/a/P85xCMZ)

Does it look good? I am currently also prepping for interviews, and I have found a good amount of resources, but any extra resources/advice/insight on how to get a DS (preferably senior) job at FANG-like companies would also be appreciated.

I hope it won't, but I am also hispanic POC born in the USA if that colors any opinions (it will be obvious to recruiters from my name).

Thank you!",t2_wu3exx,3rd year data scientist w/ PhD: Any advice for my resume?,,t3_hlxnqg,0.47,0,Job Search,0,1594024544.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi folks -&lt;/p&gt;

&lt;p&gt;I am possibly looking to find another DS job for multiple reasons. I have been reached approached by recruiters from Amazon, Facebook (several times), Netflix, Lyft, Microsoft, AirBnB and Pinterest (I failed my first invite from Google). My current interest is Netflix.&lt;/p&gt;

&lt;p&gt;Can I get a review on my resume:&lt;a href=""https://imgur.com/a/P85xCMZ""&gt;https://imgur.com/a/P85xCMZ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Does it look good? I am currently also prepping for interviews, and I have found a good amount of resources, but any extra resources/advice/insight on how to get a DS (preferably senior) job at FANG-like companies would also be appreciated.&lt;/p&gt;

&lt;p&gt;I hope it won&amp;#39;t, but I am also hispanic POC born in the USA if that colors any opinions (it will be obvious to recruiters from my name).&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hlxnqg,bonjarno65,26,/r/datascience/comments/hlxnqg/3rd_year_data_scientist_w_phd_any_advice_for_my/,https://www.reddit.com/r/datascience/comments/hlxnqg/3rd_year_data_scientist_w_phd_any_advice_for_my/,1593995744.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 05 Jul 2020 - 12 Jul 2020,,t3_hllhs9,0.88,6,Discussion,6,1593979231.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hllhs9,datascience-bot,156,/r/datascience/comments/hllhs9/weekly_entering_transitioning_thread_05_jul_2020/,https://www.reddit.com/r/datascience/comments/hllhs9/weekly_entering_transitioning_thread_05_jul_2020/,1593950431.0
r/datascience,"Hi Guys,

I recently switched from Jupyter notebooks to Pycharm and I'm loving it so far.

Was wondering if there are other pycharm users on this sub and what the data science community thinks of the IDE.

Also, what are some interesting add-on's (for ex. Kite) that boost productivity/aesthetics",t2_xyl79,Any PyCharm Users here?,discussion,t3_hl4crd,0.96,242,Discussion,242,1593902428.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;

&lt;p&gt;I recently switched from Jupyter notebooks to Pycharm and I&amp;#39;m loving it so far.&lt;/p&gt;

&lt;p&gt;Was wondering if there are other pycharm users on this sub and what the data science community thinks of the IDE.&lt;/p&gt;

&lt;p&gt;Also, what are some interesting add-on&amp;#39;s (for ex. Kite) that boost productivity/aesthetics&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hl4crd,Hopes_High,99,/r/datascience/comments/hl4crd/any_pycharm_users_here/,https://www.reddit.com/r/datascience/comments/hl4crd/any_pycharm_users_here/,1593873628.0
r/datascience,"Hi all! 

So I’m currently doing a bootcamp and I chose to do it through terminal on my Mac. It’s a SQLite script (?) that I’m supposed to get answers to the questions. I don’t know how to push the terminal commands to my github for that sql project. It doesn’t seem like another project that you link the path and all. 
Can anyone help me please?",t2_6o2ab9kp,How to push my SQLite code to my github from my Mac terminal ?,projects,t3_hlqj1k,0.36,0,Projects,0,1593999206.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all! &lt;/p&gt;

&lt;p&gt;So I’m currently doing a bootcamp and I chose to do it through terminal on my Mac. It’s a SQLite script (?) that I’m supposed to get answers to the questions. I don’t know how to push the terminal commands to my github for that sql project. It doesn’t seem like another project that you link the path and all. 
Can anyone help me please?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hlqj1k,monmoncherie,7,/r/datascience/comments/hlqj1k/how_to_push_my_sqlite_code_to_my_github_from_my/,https://www.reddit.com/r/datascience/comments/hlqj1k/how_to_push_my_sqlite_code_to_my_github_from_my/,1593970406.0
r/datascience,"Hey everyone, i have a masters in Data science and also one year working experience  as a data analyst in a pretty big company in the UK. 

 Due to life, covid etc i will be moving back to my country. (Greece) 

Problem is my country is not exactly booming with opportunities right now. 

I decided to take a break for 2 months to relax and clear my mind but i am kinda worried about the future.

Has anyone been in the same situation and how did they handle it?

I  was also looking for fully remote works but haven't found much by googling. If anyone else has insights in that they are welcome to post. 

I ruled out of freelancing because i am not sure if my skills will translate to that and it has pretty big variations.

&amp;#x200B;

Any opinions, suggestions, stories are more than welcome.",t2_fmzty,Career advice,career,t3_hlnazs,0.54,1,Career,1,1593987291.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone, i have a masters in Data science and also one year working experience  as a data analyst in a pretty big company in the UK. &lt;/p&gt;

&lt;p&gt;Due to life, covid etc i will be moving back to my country. (Greece) &lt;/p&gt;

&lt;p&gt;Problem is my country is not exactly booming with opportunities right now. &lt;/p&gt;

&lt;p&gt;I decided to take a break for 2 months to relax and clear my mind but i am kinda worried about the future.&lt;/p&gt;

&lt;p&gt;Has anyone been in the same situation and how did they handle it?&lt;/p&gt;

&lt;p&gt;I  was also looking for fully remote works but haven&amp;#39;t found much by googling. If anyone else has insights in that they are welcome to post. &lt;/p&gt;

&lt;p&gt;I ruled out of freelancing because i am not sure if my skills will translate to that and it has pretty big variations.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any opinions, suggestions, stories are more than welcome.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hlnazs,Andrewwww14,3,/r/datascience/comments/hlnazs/career_advice/,https://www.reddit.com/r/datascience/comments/hlnazs/career_advice/,1593958491.0
r/datascience,"Can I please get to see a site/project that incorporates Economics into Data Science? 

(Would love it if you share the links below 😊)",t2_543lzyxy,Data Science in Economics?,projects,t3_hlnozo,0.47,0,Projects,0,1593988891.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can I please get to see a site/project that incorporates Economics into Data Science? &lt;/p&gt;

&lt;p&gt;(Would love it if you share the links below 😊)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hlnozo,darpsboybd,10,/r/datascience/comments/hlnozo/data_science_in_economics/,https://www.reddit.com/r/datascience/comments/hlnozo/data_science_in_economics/,1593960091.0
r/datascience,"One I was asked at a job interview and didn't do particularly well:

&amp;#x200B;

&gt;A media company makes its money from monthly subscription fees. The company is considering entering the podcast space. How would you measure the impact on customer lifetime value of such a move?

&amp;#x200B;

I guess the trick here is that there's some self selecting behaviour here... you can't really look at the LTV (lifetime value) of users who use the new feature and compare it to users that don't use it, because arguably users who will use podcasts are a-priori different than those who don't. Alternatively, you can say that having this new feature would attract a certain type of (new) subscribers, and hence again it's unfair comparison.

Some ideas I floated:

\- holdout group

\- synthetic controls

&amp;#x200B;

Eager to hear your thoughts!",t2_de5yq,How to estimate the impact of a new product feature on lifetime-value ?,discussion,t3_hl29mc,0.95,57,Discussion,57,1593893081.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;One I was asked at a job interview and didn&amp;#39;t do particularly well:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A media company makes its money from monthly subscription fees. The company is considering entering the podcast space. How would you measure the impact on customer lifetime value of such a move?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I guess the trick here is that there&amp;#39;s some self selecting behaviour here... you can&amp;#39;t really look at the LTV (lifetime value) of users who use the new feature and compare it to users that don&amp;#39;t use it, because arguably users who will use podcasts are a-priori different than those who don&amp;#39;t. Alternatively, you can say that having this new feature would attract a certain type of (new) subscribers, and hence again it&amp;#39;s unfair comparison.&lt;/p&gt;

&lt;p&gt;Some ideas I floated:&lt;/p&gt;

&lt;p&gt;- holdout group&lt;/p&gt;

&lt;p&gt;- synthetic controls&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Eager to hear your thoughts!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hl29mc,Optimesh,19,/r/datascience/comments/hl29mc/how_to_estimate_the_impact_of_a_new_product/,https://www.reddit.com/r/datascience/comments/hl29mc/how_to_estimate_the_impact_of_a_new_product/,1593864281.0
r/datascience,"Someone help me understand the real value of SQL in a data science job? IME other than querying big data it offers me very little in the form of visualization, storytelling, stats, models, cross validation, and feature engineering. Is there something I am missing?",t2_1q6oq5dl,Value of SQL in data science,discussion,t3_hlr4xw,0.33,0,Discussion,0,1594001289.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Someone help me understand the real value of SQL in a data science job? IME other than querying big data it offers me very little in the form of visualization, storytelling, stats, models, cross validation, and feature engineering. Is there something I am missing?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hlr4xw,dmorris87,20,/r/datascience/comments/hlr4xw/value_of_sql_in_data_science/,https://www.reddit.com/r/datascience/comments/hlr4xw/value_of_sql_in_data_science/,1593972489.0
r/datascience,"When data contains categorical variables (either purely categorical or continuous and categorical together) , i see online that people either carefully implement sophisticated algorithms (involving dissimilarity, hamming distance, gower distance) ... or they just hot encode the data and use standard machine learning algorithms (svm, knn, etc). 

What are your opinions on this? When working on data science projects, how do you guys treat mixed data? So far the way I see it, suppose you hot encode your data, use machine learning algorithms and get good results (auc, f1 score) - how much does it matter?

I guess the best compromise is to use a random forest style algorithm which can readily handle continuous-categorical data while having the potential to provide strong results. 

Btw, if you have heavily unbalanced data - is it appropriate to use the SMOTE algorithm to resample and balance the data?",t2_3tosvccj,Properly analyzing mixed data vs one hot encoding,discussion,t3_hlhy5d,0.57,1,Discussion,1,1593958874.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When data contains categorical variables (either purely categorical or continuous and categorical together) , i see online that people either carefully implement sophisticated algorithms (involving dissimilarity, hamming distance, gower distance) ... or they just hot encode the data and use standard machine learning algorithms (svm, knn, etc). &lt;/p&gt;

&lt;p&gt;What are your opinions on this? When working on data science projects, how do you guys treat mixed data? So far the way I see it, suppose you hot encode your data, use machine learning algorithms and get good results (auc, f1 score) - how much does it matter?&lt;/p&gt;

&lt;p&gt;I guess the best compromise is to use a random forest style algorithm which can readily handle continuous-categorical data while having the potential to provide strong results. &lt;/p&gt;

&lt;p&gt;Btw, if you have heavily unbalanced data - is it appropriate to use the SMOTE algorithm to resample and balance the data?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hlhy5d,jj4646,4,/r/datascience/comments/hlhy5d/properly_analyzing_mixed_data_vs_one_hot_encoding/,https://www.reddit.com/r/datascience/comments/hlhy5d/properly_analyzing_mixed_data_vs_one_hot_encoding/,1593930074.0
r/datascience,"I've been studying Data Science/ML for a few months now. And now I'm at the stage where I seriously need a mentor. A mentor can be a life saver. This is what I've think of.

Let's make a group somewhere like discord with a very small number of mentees and a couple of mentors. The mentors can give us tasks on weekends and we discuss it after one week on the group. 

This group can help the beginners like me to not get lost, study the most important stuff first and have a guided journey.

I know professionals are listening, mentor us, please?

If you're a beginner and interested to be added in the group, comment below. 

Hoping for a positive response! 
Thank you.


Edit: If you are interested to join as a mentor/mentee please comment with a brief bio. 

My profile: I will be starting my MSc Computer Science in Ireland this September. I have 2 years experience in Supply Chain operations. I know Python/SQL/Jupyter notebooks/ML algorithms etc.",t2_29a2szc9,A request to professionals here,discussion,t3_hlgz5q,0.46,0,Discussion,0,1593953486.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been studying Data Science/ML for a few months now. And now I&amp;#39;m at the stage where I seriously need a mentor. A mentor can be a life saver. This is what I&amp;#39;ve think of.&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s make a group somewhere like discord with a very small number of mentees and a couple of mentors. The mentors can give us tasks on weekends and we discuss it after one week on the group. &lt;/p&gt;

&lt;p&gt;This group can help the beginners like me to not get lost, study the most important stuff first and have a guided journey.&lt;/p&gt;

&lt;p&gt;I know professionals are listening, mentor us, please?&lt;/p&gt;

&lt;p&gt;If you&amp;#39;re a beginner and interested to be added in the group, comment below. &lt;/p&gt;

&lt;p&gt;Hoping for a positive response! 
Thank you.&lt;/p&gt;

&lt;p&gt;Edit: If you are interested to join as a mentor/mentee please comment with a brief bio. &lt;/p&gt;

&lt;p&gt;My profile: I will be starting my MSc Computer Science in Ireland this September. I have 2 years experience in Supply Chain operations. I know Python/SQL/Jupyter notebooks/ML algorithms etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hlgz5q,beingvam,11,/r/datascience/comments/hlgz5q/a_request_to_professionals_here/,https://www.reddit.com/r/datascience/comments/hlgz5q/a_request_to_professionals_here/,1593924686.0
r/datascience,"When I use a random sample of my dataset, about 10-15% of its size, T-SNE algorithm repeatedly produces visualisations having a shape of a mesh. This behaviour vanishes when I use a bigger sample or whole dataset.

Example figure: [https://i.imgur.com/9a1Eazy.png](https://i.imgur.com/9a1Eazy.png)

The items in my set are represented by an n-dimensional vector, which is a product of a concatenation of two vectors from two different spaces. My guess is that a variation of items from one of the spaces is significantly higher than a variation of items from the other space. I mean that the later one (low) describes items from a more generalised standpoint. Therefore, the apparent clusters are inferred from the low-variational space and the items inside clusters might be organised based on the higher-variational space. I do not know how to verify this hypothesis, though.

Please do not mind colour in the figure, it says nothing.",t2_404pimvo,Is there any particular reason why T-SNE produces a mesh-like visualisation?,discussion,t3_hl7w3p,1.0,4,Discussion,4,1593915323.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;When I use a random sample of my dataset, about 10-15% of its size, T-SNE algorithm repeatedly produces visualisations having a shape of a mesh. This behaviour vanishes when I use a bigger sample or whole dataset.&lt;/p&gt;

&lt;p&gt;Example figure: &lt;a href=""https://i.imgur.com/9a1Eazy.png""&gt;https://i.imgur.com/9a1Eazy.png&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The items in my set are represented by an n-dimensional vector, which is a product of a concatenation of two vectors from two different spaces. My guess is that a variation of items from one of the spaces is significantly higher than a variation of items from the other space. I mean that the later one (low) describes items from a more generalised standpoint. Therefore, the apparent clusters are inferred from the low-variational space and the items inside clusters might be organised based on the higher-variational space. I do not know how to verify this hypothesis, though.&lt;/p&gt;

&lt;p&gt;Please do not mind colour in the figure, it says nothing.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hl7w3p,unskilledexplorer,4,/r/datascience/comments/hl7w3p/is_there_any_particular_reason_why_tsne_produces/,https://www.reddit.com/r/datascience/comments/hl7w3p/is_there_any_particular_reason_why_tsne_produces/,1593886523.0
r/datascience,"Someone close in my family recently died of Covid and we all as a family had our mind's just shut-off for days, mine is still numb.

Meanwhile, in parallel, the company which I work for is a digital news platform and has a sudden need to figure out a way to increase engagement in their comments, they want a pure quantitative analysis of past data to tell them a way out and since they are on a loss spree they have threatened to fire me if I don't come up with an analysis in 3 days, I have tried many ways out of this HR wise, but it doesn't bode well for me in long run.

I only have their full-fledged Google Analytics 360 access, and have to use it to somehow to draw some conclusions.

I still am in my blank mind phase with absolutely no creative juices, because of the incident, and thus plead the community to give me some ideas to draw up a story using data, only the optics of the analysis should look good for me to save my job.

I will go to professional medical help **later**, but to pay that bill too I need help on this guys asap.",t2_apf56,I need help from all of you at this.,projects,t3_hkpza8,0.79,122,Projects,122,1593835667.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Someone close in my family recently died of Covid and we all as a family had our mind&amp;#39;s just shut-off for days, mine is still numb.&lt;/p&gt;

&lt;p&gt;Meanwhile, in parallel, the company which I work for is a digital news platform and has a sudden need to figure out a way to increase engagement in their comments, they want a pure quantitative analysis of past data to tell them a way out and since they are on a loss spree they have threatened to fire me if I don&amp;#39;t come up with an analysis in 3 days, I have tried many ways out of this HR wise, but it doesn&amp;#39;t bode well for me in long run.&lt;/p&gt;

&lt;p&gt;I only have their full-fledged Google Analytics 360 access, and have to use it to somehow to draw some conclusions.&lt;/p&gt;

&lt;p&gt;I still am in my blank mind phase with absolutely no creative juices, because of the incident, and thus plead the community to give me some ideas to draw up a story using data, only the optics of the analysis should look good for me to save my job.&lt;/p&gt;

&lt;p&gt;I will go to professional medical help &lt;strong&gt;later&lt;/strong&gt;, but to pay that bill too I need help on this guys asap.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hkpza8,anshukg,54,/r/datascience/comments/hkpza8/i_need_help_from_all_of_you_at_this/,https://www.reddit.com/r/datascience/comments/hkpza8/i_need_help_from_all_of_you_at_this/,1593806867.0
r/datascience,,t2_4b3lupr,"If we were not battling an infectious disease, is it bad for your career to NEVER attend holiday parties and other company social events? Does it send a bad message, assuming you are pleasant to work with and are good at your job?",career,t3_hl7oxd,0.56,1,Career,1,1593914619.0,,hl7oxd,LetsEndSuffering,26,/r/datascience/comments/hl7oxd/if_we_were_not_battling_an_infectious_disease_is/,https://www.reddit.com/r/datascience/comments/hl7oxd/if_we_were_not_battling_an_infectious_disease_is/,1593885819.0
r/datascience,"Suppose I have variable A that has 2000 entries, Variable B that has 800 entries, and Variable C with 200 entries. How do I assign a weighting scale to these 3 variables such as to give more importance to Variable C than Variable A? I am trying to combine all these variables to calculate a metric which is dependent and based on these 3 Variables but I can't figure out a proper way to distribute them equally.

Edit: This is assuming that the other values for B and C are zero and not null",t2_10bohd,How to assign weights to multiple variables having different frequencies of occurrence?,projects,t3_hl4v19,0.33,0,Projects,0,1593904342.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Suppose I have variable A that has 2000 entries, Variable B that has 800 entries, and Variable C with 200 entries. How do I assign a weighting scale to these 3 variables such as to give more importance to Variable C than Variable A? I am trying to combine all these variables to calculate a metric which is dependent and based on these 3 Variables but I can&amp;#39;t figure out a proper way to distribute them equally.&lt;/p&gt;

&lt;p&gt;Edit: This is assuming that the other values for B and C are zero and not null&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hl4v19,Natsucr7,9,/r/datascience/comments/hl4v19/how_to_assign_weights_to_multiple_variables/,https://www.reddit.com/r/datascience/comments/hl4v19/how_to_assign_weights_to_multiple_variables/,1593875542.0
r/datascience,Is anyone aware of public data sets where it contains transaction data? Has anyone tried creating a model to predict future spending based on transaction data and if so how did it turn out?,t2_11hf9z,Has anyone tried to use Transaction data to predict future consumer spending behavior?,projects,t3_hkxypj,0.67,5,Projects,5,1593868635.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is anyone aware of public data sets where it contains transaction data? Has anyone tried creating a model to predict future spending based on transaction data and if so how did it turn out?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hkxypj,Kemosabe0,4,/r/datascience/comments/hkxypj/has_anyone_tried_to_use_transaction_data_to/,https://www.reddit.com/r/datascience/comments/hkxypj/has_anyone_tried_to_use_transaction_data_to/,1593839835.0
r/datascience,"I have been struggling to find implementations for python of K-Medoids.

I only found the pyclustering which lets me precompute a dissimilarity matrix, I am using Gower distance, instead of a inbuilt distance metric.

This would be fine but there are no inbuilt metrics that I can use to evaluate these K-Medoids results. There is the silhouette score but I can't find an example of how to use it with a precomputed distance instead of the euclidean distance, nor the docstrings help to find out how.

Ideally what I wanted was a impletation that would give me the Inertia(within clusters sum of squares) and the silhouette score so I could evalute the number of clusters, instead of having to build my own.

Any suggestions?",t2_719vr9ao,K-medoids implementation with python,tooling,t3_hkrm5q,0.93,21,Tooling,21,1593841510.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been struggling to find implementations for python of K-Medoids.&lt;/p&gt;

&lt;p&gt;I only found the pyclustering which lets me precompute a dissimilarity matrix, I am using Gower distance, instead of a inbuilt distance metric.&lt;/p&gt;

&lt;p&gt;This would be fine but there are no inbuilt metrics that I can use to evaluate these K-Medoids results. There is the silhouette score but I can&amp;#39;t find an example of how to use it with a precomputed distance instead of the euclidean distance, nor the docstrings help to find out how.&lt;/p&gt;

&lt;p&gt;Ideally what I wanted was a impletation that would give me the Inertia(within clusters sum of squares) and the silhouette score so I could evalute the number of clusters, instead of having to build my own.&lt;/p&gt;

&lt;p&gt;Any suggestions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hkrm5q,rpinto02,14,/r/datascience/comments/hkrm5q/kmedoids_implementation_with_python/,https://www.reddit.com/r/datascience/comments/hkrm5q/kmedoids_implementation_with_python/,1593812710.0
r/datascience,"They have an RND backend that deals with databases and infrastructure and then data scientists positions

Thing is, I have little expectations regarding pay or day to day or what I should bring to the table.

Currently I am a sysadmin/application developer.
I think I have a decent chance at the job, as I shadowed and talked to the manager.

Any ideas or thoughts? Not even sure I’d like it!

Thanks",t2_yqjj5,What can I expect in terms of work and pay from a jr. quantitative strategy position?,career,t3_hl3q9j,0.54,1,Career,1,1593899911.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;They have an RND backend that deals with databases and infrastructure and then data scientists positions&lt;/p&gt;

&lt;p&gt;Thing is, I have little expectations regarding pay or day to day or what I should bring to the table.&lt;/p&gt;

&lt;p&gt;Currently I am a sysadmin/application developer.
I think I have a decent chance at the job, as I shadowed and talked to the manager.&lt;/p&gt;

&lt;p&gt;Any ideas or thoughts? Not even sure I’d like it!&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hl3q9j,The_Rim_Greaper,8,/r/datascience/comments/hl3q9j/what_can_i_expect_in_terms_of_work_and_pay_from_a/,https://www.reddit.com/r/datascience/comments/hl3q9j/what_can_i_expect_in_terms_of_work_and_pay_from_a/,1593871111.0
r/datascience,"I've been researching different masters programs and all seem to have good perks and downfalls.

I'm more interested in the actual science behind data and using it to draw conclusions/predictions.  Im just concerned that if the masters program im currently considering, Texas University at Austin online MSDS, is a good choice overall for what I would like to do career wise. I have very little background in the data field but I do have a B.A. math degree and I'm thinking getting my masters would help me break into the industry. Any and all advice is appreciated.",t2_4u0e08zz,Is a MS in Data Science a good choice?,education,t3_hkt2wi,0.72,9,Education,9,1593846967.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been researching different masters programs and all seem to have good perks and downfalls.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m more interested in the actual science behind data and using it to draw conclusions/predictions.  Im just concerned that if the masters program im currently considering, Texas University at Austin online MSDS, is a good choice overall for what I would like to do career wise. I have very little background in the data field but I do have a B.A. math degree and I&amp;#39;m thinking getting my masters would help me break into the industry. Any and all advice is appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hkt2wi,AlephNull89,42,/r/datascience/comments/hkt2wi/is_a_ms_in_data_science_a_good_choice/,https://www.reddit.com/r/datascience/comments/hkt2wi/is_a_ms_in_data_science_a_good_choice/,1593818167.0
r/datascience,https://youtu.be/nlsd2LO-S50,t2_53nxdimv,I built a machine learning model and used it with encrypted data using homomorphic encryption. What’s your take on the future of data and privacy?,education,t3_hl4upl,0.25,0,Education,0,1593904306.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://youtu.be/nlsd2LO-S50""&gt;https://youtu.be/nlsd2LO-S50&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hl4upl,sks8100,2,/r/datascience/comments/hl4upl/i_built_a_machine_learning_model_and_used_it_with/,https://www.reddit.com/r/datascience/comments/hl4upl/i_built_a_machine_learning_model_and_used_it_with/,1593875506.0
r/datascience,"I am trying to find a standard test for machine learning knowledge. I have a course that I need to develop a basic test for on the following topics:

* Regression
* Classification (logistic only)
* Clustering and document retrieval (measures of similarity, KNN, and K-Means)
* Recommenders (including matrix factorization)
* Deep learning (basic network architecture and transfer learning)

Does anyone know of a good resource out there with a broad set of exam questions that target these topics?",t2_1y38h8jw,Standard test of ML knowledge,education,t3_hkllc3,0.82,25,Education,25,1593820773.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to find a standard test for machine learning knowledge. I have a course that I need to develop a basic test for on the following topics:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Regression&lt;/li&gt;
&lt;li&gt;Classification (logistic only)&lt;/li&gt;
&lt;li&gt;Clustering and document retrieval (measures of similarity, KNN, and K-Means)&lt;/li&gt;
&lt;li&gt;Recommenders (including matrix factorization)&lt;/li&gt;
&lt;li&gt;Deep learning (basic network architecture and transfer learning)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Does anyone know of a good resource out there with a broad set of exam questions that target these topics?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hkllc3,ratterstinkle,4,/r/datascience/comments/hkllc3/standard_test_of_ml_knowledge/,https://www.reddit.com/r/datascience/comments/hkllc3/standard_test_of_ml_knowledge/,1593791973.0
r/datascience,"How important is it for data scientists to have clean, modular, reusable code? Here’s my problem: while working on a project, I’ll start off in Jupyter notebooks, toying around with the data, doing some EDA, etc. Eventually I’ll pull out some of that code into functions in a Python file, and call those functions from the Jupyter. Neat.

The problem is, as I get more and more functions, I want to organize them more, make them more generalizable and consistent, etc. I’ll also get carried away with organizing files and source control, cleaning up my notes, and making documentation to explain what models/data/source files/results exist, what they mean, etc.

And then I realize I’ve been spending less and less time getting results, and more on this “overhead”. I struggle to balance the desire the rush ahead and get results with the compulsion to make the code “beautiful” and to have the project in the cleanest possible state. I’ve seen plenty of other projects with terrible organization, no documentation, and confusing, poorly formatted code. But if I’m not producing value, my neatness doesn’t matter.

All in all, I’m feeling pretty unproductive because of these habits. Any advice?",t2_4ghcp,"Too much code cleaning, not enough results",,t3_hkbjlj,0.98,225,,225,1593774592.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How important is it for data scientists to have clean, modular, reusable code? Here’s my problem: while working on a project, I’ll start off in Jupyter notebooks, toying around with the data, doing some EDA, etc. Eventually I’ll pull out some of that code into functions in a Python file, and call those functions from the Jupyter. Neat.&lt;/p&gt;

&lt;p&gt;The problem is, as I get more and more functions, I want to organize them more, make them more generalizable and consistent, etc. I’ll also get carried away with organizing files and source control, cleaning up my notes, and making documentation to explain what models/data/source files/results exist, what they mean, etc.&lt;/p&gt;

&lt;p&gt;And then I realize I’ve been spending less and less time getting results, and more on this “overhead”. I struggle to balance the desire the rush ahead and get results with the compulsion to make the code “beautiful” and to have the project in the cleanest possible state. I’ve seen plenty of other projects with terrible organization, no documentation, and confusing, poorly formatted code. But if I’m not producing value, my neatness doesn’t matter.&lt;/p&gt;

&lt;p&gt;All in all, I’m feeling pretty unproductive because of these habits. Any advice?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hkbjlj,syntaxspam,67,/r/datascience/comments/hkbjlj/too_much_code_cleaning_not_enough_results/,https://www.reddit.com/r/datascience/comments/hkbjlj/too_much_code_cleaning_not_enough_results/,1593745792.0
r/datascience,,t2_16fwkn26,Do data analyst/business analyst or consultants use deep learning,discussion,t3_hkzbdf,0.6,1,Discussion,1,1593876022.0,,hkzbdf,-S-I-D-,8,/r/datascience/comments/hkzbdf/do_data_analystbusiness_analyst_or_consultants/,https://www.reddit.com/r/datascience/comments/hkzbdf/do_data_analystbusiness_analyst_or_consultants/,1593847222.0
r/datascience,I do not understand. How are there so many self taught folks and how are you all landing jobs? I’m not against it but I do not see how it is possible. Every single job I encounter requires a minimum of a masters in a technical field. How are you folks bypassing this?,t2_2a6kv3r,How are there so many self taught data scientists on this sub when every data science job near me requires a masters or higher?,discussion,t3_hkdcw3,0.93,117,Discussion,117,1593782656.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I do not understand. How are there so many self taught folks and how are you all landing jobs? I’m not against it but I do not see how it is possible. Every single job I encounter requires a minimum of a masters in a technical field. How are you folks bypassing this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hkdcw3,alamar1,98,/r/datascience/comments/hkdcw3/how_are_there_so_many_self_taught_data_scientists/,https://www.reddit.com/r/datascience/comments/hkdcw3/how_are_there_so_many_self_taught_data_scientists/,1593753856.0
r/datascience,"Hello. I have this dataset and I would like to apply HDBSCAN.

For learning, I implemented HDBSCAN on a noisy sklearn blobs simulation and it looks great, but I noticed that the cluster assignment is different each time I fit the model, and there doesn't seem to be a \`random\_state\` parameter. I saw [a github issue](https://github.com/scikit-learn-contrib/hdbscan/issues/326) where this point was raised and it was suggested that setting `approx_min_span_tree=False` deals with the issue, but in my own testing this doesn't seem to be true. Is there a way to ensure reproducible results with this?

As a side note, I know it's questionable but what are some recommended evaluation metrics for HDBSCAN?

&amp;#x200B;

Thanks!",t2_tfb3c,HDBSCAN reproducibility?,discussion,t3_hkm2hc,0.67,2,Discussion,2,1593822329.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello. I have this dataset and I would like to apply HDBSCAN.&lt;/p&gt;

&lt;p&gt;For learning, I implemented HDBSCAN on a noisy sklearn blobs simulation and it looks great, but I noticed that the cluster assignment is different each time I fit the model, and there doesn&amp;#39;t seem to be a `random_state` parameter. I saw &lt;a href=""https://github.com/scikit-learn-contrib/hdbscan/issues/326""&gt;a github issue&lt;/a&gt; where this point was raised and it was suggested that setting &lt;code&gt;approx_min_span_tree=False&lt;/code&gt; deals with the issue, but in my own testing this doesn&amp;#39;t seem to be true. Is there a way to ensure reproducible results with this?&lt;/p&gt;

&lt;p&gt;As a side note, I know it&amp;#39;s questionable but what are some recommended evaluation metrics for HDBSCAN?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hkm2hc,fffrost,7,/r/datascience/comments/hkm2hc/hdbscan_reproducibility/,https://www.reddit.com/r/datascience/comments/hkm2hc/hdbscan_reproducibility/,1593793529.0
r/datascience,"Tried plotly but it looks like unless I use the ipywidgets library, I'm stuck with one dropdown. Looking for something that is aesthetically pleasing, interactive and embeddable. Any help would be appreciated, thank you",t2_tm22o,Python plotting library which allows for multiple dropdowns/widgets to filter data?,projects,t3_hklhyd,1.0,2,Projects,2,1593820460.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Tried plotly but it looks like unless I use the ipywidgets library, I&amp;#39;m stuck with one dropdown. Looking for something that is aesthetically pleasing, interactive and embeddable. Any help would be appreciated, thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hklhyd,andreaslordos,4,/r/datascience/comments/hklhyd/python_plotting_library_which_allows_for_multiple/,https://www.reddit.com/r/datascience/comments/hklhyd/python_plotting_library_which_allows_for_multiple/,1593791660.0
r/datascience,"I know it's common practice to apply satandardization to the data before running a clustering algorithm due to the distances that those algorithms need to calculate across dimensions.

However I have a set of data that looks like this, all but one columns are categorical (0,1 columns), and the remaining column is a float. Does it make sense only to standarize this column and keep the remaining as 0,1s? Since the remaings columns are all 0,1 the distances inbetween these dimensions wouldn't be distorted right?

Furthermore of 175 dimensions, 80 or so are 0 in three of the subsets I need to clusterize. What would be the implications of removing these 80 features, and clusterizing only with non all zero columns? At the end I would add to the clusters 0 values to the missing columns in order to be able to compare these clusters in the main dataset.

&amp;#x200B;

Before anyone asks what I need to do is, to clusterize 3 subsets to indeintify the ""main"" clients in each subset and then look for these ""main"" clients in the whole database to rank similar clients to these identified clients.",t2_719vr9ao,Standardization and Zero value columns in clustering algorithms,discussion,t3_hk14cc,0.93,55,Discussion,55,1593739096.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know it&amp;#39;s common practice to apply satandardization to the data before running a clustering algorithm due to the distances that those algorithms need to calculate across dimensions.&lt;/p&gt;

&lt;p&gt;However I have a set of data that looks like this, all but one columns are categorical (0,1 columns), and the remaining column is a float. Does it make sense only to standarize this column and keep the remaining as 0,1s? Since the remaings columns are all 0,1 the distances inbetween these dimensions wouldn&amp;#39;t be distorted right?&lt;/p&gt;

&lt;p&gt;Furthermore of 175 dimensions, 80 or so are 0 in three of the subsets I need to clusterize. What would be the implications of removing these 80 features, and clusterizing only with non all zero columns? At the end I would add to the clusters 0 values to the missing columns in order to be able to compare these clusters in the main dataset.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Before anyone asks what I need to do is, to clusterize 3 subsets to indeintify the &amp;quot;main&amp;quot; clients in each subset and then look for these &amp;quot;main&amp;quot; clients in the whole database to rank similar clients to these identified clients.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hk14cc,rpinto02,18,/r/datascience/comments/hk14cc/standardization_and_zero_value_columns_in/,https://www.reddit.com/r/datascience/comments/hk14cc/standardization_and_zero_value_columns_in/,1593710296.0
r/datascience,,t2_xihvg,"Datacamp suing Rstudio, Rstudio refusing to work with Datacamp over Datacamp 2017 sexual harassment",discussion,t3_hjnil8,0.98,412,Discussion,412,1593681269.0,,hjnil8,elways_love_child,156,/r/datascience/comments/hjnil8/datacamp_suing_rstudio_rstudio_refusing_to_work/,https://www.datacamp.com/community/blog/rstudio-pending-legal-matter,1593652469.0
r/datascience,"I started learning data science for two months, did a variety of projects and this week my friend was able to get me into a data science internship, and that's when I realized how much I don't actually know and how daunting it can be. Which is at the same time, fun to keep up with and learn on how to implement a process. Was I wrong to choose this internship this early into learning the subject or should I keep my motivation going with the work that's thrown at me? I hate disappointing people so I'm just hoping things go smoothly for me here",t2_10bohd,"Very new at data science, but luckily got into an internship on a startup company",career,t3_hklkgg,0.22,0,Career,0,1593820691.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I started learning data science for two months, did a variety of projects and this week my friend was able to get me into a data science internship, and that&amp;#39;s when I realized how much I don&amp;#39;t actually know and how daunting it can be. Which is at the same time, fun to keep up with and learn on how to implement a process. Was I wrong to choose this internship this early into learning the subject or should I keep my motivation going with the work that&amp;#39;s thrown at me? I hate disappointing people so I&amp;#39;m just hoping things go smoothly for me here&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hklkgg,Natsucr7,13,/r/datascience/comments/hklkgg/very_new_at_data_science_but_luckily_got_into_an/,https://www.reddit.com/r/datascience/comments/hklkgg/very_new_at_data_science_but_luckily_got_into_an/,1593791891.0
r/datascience,"I'm not as knowledgeable as many of you; my issue is I don't have the appropriate vocabulary to even figure out what to google to find my answers. So that said, here is my problem thank you in advance.

My company handles customer machines, and I handle the data. Each machine has a Model they start off simple, 16D, 16C, 17D and so on. But then customers get add ons, and so while the machine is still a 16D the sales rep or customer will call it a 16D HD, for Heavy Duty.

And then it gets more complex from there. ie: 1234T, 1234R, D6, D6T, D6-20

In the data there ""Model"" column is just whatever people type in. There it would be ideal to have a ""ParentModel"" (D6) ""ChildModel"" (D6D) ""Model"" (D6D-20) columns but I don't. I started by converting all the numbers and letters into placeholders to get patterns but that didn't work out really.

So my desire is to extract from this garbage pile these common denominators into the parent group and child group. I think all i will need is two tiers.

If anyone has suggestions on reading or remember something from stack that'd be great. I'd appreciate any help here.

edit: i included a sample set in the comments and here is a desired output with the source data on the left.

I realize that I forgot to include an ideal output

Model|ParentModel|ChildModel
---|---|----
2500 | 2500 | 2500
2500-4 | 2500 | 2500
2500B | 2500 | 2500B
2500BCM | 2500 | 2500B
2503PD | 2503 | 2503P
25040 | 2504 | 2504
250G | 250 | 230G
250H | 250 | 250H
250H-00 | 250 | 250H
250H BR | 250 | 250H
250K | 250 | 250K
250LVR | 250 | 250L
250M | 250 | 250M
250M AWD | 250 | 250M
250M BR | 250 | 250M",t2_d1iad,[R] Extracting / matching branching text groups,projects,t3_hk63oj,0.72,3,Projects,3,1593754877.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m not as knowledgeable as many of you; my issue is I don&amp;#39;t have the appropriate vocabulary to even figure out what to google to find my answers. So that said, here is my problem thank you in advance.&lt;/p&gt;

&lt;p&gt;My company handles customer machines, and I handle the data. Each machine has a Model they start off simple, 16D, 16C, 17D and so on. But then customers get add ons, and so while the machine is still a 16D the sales rep or customer will call it a 16D HD, for Heavy Duty.&lt;/p&gt;

&lt;p&gt;And then it gets more complex from there. ie: 1234T, 1234R, D6, D6T, D6-20&lt;/p&gt;

&lt;p&gt;In the data there &amp;quot;Model&amp;quot; column is just whatever people type in. There it would be ideal to have a &amp;quot;ParentModel&amp;quot; (D6) &amp;quot;ChildModel&amp;quot; (D6D) &amp;quot;Model&amp;quot; (D6D-20) columns but I don&amp;#39;t. I started by converting all the numbers and letters into placeholders to get patterns but that didn&amp;#39;t work out really.&lt;/p&gt;

&lt;p&gt;So my desire is to extract from this garbage pile these common denominators into the parent group and child group. I think all i will need is two tiers.&lt;/p&gt;

&lt;p&gt;If anyone has suggestions on reading or remember something from stack that&amp;#39;d be great. I&amp;#39;d appreciate any help here.&lt;/p&gt;

&lt;p&gt;edit: i included a sample set in the comments and here is a desired output with the source data on the left.&lt;/p&gt;

&lt;p&gt;I realize that I forgot to include an ideal output&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;ParentModel&lt;/th&gt;
&lt;th&gt;ChildModel&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2500&lt;/td&gt;
&lt;td&gt;2500&lt;/td&gt;
&lt;td&gt;2500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2500-4&lt;/td&gt;
&lt;td&gt;2500&lt;/td&gt;
&lt;td&gt;2500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2500B&lt;/td&gt;
&lt;td&gt;2500&lt;/td&gt;
&lt;td&gt;2500B&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2500BCM&lt;/td&gt;
&lt;td&gt;2500&lt;/td&gt;
&lt;td&gt;2500B&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2503PD&lt;/td&gt;
&lt;td&gt;2503&lt;/td&gt;
&lt;td&gt;2503P&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25040&lt;/td&gt;
&lt;td&gt;2504&lt;/td&gt;
&lt;td&gt;2504&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;250G&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;td&gt;230G&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;250H&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;td&gt;250H&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;250H-00&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;td&gt;250H&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;250H BR&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;td&gt;250H&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;250K&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;td&gt;250K&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;250LVR&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;td&gt;250L&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;250M&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;td&gt;250M&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;250M AWD&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;td&gt;250M&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;250M BR&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;td&gt;250M&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hk63oj,zykezero,10,/r/datascience/comments/hk63oj/r_extracting_matching_branching_text_groups/,https://www.reddit.com/r/datascience/comments/hk63oj/r_extracting_matching_branching_text_groups/,1593726077.0
r/datascience,"I've been on the typical data science stack rollercoaster for a few years now. First, there was nothing. Then we got \`nbdime\` and \`nbstripout\`. Google Collab came and went in a heartbeat. Now folks are trying to essentially turn JupyterLab into a fully-functional IDE. Well, for anyone who needs to be able to work on Python apps/libraries and uses notebooks for visualization and prototyping, I think we finally have a stable answer: jupytext ([https://github.com/mwouts/jupytext](https://github.com/mwouts/jupytext)).

Three advantages:

* Notebooks are now python scripts which have human-readable git diffs without special extensions or UIs
* \`percent\` format scripts can be auto-formatted with things like \`black\`
* \`percent\` scripts can utilize existing IDE tools (eg Pycharm debugging)

&amp;#x200B;

For more info, here's an article written by the Jupytext creator: [https://towardsdatascience.com/jupyter-notebooks-in-the-ide-visual-studio-code-versus-pycharm-5e72218eb3e8](https://towardsdatascience.com/jupyter-notebooks-in-the-ide-visual-studio-code-versus-pycharm-5e72218eb3e8).",t2_5h45p,Stop trying to make Jupyter an IDE and use Jupytext,tooling,t3_hjm55r,0.88,25,Tooling,25,1593676287.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been on the typical data science stack rollercoaster for a few years now. First, there was nothing. Then we got `nbdime` and `nbstripout`. Google Collab came and went in a heartbeat. Now folks are trying to essentially turn JupyterLab into a fully-functional IDE. Well, for anyone who needs to be able to work on Python apps/libraries and uses notebooks for visualization and prototyping, I think we finally have a stable answer: jupytext (&lt;a href=""https://github.com/mwouts/jupytext""&gt;https://github.com/mwouts/jupytext&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Three advantages:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Notebooks are now python scripts which have human-readable git diffs without special extensions or UIs&lt;/li&gt;
&lt;li&gt;`percent` format scripts can be auto-formatted with things like `black`&lt;/li&gt;
&lt;li&gt;`percent` scripts can utilize existing IDE tools (eg Pycharm debugging)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;For more info, here&amp;#39;s an article written by the Jupytext creator: &lt;a href=""https://towardsdatascience.com/jupyter-notebooks-in-the-ide-visual-studio-code-versus-pycharm-5e72218eb3e8""&gt;https://towardsdatascience.com/jupyter-notebooks-in-the-ide-visual-studio-code-versus-pycharm-5e72218eb3e8&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hjm55r,WolfFang15,22,/r/datascience/comments/hjm55r/stop_trying_to_make_jupyter_an_ide_and_use/,https://www.reddit.com/r/datascience/comments/hjm55r/stop_trying_to_make_jupyter_an_ide_and_use/,1593647487.0
r/datascience,"I have been working as a data scientist for the last 2.5 years.  While the job itself has been challenging and rewarding, I'm not sure if this is the branch of analytics that I want to be in.  Having a business admin undergrad and a business intelligence and analytics masters, my background isn't quantitative.  I have therefore been finding myself frustrated and struggling at the absence of some foundational math skills that my shitty k-12 education didn't help me get pat down.  I've been going down the route of trying to address this through mocc courses, khan academy and anything I can get my hands on.  I know that in due time (years?) I might have such a grasp on the underlying math in data science to construct algorithms from scratch in python and speak on every component of every line.  I just don't know if that's the path I want to go down.


My background to this day has been more technical, so I have been looking toward data engineer positions.  I have been getting discouraged by that process, as it seems that I am falling short during the technical interviews.  During one 4 hour analyst interview, I was asked to connect to an API, download the data and build visualizations around the data.  The night before I found some good articles on web analytics vizzes using python, and used those as a reference to do the project (all permitted).  The test was live, and the hiring manager even stated that I could copy and paste code.  The feedback I got the next day was that I copied pasted too much, and they were worried I wouldn't be able to come up with a solution on my own.  My thought process going into it was to be able to apply these concepts I researched to the company's data.

One of The latest positions I applied for was a data engineering position where the recruiter contacted me.  I went through a couple of rounds of interviews then a technical exam.  Again, connecting to an API, pulling data down, loading it into a sqlite dB then querying for a certain result.  I did everything I was asked of and got the following rejection:

""blahblahblah and I both really enjoyed meeting you and we see you being a great fit on this team in a BI/analyst capacity. For this particular role, we have some specific needs technically and our team reviewing your project unfortunately did not feel you reached their expectations. We're fortunate to have had a lot of interest in this and all of our current openings which has led to some tough decisions""

So in both of these cases I got very little direction of what I can improve on.  I'm burned out and very discouraged by my career path at the moment.  I feel like I lucked into my current role but my deficiencies are showing up when I try to go for a new role.


Tldr; Is there any advice for someone who is no longer in the beginning stages of data science but can't seem to figure out the right analytics path to go on?",t2_71tu1,Is a career coach worth it?,career,t3_hjy0u0,0.56,1,Career,1,1593728951.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been working as a data scientist for the last 2.5 years.  While the job itself has been challenging and rewarding, I&amp;#39;m not sure if this is the branch of analytics that I want to be in.  Having a business admin undergrad and a business intelligence and analytics masters, my background isn&amp;#39;t quantitative.  I have therefore been finding myself frustrated and struggling at the absence of some foundational math skills that my shitty k-12 education didn&amp;#39;t help me get pat down.  I&amp;#39;ve been going down the route of trying to address this through mocc courses, khan academy and anything I can get my hands on.  I know that in due time (years?) I might have such a grasp on the underlying math in data science to construct algorithms from scratch in python and speak on every component of every line.  I just don&amp;#39;t know if that&amp;#39;s the path I want to go down.&lt;/p&gt;

&lt;p&gt;My background to this day has been more technical, so I have been looking toward data engineer positions.  I have been getting discouraged by that process, as it seems that I am falling short during the technical interviews.  During one 4 hour analyst interview, I was asked to connect to an API, download the data and build visualizations around the data.  The night before I found some good articles on web analytics vizzes using python, and used those as a reference to do the project (all permitted).  The test was live, and the hiring manager even stated that I could copy and paste code.  The feedback I got the next day was that I copied pasted too much, and they were worried I wouldn&amp;#39;t be able to come up with a solution on my own.  My thought process going into it was to be able to apply these concepts I researched to the company&amp;#39;s data.&lt;/p&gt;

&lt;p&gt;One of The latest positions I applied for was a data engineering position where the recruiter contacted me.  I went through a couple of rounds of interviews then a technical exam.  Again, connecting to an API, pulling data down, loading it into a sqlite dB then querying for a certain result.  I did everything I was asked of and got the following rejection:&lt;/p&gt;

&lt;p&gt;&amp;quot;blahblahblah and I both really enjoyed meeting you and we see you being a great fit on this team in a BI/analyst capacity. For this particular role, we have some specific needs technically and our team reviewing your project unfortunately did not feel you reached their expectations. We&amp;#39;re fortunate to have had a lot of interest in this and all of our current openings which has led to some tough decisions&amp;quot;&lt;/p&gt;

&lt;p&gt;So in both of these cases I got very little direction of what I can improve on.  I&amp;#39;m burned out and very discouraged by my career path at the moment.  I feel like I lucked into my current role but my deficiencies are showing up when I try to go for a new role.&lt;/p&gt;

&lt;p&gt;Tldr; Is there any advice for someone who is no longer in the beginning stages of data science but can&amp;#39;t seem to figure out the right analytics path to go on?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hjy0u0,Number1toolfool,6,/r/datascience/comments/hjy0u0/is_a_career_coach_worth_it/,https://www.reddit.com/r/datascience/comments/hjy0u0/is_a_career_coach_worth_it/,1593700151.0
r/datascience,"Lets say I work with consumer electronics. People use them, they break in X days, they return them for a refund. We can measure qualities of the device which get sent to our database, for example average temperature every 24 hours.

My goal would be to add quantitative insights around typical avg temperature for a returned device versus the background (not returned) population. The idea is that a returned device ""is hotter"" than a non-returned device.

So, I'm taking a bunch of random devices unrelated to one another which are returned, along with a piece of information in time, and comparing that against a larger pool of random variables to make a conclusion.

Is there a name for this kind of analysis? I'm trying to dive deeper into DS, but the domain of problem types is so large I'm having problems focusing in on a niche.",t2_8pgqi,What category is my data science problem?,education,t3_hk1nbj,0.44,0,Education,0,1593740748.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Lets say I work with consumer electronics. People use them, they break in X days, they return them for a refund. We can measure qualities of the device which get sent to our database, for example average temperature every 24 hours.&lt;/p&gt;

&lt;p&gt;My goal would be to add quantitative insights around typical avg temperature for a returned device versus the background (not returned) population. The idea is that a returned device &amp;quot;is hotter&amp;quot; than a non-returned device.&lt;/p&gt;

&lt;p&gt;So, I&amp;#39;m taking a bunch of random devices unrelated to one another which are returned, along with a piece of information in time, and comparing that against a larger pool of random variables to make a conclusion.&lt;/p&gt;

&lt;p&gt;Is there a name for this kind of analysis? I&amp;#39;m trying to dive deeper into DS, but the domain of problem types is so large I&amp;#39;m having problems focusing in on a niche.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hk1nbj,delabay,7,/r/datascience/comments/hk1nbj/what_category_is_my_data_science_problem/,https://www.reddit.com/r/datascience/comments/hk1nbj/what_category_is_my_data_science_problem/,1593711948.0
r/datascience,"Hello

I am a final year Master's student pursuing Computer Science, specialization AI. I am currently working on my dissertation which I thought would be Penalty Classification based on Player FIFA attributes. So what I had was a record of penalties scored in Europe Top5 football leagues, the striker attributes (FIFA and WhoScored/Opta), the GK attributes (FIFA and WhoScored/Opta) and the classifier. So I intended to run basic ML algorithms to work towards a Deep model and classify whether a penalty would go in or not given such attributes and Gk's attributes. 

But on the contrary, my professor has disregarded the project two months into it and has asked me to give a formal new hypothesis/problem statement within two days. I am absolutely confused as to how to move forward with it as I was not expecting this to happen. I have FIFA attributes data from 2007-2020, Opta Data, Events- play by play data, and result odds. I need to formulate a new statement within a couple of days. Can you guys please help with this?

Thanks",t2_1hklp3qg,Help regarding Dissertation,projects,t3_hk0ff3,0.33,0,Projects,0,1593736898.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello&lt;/p&gt;

&lt;p&gt;I am a final year Master&amp;#39;s student pursuing Computer Science, specialization AI. I am currently working on my dissertation which I thought would be Penalty Classification based on Player FIFA attributes. So what I had was a record of penalties scored in Europe Top5 football leagues, the striker attributes (FIFA and WhoScored/Opta), the GK attributes (FIFA and WhoScored/Opta) and the classifier. So I intended to run basic ML algorithms to work towards a Deep model and classify whether a penalty would go in or not given such attributes and Gk&amp;#39;s attributes. &lt;/p&gt;

&lt;p&gt;But on the contrary, my professor has disregarded the project two months into it and has asked me to give a formal new hypothesis/problem statement within two days. I am absolutely confused as to how to move forward with it as I was not expecting this to happen. I have FIFA attributes data from 2007-2020, Opta Data, Events- play by play data, and result odds. I need to formulate a new statement within a couple of days. Can you guys please help with this?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hk0ff3,takemeto95,5,/r/datascience/comments/hk0ff3/help_regarding_dissertation/,https://www.reddit.com/r/datascience/comments/hk0ff3/help_regarding_dissertation/,1593708098.0
r/datascience," Does anyone have any good tips or resources about DS project management? I would like to become more formal in my requirements gathering and scoping phase, but it is a different beast for modeling projects. I want to get better at making sure my modeling project has a clear use case established before I develop the model. And I want to ensure that other departments are on board.

I would love a book that is catered specifically towards Data Science project management/ scoping/ requirements gathering/etc. Does anyone know of anything like this?",t2_kyu8a,Any resources for the project management side of Data Science?,education,t3_hjhdbx,0.93,20,Education,20,1593661028.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone have any good tips or resources about DS project management? I would like to become more formal in my requirements gathering and scoping phase, but it is a different beast for modeling projects. I want to get better at making sure my modeling project has a clear use case established before I develop the model. And I want to ensure that other departments are on board.&lt;/p&gt;

&lt;p&gt;I would love a book that is catered specifically towards Data Science project management/ scoping/ requirements gathering/etc. Does anyone know of anything like this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hjhdbx,azzipog,7,/r/datascience/comments/hjhdbx/any_resources_for_the_project_management_side_of/,https://www.reddit.com/r/datascience/comments/hjhdbx/any_resources_for_the_project_management_side_of/,1593632228.0
r/datascience,"Hi, I am a graduate in mechanical engineering, and the past month I have been researching data science. A lot of web scraping, smoothing data and organizing it for proper analysis, testing and tweaking predictions to match models, etc. That all makes sense. However, I really want to see an example of an actual SPECIFIC problem that a data scientist does. For example, at each of your respective jobs, what do you usually do? Can you be more specific? 

  
For example, I graduated with a degree in mechanical engineering. If I go into design (there are a lot of subfields in ME) I will spend my day making sure the requirements for the design are met (measuring specifications, collecting and verifying CTC's, and then drawing something on scratch paper that makes sense. THen I will get the design approved. Day 2 I might spend in a 3D design program creating it. This involves using sketch tools, molding tools, and a deep understanding of the rendering software to do properly (you could use solidworks, catia, revit, etc)

I know there are a lot of sub-fields within the field of Data Science, but I would love to hear specifics about your job and what you like about it!",t2_qjuyv,What does a day in the life of a DS look like?,discussion,t3_hjgxvy,0.88,12,Discussion,12,1593659743.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I am a graduate in mechanical engineering, and the past month I have been researching data science. A lot of web scraping, smoothing data and organizing it for proper analysis, testing and tweaking predictions to match models, etc. That all makes sense. However, I really want to see an example of an actual SPECIFIC problem that a data scientist does. For example, at each of your respective jobs, what do you usually do? Can you be more specific? &lt;/p&gt;

&lt;p&gt;For example, I graduated with a degree in mechanical engineering. If I go into design (there are a lot of subfields in ME) I will spend my day making sure the requirements for the design are met (measuring specifications, collecting and verifying CTC&amp;#39;s, and then drawing something on scratch paper that makes sense. THen I will get the design approved. Day 2 I might spend in a 3D design program creating it. This involves using sketch tools, molding tools, and a deep understanding of the rendering software to do properly (you could use solidworks, catia, revit, etc)&lt;/p&gt;

&lt;p&gt;I know there are a lot of sub-fields within the field of Data Science, but I would love to hear specifics about your job and what you like about it!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hjgxvy,jcruise322,15,/r/datascience/comments/hjgxvy/what_does_a_day_in_the_life_of_a_ds_look_like/,https://www.reddit.com/r/datascience/comments/hjgxvy/what_does_a_day_in_the_life_of_a_ds_look_like/,1593630943.0
r/datascience,"Imagine you have a magical person who has all of the major skills and equivalent experience in all roles. If they got offers for all role types, this is roughly the order they'd be, in terms of total compensation (base salary + bonus + stock), based on my experience and network.

I think you should expect the ranking to change slightly depending on city-specific market. No very-niche skills included.

Special Skills refers to skills needed to land the job that have extra emphasis among all data science skills.

Supply/Demand is which way the market is for job seekers vs hiring. Seekers+++ means there are a lot more qualified job seekers than jobs. Jobs+++ means there are a lot more jobs than qualified job seekers.

Did I miss any roles? Let me know.

Think some order should be swapped? Explain why.

|Role|Description|Special Skills|Supply/Demand|
|:-|:-|:-|:-|
|Quantitative Researcher|Analyzes all kinds of data to try to identify strategies for trading financial products at, e.g., hedge funds, prop shops, investment banks, etc.|C++, logic puzzle solving, degree from top school|Seekers++|
|Machine learning Product builder|Builds products that heavily rely on algorithmic decision making.|Ability to translate business goals into algorithms, software engineering|Jobs+++|
|Machine learning infrastructure|Builds infrastructure to specifically support machine learning workflows (model training, deployment, monitoring, etc.)|Software engineering, some machine learning|Jobs+|
|Machine learning researchers|Close to pure research, though directions might be loosely related to business needed|PhD, top conference publications|Seekers+++|
|Data Engineers|Build and maintain infrastructure for data processing pipelines|Software engineering, ""big data""|Jobs++|
|Experimentation Infrastructure engineers|Build and maintain experimentation infrastructure|Statistics, software engineering|Jobs+|
|Product Experimentation|Design experiments to test product direction and do analysis to identify product opportunities|Statistics, SQL|Seekers+|
|Data analyst|Perform measurements and some predictive analysis|SQL, PowerBI, Tableau|Seekers+++|",t2_45m0b,My Ranking of Data Science Roles by Lucrativeness,discussion,t3_hk22ea,0.35,0,Discussion,0,1593742057.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Imagine you have a magical person who has all of the major skills and equivalent experience in all roles. If they got offers for all role types, this is roughly the order they&amp;#39;d be, in terms of total compensation (base salary + bonus + stock), based on my experience and network.&lt;/p&gt;

&lt;p&gt;I think you should expect the ranking to change slightly depending on city-specific market. No very-niche skills included.&lt;/p&gt;

&lt;p&gt;Special Skills refers to skills needed to land the job that have extra emphasis among all data science skills.&lt;/p&gt;

&lt;p&gt;Supply/Demand is which way the market is for job seekers vs hiring. Seekers+++ means there are a lot more qualified job seekers than jobs. Jobs+++ means there are a lot more jobs than qualified job seekers.&lt;/p&gt;

&lt;p&gt;Did I miss any roles? Let me know.&lt;/p&gt;

&lt;p&gt;Think some order should be swapped? Explain why.&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=""left""&gt;Role&lt;/th&gt;
&lt;th align=""left""&gt;Description&lt;/th&gt;
&lt;th align=""left""&gt;Special Skills&lt;/th&gt;
&lt;th align=""left""&gt;Supply/Demand&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Quantitative Researcher&lt;/td&gt;
&lt;td align=""left""&gt;Analyzes all kinds of data to try to identify strategies for trading financial products at, e.g., hedge funds, prop shops, investment banks, etc.&lt;/td&gt;
&lt;td align=""left""&gt;C++, logic puzzle solving, degree from top school&lt;/td&gt;
&lt;td align=""left""&gt;Seekers++&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Machine learning Product builder&lt;/td&gt;
&lt;td align=""left""&gt;Builds products that heavily rely on algorithmic decision making.&lt;/td&gt;
&lt;td align=""left""&gt;Ability to translate business goals into algorithms, software engineering&lt;/td&gt;
&lt;td align=""left""&gt;Jobs+++&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Machine learning infrastructure&lt;/td&gt;
&lt;td align=""left""&gt;Builds infrastructure to specifically support machine learning workflows (model training, deployment, monitoring, etc.)&lt;/td&gt;
&lt;td align=""left""&gt;Software engineering, some machine learning&lt;/td&gt;
&lt;td align=""left""&gt;Jobs+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Machine learning researchers&lt;/td&gt;
&lt;td align=""left""&gt;Close to pure research, though directions might be loosely related to business needed&lt;/td&gt;
&lt;td align=""left""&gt;PhD, top conference publications&lt;/td&gt;
&lt;td align=""left""&gt;Seekers+++&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Data Engineers&lt;/td&gt;
&lt;td align=""left""&gt;Build and maintain infrastructure for data processing pipelines&lt;/td&gt;
&lt;td align=""left""&gt;Software engineering, &amp;quot;big data&amp;quot;&lt;/td&gt;
&lt;td align=""left""&gt;Jobs++&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Experimentation Infrastructure engineers&lt;/td&gt;
&lt;td align=""left""&gt;Build and maintain experimentation infrastructure&lt;/td&gt;
&lt;td align=""left""&gt;Statistics, software engineering&lt;/td&gt;
&lt;td align=""left""&gt;Jobs+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Product Experimentation&lt;/td&gt;
&lt;td align=""left""&gt;Design experiments to test product direction and do analysis to identify product opportunities&lt;/td&gt;
&lt;td align=""left""&gt;Statistics, SQL&lt;/td&gt;
&lt;td align=""left""&gt;Seekers+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Data analyst&lt;/td&gt;
&lt;td align=""left""&gt;Perform measurements and some predictive analysis&lt;/td&gt;
&lt;td align=""left""&gt;SQL, PowerBI, Tableau&lt;/td&gt;
&lt;td align=""left""&gt;Seekers+++&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hk22ea,mhwalker,30,/r/datascience/comments/hk22ea/my_ranking_of_data_science_roles_by_lucrativeness/,https://www.reddit.com/r/datascience/comments/hk22ea/my_ranking_of_data_science_roles_by_lucrativeness/,1593713257.0
r/datascience,What are some of your tips and tricks to presenting a predictive model to a cSuite . What would you include in an executive overview of a model?,t2_he02w,Tips for presenting predictive models to cSuite,career,t3_hjpqeo,1.0,2,Career,2,1593690334.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What are some of your tips and tricks to presenting a predictive model to a cSuite . What would you include in an executive overview of a model?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hjpqeo,Vervain7,5,/r/datascience/comments/hjpqeo/tips_for_presenting_predictive_models_to_csuite/,https://www.reddit.com/r/datascience/comments/hjpqeo/tips_for_presenting_predictive_models_to_csuite/,1593661534.0
r/datascience,"I participated in a Kaggle competion that just concluded in which the goal was to produce accurate point forecasts for over 30,000 Walmart products. My solution put me in the top 28%. I used the ""bottom-level"" approach, which is to fit a model to each time series individually. This resulted in 30,000+ supervised Random Forest models. I parallelized the entire pipeline so the runtime was under 2 hours.

What are the alternatives to modeling each time series independently? I'm afraid I didn't capture the relationships between time series.  I considered merging all products into a single dataframe but that seemed impractical because the result would have been 55M rows by 190 columns. It's not clear to me what approaches the top performers used.",t2_1q6oq5dl,Strategies for accurate hierarchical forecasting,discussion,t3_hjgj6f,1.0,5,Discussion,5,1593658555.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I participated in a Kaggle competion that just concluded in which the goal was to produce accurate point forecasts for over 30,000 Walmart products. My solution put me in the top 28%. I used the &amp;quot;bottom-level&amp;quot; approach, which is to fit a model to each time series individually. This resulted in 30,000+ supervised Random Forest models. I parallelized the entire pipeline so the runtime was under 2 hours.&lt;/p&gt;

&lt;p&gt;What are the alternatives to modeling each time series independently? I&amp;#39;m afraid I didn&amp;#39;t capture the relationships between time series.  I considered merging all products into a single dataframe but that seemed impractical because the result would have been 55M rows by 190 columns. It&amp;#39;s not clear to me what approaches the top performers used.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hjgj6f,dmorris87,10,/r/datascience/comments/hjgj6f/strategies_for_accurate_hierarchical_forecasting/,https://www.reddit.com/r/datascience/comments/hjgj6f/strategies_for_accurate_hierarchical_forecasting/,1593629755.0
r/datascience,"Hello everyone,

I have been browsing this and other related subs (r/cscareerquestionsEU, r/datascience, etc) for a long time now looking for advice on my journey to find a full-time job and our field in general. I graduated from my Master's program (major in ML, from a top tier university in Germany) this year in March and have been looking for full-time positions in the area for about 6 months now. Today I had a Zoom interview with a company (eCommerce) I had been in touch with for the past couple of weeks and about an hour ago, they called me saying they were really impressed and the job is basically mine if I want it. I am absolutely elated.

To give an idea about my job search process if it gives anyone a perspective being in a similar position, I applied for a total of 222 positions in the areas of Data Science, ML Engineering, Data Engineering, and a handful of Software Development positions as well (CV was same for every application and cover letter was modified a little bit depending on the company - in most cases, it was also the same. Perhaps that explains so many straight-up rejections).

**Ghosted:** 118.

**Outright rejections**: 68.

**Rejections after the technical stage**: 14.

**Still in the process** (applied less than 10 days ago and haven't heard): 22.

**Offers**: 2 (the other one is ML Engineer).

&amp;#x200B;

I feel I am a little above average when it comes to programming but I do have a theoretical understanding of ML algorithms (master's helped), so that helped in some interviews. Regarding the choice between the offers, I feel I am gonna go with the Data Engineering one since there is a lot of room to learn new frameworks which I did not experience in academia (PySpark, Airflow, etc.), there is room to turn into a Data Scientist as the project continues and because the location is excellent.

There were a few days where I was really depressed about my rejections (especially when I got one or two emails in the morning) but I made myself resilient by thinking that the rejections don't matter much (especially the ones given without any interview) and kept on learning and applying. If you are in a similar position, keep on going. Things will turn for the better. :)

&amp;#x200B;

EDIT: Just wanted to add a couple of things since this post is getting a bit of attention. I had a grade of 1.7/5 (in Europe/Germany, 1 is the best you can have and 4 is the worst; anything lower is failing) in my Master's. I had one and a half years of part-time working experience and I was a Teaching Assistant for two years for an ML/DL course in my program.",t2_z6v7c,Landed my first full time job today - Data Engineering,,t3_hipozj,0.98,691,Job Search,691,1593560325.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I have been browsing this and other related subs (&lt;a href=""/r/cscareerquestionsEU""&gt;r/cscareerquestionsEU&lt;/a&gt;, &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt;, etc) for a long time now looking for advice on my journey to find a full-time job and our field in general. I graduated from my Master&amp;#39;s program (major in ML, from a top tier university in Germany) this year in March and have been looking for full-time positions in the area for about 6 months now. Today I had a Zoom interview with a company (eCommerce) I had been in touch with for the past couple of weeks and about an hour ago, they called me saying they were really impressed and the job is basically mine if I want it. I am absolutely elated.&lt;/p&gt;

&lt;p&gt;To give an idea about my job search process if it gives anyone a perspective being in a similar position, I applied for a total of 222 positions in the areas of Data Science, ML Engineering, Data Engineering, and a handful of Software Development positions as well (CV was same for every application and cover letter was modified a little bit depending on the company - in most cases, it was also the same. Perhaps that explains so many straight-up rejections).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ghosted:&lt;/strong&gt; 118.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Outright rejections&lt;/strong&gt;: 68.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rejections after the technical stage&lt;/strong&gt;: 14.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Still in the process&lt;/strong&gt; (applied less than 10 days ago and haven&amp;#39;t heard): 22.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Offers&lt;/strong&gt;: 2 (the other one is ML Engineer).&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I feel I am a little above average when it comes to programming but I do have a theoretical understanding of ML algorithms (master&amp;#39;s helped), so that helped in some interviews. Regarding the choice between the offers, I feel I am gonna go with the Data Engineering one since there is a lot of room to learn new frameworks which I did not experience in academia (PySpark, Airflow, etc.), there is room to turn into a Data Scientist as the project continues and because the location is excellent.&lt;/p&gt;

&lt;p&gt;There were a few days where I was really depressed about my rejections (especially when I got one or two emails in the morning) but I made myself resilient by thinking that the rejections don&amp;#39;t matter much (especially the ones given without any interview) and kept on learning and applying. If you are in a similar position, keep on going. Things will turn for the better. :)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;EDIT: Just wanted to add a couple of things since this post is getting a bit of attention. I had a grade of 1.7/5 (in Europe/Germany, 1 is the best you can have and 4 is the worst; anything lower is failing) in my Master&amp;#39;s. I had one and a half years of part-time working experience and I was a Teaching Assistant for two years for an ML/DL course in my program.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hipozj,TheStampTramp,192,/r/datascience/comments/hipozj/landed_my_first_full_time_job_today_data/,https://www.reddit.com/r/datascience/comments/hipozj/landed_my_first_full_time_job_today_data/,1593531525.0
r/datascience,"Hello, 

&amp;#x200B;

I've heard and read online that data scientists and machine learning engineers are in high demand. With that being said, how is the state of said demand during this pandemic?",t2_2ich5u4y,Question about the state of the job market during pandemic,discussion,t3_hjmu8x,0.43,0,Discussion,0,1593678796.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve heard and read online that data scientists and machine learning engineers are in high demand. With that being said, how is the state of said demand during this pandemic?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hjmu8x,Stutoucan12,1,/r/datascience/comments/hjmu8x/question_about_the_state_of_the_job_market_during/,https://www.reddit.com/r/datascience/comments/hjmu8x/question_about_the_state_of_the_job_market_during/,1593649996.0
r/datascience,"Hello everyone,

I’m very interested in data science, and plan to eventually apply for a data science masters. I wanted to know what are the typical/common programming languages a DS deals with?

I’ve been teaching myself python, and looking it up online I know for sure python and R are huge tools for DS. Others that came up were SQL, and it was hit or miss for C#/C++. Also would your recommend learning tools like tableau, and VBA for excel?",t2_29furaef,Languages a data scientist deals with daily?,education,t3_hjokfq,0.29,0,Education,0,1593685401.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I’m very interested in data science, and plan to eventually apply for a data science masters. I wanted to know what are the typical/common programming languages a DS deals with?&lt;/p&gt;

&lt;p&gt;I’ve been teaching myself python, and looking it up online I know for sure python and R are huge tools for DS. Others that came up were SQL, and it was hit or miss for C#/C++. Also would your recommend learning tools like tableau, and VBA for excel?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hjokfq,Chowder1054,17,/r/datascience/comments/hjokfq/languages_a_data_scientist_deals_with_daily/,https://www.reddit.com/r/datascience/comments/hjokfq/languages_a_data_scientist_deals_with_daily/,1593656601.0
r/datascience,"Hello! I've downloaded Python from [python.org](https://python.org), and when I launch it, it just looks like the Windows Command Prompt. I was wondering what environment is good for a beginner looking to get started with some simple projects to learn data science. Thanks!",t2_xx7p674,Development Environment for Python,tooling,t3_hjndw8,0.38,0,Tooling,0,1593680786.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello! I&amp;#39;ve downloaded Python from &lt;a href=""https://python.org""&gt;python.org&lt;/a&gt;, and when I launch it, it just looks like the Windows Command Prompt. I was wondering what environment is good for a beginner looking to get started with some simple projects to learn data science. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hjndw8,badmanveach,9,/r/datascience/comments/hjndw8/development_environment_for_python/,https://www.reddit.com/r/datascience/comments/hjndw8/development_environment_for_python/,1593651986.0
r/datascience,"I’m compiling a dataset from the past ~15 years but some of the features were only recorded in the most recent 6 years. 

What’s the process regarding handling a dataset like this?

Do I use the dataset and train my model without these features (use 15 years worth of data)?

Do I include these features and only look at the most recent 6 years? 

Or is there something I can do to produce some sort of hybrid between the two?

It seems a waste to throw away these features, but then it’s also a waste throwing away previous data, is there something I can do about this?",t2_14h1nx,Dataset where some features were only recorded in recent years?,discussion,t3_hj9kg7,0.6,1,Discussion,1,1593636654.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m compiling a dataset from the past ~15 years but some of the features were only recorded in the most recent 6 years. &lt;/p&gt;

&lt;p&gt;What’s the process regarding handling a dataset like this?&lt;/p&gt;

&lt;p&gt;Do I use the dataset and train my model without these features (use 15 years worth of data)?&lt;/p&gt;

&lt;p&gt;Do I include these features and only look at the most recent 6 years? &lt;/p&gt;

&lt;p&gt;Or is there something I can do to produce some sort of hybrid between the two?&lt;/p&gt;

&lt;p&gt;It seems a waste to throw away these features, but then it’s also a waste throwing away previous data, is there something I can do about this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hj9kg7,BasslineButty,4,/r/datascience/comments/hj9kg7/dataset_where_some_features_were_only_recorded_in/,https://www.reddit.com/r/datascience/comments/hj9kg7/dataset_where_some_features_were_only_recorded_in/,1593607854.0
r/datascience,"I am looking for a minimal Python development and production environment. The Anaconda distribution installs a lot of unnecessary packages that may make it confusing to detect any dependency issues during development and when deploying to production (you don't want to include unnecessary software in your environment). Any tips or guidelines?

Also, I see people suggesting to up a virtual environment for each individual project, how to do that? Do we set it up in Linux or in Conda?",t2_57j4x5fp,Python development and production environment: Alternatives to Anaconda distribution?,discussion,t3_hj5aj3,1.0,2,Discussion,2,1593615343.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am looking for a minimal Python development and production environment. The Anaconda distribution installs a lot of unnecessary packages that may make it confusing to detect any dependency issues during development and when deploying to production (you don&amp;#39;t want to include unnecessary software in your environment). Any tips or guidelines?&lt;/p&gt;

&lt;p&gt;Also, I see people suggesting to up a virtual environment for each individual project, how to do that? Do we set it up in Linux or in Conda?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hj5aj3,AMGraduate564,15,/r/datascience/comments/hj5aj3/python_development_and_production_environment/,https://www.reddit.com/r/datascience/comments/hj5aj3/python_development_and_production_environment/,1593586543.0
r/datascience,"

So I have this file that has the data of different acceleration sensors.  how would I go about making the data as  clean as possible  considering it has a bunch of noise like even if it isn't moving the sensors are still picking up acceleration signals.

If the question seems rather vague let me know please.


How do you guys go about making this data as accurate as possible?",t2_ccs4c,Just getting started and need some help with processing data that is not fully correct.,education,t3_hj7p12,0.33,0,Education,0,1593628115.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have this file that has the data of different acceleration sensors.  how would I go about making the data as  clean as possible  considering it has a bunch of noise like even if it isn&amp;#39;t moving the sensors are still picking up acceleration signals.&lt;/p&gt;

&lt;p&gt;If the question seems rather vague let me know please.&lt;/p&gt;

&lt;p&gt;How do you guys go about making this data as accurate as possible?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hj7p12,salmix21,5,/r/datascience/comments/hj7p12/just_getting_started_and_need_some_help_with/,https://www.reddit.com/r/datascience/comments/hj7p12/just_getting_started_and_need_some_help_with/,1593599315.0
r/datascience,"I have time series data which I think is not stationary.

But I need to keep the data values interpretable (1€ is 1€) when using it in e.g. a Random Forest Regression , Xgboost Regression or a multiple regression. The techniques I've seen so far don't seem to keep the data in such way.

Is there material out there that explains options to do so while preserving it in such way?",t2_kn00t,Is there a step by step guide to make my time series data stationary while keeping it interpretable?,discussion,t3_hj7l4q,1.0,1,Discussion,1,1593627579.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have time series data which I think is not stationary.&lt;/p&gt;

&lt;p&gt;But I need to keep the data values interpretable (1€ is 1€) when using it in e.g. a Random Forest Regression , Xgboost Regression or a multiple regression. The techniques I&amp;#39;ve seen so far don&amp;#39;t seem to keep the data in such way.&lt;/p&gt;

&lt;p&gt;Is there material out there that explains options to do so while preserving it in such way?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hj7l4q,Yojihito,24,/r/datascience/comments/hj7l4q/is_there_a_step_by_step_guide_to_make_my_time/,https://www.reddit.com/r/datascience/comments/hj7l4q/is_there_a_step_by_step_guide_to_make_my_time/,1593598779.0
r/datascience,"Hey, so, I posted here not too long ago looking for ways to measure the difference between curves. I got a lot of good suggestions (frechet, l2, etc) and have implemented one of them. I took a python implementation of frechet distance (frechetdist) and made a frechet distance matrix for 136 curves. So, now I have a 136x136 matrix where every column and row describes the frechet distance between each point. 

I have some experience with k-means and I'm not certain i can understand anything meaningful using k-means here. I think what I'm probably looking for is more like network analysis, with frechet distance being like an inverted edge strength metric? I have the vague idea that scikit can do that but I have no idea how to implement it (even after having looked at [this](https://scikit-learn.org/stable/modules/clustering.html). Also, my matrix isn't like an np matrix, it's just list of lists. I'm looking to end up with at minimum a network diagram and, if possible, cluster assignment.

Any help you can offer would be greatly appreciated.",t2_4uy7nsid,Looking for appropriate clustering algorithm,projects,t3_hj18fa,1.0,3,Projects,3,1593597698.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, so, I posted here not too long ago looking for ways to measure the difference between curves. I got a lot of good suggestions (frechet, l2, etc) and have implemented one of them. I took a python implementation of frechet distance (frechetdist) and made a frechet distance matrix for 136 curves. So, now I have a 136x136 matrix where every column and row describes the frechet distance between each point. &lt;/p&gt;

&lt;p&gt;I have some experience with k-means and I&amp;#39;m not certain i can understand anything meaningful using k-means here. I think what I&amp;#39;m probably looking for is more like network analysis, with frechet distance being like an inverted edge strength metric? I have the vague idea that scikit can do that but I have no idea how to implement it (even after having looked at &lt;a href=""https://scikit-learn.org/stable/modules/clustering.html""&gt;this&lt;/a&gt;. Also, my matrix isn&amp;#39;t like an np matrix, it&amp;#39;s just list of lists. I&amp;#39;m looking to end up with at minimum a network diagram and, if possible, cluster assignment.&lt;/p&gt;

&lt;p&gt;Any help you can offer would be greatly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hj18fa,30minute_un,3,/r/datascience/comments/hj18fa/looking_for_appropriate_clustering_algorithm/,https://www.reddit.com/r/datascience/comments/hj18fa/looking_for_appropriate_clustering_algorithm/,1593568898.0
r/datascience,"Hey everyone!

I recently started creating tutorials on data analysis / data collection, and I just made a quick video showing **5 quick improvements you can make to your ggplots in R.**

[Here](https://i.imgur.com/1TDrLKJ.jpg) is what the before and after look like

**And here's a link to the** [**YouTube video**](https://youtu.be/qnw1xDnt_Ec)

I haven't been making videos for long and am still trying to see what works well and what doesn't, so all feedback is welcome! And if you're interested in this type of content, **feel free to** [**subscribe**](https://www.youtube.com/channel/UCBV194XNr6CIQCCuw1v2rMQ?sub_confirmation=1) **to the channel :-).**

Thanks!

&amp;#x200B;

edit: formatting",t2_7378bvlf,5 Ways to Make Your R Graphs Look Beautiful (using ggplot2),education,t3_hib1hd,0.96,372,Education,372,1593500579.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;

&lt;p&gt;I recently started creating tutorials on data analysis / data collection, and I just made a quick video showing &lt;strong&gt;5 quick improvements you can make to your ggplots in R.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://i.imgur.com/1TDrLKJ.jpg""&gt;Here&lt;/a&gt; is what the before and after look like&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;And here&amp;#39;s a link to the&lt;/strong&gt; &lt;a href=""https://youtu.be/qnw1xDnt_Ec""&gt;&lt;strong&gt;YouTube video&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I haven&amp;#39;t been making videos for long and am still trying to see what works well and what doesn&amp;#39;t, so all feedback is welcome! And if you&amp;#39;re interested in this type of content, &lt;strong&gt;feel free to&lt;/strong&gt; &lt;a href=""https://www.youtube.com/channel/UCBV194XNr6CIQCCuw1v2rMQ?sub_confirmation=1""&gt;&lt;strong&gt;subscribe&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;to the channel :-).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;edit: formatting&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hib1hd,datasliceYT,67,/r/datascience/comments/hib1hd/5_ways_to_make_your_r_graphs_look_beautiful_using/,https://www.reddit.com/r/datascience/comments/hib1hd/5_ways_to_make_your_r_graphs_look_beautiful_using/,1593471779.0
r/datascience,"Hi,

today I had a discussion with a colleague about professional code. I work in neuroscience research and the code that is written by researchers is often far from perfect since most of us never learned programming other than an intro level course and then some tutorials.

I wanted to ask what you think is the biggest difference between the code a researcher would write for his data analysis and the code by professional programmer that is sold to the industry is?

The next question would be: How can we as researchers learn to write code that is less error-prone and is written such that other researchers can collaborate with us?",t2_5rz9euy,Difference between intermediate level programming and professional programming in data science,education,t3_hioe0p,0.91,15,Education,15,1593556132.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;today I had a discussion with a colleague about professional code. I work in neuroscience research and the code that is written by researchers is often far from perfect since most of us never learned programming other than an intro level course and then some tutorials.&lt;/p&gt;

&lt;p&gt;I wanted to ask what you think is the biggest difference between the code a researcher would write for his data analysis and the code by professional programmer that is sold to the industry is?&lt;/p&gt;

&lt;p&gt;The next question would be: How can we as researchers learn to write code that is less error-prone and is written such that other researchers can collaborate with us?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hioe0p,Zhusters,25,/r/datascience/comments/hioe0p/difference_between_intermediate_level_programming/,https://www.reddit.com/r/datascience/comments/hioe0p/difference_between_intermediate_level_programming/,1593527332.0
r/datascience,"I have Bachelor of Science, majoring in Statistics. But I feel like I know nothing about data 😭 I am working at this charity company (mid size). But can I do Statistical analysis, maybe, I know the scratch. Can I do analysis report, yeah more confident about this, can I please get some advice what would be the best starting point for this first ever report? Do I need to rebrush my university courses? It will help me a lot, thank you so much",t2_hysxmdu,"Manager request a report and this will be my first report at work, I dunno what to do!",projects,t3_hj614s,0.33,0,Projects,0,1593619288.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have Bachelor of Science, majoring in Statistics. But I feel like I know nothing about data 😭 I am working at this charity company (mid size). But can I do Statistical analysis, maybe, I know the scratch. Can I do analysis report, yeah more confident about this, can I please get some advice what would be the best starting point for this first ever report? Do I need to rebrush my university courses? It will help me a lot, thank you so much&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hj614s,faithecup,6,/r/datascience/comments/hj614s/manager_request_a_report_and_this_will_be_my/,https://www.reddit.com/r/datascience/comments/hj614s/manager_request_a_report_and_this_will_be_my/,1593590488.0
r/datascience,,t2_4b3lupr,What is relative quantity of data jobs in SF Bay Area during COVID 19 pandemic compared to during the boom in early 2020? How much harder is it now to find a job in data science?,career,t3_hi4y8e,0.91,91,Career,91,1593482445.0,,hi4y8e,LetsEndSuffering,54,/r/datascience/comments/hi4y8e/what_is_relative_quantity_of_data_jobs_in_sf_bay/,https://www.reddit.com/r/datascience/comments/hi4y8e/what_is_relative_quantity_of_data_jobs_in_sf_bay/,1593453645.0
r/datascience,"Hello all, recently I've been wondering which direction I should take my programming too if I want to get into the clinical/medical field for research. 

Just want to know what the life of a Clinical Data scientist is like. Would it be possible to give me some details as well? Like what a day in your shoes is, or how a week is spent, what resources you use and what I need to familiarise myself with before I start.

A bit about myself:
I have a  BSc in biomed and have done some bioinformatics and pharmacology. So I can pick those subjects again if required (it seemed like those 2 were the main branches so I've just mentioned them, I understand this is oversimplified). I am currently working as an analyst in a clinical setting and have been thinking of driving in to either training to become a data scientist in this field or delving into machine learning instead.

Apart from answering the 2nd para, any advice would also be appreciated.",t2_my3ih,Life of a Clinical Data scientist,career,t3_hijr47,0.67,3,Career,3,1593536758.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all, recently I&amp;#39;ve been wondering which direction I should take my programming too if I want to get into the clinical/medical field for research. &lt;/p&gt;

&lt;p&gt;Just want to know what the life of a Clinical Data scientist is like. Would it be possible to give me some details as well? Like what a day in your shoes is, or how a week is spent, what resources you use and what I need to familiarise myself with before I start.&lt;/p&gt;

&lt;p&gt;A bit about myself:
I have a  BSc in biomed and have done some bioinformatics and pharmacology. So I can pick those subjects again if required (it seemed like those 2 were the main branches so I&amp;#39;ve just mentioned them, I understand this is oversimplified). I am currently working as an analyst in a clinical setting and have been thinking of driving in to either training to become a data scientist in this field or delving into machine learning instead.&lt;/p&gt;

&lt;p&gt;Apart from answering the 2nd para, any advice would also be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hijr47,Roxdeath,2,/r/datascience/comments/hijr47/life_of_a_clinical_data_scientist/,https://www.reddit.com/r/datascience/comments/hijr47/life_of_a_clinical_data_scientist/,1593507958.0
r/datascience,"So this is not notebook disconnecting itself after 90 minutes or 12 hours or whatever automatically. This is extending the amount of time it waits while trying to make an API pull. I have the following code:

`&gt;import pandas as pd`

`from nba_api.stats.static import players`

`from nba_api.stats.endpoints import playergamelog`

`from nba_api.stats.endpoints import commonplayerinfo`

`from nba_api.stats.library.parameters import SeasonAll`

`from time import sleep`

&amp;#x200B;

and I try to run a simple data pull:  


    r = commonplayerinfo.CommonPlayerInfo(player_id=2544)

this results in a timeout error after waiting 30 seconds:  
---------------------------------------------------------------------------  
            timeout                                   Traceback (most recent call last)  
            /usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)  
                383                     # otherwise it looks like a programming error was the cause.  
            --&gt; 384                     six.raise_from(e, None)  
                385         except (SocketTimeout, BaseSSLError, SocketError) as e:  
        
        24 frames  
    timeout: The read operation timed out  
    
    During handling of the above exception, another exception occurred:  
    
    ReadTimeoutError                          Traceback (most recent call last)  
    ReadTimeoutError: HTTPSConnectionPool(host='stats.nba.com', port=443): Read timed out. (read timeout=30)  
    
    During handling of the above exception, another exception occurred:  
    
    ReadTimeout                               Traceback (most recent call last)  
    /usr/local/lib/python3.6/dist-packages/requests/adapters.py in send(self, request, stream, timeout, verify, cert, proxies)  
        527                 raise SSLError(e, request=request)  
        528             elif isinstance(e, ReadTimeoutError):  
    --&gt; 529                 raise ReadTimeout(e, request=request)  
        530             else:  
        531                 raise  
    
    ReadTimeout: HTTPSConnectionPool(host='stats.nba.com', port=443): Read timed out. (read timeout=30)

&amp;#x200B;

I would like to just increase the wait time? as I think that is the issue",t2_109w88,How to avoid read timeouts in google colab?,discussion,t3_himwch,1.0,1,Discussion,1,1593550837.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So this is not notebook disconnecting itself after 90 minutes or 12 hours or whatever automatically. This is extending the amount of time it waits while trying to make an API pull. I have the following code:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;gt;import pandas as pd&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from nba_api.stats.static import players&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from nba_api.stats.endpoints import playergamelog&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from nba_api.stats.endpoints import commonplayerinfo&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from nba_api.stats.library.parameters import SeasonAll&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;from time import sleep&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;and I try to run a simple data pull:  &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r = commonplayerinfo.CommonPlayerInfo(player_id=2544)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;this results in a timeout error after waiting 30 seconds:  &lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;        timeout                                   Traceback (most recent call last)  
        /usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)  
            383                     # otherwise it looks like a programming error was the cause.  
        --&amp;gt; 384                     six.raise_from(e, None)  
            385         except (SocketTimeout, BaseSSLError, SocketError) as e:  

    24 frames  
timeout: The read operation timed out  

During handling of the above exception, another exception occurred:  

ReadTimeoutError                          Traceback (most recent call last)  
ReadTimeoutError: HTTPSConnectionPool(host=&amp;#39;stats.nba.com&amp;#39;, port=443): Read timed out. (read timeout=30)  

During handling of the above exception, another exception occurred:  

ReadTimeout                               Traceback (most recent call last)  
/usr/local/lib/python3.6/dist-packages/requests/adapters.py in send(self, request, stream, timeout, verify, cert, proxies)  
    527                 raise SSLError(e, request=request)  
    528             elif isinstance(e, ReadTimeoutError):  
--&amp;gt; 529                 raise ReadTimeout(e, request=request)  
    530             else:  
    531                 raise  

ReadTimeout: HTTPSConnectionPool(host=&amp;#39;stats.nba.com&amp;#39;, port=443): Read timed out. (read timeout=30)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I would like to just increase the wait time? as I think that is the issue&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",himwch,back_to_the_homeland,7,/r/datascience/comments/himwch/how_to_avoid_read_timeouts_in_google_colab/,https://www.reddit.com/r/datascience/comments/himwch/how_to_avoid_read_timeouts_in_google_colab/,1593522037.0
r/datascience,"I’m considering possible recommenders for work. Our particular industry and product/service portfolio doesn’t really lend itself to collaborative filtering. Generally, our customers with invest in 1-2 products/services at a time and they are very tightly coupled. No need for an algorithm to see that. It’s more about the order in which they “purchase” and the time between those “purchases.” 

Anyway, there are a hunch of ways to do this, but some that I’ve already considered would likely need to be “retrained” over some interval; either when performance falls off or just at some prescheduled interval. But, how do the successful recommendations affect future training? Wouldn’t this kind of be like raising the weight of recommendations by powers compared to “organic” instances? 

Like, if the system recommends products A, B, C in that order often, and people succumb to the recommendation, then retraining will develop bias towards that ordered set. 

Would it be a best practice to track recommended “purchases” and not recommended and only train in the organic purchases? How do collaborative filtering techniques address this?",t2_6nx6nyfy,Recommender system in production learning from the results of its own recommendations; good or bad?,discussion,t3_hi80z0,0.76,6,Discussion,6,1593491279.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m considering possible recommenders for work. Our particular industry and product/service portfolio doesn’t really lend itself to collaborative filtering. Generally, our customers with invest in 1-2 products/services at a time and they are very tightly coupled. No need for an algorithm to see that. It’s more about the order in which they “purchase” and the time between those “purchases.” &lt;/p&gt;

&lt;p&gt;Anyway, there are a hunch of ways to do this, but some that I’ve already considered would likely need to be “retrained” over some interval; either when performance falls off or just at some prescheduled interval. But, how do the successful recommendations affect future training? Wouldn’t this kind of be like raising the weight of recommendations by powers compared to “organic” instances? &lt;/p&gt;

&lt;p&gt;Like, if the system recommends products A, B, C in that order often, and people succumb to the recommendation, then retraining will develop bias towards that ordered set. &lt;/p&gt;

&lt;p&gt;Would it be a best practice to track recommended “purchases” and not recommended and only train in the organic purchases? How do collaborative filtering techniques address this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hi80z0,decucar,7,/r/datascience/comments/hi80z0/recommender_system_in_production_learning_from/,https://www.reddit.com/r/datascience/comments/hi80z0/recommender_system_in_production_learning_from/,1593462479.0
r/datascience,"I currently work at a charity which also runs 3 social enterprises and puts on major fundraising events. Currently, there is no one within the organisation in a data role, we do not even have a central database system yet and there is a low level of data literacy throughout the whole organisation. I have now been given permission to pivot from my fundraising role to the companies first data role.

&amp;#x200B;

I have no real background in data other than the excel work and basic analysis I performed when fundraising/project managing however I am very motivated to learn and I have ambitions to transition into a data-focused career. We have a very complex business structure with several charity programmes which will need impact measurement, fundraising (including major events) and 3 different commercial social enterprises. I am going to have to start from scratch to document all business processes and unearth all of the data from these different areas for analysis. I will also be taking charge of implementing a CRM system (Salesforce) across the whole group (impact, commercial, fundraising, events), I will have the help of an implementation partner but it will still require a lot of heavy lifting and administration from myself.

&amp;#x200B;

It is a mammoth task, especially due to my complete lack of real experience but I am up for the challenge and see it as an excellent learning opportunity and way for me to gain experience at the start of this new career. 

&amp;#x200B;

My question is, is there anywhere online I can find mentors and/or 'consultants' in the data world who I can turn to when I need advice? There is no other inhouse data expertise as far as everyone else knows 'python' is just a type of snake. Reddit is obviously a helpful source of information but it would be great to be able to occasionally pick up the phone to someone to get advice on how I approach a data problem.

&amp;#x200B;

Thank you for your help,",t2_7t2l9,"Starting a new Data role within organisation, where can I find a mentor/pay for advice?",career,t3_hiirpg,0.67,1,Career,1,1593531914.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I currently work at a charity which also runs 3 social enterprises and puts on major fundraising events. Currently, there is no one within the organisation in a data role, we do not even have a central database system yet and there is a low level of data literacy throughout the whole organisation. I have now been given permission to pivot from my fundraising role to the companies first data role.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have no real background in data other than the excel work and basic analysis I performed when fundraising/project managing however I am very motivated to learn and I have ambitions to transition into a data-focused career. We have a very complex business structure with several charity programmes which will need impact measurement, fundraising (including major events) and 3 different commercial social enterprises. I am going to have to start from scratch to document all business processes and unearth all of the data from these different areas for analysis. I will also be taking charge of implementing a CRM system (Salesforce) across the whole group (impact, commercial, fundraising, events), I will have the help of an implementation partner but it will still require a lot of heavy lifting and administration from myself.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;It is a mammoth task, especially due to my complete lack of real experience but I am up for the challenge and see it as an excellent learning opportunity and way for me to gain experience at the start of this new career. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;My question is, is there anywhere online I can find mentors and/or &amp;#39;consultants&amp;#39; in the data world who I can turn to when I need advice? There is no other inhouse data expertise as far as everyone else knows &amp;#39;python&amp;#39; is just a type of snake. Reddit is obviously a helpful source of information but it would be great to be able to occasionally pick up the phone to someone to get advice on how I approach a data problem.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you for your help,&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hiirpg,jboyd88,5,/r/datascience/comments/hiirpg/starting_a_new_data_role_within_organisation/,https://www.reddit.com/r/datascience/comments/hiirpg/starting_a_new_data_role_within_organisation/,1593503114.0
r/datascience,"I love to read about Data stories but it seems that Kaggle and the occasional Medium articles are the two areas that I can find? 

Would love to get some suggestions from the community. Cheers!",t2_1e801nrb,Where else do you go for your data fix?,discussion,t3_hih1w6,1.0,1,Discussion,1,1593523608.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I love to read about Data stories but it seems that Kaggle and the occasional Medium articles are the two areas that I can find? &lt;/p&gt;

&lt;p&gt;Would love to get some suggestions from the community. Cheers!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hih1w6,ysl17,2,/r/datascience/comments/hih1w6/where_else_do_you_go_for_your_data_fix/,https://www.reddit.com/r/datascience/comments/hih1w6/where_else_do_you_go_for_your_data_fix/,1593494808.0
r/datascience,,t2_o6hb7,Comprehensive Python Cheatsheet now also covers Pandas,education,t3_hhfqbl,0.99,648,Education,648,1593384883.0,,hhfqbl,pizzaburek,32,/r/datascience/comments/hhfqbl/comprehensive_python_cheatsheet_now_also_covers/,https://gto76.github.io/python-cheatsheet/#pandas,1593356083.0
r/datascience,"I'd like to get a better understanding of why some of my charts convey the thing I'm interested in, and some of them look like trash. Are there any good data visualization courses on youtube? I'm a full-time programmer and I'm moderately familiar with matplotlib so I'm not so interested in ""learn Python via charting libraries"" type stuff; more language-agnostic best practices.",t2_dhgh1,Good data visualization lectures on youtube?,education,t3_hidm01,1.0,1,Education,1,1593509875.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;d like to get a better understanding of why some of my charts convey the thing I&amp;#39;m interested in, and some of them look like trash. Are there any good data visualization courses on youtube? I&amp;#39;m a full-time programmer and I&amp;#39;m moderately familiar with matplotlib so I&amp;#39;m not so interested in &amp;quot;learn Python via charting libraries&amp;quot; type stuff; more language-agnostic best practices.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hidm01,capitalsigma,2,/r/datascience/comments/hidm01/good_data_visualization_lectures_on_youtube/,https://www.reddit.com/r/datascience/comments/hidm01/good_data_visualization_lectures_on_youtube/,1593481075.0
r/datascience,"Hi everyone,

as the title says, do you have KPIs or quantitative goals in your team? If yes, what are they? Did you chose them yourselves or were they imposed by management?

IMHO it's quite difficult for a data science team to show quantitative results for e.g. the value of strategic insights or fostering corporate innovativeness. Somewhat easier maybe if you're working on e.g. using ML for process improvements and can calculate the resulting savings. 

This isn't necessarily a data science problem, [perverse incentive](https://en.wikipedia.org/wiki/Perverse_incentive) / [cobra effect](https://en.wikipedia.org/wiki/Cobra_effect) / [McNamara fallacy](https://en.wikipedia.org/wiki/McNamara_fallacy) are pervasive in corporate environments, just wondering how you handle it and if there's some data-science-specific perspective on it. Thanks! [edit: typo]",t2_l4fifhm,Does your data science team have KPIs / quantitative goals?,discussion,t3_hhwejv,0.88,16,Discussion,16,1593449647.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;as the title says, do you have KPIs or quantitative goals in your team? If yes, what are they? Did you chose them yourselves or were they imposed by management?&lt;/p&gt;

&lt;p&gt;IMHO it&amp;#39;s quite difficult for a data science team to show quantitative results for e.g. the value of strategic insights or fostering corporate innovativeness. Somewhat easier maybe if you&amp;#39;re working on e.g. using ML for process improvements and can calculate the resulting savings. &lt;/p&gt;

&lt;p&gt;This isn&amp;#39;t necessarily a data science problem, &lt;a href=""https://en.wikipedia.org/wiki/Perverse_incentive""&gt;perverse incentive&lt;/a&gt; / &lt;a href=""https://en.wikipedia.org/wiki/Cobra_effect""&gt;cobra effect&lt;/a&gt; / &lt;a href=""https://en.wikipedia.org/wiki/McNamara_fallacy""&gt;McNamara fallacy&lt;/a&gt; are pervasive in corporate environments, just wondering how you handle it and if there&amp;#39;s some data-science-specific perspective on it. Thanks! [edit: typo]&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hhwejv,dhaitz,13,/r/datascience/comments/hhwejv/does_your_data_science_team_have_kpis/,https://www.reddit.com/r/datascience/comments/hhwejv/does_your_data_science_team_have_kpis/,1593420847.0
r/datascience,"I have worked with auto-regessive models like ARIMA. But I haven't done anything on GARCH/ARCH.

Anyway I needed to model volatility for a project, and Google search said GARCH was the way to go. So I calculated the annual volatility of my series and chucked that series into a GARCH (1,1) model on python, only to be outputted really shitty results.

I found out now that the GARCH model on python requires the raw data, and not the volatility data.

Anyway my question is this. If I used an ARIMA process to model the volatility data that I made, would the modelling of volatility be better or worse than the GARCH model?",t2_2ugvk6iw,ARIMA vs GARCH,education,t3_hib4z9,1.0,1,Education,1,1593500897.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have worked with auto-regessive models like ARIMA. But I haven&amp;#39;t done anything on GARCH/ARCH.&lt;/p&gt;

&lt;p&gt;Anyway I needed to model volatility for a project, and Google search said GARCH was the way to go. So I calculated the annual volatility of my series and chucked that series into a GARCH (1,1) model on python, only to be outputted really shitty results.&lt;/p&gt;

&lt;p&gt;I found out now that the GARCH model on python requires the raw data, and not the volatility data.&lt;/p&gt;

&lt;p&gt;Anyway my question is this. If I used an ARIMA process to model the volatility data that I made, would the modelling of volatility be better or worse than the GARCH model?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hib4z9,Otto_the_Fox,2,/r/datascience/comments/hib4z9/arima_vs_garch/,https://www.reddit.com/r/datascience/comments/hib4z9/arima_vs_garch/,1593472097.0
r/datascience,"I'm a fresh grad, and with a degree in Economics. Currently doing the Data Science career path on codeacademy, and looking for someone to team up with so I can apply all that I've learnt into some project. Open to any internship opportunities as well (need not be paid!). 

I'm just having a hard time figuring out any project that I want to work on. Any tips would be appreciated as well!",t2_keilc,Looking to team-up with someone to work on data-science projects!,projects,t3_hi7m46,1.0,1,Projects,1,1593490100.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a fresh grad, and with a degree in Economics. Currently doing the Data Science career path on codeacademy, and looking for someone to team up with so I can apply all that I&amp;#39;ve learnt into some project. Open to any internship opportunities as well (need not be paid!). &lt;/p&gt;

&lt;p&gt;I&amp;#39;m just having a hard time figuring out any project that I want to work on. Any tips would be appreciated as well!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hi7m46,vivek2396,3,/r/datascience/comments/hi7m46/looking_to_teamup_with_someone_to_work_on/,https://www.reddit.com/r/datascience/comments/hi7m46/looking_to_teamup_with_someone_to_work_on/,1593461300.0
r/datascience,"I'm currently in the process of building a recommendation system with implicit data (e.g. clicks, views, purchases), however much of the research I've looked at seems to skip the step of ""aggregating implicit data"".  For example,  how do you aggregate multiple clicks and purchases overtime into a single user rating (as is required for a standard matrix factorization model)?  


I've been experimenting with several Matrix Factorization based methods, including Neural Collaborative Filtering, Deep Factorization Machines, LightFM, and Variational Autoencoders. None of these papers seem to address the issue of aggregating implicit data. They also do not discuss how to weight different types of user events (e.g. clicks vs purchase) when calculating a score. 

For now I've been using a confidence score approach (the conference score corresponds to the count of events) as outlined in this paper: [http://yifanhu.net/PUB/cf.pdf](http://yifanhu.net/PUB/cf.pdf). However this approach doesn't address incorporating other types of user events (other than clicks), nor does it address negative implicit feedback (e.g. a ton of impressions with zero clicks).   


Anyway, I'd love some insight on this topic! Any thoughts at all would be hugely appreciated!",t2_45jwt7z5,"Converting ""Implicit"" user interactions to ""Explicit"" user ratings for recommendation systems",projects,t3_hi5wqo,1.0,1,Projects,1,1593485189.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently in the process of building a recommendation system with implicit data (e.g. clicks, views, purchases), however much of the research I&amp;#39;ve looked at seems to skip the step of &amp;quot;aggregating implicit data&amp;quot;.  For example,  how do you aggregate multiple clicks and purchases overtime into a single user rating (as is required for a standard matrix factorization model)?  &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been experimenting with several Matrix Factorization based methods, including Neural Collaborative Filtering, Deep Factorization Machines, LightFM, and Variational Autoencoders. None of these papers seem to address the issue of aggregating implicit data. They also do not discuss how to weight different types of user events (e.g. clicks vs purchase) when calculating a score. &lt;/p&gt;

&lt;p&gt;For now I&amp;#39;ve been using a confidence score approach (the conference score corresponds to the count of events) as outlined in this paper: &lt;a href=""http://yifanhu.net/PUB/cf.pdf""&gt;http://yifanhu.net/PUB/cf.pdf&lt;/a&gt;. However this approach doesn&amp;#39;t address incorporating other types of user events (other than clicks), nor does it address negative implicit feedback (e.g. a ton of impressions with zero clicks).   &lt;/p&gt;

&lt;p&gt;Anyway, I&amp;#39;d love some insight on this topic! Any thoughts at all would be hugely appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hi5wqo,john-c34,5,/r/datascience/comments/hi5wqo/converting_implicit_user_interactions_to_explicit/,https://www.reddit.com/r/datascience/comments/hi5wqo/converting_implicit_user_interactions_to_explicit/,1593456389.0
r/datascience,"Am I the only one enraged and disgusted by the fact that Microsoft is offering paid courses in Python for beginners? Like, you have done absolutely nothing for the development of the language and its ecosystem, have fought open source in all possible ways, still offer no way to integrate Python with your software (Excel would benefit tremendously of a native Python integration to replace or give users an alternative to the garbled Frankenstein monster that is VBA) but you make money off people attracted by the Big Corporation name? Seriously, this pisses me off more than it probably should but I can't help that:

[https://docs.microsoft.com/en-us/learn/certifications/exams/98-381](https://docs.microsoft.com/en-us/learn/certifications/exams/98-381)",t2_9yb4lav,Microsoft certificate for Python? Seriously?,discussion,t3_hiimdx,0.31,0,Discussion,0,1593531177.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Am I the only one enraged and disgusted by the fact that Microsoft is offering paid courses in Python for beginners? Like, you have done absolutely nothing for the development of the language and its ecosystem, have fought open source in all possible ways, still offer no way to integrate Python with your software (Excel would benefit tremendously of a native Python integration to replace or give users an alternative to the garbled Frankenstein monster that is VBA) but you make money off people attracted by the Big Corporation name? Seriously, this pisses me off more than it probably should but I can&amp;#39;t help that:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://docs.microsoft.com/en-us/learn/certifications/exams/98-381""&gt;https://docs.microsoft.com/en-us/learn/certifications/exams/98-381&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hiimdx,Alav81,30,/r/datascience/comments/hiimdx/microsoft_certificate_for_python_seriously/,https://www.reddit.com/r/datascience/comments/hiimdx/microsoft_certificate_for_python_seriously/,1593502377.0
r/datascience,"We are trying to analyze traffic from four variants (base + three variants) from external sources using a diff-in-diff analysis. 

Setup: We added richer images to the thumbnails in the three variants, hoping that a better quality thumbnail would result in higher click throughs back to our website. The pages in the four variants are different, and we can't see the CTR directly on external websites, so we are using a diff-in-diff approach to see if the traffic that we get from the three variants had an upward trend since this intervention.

My question is: The daily visitor trend is pretty spiky, so the way causalimpact works (calculating counterfactual per day based on the base variant and pointwise difference) will also be pretty spiky and unstable (atleast that's what my guess is). In this situation, would using a 7-day rolling visitor count instead of a daily visitor trend be more helpful, as that is more representative of trend, rather than individual day visits?

Thanks for your help",t2_3endwkme,Using Daily vs. Rolling Visitors Timeseries for CausalImpact,discussion,t3_hi4nr2,1.0,1,Discussion,1,1593481610.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We are trying to analyze traffic from four variants (base + three variants) from external sources using a diff-in-diff analysis. &lt;/p&gt;

&lt;p&gt;Setup: We added richer images to the thumbnails in the three variants, hoping that a better quality thumbnail would result in higher click throughs back to our website. The pages in the four variants are different, and we can&amp;#39;t see the CTR directly on external websites, so we are using a diff-in-diff approach to see if the traffic that we get from the three variants had an upward trend since this intervention.&lt;/p&gt;

&lt;p&gt;My question is: The daily visitor trend is pretty spiky, so the way causalimpact works (calculating counterfactual per day based on the base variant and pointwise difference) will also be pretty spiky and unstable (atleast that&amp;#39;s what my guess is). In this situation, would using a 7-day rolling visitor count instead of a daily visitor trend be more helpful, as that is more representative of trend, rather than individual day visits?&lt;/p&gt;

&lt;p&gt;Thanks for your help&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hi4nr2,philosophytautology,2,/r/datascience/comments/hi4nr2/using_daily_vs_rolling_visitors_timeseries_for/,https://www.reddit.com/r/datascience/comments/hi4nr2/using_daily_vs_rolling_visitors_timeseries_for/,1593452810.0
r/datascience,"I'm struggling with creating a csv database to import. The docs to setting this part up seems quite limited :/  


Where can I learn more about formatting the datasets, corresponding to respective tasks?",t2_4z9k9a9h,Anyone use the Orange Data Mining tool?,discussion,t3_hhzmbw,0.6,1,Discussion,1,1593465220.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m struggling with creating a csv database to import. The docs to setting this part up seems quite limited :/  &lt;/p&gt;

&lt;p&gt;Where can I learn more about formatting the datasets, corresponding to respective tasks?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hhzmbw,AnonAppliedPhysicist,2,/r/datascience/comments/hhzmbw/anyone_use_the_orange_data_mining_tool/,https://www.reddit.com/r/datascience/comments/hhzmbw/anyone_use_the_orange_data_mining_tool/,1593436420.0
r/datascience,"Basically, you get to skip the dirt work (cleaning data) and have data all cleaned and ready for you? And is this going to be trend?  Given that ""Data Analysts"" roles (SQL monkeys) are becoming more a thing so Data Scientists can focus on doing Machine Learning projects, etc? 

Data Science seems like a ""buzz word"" and no offense  to any Data Scientists here, but couldn't just regular SWE do your job? I don't get the point of having a PhD at all. Also when it comes to math, do you actually jot down formulas and work on them, or just run built-in function statistical programs using Python/R or even just use WolfRamAlpha to get your job done.   


I'm just really curious as to why people want to become data scientists and why companies set the bar so high. Getting a PhD just to get a DS role doesn't really makes any sense to me, to be quite honest.",t2_h2t9l,Any Data Scientists here not doing any data analysis work at all?,discussion,t3_hhosxw,0.6,6,Discussion,6,1593415537.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Basically, you get to skip the dirt work (cleaning data) and have data all cleaned and ready for you? And is this going to be trend?  Given that &amp;quot;Data Analysts&amp;quot; roles (SQL monkeys) are becoming more a thing so Data Scientists can focus on doing Machine Learning projects, etc? &lt;/p&gt;

&lt;p&gt;Data Science seems like a &amp;quot;buzz word&amp;quot; and no offense  to any Data Scientists here, but couldn&amp;#39;t just regular SWE do your job? I don&amp;#39;t get the point of having a PhD at all. Also when it comes to math, do you actually jot down formulas and work on them, or just run built-in function statistical programs using Python/R or even just use WolfRamAlpha to get your job done.   &lt;/p&gt;

&lt;p&gt;I&amp;#39;m just really curious as to why people want to become data scientists and why companies set the bar so high. Getting a PhD just to get a DS role doesn&amp;#39;t really makes any sense to me, to be quite honest.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hhosxw,jackielarson,21,/r/datascience/comments/hhosxw/any_data_scientists_here_not_doing_any_data/,https://www.reddit.com/r/datascience/comments/hhosxw/any_data_scientists_here_not_doing_any_data/,1593386737.0
r/datascience," Background: I am a masters(CS) and around 2 years experience in data engineering. My industry experience is mostly with spark, kafka, sql, NooSql and AWS, building data migration and ETL systems. Initially I liked data engineering better and always attempted to stay in the same field. However now I feel like I want to switch to a data scientist role, or even a Machine Learning Engineer (dream).

To add, I do have experience with data science tools and techniques(spark,pyspark,pandas, numpy ,building and hyper parameter tuning ML models, CNNs,LSTMs, tensorflow,keras etc) through my projects in my masters. However, companies seem to value titles more than my experience, and since I've never held a data scientist/MLE title, I keep getting approached by recruiters for senior data engineer roles but can't get an interview even for a junior data science role, despite applying to so many places

How to overcome this? I've seen people with non CS degrees become software engineers and data scientists, surely it shouldn't be impossible for me? Is there anyone who has done this who can advise? Thanks in advance",t2_72qrhcnm,How to switch from Data Engineering to Data Science?,career,t3_hhqf7r,0.73,5,Career,5,1593421720.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Background: I am a masters(CS) and around 2 years experience in data engineering. My industry experience is mostly with spark, kafka, sql, NooSql and AWS, building data migration and ETL systems. Initially I liked data engineering better and always attempted to stay in the same field. However now I feel like I want to switch to a data scientist role, or even a Machine Learning Engineer (dream).&lt;/p&gt;

&lt;p&gt;To add, I do have experience with data science tools and techniques(spark,pyspark,pandas, numpy ,building and hyper parameter tuning ML models, CNNs,LSTMs, tensorflow,keras etc) through my projects in my masters. However, companies seem to value titles more than my experience, and since I&amp;#39;ve never held a data scientist/MLE title, I keep getting approached by recruiters for senior data engineer roles but can&amp;#39;t get an interview even for a junior data science role, despite applying to so many places&lt;/p&gt;

&lt;p&gt;How to overcome this? I&amp;#39;ve seen people with non CS degrees become software engineers and data scientists, surely it shouldn&amp;#39;t be impossible for me? Is there anyone who has done this who can advise? Thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hhqf7r,tangerine_make,6,/r/datascience/comments/hhqf7r/how_to_switch_from_data_engineering_to_data/,https://www.reddit.com/r/datascience/comments/hhqf7r/how_to_switch_from_data_engineering_to_data/,1593392920.0
r/datascience,,t2_ymkj2,I’m starting an unpaid internship this week with a new startup (&lt; 3 months). The 4 interns are getting given a small project for a month. Is there anything I should be aware of?,career,t3_hhdq0i,0.86,22,Career,22,1593376873.0,,hhdq0i,elisimicr,45,/r/datascience/comments/hhdq0i/im_starting_an_unpaid_internship_this_week_with_a/,https://www.reddit.com/r/datascience/comments/hhdq0i/im_starting_an_unpaid_internship_this_week_with_a/,1593348073.0
r/datascience,Is that computing power dependent on the size of the training data? What would be required if using just a playground dataset (~10k tokens)?,t2_1rfg9tf5,What is the computing power required to train a language model like Bert or GPT2?,discussion,t3_hh9a1r,0.85,34,Discussion,34,1593352173.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is that computing power dependent on the size of the training data? What would be required if using just a playground dataset (~10k tokens)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hh9a1r,rodrigonader,15,/r/datascience/comments/hh9a1r/what_is_the_computing_power_required_to_train_a/,https://www.reddit.com/r/datascience/comments/hh9a1r/what_is_the_computing_power_required_to_train_a/,1593323373.0
r/datascience,"Has anyone ever evaluated the Gower's Distance (dissimilarity) for their data? I have mixed categorical/continuous data which makes it difficult to perform statistical analysis. Recently, I found out of Gower's distance : for a given dataset, you can calculate a Gower's matrix. Then, (as far as I understand) you can take this Gower's matrix and feed it into a statistical algorithms. Apparently, this is a better option than ""one hot encoding"" categorical variables.

Has anyone ever heard about Gower's Distance and used it in statistical analysis (e.g. K nearest neighbor, Support Vector Machines, etc)? Are you still required to normalize or scale the coefficients of the Gower's matrix?",t2_3f0i9m72,Gower Distance: Working with categorical and continuous data,discussion,t3_hhgaz6,1.0,4,Discussion,4,1593386890.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Has anyone ever evaluated the Gower&amp;#39;s Distance (dissimilarity) for their data? I have mixed categorical/continuous data which makes it difficult to perform statistical analysis. Recently, I found out of Gower&amp;#39;s distance : for a given dataset, you can calculate a Gower&amp;#39;s matrix. Then, (as far as I understand) you can take this Gower&amp;#39;s matrix and feed it into a statistical algorithms. Apparently, this is a better option than &amp;quot;one hot encoding&amp;quot; categorical variables.&lt;/p&gt;

&lt;p&gt;Has anyone ever heard about Gower&amp;#39;s Distance and used it in statistical analysis (e.g. K nearest neighbor, Support Vector Machines, etc)? Are you still required to normalize or scale the coefficients of the Gower&amp;#39;s matrix?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hhgaz6,SQL_beginner,1,/r/datascience/comments/hhgaz6/gower_distance_working_with_categorical_and/,https://www.reddit.com/r/datascience/comments/hhgaz6/gower_distance_working_with_categorical_and/,1593358090.0
r/datascience,"Is anyone familiar with the LOF (Local Outlier Factor) algorithm?

What if the LOF scores are extremely large or infinity? Does this mean that the data is not ideal for the LOF algorithm? Or simply ignore these observations? It seems doubtful that the LOF score could be naturally so big.

I would be interested in hearing your thoughts!",t2_3tosvccj,Extremely large LOF scores,discussion,t3_hho725,0.67,1,Discussion,1,1593413265.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is anyone familiar with the LOF (Local Outlier Factor) algorithm?&lt;/p&gt;

&lt;p&gt;What if the LOF scores are extremely large or infinity? Does this mean that the data is not ideal for the LOF algorithm? Or simply ignore these observations? It seems doubtful that the LOF score could be naturally so big.&lt;/p&gt;

&lt;p&gt;I would be interested in hearing your thoughts!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hho725,jj4646,0,/r/datascience/comments/hho725/extremely_large_lof_scores/,https://www.reddit.com/r/datascience/comments/hho725/extremely_large_lof_scores/,1593384465.0
r/datascience,"I find myself being really confused about the intended uses of k means clustering. As far as I understand, clustering is a unsupervised algorithm intended for discovering relationships in the data. The intended use of clustering is not to classify observations. However, I have seen k means being used to cluster data, and then k means being used to predict which of these clusters a new data point will belong to. This seems to be classification and not clustering. Can someone confirm if this is correct?",t2_3f0i9m72,Fundamental confusion about k means clustering,discussion,t3_hhm0eg,1.0,1,Discussion,1,1593405686.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I find myself being really confused about the intended uses of k means clustering. As far as I understand, clustering is a unsupervised algorithm intended for discovering relationships in the data. The intended use of clustering is not to classify observations. However, I have seen k means being used to cluster data, and then k means being used to predict which of these clusters a new data point will belong to. This seems to be classification and not clustering. Can someone confirm if this is correct?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hhm0eg,SQL_beginner,2,/r/datascience/comments/hhm0eg/fundamental_confusion_about_k_means_clustering/,https://www.reddit.com/r/datascience/comments/hhm0eg/fundamental_confusion_about_k_means_clustering/,1593376886.0
r/datascience,"What does everyone here use for classifying mixed data? Suppose I have data on salary (continuous) and blood type (discrete). I am somewhat skeptical of transforming blood type into a dummy variable for mathematical reasons. If a given statistical algorithms uses a distance measure (e.g. euclidean distance), I am not sure if the concept of distance works for discrete data. 

Is hot encoding a good idea? Other than using a decision tree or a random forest, how else can mixed data be classified?

Thanks!",t2_3tosvccj,Classification of mixed data,discussion,t3_hhhkiq,1.0,2,Discussion,2,1593391216.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What does everyone here use for classifying mixed data? Suppose I have data on salary (continuous) and blood type (discrete). I am somewhat skeptical of transforming blood type into a dummy variable for mathematical reasons. If a given statistical algorithms uses a distance measure (e.g. euclidean distance), I am not sure if the concept of distance works for discrete data. &lt;/p&gt;

&lt;p&gt;Is hot encoding a good idea? Other than using a decision tree or a random forest, how else can mixed data be classified?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hhhkiq,jj4646,7,/r/datascience/comments/hhhkiq/classification_of_mixed_data/,https://www.reddit.com/r/datascience/comments/hhhkiq/classification_of_mixed_data/,1593362416.0
r/datascience,"Hey r/datascience,

I'm a grad student in data science, trying to decide what to study in my Fall semester.  I'm primarily interested in inference and experimental methods.  I was wondering - what is the utility of classical time series analysis (ARIMA, that type of thing) in practice?  When and how does it come up in the inference domain?  Does it come up at all?  Is it critical or not critical?  How has modern machine learning changed the necessity of time series analysis, if at all?

Appreciate your thoughts - I have little mentorship for the utility of specific data science methodologies through my program, so your thoughts are really helpful",t2_aewcc,Utility of Classical Time Series Analysis in Industry,discussion,t3_hgzret,0.93,81,Discussion,81,1593314836.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a grad student in data science, trying to decide what to study in my Fall semester.  I&amp;#39;m primarily interested in inference and experimental methods.  I was wondering - what is the utility of classical time series analysis (ARIMA, that type of thing) in practice?  When and how does it come up in the inference domain?  Does it come up at all?  Is it critical or not critical?  How has modern machine learning changed the necessity of time series analysis, if at all?&lt;/p&gt;

&lt;p&gt;Appreciate your thoughts - I have little mentorship for the utility of specific data science methodologies through my program, so your thoughts are really helpful&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hgzret,i_am_baldilocks,39,/r/datascience/comments/hgzret/utility_of_classical_time_series_analysis_in/,https://www.reddit.com/r/datascience/comments/hgzret/utility_of_classical_time_series_analysis_in/,1593286036.0
r/datascience,Title,t2_46mkj7i9,"Excuse my ignorance, but is Data Science and Data Analysis two different fields?",career,t3_hhii74,0.67,1,Career,1,1593394295.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Title&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hhii74,bluur_blob5,6,/r/datascience/comments/hhii74/excuse_my_ignorance_but_is_data_science_and_data/,https://www.reddit.com/r/datascience/comments/hhii74/excuse_my_ignorance_but_is_data_science_and_data/,1593365495.0
r/datascience,,t2_3op9qx89,IYO is the line between data scientist and machine learning engineer becoming blurred?,discussion,t3_hhhoh9,0.5,0,Discussion,0,1593391592.0,,hhhoh9,LatterConcentrate6,7,/r/datascience/comments/hhhoh9/iyo_is_the_line_between_data_scientist_and/,https://www.reddit.com/r/datascience/comments/hhhoh9/iyo_is_the_line_between_data_scientist_and/,1593362792.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 28 Jun 2020 - 05 Jul 2020,,t3_hhd829,0.75,2,Discussion,2,1593374430.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hhd829,datascience-bot,108,/r/datascience/comments/hhd829/weekly_entering_transitioning_thread_28_jun_2020/,https://www.reddit.com/r/datascience/comments/hhd829/weekly_entering_transitioning_thread_28_jun_2020/,1593345630.0
r/datascience,"**\[Reached Max Limit\] H There. I've reached my max limit and will not be able to include any more people as of now but feel free to DM so I'd be aware that you'd want in if there's a chance. Thanks**

**The Project:**

Attribution modelling has been a common problem in the online marketing world. The problem is that people don't know which attribution model would work best for them and hence I feel Data Science has a big role to play here.

I'm working on a product that can generate user level data, basically which sources people come from and what actions they take. I also have some sample data to start working on this but we can always create artificial data using this sample.

I'm looking for like minded people who want to work with me on this and if we get any success, we can essentially turn this into a product.

That's too far fetched right now, but yeah, the problem statement exists and no solution exists for now, no convincing enough solution I'd say.

Let me know your thoughts. You don't have to be DS pro but interested enough in the problem statement

**\[Update\]** *Please let me know a bit about your experience as well and background if possible as I won't be able to include everyone. Note that this is just a project that you'd want to be in just for interest and learning*

*I'll create a slack group probably. I'll do this starting Monday. Keeping the weekend window open for people to get aware of this.*

**MY BACKGROUND:**

Working in Data Science field for 3 years, professionally 4 years. Mostly worked on blend of DS and Data Engineering projects.

In marketing, I've setup predictive pipelines and wrote a blog on Behavioral Marketing and a couple on DS. Other than this, I work on my SAAS tool on the side. Since I talk to people occasionally on different platforms, this specific problem statement has come up many times and hence the post

**FOR PEOPLE WHO ARE NEW TO AM:**

Multitouch attribution OR Attribution Modelling basically seeks to figure out which marketing channels are contributing to KPIs and to find the optimal media-mix to maximize performance. A fully comprehensive attribution solution would be able to tell you exactly how much each click, impression, or interaction with branded content contributed to a customer making a purchase and exactly how much value should be assigned to each touchpoint. This is essentially impossible without being able to read minds. We can only get closer using behavioral data

**\[People Who Just Got Aware of This + Who DM Me\]**

Honestly, I did not expect a response like this, people have started to DM me. I'd be very upfront here, It won't be possible for me to include everyone and anyone for this project as it makes it harder to split the work and also the fact that some people might feel left out or feel the project isn't going on If I include everyone reaching out to me. The best mix would be people who are new and passionate, that brings in energy + who have already worked in something similar, that brings in experience.

But, this does not mean there won't be any collaboration at all. You've taken out time to reach out to me or comment here, I'd possible come up with a similar project in parallel and get you aligned there.

**\[Open To Feedback\]**

**If you think you can help in managing this project or have better way to set this up. Feel free to comment or DM**

**\[What Do You Get From This Project\]**

Experience, Learning, Networking. Nothing else. Just setting the expectations right!

**\[When Does It Start\]**

Next week definitely. I'll setup a slack group as a first and share few docs there. I'm planning Monday late evening to send out the invites. I'll push this to Wednesday max if I have to!

**\[How To Comment/DM\]**

Feel free to write in your thoughts, but it'd help me in filtering out people among different skills. So, please add a tag like this in your comments based on your skills:

* **#only\_pythoncoding** \-&gt; Front-line people, who'll code in python to do the dirty stuff
* **#marketing\_and\_code** \-&gt; People who can code and also know the market basics
* **#only\_marketing** \-&gt; If you're more of a non-tech who can mentor/share thoughts
* **#only\_stats\_analytical** \-&gt; People who have stats background but not much experienced in code/market",t2_4sepodzn,Anyone wants to team up for doing Attribution Modelling in Marketing?,projects,t3_hgpx2j,0.89,137,Projects,137,1593275595.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;[Reached Max Limit] H There. I&amp;#39;ve reached my max limit and will not be able to include any more people as of now but feel free to DM so I&amp;#39;d be aware that you&amp;#39;d want in if there&amp;#39;s a chance. Thanks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Project:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Attribution modelling has been a common problem in the online marketing world. The problem is that people don&amp;#39;t know which attribution model would work best for them and hence I feel Data Science has a big role to play here.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m working on a product that can generate user level data, basically which sources people come from and what actions they take. I also have some sample data to start working on this but we can always create artificial data using this sample.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m looking for like minded people who want to work with me on this and if we get any success, we can essentially turn this into a product.&lt;/p&gt;

&lt;p&gt;That&amp;#39;s too far fetched right now, but yeah, the problem statement exists and no solution exists for now, no convincing enough solution I&amp;#39;d say.&lt;/p&gt;

&lt;p&gt;Let me know your thoughts. You don&amp;#39;t have to be DS pro but interested enough in the problem statement&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Update]&lt;/strong&gt; &lt;em&gt;Please let me know a bit about your experience as well and background if possible as I won&amp;#39;t be able to include everyone. Note that this is just a project that you&amp;#39;d want to be in just for interest and learning&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I&amp;#39;ll create a slack group probably. I&amp;#39;ll do this starting Monday. Keeping the weekend window open for people to get aware of this.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MY BACKGROUND:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Working in Data Science field for 3 years, professionally 4 years. Mostly worked on blend of DS and Data Engineering projects.&lt;/p&gt;

&lt;p&gt;In marketing, I&amp;#39;ve setup predictive pipelines and wrote a blog on Behavioral Marketing and a couple on DS. Other than this, I work on my SAAS tool on the side. Since I talk to people occasionally on different platforms, this specific problem statement has come up many times and hence the post&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FOR PEOPLE WHO ARE NEW TO AM:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Multitouch attribution OR Attribution Modelling basically seeks to figure out which marketing channels are contributing to KPIs and to find the optimal media-mix to maximize performance. A fully comprehensive attribution solution would be able to tell you exactly how much each click, impression, or interaction with branded content contributed to a customer making a purchase and exactly how much value should be assigned to each touchpoint. This is essentially impossible without being able to read minds. We can only get closer using behavioral data&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[People Who Just Got Aware of This + Who DM Me]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Honestly, I did not expect a response like this, people have started to DM me. I&amp;#39;d be very upfront here, It won&amp;#39;t be possible for me to include everyone and anyone for this project as it makes it harder to split the work and also the fact that some people might feel left out or feel the project isn&amp;#39;t going on If I include everyone reaching out to me. The best mix would be people who are new and passionate, that brings in energy + who have already worked in something similar, that brings in experience.&lt;/p&gt;

&lt;p&gt;But, this does not mean there won&amp;#39;t be any collaboration at all. You&amp;#39;ve taken out time to reach out to me or comment here, I&amp;#39;d possible come up with a similar project in parallel and get you aligned there.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Open To Feedback]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you think you can help in managing this project or have better way to set this up. Feel free to comment or DM&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[What Do You Get From This Project]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Experience, Learning, Networking. Nothing else. Just setting the expectations right!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[When Does It Start]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Next week definitely. I&amp;#39;ll setup a slack group as a first and share few docs there. I&amp;#39;m planning Monday late evening to send out the invites. I&amp;#39;ll push this to Wednesday max if I have to!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[How To Comment/DM]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Feel free to write in your thoughts, but it&amp;#39;d help me in filtering out people among different skills. So, please add a tag like this in your comments based on your skills:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;#only_pythoncoding&lt;/strong&gt; -&amp;gt; Front-line people, who&amp;#39;ll code in python to do the dirty stuff&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;#marketing_and_code&lt;/strong&gt; -&amp;gt; People who can code and also know the market basics&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;#only_marketing&lt;/strong&gt; -&amp;gt; If you&amp;#39;re more of a non-tech who can mentor/share thoughts&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;#only_stats_analytical&lt;/strong&gt; -&amp;gt; People who have stats background but not much experienced in code/market&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hgpx2j,mrnerdy59,166,/r/datascience/comments/hgpx2j/anyone_wants_to_team_up_for_doing_attribution/,https://www.reddit.com/r/datascience/comments/hgpx2j/anyone_wants_to_team_up_for_doing_attribution/,1593246795.0
r/datascience,"Morning all

Data science director here, working for a consultancy. My last 6 months at work have been 100% about overseeing large projects with a sprinkle of sales and team strategy. This is just where I am in my career and it’s great. However I’m dying to start to carve out some time again to spend on the detail.

I’ve been holding out to do a MSc for about 5 years now, but I haven’t found the right time with work - always a promotion opportunity 1-2 years away so didn’t want to lose my slot. 

So I’m looking for some learning to do which isn’t quite a masters, but is a bit more than a Coursera or Udacity course. Ideally something that is semi-recognised - possibly with decent Uni. Machine learning related ideally. Happy to dedicate 7-10 hours per week.

Thanks in advance for any ideas!!",t2_4lfd0goj,Interesting and recognised certificate?,education,t3_hgpslh,0.7,10,Education,10,1593274943.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Morning all&lt;/p&gt;

&lt;p&gt;Data science director here, working for a consultancy. My last 6 months at work have been 100% about overseeing large projects with a sprinkle of sales and team strategy. This is just where I am in my career and it’s great. However I’m dying to start to carve out some time again to spend on the detail.&lt;/p&gt;

&lt;p&gt;I’ve been holding out to do a MSc for about 5 years now, but I haven’t found the right time with work - always a promotion opportunity 1-2 years away so didn’t want to lose my slot. &lt;/p&gt;

&lt;p&gt;So I’m looking for some learning to do which isn’t quite a masters, but is a bit more than a Coursera or Udacity course. Ideally something that is semi-recognised - possibly with decent Uni. Machine learning related ideally. Happy to dedicate 7-10 hours per week.&lt;/p&gt;

&lt;p&gt;Thanks in advance for any ideas!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hgpslh,Arty8866,7,/r/datascience/comments/hgpslh/interesting_and_recognised_certificate/,https://www.reddit.com/r/datascience/comments/hgpslh/interesting_and_recognised_certificate/,1593246143.0
r/datascience,"First of all the problem is the following:

I  have a company's portfolio where each row is a client, and I have to  look for the clusters who represent the most meaningful clients, so I  could then look for similar clients to each cluster in another dataset.  
The  outlier issue began because I wanted to improve the clusters and since I  was using K-means to clusterize outliers affect it too much. 

  
I have two dataframes that I need to clusterize where I am trying to do the following:

1. Apply  PCA to remove outliers and use PCA with 3 components to  visualize it.I  am using a total of explained variance of 97,5% for the  outlier  removal process.The idea behind it is this: [https://www.kaggle.com/yairhadad1/detect-outliers-with-pca](https://www.kaggle.com/yairhadad1/detect-outliers-with-pca)
2. Inverse transform and get the MSE score between the inversed tranformed dataframes and the original ones.
3. Use the InterQuartlie Range (IQR) upper bracket limit using the calculated Mean squared error (MSE) score to remove the outliers.
4. Applying the PCA with 3 components to visualize and determine the number of clusters on the new dataframe.

My main issues are:

Is the IQR on MSE a good criteria for removal?

I  have limited to the upper bracket since we are working with  absolute  values. If not and I am mixing concepts, what would be a good  criteria  for this type of transformation?

Or I should drop PCA and go for other methods of outliers detection, if so which?

And  ultimately I still visualize points very far from the clusters  when  doing the x,y,z plot, does this mean they aren't outliers, just a  few  scattered far away points that represent a small cluster? Or the   outlier detecting isn't being effective?

Finally  on the second dataframe a 3D visualization has roughly 40% of   explained variance, is it fair to apply the same decision making   process?",t2_719vr9ao,Removing outliers with PCA in multidmension (100+) cluster problem,discussion,t3_hgf3er,0.94,94,Discussion,94,1593231294.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;First of all the problem is the following:&lt;/p&gt;

&lt;p&gt;I  have a company&amp;#39;s portfolio where each row is a client, and I have to  look for the clusters who represent the most meaningful clients, so I  could then look for similar clients to each cluster in another dataset.&lt;br/&gt;
The  outlier issue began because I wanted to improve the clusters and since I  was using K-means to clusterize outliers affect it too much. &lt;/p&gt;

&lt;p&gt;I have two dataframes that I need to clusterize where I am trying to do the following:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Apply  PCA to remove outliers and use PCA with 3 components to  visualize it.I  am using a total of explained variance of 97,5% for the  outlier  removal process.The idea behind it is this: &lt;a href=""https://www.kaggle.com/yairhadad1/detect-outliers-with-pca""&gt;https://www.kaggle.com/yairhadad1/detect-outliers-with-pca&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Inverse transform and get the MSE score between the inversed tranformed dataframes and the original ones.&lt;/li&gt;
&lt;li&gt;Use the InterQuartlie Range (IQR) upper bracket limit using the calculated Mean squared error (MSE) score to remove the outliers.&lt;/li&gt;
&lt;li&gt;Applying the PCA with 3 components to visualize and determine the number of clusters on the new dataframe.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;My main issues are:&lt;/p&gt;

&lt;p&gt;Is the IQR on MSE a good criteria for removal?&lt;/p&gt;

&lt;p&gt;I  have limited to the upper bracket since we are working with  absolute  values. If not and I am mixing concepts, what would be a good  criteria  for this type of transformation?&lt;/p&gt;

&lt;p&gt;Or I should drop PCA and go for other methods of outliers detection, if so which?&lt;/p&gt;

&lt;p&gt;And  ultimately I still visualize points very far from the clusters  when  doing the x,y,z plot, does this mean they aren&amp;#39;t outliers, just a  few  scattered far away points that represent a small cluster? Or the   outlier detecting isn&amp;#39;t being effective?&lt;/p&gt;

&lt;p&gt;Finally  on the second dataframe a 3D visualization has roughly 40% of   explained variance, is it fair to apply the same decision making   process?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hgf3er,rpinto02,34,/r/datascience/comments/hgf3er/removing_outliers_with_pca_in_multidmension_100/,https://www.reddit.com/r/datascience/comments/hgf3er/removing_outliers_with_pca_in_multidmension_100/,1593202494.0
r/datascience,"I will be starting my first data science internship in a few weeks, and I have the opportunity to specify the kind of projects I would like to work on. But given that this is my first internship, I'm not sure what kind of data science projects even exist.

So I wanted to ask the experienced data scientists here: **If you could go back to your days as an intern, what kind of projects would you choose to work on? What skills would you care to learn from the mentors on your team?**",t2_5ddenqhj,What kind of projects do you wish you tackled as an intern?,discussion,t3_hgfzws,0.95,78,Discussion,78,1593234182.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I will be starting my first data science internship in a few weeks, and I have the opportunity to specify the kind of projects I would like to work on. But given that this is my first internship, I&amp;#39;m not sure what kind of data science projects even exist.&lt;/p&gt;

&lt;p&gt;So I wanted to ask the experienced data scientists here: &lt;strong&gt;If you could go back to your days as an intern, what kind of projects would you choose to work on? What skills would you care to learn from the mentors on your team?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hgfzws,Busy-Chipmunk,15,/r/datascience/comments/hgfzws/what_kind_of_projects_do_you_wish_you_tackled_as/,https://www.reddit.com/r/datascience/comments/hgfzws/what_kind_of_projects_do_you_wish_you_tackled_as/,1593205382.0
r/datascience,"I've encountered some job listings that ask for familiarity with big data toolsets like Spark, MapReduce, and Kafka. From my data science work so far the biggest dataset I had to work with was in the million range that didn't require me to use these particular tools. Does anyone have any suggestions of how I can actually get exposure to working with these tools - or are these opportunities more limited to when you're working with heavy industry data?",t2_3ahwym06,Getting experience with Spark and other big data tools,tooling,t3_hgkxu8,0.94,25,Tooling,25,1593251994.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve encountered some job listings that ask for familiarity with big data toolsets like Spark, MapReduce, and Kafka. From my data science work so far the biggest dataset I had to work with was in the million range that didn&amp;#39;t require me to use these particular tools. Does anyone have any suggestions of how I can actually get exposure to working with these tools - or are these opportunities more limited to when you&amp;#39;re working with heavy industry data?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hgkxu8,bigchungusmode96,6,/r/datascience/comments/hgkxu8/getting_experience_with_spark_and_other_big_data/,https://www.reddit.com/r/datascience/comments/hgkxu8/getting_experience_with_spark_and_other_big_data/,1593223194.0
r/datascience,"[UPDATE] thank you all for the responses. I definitely need to mature and think more about what I value. In the meantime I’m looking for new work. Also to clarify, the reason why I’m ranting is because this is the data science board. We all want to do meaningful work; we like what we do. So from all the helpful suggestions here, I will aim to balance satisfaction from boss and sneak in more valuable work in between. Thanks all! 

 I work in Real Estate, and currently the only function the C-level staff sees is to pump out ""research"" that hits the market and shows what we're capable of.

I'm not solving problems. I am going through datasets to see what models and ""assumptions"" I can solve; showcasing our ability to use AI.

When I asked, ""wouldn't investors ask right from the beginning, ""what's the point?"" or ""what are they trying to solve?"""" I was rewarded with the response, ""investors are too dumb to know what AI is.""

Oh the contrary, I think WE'RE too dumb to know what AI is.

My department spends money, and we haven't received a strip of evidence that has shown my work has had any significant impact.

I offered to some cost modelling. I've proposed to do affordability modelling for an investor, however it all fell on dead ears.

Apparently investors don't care where they're putting their money?

EDIT: It's like getting a doctor to showcase his skills by performing surgery on people he thinks are sick. Why don't I invest in time on investors to show the QUALITY of our work?",t2_5e34w9d2,"I'm being prostituted, Data Science prostitution. (RANT)",discussion,t3_hg4fzc,0.85,273,Discussion,273,1593192686.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[UPDATE] thank you all for the responses. I definitely need to mature and think more about what I value. In the meantime I’m looking for new work. Also to clarify, the reason why I’m ranting is because this is the data science board. We all want to do meaningful work; we like what we do. So from all the helpful suggestions here, I will aim to balance satisfaction from boss and sneak in more valuable work in between. Thanks all! &lt;/p&gt;

&lt;p&gt;I work in Real Estate, and currently the only function the C-level staff sees is to pump out &amp;quot;research&amp;quot; that hits the market and shows what we&amp;#39;re capable of.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m not solving problems. I am going through datasets to see what models and &amp;quot;assumptions&amp;quot; I can solve; showcasing our ability to use AI.&lt;/p&gt;

&lt;p&gt;When I asked, &amp;quot;wouldn&amp;#39;t investors ask right from the beginning, &amp;quot;what&amp;#39;s the point?&amp;quot; or &amp;quot;what are they trying to solve?&amp;quot;&amp;quot; I was rewarded with the response, &amp;quot;investors are too dumb to know what AI is.&amp;quot;&lt;/p&gt;

&lt;p&gt;Oh the contrary, I think WE&amp;#39;RE too dumb to know what AI is.&lt;/p&gt;

&lt;p&gt;My department spends money, and we haven&amp;#39;t received a strip of evidence that has shown my work has had any significant impact.&lt;/p&gt;

&lt;p&gt;I offered to some cost modelling. I&amp;#39;ve proposed to do affordability modelling for an investor, however it all fell on dead ears.&lt;/p&gt;

&lt;p&gt;Apparently investors don&amp;#39;t care where they&amp;#39;re putting their money?&lt;/p&gt;

&lt;p&gt;EDIT: It&amp;#39;s like getting a doctor to showcase his skills by performing surgery on people he thinks are sick. Why don&amp;#39;t I invest in time on investors to show the QUALITY of our work?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hg4fzc,expatwithajetpack,152,/r/datascience/comments/hg4fzc/im_being_prostituted_data_science_prostitution/,https://www.reddit.com/r/datascience/comments/hg4fzc/im_being_prostituted_data_science_prostitution/,1593163886.0
r/datascience,"Hi there,

I have a problem I'm trying to solve and wanting to know if there are any pre-made tools or algorithms that can get the job done.  I'll try to define the problem.

Let's say I have 4 groups of data, and each group of data has 50 samples each.  The samples are conversations people had and the conversations are about the group ti which the sample belongs.

Is there a tool that could find commonalities in the conversations that could then be used to determine the group?  I believe that would be called natural language processing?",t2_3avisr2s,"Assigned a task at work regarding data science, but know nothing about data acience",discussion,t3_hguxtm,0.6,1,Discussion,1,1593298595.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there,&lt;/p&gt;

&lt;p&gt;I have a problem I&amp;#39;m trying to solve and wanting to know if there are any pre-made tools or algorithms that can get the job done.  I&amp;#39;ll try to define the problem.&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s say I have 4 groups of data, and each group of data has 50 samples each.  The samples are conversations people had and the conversations are about the group ti which the sample belongs.&lt;/p&gt;

&lt;p&gt;Is there a tool that could find commonalities in the conversations that could then be used to determine the group?  I believe that would be called natural language processing?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hguxtm,LeadFootSaunders,5,/r/datascience/comments/hguxtm/assigned_a_task_at_work_regarding_data_science/,https://www.reddit.com/r/datascience/comments/hguxtm/assigned_a_task_at_work_regarding_data_science/,1593269795.0
r/datascience,"Anyone read *AI Superpowers: China, Silicon Valley, and the New Order*? It looks like we are going to be surpassed by China when it comes to data science, ML in particular. The book argues that China, as a nation without copyright laws and no gripes about copying, has built a nation enamored with AI, funneling massive amounts of cash into startups and other ML ventures. China has built this on the infrastructure created by Silicone Valley, while the US has remained stagnant and complacent. Any thoughts on this thesis?",t2_3pnizflv,"Anyone read AI Superpowers: China, Silicon Valley, and the New Order?",education,t3_hgiv6f,0.81,12,Education,12,1593243916.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anyone read &lt;em&gt;AI Superpowers: China, Silicon Valley, and the New Order&lt;/em&gt;? It looks like we are going to be surpassed by China when it comes to data science, ML in particular. The book argues that China, as a nation without copyright laws and no gripes about copying, has built a nation enamored with AI, funneling massive amounts of cash into startups and other ML ventures. China has built this on the infrastructure created by Silicone Valley, while the US has remained stagnant and complacent. Any thoughts on this thesis?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hgiv6f,Tyron_Slothrop,12,/r/datascience/comments/hgiv6f/anyone_read_ai_superpowers_china_silicon_valley/,https://www.reddit.com/r/datascience/comments/hgiv6f/anyone_read_ai_superpowers_china_silicon_valley/,1593215116.0
r/datascience,"Hello. So I am currently a Junior Data Scientist and I am now brushing up on the fundamentals of statistics, currently around hypothesis testing. I am wondering though, does anybody in here use hypothesis testing on their Data Science jobs? In which context? 

Also, what would you say are the most fundamental statistical concepts that every Data Scientist should know?

Thank you!",t2_wik6z,Hypothesis testing,discussion,t3_hgrkz4,0.5,0,Discussion,0,1593284382.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello. So I am currently a Junior Data Scientist and I am now brushing up on the fundamentals of statistics, currently around hypothesis testing. I am wondering though, does anybody in here use hypothesis testing on their Data Science jobs? In which context? &lt;/p&gt;

&lt;p&gt;Also, what would you say are the most fundamental statistical concepts that every Data Scientist should know?&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hgrkz4,Elbarro,8,/r/datascience/comments/hgrkz4/hypothesis_testing/,https://www.reddit.com/r/datascience/comments/hgrkz4/hypothesis_testing/,1593255582.0
r/datascience,"TLDR: how do you assert yourself at work for a small company with a lot of procedural inertia?

I work for a small software company. They have been around for a long time and have never integrated data science into their software suites. They hired me as their first data scientist and AI expert. I find it very difficult to get the cycles from development and management to get my models (which perform well) productionized. 

We follow the Agile cycle and in all of our iteration any sprint planning meetings I fight for more time with developers and executives but then nothing changes. The higher-ups talk all about how AI is their future then when I try to implement something it just keeps getting put on the back burner for their other priorities, which always seem to come up.

Seeking advise, thanks!

Edit: typo",t2_4w2jwmn7,Asserting yourself at work,career,t3_hg8q1s,1.0,5,Career,5,1593210945.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TLDR: how do you assert yourself at work for a small company with a lot of procedural inertia?&lt;/p&gt;

&lt;p&gt;I work for a small software company. They have been around for a long time and have never integrated data science into their software suites. They hired me as their first data scientist and AI expert. I find it very difficult to get the cycles from development and management to get my models (which perform well) productionized. &lt;/p&gt;

&lt;p&gt;We follow the Agile cycle and in all of our iteration any sprint planning meetings I fight for more time with developers and executives but then nothing changes. The higher-ups talk all about how AI is their future then when I try to implement something it just keeps getting put on the back burner for their other priorities, which always seem to come up.&lt;/p&gt;

&lt;p&gt;Seeking advise, thanks!&lt;/p&gt;

&lt;p&gt;Edit: typo&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hg8q1s,mgmillem,23,/r/datascience/comments/hg8q1s/asserting_yourself_at_work/,https://www.reddit.com/r/datascience/comments/hg8q1s/asserting_yourself_at_work/,1593182145.0
r/datascience,What are some well-known binary classification datasets where neural nets or deep learning fails badly?,t2_zmqho4m,What are some well-known binary classification datasets where neural nets or deep learning fails badly?,discussion,t3_hg5jnt,0.83,8,Discussion,8,1593198701.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What are some well-known binary classification datasets where neural nets or deep learning fails badly?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hg5jnt,leockl,24,/r/datascience/comments/hg5jnt/what_are_some_wellknown_binary_classification/,https://www.reddit.com/r/datascience/comments/hg5jnt/what_are_some_wellknown_binary_classification/,1593169901.0
r/datascience,"My current role is more heavily focused on data prep/cleansing/automation/reporting and project management. I can develop and implement solutions but I'm not as strong as I need to be when it comes to the more abstract thinking like deriving actionable insights from data, drawing conclusions , making recommendations, etc. 

My company is in professional services and they're very implementation focused so I can have 10-15 ongoing projects where we deliver a solution and it's on to the next project, while the end users (auditors/accountants) are left to do most of the deeper analysis themselves. This is also in a very niche industry (audit/accounting) and while I've picked up on some of the concepts specific to this field, I don't have a deep accounting/audit background.

I also ran into this issue when I was going through the beginner courses on Kaggle where a few questions were posed and we had to examine the data in the exercise and draw conclusions from it. I was completely stumped as my brain isn't used to this type of abstract critical thinking. How can I further develop and improve in this area?",t2_fi9mt,"How to be more analytical, derive insights, draw conclusions from data, etc.?",education,t3_hfq0uv,0.97,211,Education,211,1593134182.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My current role is more heavily focused on data prep/cleansing/automation/reporting and project management. I can develop and implement solutions but I&amp;#39;m not as strong as I need to be when it comes to the more abstract thinking like deriving actionable insights from data, drawing conclusions , making recommendations, etc. &lt;/p&gt;

&lt;p&gt;My company is in professional services and they&amp;#39;re very implementation focused so I can have 10-15 ongoing projects where we deliver a solution and it&amp;#39;s on to the next project, while the end users (auditors/accountants) are left to do most of the deeper analysis themselves. This is also in a very niche industry (audit/accounting) and while I&amp;#39;ve picked up on some of the concepts specific to this field, I don&amp;#39;t have a deep accounting/audit background.&lt;/p&gt;

&lt;p&gt;I also ran into this issue when I was going through the beginner courses on Kaggle where a few questions were posed and we had to examine the data in the exercise and draw conclusions from it. I was completely stumped as my brain isn&amp;#39;t used to this type of abstract critical thinking. How can I further develop and improve in this area?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfq0uv,pmbro,22,/r/datascience/comments/hfq0uv/how_to_be_more_analytical_derive_insights_draw/,https://www.reddit.com/r/datascience/comments/hfq0uv/how_to_be_more_analytical_derive_insights_draw/,1593105382.0
r/datascience,"I’m one of a team of two that does mostly analysis and insights with a smattering of ML when the need arises.

We would like to (and, frankly, have been asked to) have more transparency into our workload and projects in flight. What is a good way to organize workload and communicate that to management? I’ve considered maybe an agile methodology, or at least stealing parts of one like a kanban board. I’d love to hear what other teams do.",t2_jqnnc,What Agile-ish framework can a small team use?,discussion,t3_hg8vhm,1.0,4,Discussion,4,1593211454.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m one of a team of two that does mostly analysis and insights with a smattering of ML when the need arises.&lt;/p&gt;

&lt;p&gt;We would like to (and, frankly, have been asked to) have more transparency into our workload and projects in flight. What is a good way to organize workload and communicate that to management? I’ve considered maybe an agile methodology, or at least stealing parts of one like a kanban board. I’d love to hear what other teams do.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hg8vhm,MindlessTime,7,/r/datascience/comments/hg8vhm/what_agileish_framework_can_a_small_team_use/,https://www.reddit.com/r/datascience/comments/hg8vhm/what_agileish_framework_can_a_small_team_use/,1593182654.0
r/datascience,"Hi all, a little background I'm an experienced data scientist who lives in Downtown Los Angeles. I live next to several non-chain restaurants who I think now more than ever might be prime candidates for consultation around optimizing and attempting to shrink costs within their business. I want to see if I could possibly provide this service to them and wanted to hear stories from others about their experience working with small businesses in the consultation space. I'd also like to hear some of the difficulties that come from pitching your service as opposed to answering a request when it comes to consultation.",t2_11nb3p,Experience freelance consultation for small businesses?,discussion,t3_hg27ht,0.94,14,Discussion,14,1593180387.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, a little background I&amp;#39;m an experienced data scientist who lives in Downtown Los Angeles. I live next to several non-chain restaurants who I think now more than ever might be prime candidates for consultation around optimizing and attempting to shrink costs within their business. I want to see if I could possibly provide this service to them and wanted to hear stories from others about their experience working with small businesses in the consultation space. I&amp;#39;d also like to hear some of the difficulties that come from pitching your service as opposed to answering a request when it comes to consultation.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hg27ht,Peppington,16,/r/datascience/comments/hg27ht/experience_freelance_consultation_for_small/,https://www.reddit.com/r/datascience/comments/hg27ht/experience_freelance_consultation_for_small/,1593151587.0
r/datascience,"[This q&amp;a thread](https://www.teamblind.com/post/[AMA]-Staff-DS-at-Airbnb-with-12-YoE-across-four-FAANGMULLA-nYGF0Tuk) has some gold insights for anyone trying to tap into top tech data science roles.

Thought that it would help out the community when recruiting!",t2_53q3b26i,Staff DS at Airbnb with 12 YoE across four FAANGMULLA,career,t3_hfymgm,0.58,3,Career,3,1593164359.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.teamblind.com/post/%5BAMA%5D-Staff-DS-at-Airbnb-with-12-YoE-across-four-FAANGMULLA-nYGF0Tuk""&gt;This q&amp;amp;a thread&lt;/a&gt; has some gold insights for anyone trying to tap into top tech data science roles.&lt;/p&gt;

&lt;p&gt;Thought that it would help out the community when recruiting!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfymgm,l33tsquad,7,/r/datascience/comments/hfymgm/staff_ds_at_airbnb_with_12_yoe_across_four/,https://www.reddit.com/r/datascience/comments/hfymgm/staff_ds_at_airbnb_with_12_yoe_across_four/,1593135559.0
r/datascience,"My job search in the DS field as an entry-level, I believe, has gone wrong.

The job I applied had the  'Analyst and Reporting Specialist' title. It's a logistics company where the products or papers are being moved to both end-users and from warehouses to supermarkets.

The second day I'm in, the biggest company my firm was working with threatened to leave them and stopped most of his operations with I believe.

My first big assignment was to standardize an excel spreadsheet so vehicles and drivers using them can be tracked daily for over a month. The thing is the format they want to work with is nowhere close to being tidy. So it's almost impossible to work with afterward. For example, A job instance where a car and a driver finish their route is spread out to two rows! This messes with other tidy data principles as you can imagine. The spreadsheet is messy!

THE BIG THING is: My company is in a crisis now where we prioritize our biggest two customers. But in order to do so, **the vehicle route optimization system had to be stopped.**

Now I'm positioned with **MANUALLY** setting the routes for our 100 carriers **on the country level.** This happened yesterday and I'm working with an excel sheet. While wondering what the fuck I was doing, I've sorted up the cities, districts, and neighbors alphabetically, and criminally and randomly assigned the routes for each one of them -- Except the one major city in which I live. It ended up leaving me laughing hysterically like Joker and a shift at 1 am.

I don't know what the heck they're doing now! LOL!

&amp;#x200B;

Where do I go from here? It's obvious this isn't a DS job I ended up. At least not for a couple of months. My two questions can be categorized as near-field and general worries:

What do heck do I do now? I will probably have to keep track of a lot of things and repeat this process of manually setting the routes for the carries a lot. Do you think it makes sense to try and automate this? This will be probably over in two months or less. I'll probably get fired or company shrinks - and I get fired again!

Are there any helpful tracking web apps or services that could help me with this period?

Or do you think I should go balls deep and start using Google APIs to try and implement vehicle route optimization? The thing is I'm way too alone for this and this doesn't look like a single person's job, especially with a BUSY time schedule.

Even after this shit storm: do you think logistics is an entry-level friendly field for data science? What do you think I can optimize in the company? How does ML or DL gets used in the field?",t2_27vsxdce,A Job Search Gone Wrong at a Logistics Firm - Logistics Experts Expected In Here,discussion,t3_hg2ljy,0.33,0,Discussion,0,1593182327.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My job search in the DS field as an entry-level, I believe, has gone wrong.&lt;/p&gt;

&lt;p&gt;The job I applied had the  &amp;#39;Analyst and Reporting Specialist&amp;#39; title. It&amp;#39;s a logistics company where the products or papers are being moved to both end-users and from warehouses to supermarkets.&lt;/p&gt;

&lt;p&gt;The second day I&amp;#39;m in, the biggest company my firm was working with threatened to leave them and stopped most of his operations with I believe.&lt;/p&gt;

&lt;p&gt;My first big assignment was to standardize an excel spreadsheet so vehicles and drivers using them can be tracked daily for over a month. The thing is the format they want to work with is nowhere close to being tidy. So it&amp;#39;s almost impossible to work with afterward. For example, A job instance where a car and a driver finish their route is spread out to two rows! This messes with other tidy data principles as you can imagine. The spreadsheet is messy!&lt;/p&gt;

&lt;p&gt;THE BIG THING is: My company is in a crisis now where we prioritize our biggest two customers. But in order to do so, &lt;strong&gt;the vehicle route optimization system had to be stopped.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now I&amp;#39;m positioned with &lt;strong&gt;MANUALLY&lt;/strong&gt; setting the routes for our 100 carriers &lt;strong&gt;on the country level.&lt;/strong&gt; This happened yesterday and I&amp;#39;m working with an excel sheet. While wondering what the fuck I was doing, I&amp;#39;ve sorted up the cities, districts, and neighbors alphabetically, and criminally and randomly assigned the routes for each one of them -- Except the one major city in which I live. It ended up leaving me laughing hysterically like Joker and a shift at 1 am.&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t know what the heck they&amp;#39;re doing now! LOL!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Where do I go from here? It&amp;#39;s obvious this isn&amp;#39;t a DS job I ended up. At least not for a couple of months. My two questions can be categorized as near-field and general worries:&lt;/p&gt;

&lt;p&gt;What do heck do I do now? I will probably have to keep track of a lot of things and repeat this process of manually setting the routes for the carries a lot. Do you think it makes sense to try and automate this? This will be probably over in two months or less. I&amp;#39;ll probably get fired or company shrinks - and I get fired again!&lt;/p&gt;

&lt;p&gt;Are there any helpful tracking web apps or services that could help me with this period?&lt;/p&gt;

&lt;p&gt;Or do you think I should go balls deep and start using Google APIs to try and implement vehicle route optimization? The thing is I&amp;#39;m way too alone for this and this doesn&amp;#39;t look like a single person&amp;#39;s job, especially with a BUSY time schedule.&lt;/p&gt;

&lt;p&gt;Even after this shit storm: do you think logistics is an entry-level friendly field for data science? What do you think I can optimize in the company? How does ML or DL gets used in the field?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hg2ljy,MadMenMadMan,3,/r/datascience/comments/hg2ljy/a_job_search_gone_wrong_at_a_logistics_firm/,https://www.reddit.com/r/datascience/comments/hg2ljy/a_job_search_gone_wrong_at_a_logistics_firm/,1593153527.0
r/datascience,"Hi everyone,

I'm looking for the collective help of Reddit as I came across a very interesting article a year or so ago which seemed to outline the needs and hires required for each of the stages of an organization and it grows. Something similar to 0-50 people these are your key objectives, you needs, and who you need to hire. Rinse and repeat for the next stage.

From what I recall, it touched on the topics of the various roles within the data science, what the immediate organization goals should be for each stage and how to progress to the next stage in terms of data maturity. A pyramid of data needs or some similar framework was also proposed. The article was also fairly lengthy from what I remember.

An additional note, I don't believe that it was an article posted on Medium but rather some private blog post. The author seemed to be an industry veteran.

Thank you in advance!

Edit: It's possible 'roadmap' was included in the title of the article.

Edit 2: I found it, here's the article, thanks to a kind redditor: https://thinkgrowth.org/the-startup-founders-guide-to-analytics-1d2176f20ac1",t2_41ake,"Trying to find an article of growing a data team and its needs at X stage (0-50 employees, 50-200, etc)",discussion,t3_hfb106,0.97,167,Discussion,167,1593066751.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m looking for the collective help of Reddit as I came across a very interesting article a year or so ago which seemed to outline the needs and hires required for each of the stages of an organization and it grows. Something similar to 0-50 people these are your key objectives, you needs, and who you need to hire. Rinse and repeat for the next stage.&lt;/p&gt;

&lt;p&gt;From what I recall, it touched on the topics of the various roles within the data science, what the immediate organization goals should be for each stage and how to progress to the next stage in terms of data maturity. A pyramid of data needs or some similar framework was also proposed. The article was also fairly lengthy from what I remember.&lt;/p&gt;

&lt;p&gt;An additional note, I don&amp;#39;t believe that it was an article posted on Medium but rather some private blog post. The author seemed to be an industry veteran.&lt;/p&gt;

&lt;p&gt;Thank you in advance!&lt;/p&gt;

&lt;p&gt;Edit: It&amp;#39;s possible &amp;#39;roadmap&amp;#39; was included in the title of the article.&lt;/p&gt;

&lt;p&gt;Edit 2: I found it, here&amp;#39;s the article, thanks to a kind redditor: &lt;a href=""https://thinkgrowth.org/the-startup-founders-guide-to-analytics-1d2176f20ac1""&gt;https://thinkgrowth.org/the-startup-founders-guide-to-analytics-1d2176f20ac1&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfb106,adiyo011,16,/r/datascience/comments/hfb106/trying_to_find_an_article_of_growing_a_data_team/,https://www.reddit.com/r/datascience/comments/hfb106/trying_to_find_an_article_of_growing_a_data_team/,1593037951.0
r/datascience,"So I have some a few machine learning models, both supervised and unsupervised models using random Forrest classifiers, deep and transfer learning using tensor flow. Models are done smoothly also with good accuracy and prediction score. For tensorflow I mainly use Colab so no local environment for my packages. So, Now my problem is how can I use those models and create web app using flask api or such? to deploy the end result to the user.
I can also accept custom data in form of images but only in Colab notebooks. How do i do they locally?",t2_12upe6,How to develop Web App based on model of jupyter notebooks? [Weekly],discussion,t3_hfpv8s,0.72,3,Discussion,3,1593133693.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have some a few machine learning models, both supervised and unsupervised models using random Forrest classifiers, deep and transfer learning using tensor flow. Models are done smoothly also with good accuracy and prediction score. For tensorflow I mainly use Colab so no local environment for my packages. So, Now my problem is how can I use those models and create web app using flask api or such? to deploy the end result to the user.
I can also accept custom data in form of images but only in Colab notebooks. How do i do they locally?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfpv8s,ddmasterdon,11,/r/datascience/comments/hfpv8s/how_to_develop_web_app_based_on_model_of_jupyter/,https://www.reddit.com/r/datascience/comments/hfpv8s/how_to_develop_web_app_based_on_model_of_jupyter/,1593104893.0
r/datascience,Anyone have experience with IVR (Interactive Voice Response) analytics or omni-channel analytics? Wondering what insights can be derived and if i should explore this for my company?,t2_1q6oq5dl,IVR Analytics,discussion,t3_hfw2xs,1.0,1,Discussion,1,1593154505.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anyone have experience with IVR (Interactive Voice Response) analytics or omni-channel analytics? Wondering what insights can be derived and if i should explore this for my company?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfw2xs,dmorris87,3,/r/datascience/comments/hfw2xs/ivr_analytics/,https://www.reddit.com/r/datascience/comments/hfw2xs/ivr_analytics/,1593125705.0
r/datascience,"I received a link for an article titled  [5 Ways to Detect Outliers/Anomalies That Every Data Scientist Should Know (Python Code)](https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623). It was in my Medium Daily Digest. I got curious and clicked on the link. But guess what!!! The freaking Pay wall!!!

Now my experience with Medium articles has usually been that the titles are very attractive but the content is underwhelming. So, I decided to pose this question to you guys instead of reading the article and being underwhelmed. I know I am being presumptuous with this article but it's just what I have learned from my experience with the platform.

I usually first check the data visually, try some boxplots and scatterplots, IQR, etc...the usual stuff. Do you guys do the same?  Do you think the article might have something other than what we already know? Let us discuss.",t2_sdvbr,How do you detect outliers in your data?,discussion,t3_hfi7a7,0.73,8,Discussion,8,1593100738.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I received a link for an article titled  &lt;a href=""https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623""&gt;5 Ways to Detect Outliers/Anomalies That Every Data Scientist Should Know (Python Code)&lt;/a&gt;. It was in my Medium Daily Digest. I got curious and clicked on the link. But guess what!!! The freaking Pay wall!!!&lt;/p&gt;

&lt;p&gt;Now my experience with Medium articles has usually been that the titles are very attractive but the content is underwhelming. So, I decided to pose this question to you guys instead of reading the article and being underwhelmed. I know I am being presumptuous with this article but it&amp;#39;s just what I have learned from my experience with the platform.&lt;/p&gt;

&lt;p&gt;I usually first check the data visually, try some boxplots and scatterplots, IQR, etc...the usual stuff. Do you guys do the same?  Do you think the article might have something other than what we already know? Let us discuss.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfi7a7,shounak2411,9,/r/datascience/comments/hfi7a7/how_do_you_detect_outliers_in_your_data/,https://www.reddit.com/r/datascience/comments/hfi7a7/how_do_you_detect_outliers_in_your_data/,1593071938.0
r/datascience,"Hi,

My job is currently just a lot of reporting, through SQL queries and dashboard creation / visualizations. How do I unstuck myself from this? I do some statistical work, but a lot of it seems unappreciated / not responded to about. (e.g. analysis of cost of picking wrong item to send out). So if that is unappreciated, how would I get them behind a data science project? Secondarily, can I list the type of projects I did at a company / models I used on a resume without exposing NDAs? I know a github post is out of the question for my code base, so it almost seems like I need to create dummy / side projects to show case I can do things, rather than simply tell that I can.",t2_74h60,un-pigeonholing from reporting to statistical work,career,t3_hf8wa3,0.88,52,Career,52,1593059663.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;My job is currently just a lot of reporting, through SQL queries and dashboard creation / visualizations. How do I unstuck myself from this? I do some statistical work, but a lot of it seems unappreciated / not responded to about. (e.g. analysis of cost of picking wrong item to send out). So if that is unappreciated, how would I get them behind a data science project? Secondarily, can I list the type of projects I did at a company / models I used on a resume without exposing NDAs? I know a github post is out of the question for my code base, so it almost seems like I need to create dummy / side projects to show case I can do things, rather than simply tell that I can.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hf8wa3,Doctrineate,17,/r/datascience/comments/hf8wa3/unpigeonholing_from_reporting_to_statistical_work/,https://www.reddit.com/r/datascience/comments/hf8wa3/unpigeonholing_from_reporting_to_statistical_work/,1593030863.0
r/datascience,"I am interested in working on a data science project (apart from my regular work) for social welfare or any project which helps improve our communities. Any ideas or organisation/people working for such causes would be really appreciated.

My purpose is to learn more skills and also give something back to our community.",t2_i1a1i0f,Data science for social good,projects,t3_hf5x2i,0.9,27,Projects,27,1593050546.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am interested in working on a data science project (apart from my regular work) for social welfare or any project which helps improve our communities. Any ideas or organisation/people working for such causes would be really appreciated.&lt;/p&gt;

&lt;p&gt;My purpose is to learn more skills and also give something back to our community.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hf5x2i,iotamadmax,15,/r/datascience/comments/hf5x2i/data_science_for_social_good/,https://www.reddit.com/r/datascience/comments/hf5x2i/data_science_for_social_good/,1593021746.0
r/datascience,"Hello, everyone! After years of learning about data science in my spare time, I got a job that'll allow me to put the knowledge into practice - very exciting.  The company - which deals with electrical equipment - wants to make a gradual transformation in its administration, becoming more 'data-driven'.

My position consists of: making bills, maintaining the database, etc. But I have the freedom to spend some time inspecting the infrastructure, searching for the points that could be improved or changed. The intel that I gather will be used in a year, where the real data science works starts.

I do the same work that the others do in the department, but I spend a little more time automatizing the process - gathering a collection of small scripts (I write in Python). When something requires a decision, I make a lot of visualizations while we debate. I also explore our data, making reports with Jupiter Notebooks. There isn't much model building though, only a few regressions.  

It's fun to help build the foundations of something. 

I would like to hear your advice and tips about how to deal with a challenge like this. What would you do to prepare a medium/big company to make a smooth transition into a data-driven business?",t2_159glx,[Request] Advice and tips to apply Data Science methods into a business.,discussion,t3_heyi95,0.91,76,Discussion,76,1593022437.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, everyone! After years of learning about data science in my spare time, I got a job that&amp;#39;ll allow me to put the knowledge into practice - very exciting.  The company - which deals with electrical equipment - wants to make a gradual transformation in its administration, becoming more &amp;#39;data-driven&amp;#39;.&lt;/p&gt;

&lt;p&gt;My position consists of: making bills, maintaining the database, etc. But I have the freedom to spend some time inspecting the infrastructure, searching for the points that could be improved or changed. The intel that I gather will be used in a year, where the real data science works starts.&lt;/p&gt;

&lt;p&gt;I do the same work that the others do in the department, but I spend a little more time automatizing the process - gathering a collection of small scripts (I write in Python). When something requires a decision, I make a lot of visualizations while we debate. I also explore our data, making reports with Jupiter Notebooks. There isn&amp;#39;t much model building though, only a few regressions.  &lt;/p&gt;

&lt;p&gt;It&amp;#39;s fun to help build the foundations of something. &lt;/p&gt;

&lt;p&gt;I would like to hear your advice and tips about how to deal with a challenge like this. What would you do to prepare a medium/big company to make a smooth transition into a data-driven business?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",heyi95,dropwaterfall,22,/r/datascience/comments/heyi95/request_advice_and_tips_to_apply_data_science/,https://www.reddit.com/r/datascience/comments/heyi95/request_advice_and_tips_to_apply_data_science/,1592993637.0
r/datascience,"I have a very simple python RFM model (scoring customers based on transaction recency, frequency, monetary value) and I want to apply it to a customer database. (in fact, just one table in a database)

The database is hosted on AWS and I can access it through MySQL Workbench.

What I currently do is download the transactions every week, run the python model on my laptop, and tell management the results.

I'd like to automate this and host my python model somewhere that automatically runs on the transactions every week, and applies the results to the database. The results will just be a new column in the table and each customer will have their labels updated every week.

e.g.

|Customer|New RFM Column|
|:-|:-|
|Jimmy|Great Customer|
|Mary|About to Churn|
|Joe|Churned|

The problem is I don't even know where to start. I'm OK with SQL, decent with python, but have not ventured into cloud hosted models yet.  So I would appreciate some pointers in the right direction.

I guess my first step would be a proof of concept on a jupyter notebook or something.  Simply try and connect to the database, crunch the numbers, and insert the results.

There's a tutorial [here](https://cooldata.wordpress.com/2014/02/26/automate-rfm-scoring-of-your-donors-with-this-python-script/) that's kind of the same idea. They run the same RFM script on a SQL database, but only saves a csv at the end rather than merging it back to the table. And it's not cloud hosted. I would like to join the results back onto the original customer database. Or perhaps create a new table altogether with just the customer ID and result column.

**tl;dr** my python script is stuck on my laptop, and the data is stuck in the cloud. I want to go hands off and have my script running on the database in the cloud without me. Could it even be an api of some sort? And have the database itself send data to the api on a weekly basis?

Any tips appreciated.",t2_xk5mr,Best way to link a model to an already up and running database? [noob question],projects,t3_hfisui,0.33,0,Projects,0,1593104160.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a very simple python RFM model (scoring customers based on transaction recency, frequency, monetary value) and I want to apply it to a customer database. (in fact, just one table in a database)&lt;/p&gt;

&lt;p&gt;The database is hosted on AWS and I can access it through MySQL Workbench.&lt;/p&gt;

&lt;p&gt;What I currently do is download the transactions every week, run the python model on my laptop, and tell management the results.&lt;/p&gt;

&lt;p&gt;I&amp;#39;d like to automate this and host my python model somewhere that automatically runs on the transactions every week, and applies the results to the database. The results will just be a new column in the table and each customer will have their labels updated every week.&lt;/p&gt;

&lt;p&gt;e.g.&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=""left""&gt;Customer&lt;/th&gt;
&lt;th align=""left""&gt;New RFM Column&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Jimmy&lt;/td&gt;
&lt;td align=""left""&gt;Great Customer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Mary&lt;/td&gt;
&lt;td align=""left""&gt;About to Churn&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;Joe&lt;/td&gt;
&lt;td align=""left""&gt;Churned&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;The problem is I don&amp;#39;t even know where to start. I&amp;#39;m OK with SQL, decent with python, but have not ventured into cloud hosted models yet.  So I would appreciate some pointers in the right direction.&lt;/p&gt;

&lt;p&gt;I guess my first step would be a proof of concept on a jupyter notebook or something.  Simply try and connect to the database, crunch the numbers, and insert the results.&lt;/p&gt;

&lt;p&gt;There&amp;#39;s a tutorial &lt;a href=""https://cooldata.wordpress.com/2014/02/26/automate-rfm-scoring-of-your-donors-with-this-python-script/""&gt;here&lt;/a&gt; that&amp;#39;s kind of the same idea. They run the same RFM script on a SQL database, but only saves a csv at the end rather than merging it back to the table. And it&amp;#39;s not cloud hosted. I would like to join the results back onto the original customer database. Or perhaps create a new table altogether with just the customer ID and result column.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; my python script is stuck on my laptop, and the data is stuck in the cloud. I want to go hands off and have my script running on the database in the cloud without me. Could it even be an api of some sort? And have the database itself send data to the api on a weekly basis?&lt;/p&gt;

&lt;p&gt;Any tips appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfisui,Scutterbum,5,/r/datascience/comments/hfisui/best_way_to_link_a_model_to_an_already_up_and/,https://www.reddit.com/r/datascience/comments/hfisui/best_way_to_link_a_model_to_an_already_up_and/,1593075360.0
r/datascience,"Hi all,I have been a marketing analyst for quite a while now, focusing mainly on SQL. I know some Python basics which have become rusty over time. Therefore I am looking for a course or basecamp to brush up my skills.

Some things I am looking for:

* It should focus on Python. I already know the basics in Stats, SQL, etc.
* It should be as applicable for a marketing context as possible. E.g. rather than simple coding exercising it would be nice if it focused on projects
* The content of the projects could be about data analysis but also about automating things

&amp;#x200B;

I found DataQuest and DataCamp, but wasn't sure which one (or something completely different) is better.

&amp;#x200B;

Any recommendations would be highly appreciated! Thank you very much in advance! :)",t2_wk3f9,Looking for a Python focused Marketing Analysis course,education,t3_hfidkb,0.5,0,Education,0,1593101696.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,I have been a marketing analyst for quite a while now, focusing mainly on SQL. I know some Python basics which have become rusty over time. Therefore I am looking for a course or basecamp to brush up my skills.&lt;/p&gt;

&lt;p&gt;Some things I am looking for:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It should focus on Python. I already know the basics in Stats, SQL, etc.&lt;/li&gt;
&lt;li&gt;It should be as applicable for a marketing context as possible. E.g. rather than simple coding exercising it would be nice if it focused on projects&lt;/li&gt;
&lt;li&gt;The content of the projects could be about data analysis but also about automating things&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I found DataQuest and DataCamp, but wasn&amp;#39;t sure which one (or something completely different) is better.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any recommendations would be highly appreciated! Thank you very much in advance! :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfidkb,dirodoro,2,/r/datascience/comments/hfidkb/looking_for_a_python_focused_marketing_analysis/,https://www.reddit.com/r/datascience/comments/hfidkb/looking_for_a_python_focused_marketing_analysis/,1593072896.0
r/datascience,"I read an old post on this subreddit about someone who had an easier time finding a data science job after they posted some data analysis projects on github. I've found some interesting projects and datasets from kaggle that I could do some analysis on to show what I know. However, is that a waste of my time or would that actually help me land a job in this field?",t2_17iju0,Is it worth the time to post data science projects on github to stand out to recruiters/employers?,,t3_hfcin7,0.83,4,,4,1593073390.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I read an old post on this subreddit about someone who had an easier time finding a data science job after they posted some data analysis projects on github. I&amp;#39;ve found some interesting projects and datasets from kaggle that I could do some analysis on to show what I know. However, is that a waste of my time or would that actually help me land a job in this field?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfcin7,datdutho,8,/r/datascience/comments/hfcin7/is_it_worth_the_time_to_post_data_science/,https://www.reddit.com/r/datascience/comments/hfcin7/is_it_worth_the_time_to_post_data_science/,1593044590.0
r/datascience,"Just curious, anyone make money from ads or affiliate marketing?",t2_4cf9hjyb,Anyone here make money from their data science blog?,discussion,t3_hfe96s,0.44,0,Discussion,0,1593080447.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just curious, anyone make money from ads or affiliate marketing?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hfe96s,iloveblazepizza,1,/r/datascience/comments/hfe96s/anyone_here_make_money_from_their_data_science/,https://www.reddit.com/r/datascience/comments/hfe96s/anyone_here_make_money_from_their_data_science/,1593051647.0
r/datascience,"suppose I'm on R running a logistic regression and I'm iterating through the model adding and subtracting variables. Besides maybe printing the model summary and paste it into an excel tab, is there an easier way to store the model for easy comparison (such as AIC, parameters, coefficients etc).  Curious to see what options are available.

&amp;#x200B;

Thanks",t2_i6go6an,"When you iterate a model multiple times, how do keep track of it all for comparison?",projects,t3_hf33sr,0.75,4,Projects,4,1593041636.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;suppose I&amp;#39;m on R running a logistic regression and I&amp;#39;m iterating through the model adding and subtracting variables. Besides maybe printing the model summary and paste it into an excel tab, is there an easier way to store the model for easy comparison (such as AIC, parameters, coefficients etc).  Curious to see what options are available.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hf33sr,mrdlau,8,/r/datascience/comments/hf33sr/when_you_iterate_a_model_multiple_times_how_do/,https://www.reddit.com/r/datascience/comments/hf33sr/when_you_iterate_a_model_multiple_times_how_do/,1593012836.0
r/datascience,"Many of us usually have at least one thing that we know we need to do. And if somehow we managed to sit down and do it from start to finish. Our life would be better because of it. The problem is that people put off that thing, they do anything under the sun to distract themselves.

Being a person who naturally gets distracted easily and was surely one of the worst procrastinators. I can confidently say it's never too late to make a change. Because if somehow even I managed to find little strategies and create little short cuts to become someone who can concentrate for long periods of time. Then you can too!

\#1 Why it's so important?

First of all, it's probably not a secret that getting sidetracked nowadays is easier than ever. We are constantly bombarded with ads and online marketing. In fact, according to research, it takes around 15-20 min. to get back to your 100% concentration after getting distracted. Basically, if we cut to the chase - this new distracting digital age creates a huge demand for people who can resist distraction and concentrate.

2#The bar is so lower than you think

If you can dive in even for one hour on your most important thing for the day with a ruthless and intense focus. You will make substantial progress in your life. And as you get used to that hour of concentration. You can upgrade that to 2 or 3 hours. Just think how much intense focus that is. You will skyrocket past your goals!

3# Guilt-free pleasure and balance

I know that many of us want to have a balanced life. We want to achieve something or do something meaningful but still enjoy life. For example, maybe you want to work on your personal projects, but at the same time, you don't want to give up video games. This was one of the biggest pains I struggled myself. I would play a lot of video games but then at the same time I would feel guilty for not making progress on my personal goals. And it's funny because the solution is so simple. You can play the crap out of those video games after you put a tremendous amount of focus on something else. This way you don't feel guilty and can fully immerse yourself into video games.

And if the perks of mastering concentration don't entice you, you can stop here...

But if it interests you, consider reaching out to me - I'd be happy to answer all of your questions!",t2_4tlo0e4n,Why the ability to concentrate is the most important skill in 2020,career,t3_hecc72,0.96,643,Career,643,1592937831.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Many of us usually have at least one thing that we know we need to do. And if somehow we managed to sit down and do it from start to finish. Our life would be better because of it. The problem is that people put off that thing, they do anything under the sun to distract themselves.&lt;/p&gt;

&lt;p&gt;Being a person who naturally gets distracted easily and was surely one of the worst procrastinators. I can confidently say it&amp;#39;s never too late to make a change. Because if somehow even I managed to find little strategies and create little short cuts to become someone who can concentrate for long periods of time. Then you can too!&lt;/p&gt;

&lt;p&gt;#1 Why it&amp;#39;s so important?&lt;/p&gt;

&lt;p&gt;First of all, it&amp;#39;s probably not a secret that getting sidetracked nowadays is easier than ever. We are constantly bombarded with ads and online marketing. In fact, according to research, it takes around 15-20 min. to get back to your 100% concentration after getting distracted. Basically, if we cut to the chase - this new distracting digital age creates a huge demand for people who can resist distraction and concentrate.&lt;/p&gt;

&lt;p&gt;2#The bar is so lower than you think&lt;/p&gt;

&lt;p&gt;If you can dive in even for one hour on your most important thing for the day with a ruthless and intense focus. You will make substantial progress in your life. And as you get used to that hour of concentration. You can upgrade that to 2 or 3 hours. Just think how much intense focus that is. You will skyrocket past your goals!&lt;/p&gt;

&lt;p&gt;3# Guilt-free pleasure and balance&lt;/p&gt;

&lt;p&gt;I know that many of us want to have a balanced life. We want to achieve something or do something meaningful but still enjoy life. For example, maybe you want to work on your personal projects, but at the same time, you don&amp;#39;t want to give up video games. This was one of the biggest pains I struggled myself. I would play a lot of video games but then at the same time I would feel guilty for not making progress on my personal goals. And it&amp;#39;s funny because the solution is so simple. You can play the crap out of those video games after you put a tremendous amount of focus on something else. This way you don&amp;#39;t feel guilty and can fully immerse yourself into video games.&lt;/p&gt;

&lt;p&gt;And if the perks of mastering concentration don&amp;#39;t entice you, you can stop here...&lt;/p&gt;

&lt;p&gt;But if it interests you, consider reaching out to me - I&amp;#39;d be happy to answer all of your questions!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hecc72,Karlos224,114,/r/datascience/comments/hecc72/why_the_ability_to_concentrate_is_the_most/,https://www.reddit.com/r/datascience/comments/hecc72/why_the_ability_to_concentrate_is_the_most/,1592909031.0
r/datascience,"I need to do some multivariate regression but can't find a Python package that also analyses the correlation between the dependent variables.

Is there anything out there? Python preferred but R may also work.

Not sure if this is the right subreddit but imo it doesn't fit in /r/statistics or /r/programming and /r/learndatascience is dead.",t2_kn00t,Multivariate Regression - any Python or R packages ?,tooling,t3_hexgbn,0.8,6,Tooling,6,1593016683.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I need to do some multivariate regression but can&amp;#39;t find a Python package that also analyses the correlation between the dependent variables.&lt;/p&gt;

&lt;p&gt;Is there anything out there? Python preferred but R may also work.&lt;/p&gt;

&lt;p&gt;Not sure if this is the right subreddit but imo it doesn&amp;#39;t fit in &lt;a href=""/r/statistics""&gt;/r/statistics&lt;/a&gt; or &lt;a href=""/r/programming""&gt;/r/programming&lt;/a&gt; and &lt;a href=""/r/learndatascience""&gt;/r/learndatascience&lt;/a&gt; is dead.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hexgbn,Yojihito,19,/r/datascience/comments/hexgbn/multivariate_regression_any_python_or_r_packages/,https://www.reddit.com/r/datascience/comments/hexgbn/multivariate_regression_any_python_or_r_packages/,1592987883.0
r/datascience,,t2_i86kg,"What are some good resources (course, book etc) to learn all things data up to but not actual analytics, so things like ingestion, cleaning and preparation?",discussion,t3_hes0tm,0.8,19,Discussion,19,1592992677.0,,hes0tm,chirau,13,/r/datascience/comments/hes0tm/what_are_some_good_resources_course_book_etc_to/,https://www.reddit.com/r/datascience/comments/hes0tm/what_are_some_good_resources_course_book_etc_to/,1592963877.0
r/datascience,"Does anyone use VBA and find their code to just run slower on average compared to other languages?

Overall it just seems like a lot is missing and what might take a second or two to run in Python might take 10+ in VBA. 

For example, just to write a Sub to transfer 4 columns with 4500 rows each to another workbook takes about 10-15 seconds....

Or maybe I’m just inefficient...

EDIT: I would use Python, but I work in the military. Installation is difficult in itself and making products that anyone can run without an Admin token is even tougher...",t2_1k7qhdhf,VBA Efficiency,discussion,t3_hesjb8,0.73,8,Discussion,8,1592994684.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone use VBA and find their code to just run slower on average compared to other languages?&lt;/p&gt;

&lt;p&gt;Overall it just seems like a lot is missing and what might take a second or two to run in Python might take 10+ in VBA. &lt;/p&gt;

&lt;p&gt;For example, just to write a Sub to transfer 4 columns with 4500 rows each to another workbook takes about 10-15 seconds....&lt;/p&gt;

&lt;p&gt;Or maybe I’m just inefficient...&lt;/p&gt;

&lt;p&gt;EDIT: I would use Python, but I work in the military. Installation is difficult in itself and making products that anyone can run without an Admin token is even tougher...&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hesjb8,Siba911,27,/r/datascience/comments/hesjb8/vba_efficiency/,https://www.reddit.com/r/datascience/comments/hesjb8/vba_efficiency/,1592965884.0
r/datascience,,t2_bi6kztp,XKCD: Modeling Study,fun,t3_he41c8,0.96,225,Fun/Trivia,225,1592899886.0,,he41c8,rohan36,10,/r/datascience/comments/he41c8/xkcd_modeling_study/,https://xkcd.com/2323/,1592871086.0
r/datascience,"In my experience, building legit data science operations requires massive capital commitment (not to mention cultural commitment). I've been thinking of this recently and it seems a lot of companies -- especially start-ups -- *vastly* underestimate infrastructure costs (data storage/transfer/processing). Meaning you're likely to drop &gt;$1M just to get a foundation, and unless you have a clear value proposition from day one you're very likely to fail. That's why I think the best data operations are at FAANG's who can subsidize via monopoly profit margins and/or start-ups who can subsidize with venture capital investment. And that makes me wonder if the field can survive real market forces. Does anyone have similar concerns about the future of the field due to some of those basic economics?",t2_2gln0h10,Economics of Data Science,discussion,t3_heg5yg,0.67,4,Discussion,4,1592953297.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my experience, building legit data science operations requires massive capital commitment (not to mention cultural commitment). I&amp;#39;ve been thinking of this recently and it seems a lot of companies -- especially start-ups -- &lt;em&gt;vastly&lt;/em&gt; underestimate infrastructure costs (data storage/transfer/processing). Meaning you&amp;#39;re likely to drop &amp;gt;$1M just to get a foundation, and unless you have a clear value proposition from day one you&amp;#39;re very likely to fail. That&amp;#39;s why I think the best data operations are at FAANG&amp;#39;s who can subsidize via monopoly profit margins and/or start-ups who can subsidize with venture capital investment. And that makes me wonder if the field can survive real market forces. Does anyone have similar concerns about the future of the field due to some of those basic economics?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",heg5yg,poopybutbaby,13,/r/datascience/comments/heg5yg/economics_of_data_science/,https://www.reddit.com/r/datascience/comments/heg5yg/economics_of_data_science/,1592924497.0
r/datascience,"I work for an ecommerce company, and I'm looking to invest in a personalization platform for my Data Science team that will allow us to easily deploy/test models, but also allow the flexibility to deploy custom models. Our current implementation is super manual, everything is built from scratch and needs to be refactored to make deployment/retraining simpler and faster. 

  
AWS Personalize service addresses many of our needs, especially the clean and simple handling of user-item interaction data (AWS is also the obvious first choice because it where we store all of our data), however you have to use their pre built black box models... which is fine for testing, but I'd like to be able to then extract those models (or at least the architecture), tweak/refine them, and then redeploy using the same platform.

Any thoughts/comments on this would be hugely helpful!",t2_45jwt7z5,Recommendation Systems (using AWS personalize as deployment platform),discussion,t3_heljeo,0.6,1,Discussion,1,1592970348.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work for an ecommerce company, and I&amp;#39;m looking to invest in a personalization platform for my Data Science team that will allow us to easily deploy/test models, but also allow the flexibility to deploy custom models. Our current implementation is super manual, everything is built from scratch and needs to be refactored to make deployment/retraining simpler and faster. &lt;/p&gt;

&lt;p&gt;AWS Personalize service addresses many of our needs, especially the clean and simple handling of user-item interaction data (AWS is also the obvious first choice because it where we store all of our data), however you have to use their pre built black box models... which is fine for testing, but I&amp;#39;d like to be able to then extract those models (or at least the architecture), tweak/refine them, and then redeploy using the same platform.&lt;/p&gt;

&lt;p&gt;Any thoughts/comments on this would be hugely helpful!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",heljeo,john-c34,4,/r/datascience/comments/heljeo/recommendation_systems_using_aws_personalize_as/,https://www.reddit.com/r/datascience/comments/heljeo/recommendation_systems_using_aws_personalize_as/,1592941548.0
r/datascience,"Professionals here, which lib do you use mostly in your career, between matplotlib and seaborn. I am currently self educating with a udemy course and YouTube. I found matplotlib very complicated and seaborn more straightforward. I don't normally proceed without getting a good grasp of what I'm currently learning but matplotlib is just complicated.

Do you think I should just go on since I understand (newbie level understanding) seaborn or is matplotlib so important I have to know it?",t2_3j9wy1ll,Which data visualization lib do you use,,t3_hei7ho,0.67,1,,1,1592959868.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Professionals here, which lib do you use mostly in your career, between matplotlib and seaborn. I am currently self educating with a udemy course and YouTube. I found matplotlib very complicated and seaborn more straightforward. I don&amp;#39;t normally proceed without getting a good grasp of what I&amp;#39;m currently learning but matplotlib is just complicated.&lt;/p&gt;

&lt;p&gt;Do you think I should just go on since I understand (newbie level understanding) seaborn or is matplotlib so important I have to know it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hei7ho,brian_o_mars,8,/r/datascience/comments/hei7ho/which_data_visualization_lib_do_you_use/,https://www.reddit.com/r/datascience/comments/hei7ho/which_data_visualization_lib_do_you_use/,1592931068.0
r/datascience,"For starters, I’m a summer intern doing some data work for a large company that isn’t centered around stereotypical “data” stuff (for privacy that’s about as much as I can share). This company also seemingly doesn’t have a data analytics team or person, to the extent that I was brought on and have essentially free will on how I’m operating in my position. Again, sorry for the lack of information, but for context, the person who I’m working under was trying to do a very scaled back version of the project I’ve taken in Excel (in a very very basic spreadsheet). Naturally, I threw it into R to analyze the data, and they looked at me like I was some sort of computer God. Anyways, hopefully you can gather some context of the situation I’m in and the void in the company there undoubtedly is.

My question is, for those of you that have been in my situation, how exactly do you present the “hey, I can do this for you full-time, and this is how incredibly valuable having someone like this would be”? Again, it’s not a mom-and-pop startup, so even in this climate they undoubtedly have the capital for the position someway somehow. I get this is maybe more of a general “young adult looking to fill a void” question, but based on the lack of work done in the data, and considering its likely that the majority
of us have at least seen some sort of iteration of this scenario, I figured this would be the best place to ask.

FWIW, I have my bachelors and am working on my masters. Also, this isn’t an issue that is commonly faced by those of us working in data of “I don’t know how to best communicate these results with someone who isn’t fluent or comfortable in data vernacular”, it’s just that I don’t know how to present my value in a way that’s not overstepping my bounds or under-presenting(?) my value as a data scientist.",t2_4jo7xlko,Presenting Your Value,career,t3_hdsxcj,0.97,107,Career,107,1592863459.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For starters, I’m a summer intern doing some data work for a large company that isn’t centered around stereotypical “data” stuff (for privacy that’s about as much as I can share). This company also seemingly doesn’t have a data analytics team or person, to the extent that I was brought on and have essentially free will on how I’m operating in my position. Again, sorry for the lack of information, but for context, the person who I’m working under was trying to do a very scaled back version of the project I’ve taken in Excel (in a very very basic spreadsheet). Naturally, I threw it into R to analyze the data, and they looked at me like I was some sort of computer God. Anyways, hopefully you can gather some context of the situation I’m in and the void in the company there undoubtedly is.&lt;/p&gt;

&lt;p&gt;My question is, for those of you that have been in my situation, how exactly do you present the “hey, I can do this for you full-time, and this is how incredibly valuable having someone like this would be”? Again, it’s not a mom-and-pop startup, so even in this climate they undoubtedly have the capital for the position someway somehow. I get this is maybe more of a general “young adult looking to fill a void” question, but based on the lack of work done in the data, and considering its likely that the majority
of us have at least seen some sort of iteration of this scenario, I figured this would be the best place to ask.&lt;/p&gt;

&lt;p&gt;FWIW, I have my bachelors and am working on my masters. Also, this isn’t an issue that is commonly faced by those of us working in data of “I don’t know how to best communicate these results with someone who isn’t fluent or comfortable in data vernacular”, it’s just that I don’t know how to present my value in a way that’s not overstepping my bounds or under-presenting(?) my value as a data scientist.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdsxcj,hungrygreg97,23,/r/datascience/comments/hdsxcj/presenting_your_value/,https://www.reddit.com/r/datascience/comments/hdsxcj/presenting_your_value/,1592834659.0
r/datascience,"Data science often involves discovering or having to learn related mathematical /statistical concepts while working on a project. People refer to this as ""Going down the rabbit hole"". 

For example, while working on a recommender engine, I decided to implement NMF. I understood it conceptually but decided to study matrix factorization deeply (had forgotten some aspects after high school). That in-turn led me to read about rank, span et all more deeply. Long story short, i spent 1 week learning about matrix and matrix operations. I realized I spent more time than necessary.

My question is

* How does one know how deep a rabbit hole one must go? 
* How to intelligently criss-cross between parallel rabbit holes gaining enough *'what you were looking for'* rather than going too deep",t2_1umdosna,How to traverse the rabbit hole in Data Science,discussion,t3_hdt3wm,0.93,56,Discussion,56,1592864115.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Data science often involves discovering or having to learn related mathematical /statistical concepts while working on a project. People refer to this as &amp;quot;Going down the rabbit hole&amp;quot;. &lt;/p&gt;

&lt;p&gt;For example, while working on a recommender engine, I decided to implement NMF. I understood it conceptually but decided to study matrix factorization deeply (had forgotten some aspects after high school). That in-turn led me to read about rank, span et all more deeply. Long story short, i spent 1 week learning about matrix and matrix operations. I realized I spent more time than necessary.&lt;/p&gt;

&lt;p&gt;My question is&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How does one know how deep a rabbit hole one must go? &lt;/li&gt;
&lt;li&gt;How to intelligently criss-cross between parallel rabbit holes gaining enough &lt;em&gt;&amp;#39;what you were looking for&amp;#39;&lt;/em&gt; rather than going too deep&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdt3wm,venkarafa,14,/r/datascience/comments/hdt3wm/how_to_traverse_the_rabbit_hole_in_data_science/,https://www.reddit.com/r/datascience/comments/hdt3wm/how_to_traverse_the_rabbit_hole_in_data_science/,1592835315.0
r/datascience,"I usually think once I get a model, I share the insights via a presentation, I'm done. But then I have limited experience in data science. What does it mean to actually ""deploy"" a model? I understand it's using it in practice, like using a classifier to predict whether someone has a disease. But what are some of the steps that needs to happen to ""deploy"" it? It can't be as simple as telling your boss ""hey, here's a good model"". 

Just want to know what happens in the real world after you have validated a model and it performed well on the test dataset.

&amp;#x200B;

Thanks",t2_33bizuj,"how are data science models ""deployed"" usually?",discussion,t3_he52o6,0.73,5,Discussion,5,1592903775.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I usually think once I get a model, I share the insights via a presentation, I&amp;#39;m done. But then I have limited experience in data science. What does it mean to actually &amp;quot;deploy&amp;quot; a model? I understand it&amp;#39;s using it in practice, like using a classifier to predict whether someone has a disease. But what are some of the steps that needs to happen to &amp;quot;deploy&amp;quot; it? It can&amp;#39;t be as simple as telling your boss &amp;quot;hey, here&amp;#39;s a good model&amp;quot;. &lt;/p&gt;

&lt;p&gt;Just want to know what happens in the real world after you have validated a model and it performed well on the test dataset.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",he52o6,engineheat,6,/r/datascience/comments/he52o6/how_are_data_science_models_deployed_usually/,https://www.reddit.com/r/datascience/comments/he52o6/how_are_data_science_models_deployed_usually/,1592874975.0
r/datascience,"I am in a unique position. I am currently a Business Analyst at a Casino, and it's unique. I do Data Science tasks at times like Time Series Forecasting, A/B Testing, etc... However, most of our work gets ignored. The casino is always making money, and they do things by their gut. Should I make a move?

I want to continue to grow my skills. I currently do most of my work in Excel, but I am skilled in Python, SQL, and Tableau.  I was wondering if I should take a leap to another organization because I'm currently safe and secure in my salary - but I don't think I'll grow. I sometimes also don't feel worth... I have an MS in Business Analytics with a concentration in Data Science. I graduated in 2018. Just looking for some input.",t2_1278ro,To be patient or to be bold?,career,t3_he950f,0.67,2,Career,2,1592920902.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am in a unique position. I am currently a Business Analyst at a Casino, and it&amp;#39;s unique. I do Data Science tasks at times like Time Series Forecasting, A/B Testing, etc... However, most of our work gets ignored. The casino is always making money, and they do things by their gut. Should I make a move?&lt;/p&gt;

&lt;p&gt;I want to continue to grow my skills. I currently do most of my work in Excel, but I am skilled in Python, SQL, and Tableau.  I was wondering if I should take a leap to another organization because I&amp;#39;m currently safe and secure in my salary - but I don&amp;#39;t think I&amp;#39;ll grow. I sometimes also don&amp;#39;t feel worth... I have an MS in Business Analytics with a concentration in Data Science. I graduated in 2018. Just looking for some input.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",he950f,littlemattjag,5,/r/datascience/comments/he950f/to_be_patient_or_to_be_bold/,https://www.reddit.com/r/datascience/comments/he950f/to_be_patient_or_to_be_bold/,1592892102.0
r/datascience,"I've got 2TB of labeled image data sitting on a server. I need to train a Pytorch model on this data. I'd appreciate any advice as to how to deal with the network bottleneck. Is there a magic trick to this or am I going to be stuck training for a week?

My current plan is to set up the images in hdf5 format on the server with a csv for the labels and access the data over smb. The server is windows, the machine doing the training is running Ubuntu 18.04.

Thanks in advance!",t2_13kjj7,"First time training on big dataset, need advice on best practices",,t3_he41cl,0.75,4,,4,1592899887.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve got 2TB of labeled image data sitting on a server. I need to train a Pytorch model on this data. I&amp;#39;d appreciate any advice as to how to deal with the network bottleneck. Is there a magic trick to this or am I going to be stuck training for a week?&lt;/p&gt;

&lt;p&gt;My current plan is to set up the images in hdf5 format on the server with a csv for the labels and access the data over smb. The server is windows, the machine doing the training is running Ubuntu 18.04.&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",he41cl,CalyxOfHelld,10,/r/datascience/comments/he41cl/first_time_training_on_big_dataset_need_advice_on/,https://www.reddit.com/r/datascience/comments/he41cl/first_time_training_on_big_dataset_need_advice_on/,1592871087.0
r/datascience,"I really hope someone can help me figure this out and that this post is allowed here. I'm sorry if I violate the rules. I don't think I can find this answer by reading FAQ or browsing on the sub.

So, you have hundreds of pages with hundreds of variables such as time customers visit the page, how long they view the page, the gender of the customer, the country origin of the customers, etc.

You are given the task to find out *which variable that influence the target the most* and *how likely a visitor is to buy based on their historical data*. Initially, I think my solution is **predict the customer churn** by following [this](https://towardsdatascience.com/hands-on-predict-customer-churn-5c2a42806266) tutorial. But I find it very hard to copy the model using the code and I'm not even sure my solution is correct. I keep finding errors on the code in that tutorial.

The steps that I propose are:

1. Reducing customer churn by identifying potential churn candidates
2. Collecting &amp; cleaning relevant data using:
3. Choosing which features we want to include in our data, prepare the data, clean the data
4. Find the right model to train the data (logistic regression &amp; model testing might be possible)
5. Use prepared data to feed the model 
6. Evaluate and interpret results

Tools, libraries, etc.:

* Python
* pandas (to structure data)
* plotly/ matplotlib (to visualize data)
* scikit-learn (to split dataset and train our predictive model)
* linear regression

Can someone tell me if I'm correct or not? If not, what should I better do? Should I find similar case, tutorial, research article? If you are given task, what should you do first if you don't have the data and only hypothetical questions like this?",t2_k1a4t,What's the best way to predict customer's behavior using machine learning algorithm?,projects,t3_hed4jf,0.42,0,Projects,0,1592941526.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I really hope someone can help me figure this out and that this post is allowed here. I&amp;#39;m sorry if I violate the rules. I don&amp;#39;t think I can find this answer by reading FAQ or browsing on the sub.&lt;/p&gt;

&lt;p&gt;So, you have hundreds of pages with hundreds of variables such as time customers visit the page, how long they view the page, the gender of the customer, the country origin of the customers, etc.&lt;/p&gt;

&lt;p&gt;You are given the task to find out &lt;em&gt;which variable that influence the target the most&lt;/em&gt; and &lt;em&gt;how likely a visitor is to buy based on their historical data&lt;/em&gt;. Initially, I think my solution is &lt;strong&gt;predict the customer churn&lt;/strong&gt; by following &lt;a href=""https://towardsdatascience.com/hands-on-predict-customer-churn-5c2a42806266""&gt;this&lt;/a&gt; tutorial. But I find it very hard to copy the model using the code and I&amp;#39;m not even sure my solution is correct. I keep finding errors on the code in that tutorial.&lt;/p&gt;

&lt;p&gt;The steps that I propose are:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Reducing customer churn by identifying potential churn candidates&lt;/li&gt;
&lt;li&gt;Collecting &amp;amp; cleaning relevant data using:&lt;/li&gt;
&lt;li&gt;Choosing which features we want to include in our data, prepare the data, clean the data&lt;/li&gt;
&lt;li&gt;Find the right model to train the data (logistic regression &amp;amp; model testing might be possible)&lt;/li&gt;
&lt;li&gt;Use prepared data to feed the model &lt;/li&gt;
&lt;li&gt;Evaluate and interpret results&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Tools, libraries, etc.:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;pandas (to structure data)&lt;/li&gt;
&lt;li&gt;plotly/ matplotlib (to visualize data)&lt;/li&gt;
&lt;li&gt;scikit-learn (to split dataset and train our predictive model)&lt;/li&gt;
&lt;li&gt;linear regression&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Can someone tell me if I&amp;#39;m correct or not? If not, what should I better do? Should I find similar case, tutorial, research article? If you are given task, what should you do first if you don&amp;#39;t have the data and only hypothetical questions like this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hed4jf,silveri5,24,/r/datascience/comments/hed4jf/whats_the_best_way_to_predict_customers_behavior/,https://www.reddit.com/r/datascience/comments/hed4jf/whats_the_best_way_to_predict_customers_behavior/,1592912726.0
r/datascience,"Let's say during interview, you talk about your current work (which is normal). But let's say the interviewer do a deep dive into your current work and you are tempted to discuss the insights gained or the outcome of a model. 

Is this appropriate? Will it be seen as divulging proprietary company info and therefore might actually hurt you in the interview?",t2_33bizuj,Is it okay to discuss the results of a model at your current job to a potential new employer?,,t3_hdip81,0.96,134,Job Search,134,1592818104.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Let&amp;#39;s say during interview, you talk about your current work (which is normal). But let&amp;#39;s say the interviewer do a deep dive into your current work and you are tempted to discuss the insights gained or the outcome of a model. &lt;/p&gt;

&lt;p&gt;Is this appropriate? Will it be seen as divulging proprietary company info and therefore might actually hurt you in the interview?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdip81,engineheat,28,/r/datascience/comments/hdip81/is_it_okay_to_discuss_the_results_of_a_model_at/,https://www.reddit.com/r/datascience/comments/hdip81/is_it_okay_to_discuss_the_results_of_a_model_at/,1592789304.0
r/datascience,"Obviously I could say ""I analyze data through applied statistics"", but that would take away from the operations research, pipeline design, and deployment aspect of it all.

I can't seem to get a grip on providing an answer that doesn't turn into a 5 minute pitch on what the scientific method looks like in Data Governance.

Anybody been through anything similar?",t2_9miwkgx,"If you had to give a formal answer to a potential business partner, how would you describe what a Data Scientist does?",meta,t3_he39ri,0.75,2,Meta,2,1592897079.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Obviously I could say &amp;quot;I analyze data through applied statistics&amp;quot;, but that would take away from the operations research, pipeline design, and deployment aspect of it all.&lt;/p&gt;

&lt;p&gt;I can&amp;#39;t seem to get a grip on providing an answer that doesn&amp;#39;t turn into a 5 minute pitch on what the scientific method looks like in Data Governance.&lt;/p&gt;

&lt;p&gt;Anybody been through anything similar?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",he39ri,OneOverNever,5,/r/datascience/comments/he39ri/if_you_had_to_give_a_formal_answer_to_a_potential/,https://www.reddit.com/r/datascience/comments/he39ri/if_you_had_to_give_a_formal_answer_to_a_potential/,1592868279.0
r/datascience,,t2_2t86pj0o,Do you need to be good at maths areas like calculus in order to be a good data scientist?,education,t3_hdnscf,0.71,27,Education,27,1592840391.0,,hdnscf,differentDrip,66,/r/datascience/comments/hdnscf/do_you_need_to_be_good_at_maths_areas_like/,https://www.reddit.com/r/datascience/comments/hdnscf/do_you_need_to_be_good_at_maths_areas_like/,1592811591.0
r/datascience,"I know that competition for DS jobs in Bay Area and New York is fierce because there are a lot of more applicants there.  I'm in Chicago and I want to find my first job. I'm willing to move to a different town if it means that I can find a DS job there more easily. Also, I'm pretty content with getting a simple Data Analyst role.

Where in the US do you think is the least desirable location for Data Science/Analyst applicants? Austin, TX?",t2_58ug1yoj,Least competitive place in the US in terms of data science jobs,,t3_hdygvj,0.71,3,Job Search,3,1592881275.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know that competition for DS jobs in Bay Area and New York is fierce because there are a lot of more applicants there.  I&amp;#39;m in Chicago and I want to find my first job. I&amp;#39;m willing to move to a different town if it means that I can find a DS job there more easily. Also, I&amp;#39;m pretty content with getting a simple Data Analyst role.&lt;/p&gt;

&lt;p&gt;Where in the US do you think is the least desirable location for Data Science/Analyst applicants? Austin, TX?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdygvj,DesolateAbomination,8,/r/datascience/comments/hdygvj/least_competitive_place_in_the_us_in_terms_of/,https://www.reddit.com/r/datascience/comments/hdygvj/least_competitive_place_in_the_us_in_terms_of/,1592852475.0
r/datascience,"There have been quite a few changes in the subreddit over the past couple of years, both behind the scenes and more visibly.  As such, the mod team thought it would be a good time to discuss our vision for the subreddit and get feedback on these changes and our moderation more generally.

**Our Vision**

To some extent, our vision for the subreddit is perhaps easier to define by what we aren't trying to be, rather than what we want to be:

* We aren't trying to be a place for academic/technical discussions, since subreddits like r/MachineLearning, r/AskStatistics, and r/Python already cover those areas more specifically
* We aren't trying to be a place for learning about, transitioning into, or getting a job in data science, since there are countless other blogs and websites discussing how to do that
* We aren't trying to be a place for people or companies to promote themselves, either for commercial gain or simply to help them find a job

In a perfect world, r/datascience would simply be a social network for data science professionals to talk about anything related to work or not.  They could discuss something technical if it really interested them, but they would be just as likely to discuss sleeping habits or joke about leadership using buzzwords.

In essence, we are trying to be a ""**water cooler for people in the DS industry**""; having the kinds of conversations you might when you bump into someone while grabbing a coffee, or hanging out in the hallways of a conference between speakers.

&amp;#x200B;

**Our Moderation**

Unfortunately, the above vision has been hard to realize due to a number of factors.  We wanted to take some time to explain some of the reasoning behind our moderation decisions, in order to get feedback.  Here are some of the main reasons we remove posts:

1. **Blog/Project Links** \- People post links to a blog or project (often their own) with little to no discussion.  These are usually attempts at self-promotion, and at this point we will remove almost all of these regardless of the quality of content out of necessity.  In fact, certain commonly-used domains are entirely restricted.  
2. **Learners/Transitioners** \- People who want to become part of the industry, but are not currently.  In theory there is no problem with beginners involved in our conversations, but unfortunately the vast majority of these posts are very transactional in nature.  The subreddit is treated as a Career Development Center or Technical Advisor, rather than the ""water cooler"" mentioned before.  We originally planned to remove these posts completely, but a compromise was made to redirect them to the **Weekly Entering &amp; Transitioning Thread**. 
3. **Video Links, Surveys, and Listicles** \- These would be fine in theory, but in practice they have mostly tended to combine the negatives of blog links with the negative of being transactional.  It is easier just to remove them all on sight, though perhaps some could be added back with more moderator capacity.
4. **Memes** \- Dealing with memes was a difficult choice, since they often prompt great conversations and certainly are something one would expect for a ""water cooler"" environment.   
 On the other hand, they are usually pretty tacky and will overrun a large-ish subreddit if allowed.  Thus, we remove memes on any day but monday.
5. **Technical Questions** \- This category is difficult, and decisions may differ depending on the moderator.  Some questions clearly belong in one of the more technical subreddits, and are directed there.  Beyond that, we assess whether it feels like a ""Stack Overflow"" question, a homework question, or a ""Google Search"" question, and then direct people to those places if needed.
6. **Junk/Low Effort** \- Name speaks for itself.  This is actually somewhat uncommon for our subreddit, though that may be due to reddit's automatic moderation at work.
7. **Politics/Off-topic** \- While eventually we wouldn't mind having off-topic conversations like you might have at a water cooler, currently we will tend to remove them for consistency sake.  Political discussions in particular are removed unless they are explicitly about data science, as we don't want the kind of trouble those conversations can lead to on reddit.

More generally than the above factors, we try to consider each post and ask ourselves if the subreddit is better or worse with that content on it.  As you might also notice, our mod team is often quite busy (more on that below), so sometimes we will leave removable posts up simply because they have a lot of activity by the time we see them.

&amp;#x200B;

**Our Future**

We are continuing to make changes to try to improve the subreddit:

* **Content -** In addition to our long-running weekly ""Entering &amp; Transitioning"" thread, we have tested ""Meme Mondays"" and ""DS Topic of the Week"" as additional content drivers.  Furthermore, some work has been done to advance the wiki.
* **Moderation Bot** \- Our new moderation bot, u/datascience-bot, has allowed us to automate some of our work, and will hopefully one day be trained (based on our manual removals) to actually take on a significant amount of the moderation.  
* **Removal Reasons** \- We want to improve our selection of removal reasons and associated text.  This will help provide the person with more context/resources around the removal, and will hopefully provide better labels for the moderation bot to learn from.
* **Flairs** \- We sorta had a process for giving flairs to long-time users, but it needs to be revisited.  The process around link flairs needs to be adjusted as well.  Our hope is to actually build this capability into the moderation bot, at some point.
* **Moderators** \- We recently lost a couple of long-time moderators, and frankly we probably never had as many moderators as we needed to accomplish our vision.  The subreddit has also grown significantly in size (10x in three years), and most of the existing mods have jobs and families that leave us with limited time for moderating the subreddit.  **Our plan is to begin recruiting new moderators as soon this State of the Subreddit discussion winds down.**  

&amp;#x200B;

Considering how long I have already made this post, I think I will leave it there.  **We welcome any questions, comments, or criticisms** about anything discussed here or about the subreddit and our moderation in general.",t2_6kl7i,[META] State of the Subreddit - 2020,meta,t3_hdmbkd,0.9,28,Meta Post of the Year,28,1592833601.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;There have been quite a few changes in the subreddit over the past couple of years, both behind the scenes and more visibly.  As such, the mod team thought it would be a good time to discuss our vision for the subreddit and get feedback on these changes and our moderation more generally.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Our Vision&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To some extent, our vision for the subreddit is perhaps easier to define by what we aren&amp;#39;t trying to be, rather than what we want to be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We aren&amp;#39;t trying to be a place for academic/technical discussions, since subreddits like &lt;a href=""/r/MachineLearning""&gt;r/MachineLearning&lt;/a&gt;, &lt;a href=""/r/AskStatistics""&gt;r/AskStatistics&lt;/a&gt;, and &lt;a href=""/r/Python""&gt;r/Python&lt;/a&gt; already cover those areas more specifically&lt;/li&gt;
&lt;li&gt;We aren&amp;#39;t trying to be a place for learning about, transitioning into, or getting a job in data science, since there are countless other blogs and websites discussing how to do that&lt;/li&gt;
&lt;li&gt;We aren&amp;#39;t trying to be a place for people or companies to promote themselves, either for commercial gain or simply to help them find a job&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In a perfect world, &lt;a href=""/r/datascience""&gt;r/datascience&lt;/a&gt; would simply be a social network for data science professionals to talk about anything related to work or not.  They could discuss something technical if it really interested them, but they would be just as likely to discuss sleeping habits or joke about leadership using buzzwords.&lt;/p&gt;

&lt;p&gt;In essence, we are trying to be a &amp;quot;&lt;strong&gt;water cooler for people in the DS industry&lt;/strong&gt;&amp;quot;; having the kinds of conversations you might when you bump into someone while grabbing a coffee, or hanging out in the hallways of a conference between speakers.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Our Moderation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, the above vision has been hard to realize due to a number of factors.  We wanted to take some time to explain some of the reasoning behind our moderation decisions, in order to get feedback.  Here are some of the main reasons we remove posts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Blog/Project Links&lt;/strong&gt; - People post links to a blog or project (often their own) with little to no discussion.  These are usually attempts at self-promotion, and at this point we will remove almost all of these regardless of the quality of content out of necessity.  In fact, certain commonly-used domains are entirely restricted.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learners/Transitioners&lt;/strong&gt; - People who want to become part of the industry, but are not currently.  In theory there is no problem with beginners involved in our conversations, but unfortunately the vast majority of these posts are very transactional in nature.  The subreddit is treated as a Career Development Center or Technical Advisor, rather than the &amp;quot;water cooler&amp;quot; mentioned before.  We originally planned to remove these posts completely, but a compromise was made to redirect them to the &lt;strong&gt;Weekly Entering &amp;amp; Transitioning Thread&lt;/strong&gt;. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Video Links, Surveys, and Listicles&lt;/strong&gt; - These would be fine in theory, but in practice they have mostly tended to combine the negatives of blog links with the negative of being transactional.  It is easier just to remove them all on sight, though perhaps some could be added back with more moderator capacity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memes&lt;/strong&gt; - Dealing with memes was a difficult choice, since they often prompt great conversations and certainly are something one would expect for a &amp;quot;water cooler&amp;quot; environment.&lt;br/&gt;
On the other hand, they are usually pretty tacky and will overrun a large-ish subreddit if allowed.  Thus, we remove memes on any day but monday.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Technical Questions&lt;/strong&gt; - This category is difficult, and decisions may differ depending on the moderator.  Some questions clearly belong in one of the more technical subreddits, and are directed there.  Beyond that, we assess whether it feels like a &amp;quot;Stack Overflow&amp;quot; question, a homework question, or a &amp;quot;Google Search&amp;quot; question, and then direct people to those places if needed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Junk/Low Effort&lt;/strong&gt; - Name speaks for itself.  This is actually somewhat uncommon for our subreddit, though that may be due to reddit&amp;#39;s automatic moderation at work.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Politics/Off-topic&lt;/strong&gt; - While eventually we wouldn&amp;#39;t mind having off-topic conversations like you might have at a water cooler, currently we will tend to remove them for consistency sake.  Political discussions in particular are removed unless they are explicitly about data science, as we don&amp;#39;t want the kind of trouble those conversations can lead to on reddit.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More generally than the above factors, we try to consider each post and ask ourselves if the subreddit is better or worse with that content on it.  As you might also notice, our mod team is often quite busy (more on that below), so sometimes we will leave removable posts up simply because they have a lot of activity by the time we see them.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Our Future&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We are continuing to make changes to try to improve the subreddit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Content -&lt;/strong&gt; In addition to our long-running weekly &amp;quot;Entering &amp;amp; Transitioning&amp;quot; thread, we have tested &amp;quot;Meme Mondays&amp;quot; and &amp;quot;DS Topic of the Week&amp;quot; as additional content drivers.  Furthermore, some work has been done to advance the wiki.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Moderation Bot&lt;/strong&gt; - Our new moderation bot, &lt;a href=""/u/datascience-bot""&gt;u/datascience-bot&lt;/a&gt;, has allowed us to automate some of our work, and will hopefully one day be trained (based on our manual removals) to actually take on a significant amount of the moderation.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Removal Reasons&lt;/strong&gt; - We want to improve our selection of removal reasons and associated text.  This will help provide the person with more context/resources around the removal, and will hopefully provide better labels for the moderation bot to learn from.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flairs&lt;/strong&gt; - We sorta had a process for giving flairs to long-time users, but it needs to be revisited.  The process around link flairs needs to be adjusted as well.  Our hope is to actually build this capability into the moderation bot, at some point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Moderators&lt;/strong&gt; - We recently lost a couple of long-time moderators, and frankly we probably never had as many moderators as we needed to accomplish our vision.  The subreddit has also grown significantly in size (10x in three years), and most of the existing mods have jobs and families that leave us with limited time for moderating the subreddit.  &lt;strong&gt;Our plan is to begin recruiting new moderators as soon this State of the Subreddit discussion winds down.&lt;/strong&gt;&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Considering how long I have already made this post, I think I will leave it there.  &lt;strong&gt;We welcome any questions, comments, or criticisms&lt;/strong&gt; about anything discussed here or about the subreddit and our moderation in general.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdmbkd,Omega037,13,/r/datascience/comments/hdmbkd/meta_state_of_the_subreddit_2020/,https://www.reddit.com/r/datascience/comments/hdmbkd/meta_state_of_the_subreddit_2020/,1592804801.0
r/datascience,"Hi all,

I'm very new to the data science community but I'm looking for some advice on a side project I'm working on. The real estate market seems very much to be an information game and I believe it results in significant market inefficiencies. With equities prices as high as they are at the moment, I'm dabbling in the world of real estate investing in anticipation for a correction in housing prices over the coming year. 

I want to take a very analytical approach to property analysis and acquisition. The first step seems to be a market selection analysis. This analysis should determine which markets are most profitable to enter as an investor. I've identified the following as key metrics:

\- Population Growth

\- Job Growth

\- Median Rental Rates (and YoY Growth)

\- Median Housing Prices (and YoY Growth)

\- # of Sales

\- Active Listings

&amp;#x200B;

I have been able to obtain datasets for most metropolitan areas in the U.S. but I am not sure about the best way to employ these sets to select a market. Given that I have a number of potential factors to consider when trying to determine the best areas, I figure I can either do a screening process similar to how one might in security analysis where you filter the data based on a set of criteria (current and future population and job growth above national avg., job creation above national avg., etc.) and I would be left with a list of qualifiers but narrowing it down would be somewhat subjective. 

The other option I think I could take is determining which factors are most important to housing prices or rent to value ratio (median home price / median rent) by running a regression or some model. Decision criteria could then be weighted on those factors and I could even create a composite score by distributing these weights to different factors and rank the locations based on composite. Is there an approach that I am missing or one that is best practice when it comes to this sort of thing?

&amp;#x200B;

It's been a while since I've done much statistical modelling and I'm currently learning python so I am hoping this will be a good starter project to develop some of those skills.  

&amp;#x200B;

Any help you could provide would be much appreciated! Thanks!",t2_nlcob,Real Estate Market Selection,projects,t3_hdh5kd,0.96,76,Projects,76,1592811876.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m very new to the data science community but I&amp;#39;m looking for some advice on a side project I&amp;#39;m working on. The real estate market seems very much to be an information game and I believe it results in significant market inefficiencies. With equities prices as high as they are at the moment, I&amp;#39;m dabbling in the world of real estate investing in anticipation for a correction in housing prices over the coming year. &lt;/p&gt;

&lt;p&gt;I want to take a very analytical approach to property analysis and acquisition. The first step seems to be a market selection analysis. This analysis should determine which markets are most profitable to enter as an investor. I&amp;#39;ve identified the following as key metrics:&lt;/p&gt;

&lt;p&gt;- Population Growth&lt;/p&gt;

&lt;p&gt;- Job Growth&lt;/p&gt;

&lt;p&gt;- Median Rental Rates (and YoY Growth)&lt;/p&gt;

&lt;p&gt;- Median Housing Prices (and YoY Growth)&lt;/p&gt;

&lt;p&gt;- # of Sales&lt;/p&gt;

&lt;p&gt;- Active Listings&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have been able to obtain datasets for most metropolitan areas in the U.S. but I am not sure about the best way to employ these sets to select a market. Given that I have a number of potential factors to consider when trying to determine the best areas, I figure I can either do a screening process similar to how one might in security analysis where you filter the data based on a set of criteria (current and future population and job growth above national avg., job creation above national avg., etc.) and I would be left with a list of qualifiers but narrowing it down would be somewhat subjective. &lt;/p&gt;

&lt;p&gt;The other option I think I could take is determining which factors are most important to housing prices or rent to value ratio (median home price / median rent) by running a regression or some model. Decision criteria could then be weighted on those factors and I could even create a composite score by distributing these weights to different factors and rank the locations based on composite. Is there an approach that I am missing or one that is best practice when it comes to this sort of thing?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;It&amp;#39;s been a while since I&amp;#39;ve done much statistical modelling and I&amp;#39;m currently learning python so I am hoping this will be a good starter project to develop some of those skills.  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any help you could provide would be much appreciated! Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdh5kd,BuckCon4,27,/r/datascience/comments/hdh5kd/real_estate_market_selection/,https://www.reddit.com/r/datascience/comments/hdh5kd/real_estate_market_selection/,1592783076.0
r/datascience,"So far, I have been saving all data files as .csv files on my computer... and that's beginning to hoard my local storage. What's the best way to store data for your personal projects? I was thinking if creating a database server is a valid method?",t2_5ddenqhj,How do you store data for your personal projects?,projects,t3_he0lqs,1.0,1,Projects,1,1592888039.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So far, I have been saving all data files as .csv files on my computer... and that&amp;#39;s beginning to hoard my local storage. What&amp;#39;s the best way to store data for your personal projects? I was thinking if creating a database server is a valid method?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",he0lqs,Busy-Chipmunk,7,/r/datascience/comments/he0lqs/how_do_you_store_data_for_your_personal_projects/,https://www.reddit.com/r/datascience/comments/he0lqs/how_do_you_store_data_for_your_personal_projects/,1592859239.0
r/datascience,,t2_3rl9tafm,The best SQL vs NoSQL mindset I've ever heard,education,t3_hd3tqs,0.93,281,Education,281,1592759240.0,,hd3tqs,kotartemiy,26,/r/datascience/comments/hd3tqs/the_best_sql_vs_nosql_mindset_ive_ever_heard/,https://codarium.substack.com/p/the-best-sql-vs-nosql-mindset-ive,1592730440.0
r/datascience,"I'm working on a production system that is using a one vs rest logistic regression model. The probability output of the spark model is highly skewed, with a majority of values in the 95%+ range, whereas when i tested the same data on the sklearn model, it was still skewed, but had more values in the lower levels.

Why could cause these two outputs be different? Could the models be implementing different math to work?

Edit: looks like the spark model didnt have regularization, whereas the sklearn model did by default",t2_6ocpr,Probability outputs of sklearn vs pyspark logistic regression,discussion,t3_hdte1a,0.6,1,Discussion,1,1592865105.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working on a production system that is using a one vs rest logistic regression model. The probability output of the spark model is highly skewed, with a majority of values in the 95%+ range, whereas when i tested the same data on the sklearn model, it was still skewed, but had more values in the lower levels.&lt;/p&gt;

&lt;p&gt;Why could cause these two outputs be different? Could the models be implementing different math to work?&lt;/p&gt;

&lt;p&gt;Edit: looks like the spark model didnt have regularization, whereas the sklearn model did by default&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdte1a,beardlesslumberjack,4,/r/datascience/comments/hdte1a/probability_outputs_of_sklearn_vs_pyspark/,https://www.reddit.com/r/datascience/comments/hdte1a/probability_outputs_of_sklearn_vs_pyspark/,1592836305.0
r/datascience,"I'm currently reading white papers and research articles to gain some insights. It's definitely a lot of pages to go through...

Has anyone ever used R to skim through text, i.e. PDFs, to have a summary of insights outputted? If so, how?

I've thought of using word clouds, but that seems like a fragment of ideas (i.e. words) vs. phrases, etc.",t2_zp62e,Using R to Skim Through Articles / Technical Reports?,discussion,t3_hdkkmh,0.81,3,Discussion,3,1592826029.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently reading white papers and research articles to gain some insights. It&amp;#39;s definitely a lot of pages to go through...&lt;/p&gt;

&lt;p&gt;Has anyone ever used R to skim through text, i.e. PDFs, to have a summary of insights outputted? If so, how?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve thought of using word clouds, but that seems like a fragment of ideas (i.e. words) vs. phrases, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdkkmh,LivingParadox8,5,/r/datascience/comments/hdkkmh/using_r_to_skim_through_articles_technical_reports/,https://www.reddit.com/r/datascience/comments/hdkkmh/using_r_to_skim_through_articles_technical_reports/,1592797229.0
r/datascience,"Several of the technical people I'm working with are brainstorming how to explain ""machine learning"" to our business stakeholders e.g. we try not to use terms like ""supervised"" or ""unsupervised learning"" - instead using very simple explanation like ""automatically putting label into data"" or ""automatically classifying the data into several defined classifications"".

Several of my team members are worried if we come off just still too technical - one of the business stakeholders can be brutal. One of them said, ""I've no idea what these ML things are - the words you're using are just too technical - sounds like something a Terminator will do - simplify it!"". He made it sound funny but he was super sarcastic about it.

Any advice on how to get through this? 
We just want to tell them ML is good for certain things, and we need the right tabular data. But we're not so sure how to get through the ML models e.g. neural networks, KNN, etc. One of the tech guys said to just drop the ML model explanation and go straight to just super generic description - one is worried that it may sound too simple.",t2_3z6gqvrh,Getting business people to understand your DS model,discussion,t3_hdgzaw,0.73,5,Discussion,5,1592811202.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Several of the technical people I&amp;#39;m working with are brainstorming how to explain &amp;quot;machine learning&amp;quot; to our business stakeholders e.g. we try not to use terms like &amp;quot;supervised&amp;quot; or &amp;quot;unsupervised learning&amp;quot; - instead using very simple explanation like &amp;quot;automatically putting label into data&amp;quot; or &amp;quot;automatically classifying the data into several defined classifications&amp;quot;.&lt;/p&gt;

&lt;p&gt;Several of my team members are worried if we come off just still too technical - one of the business stakeholders can be brutal. One of them said, &amp;quot;I&amp;#39;ve no idea what these ML things are - the words you&amp;#39;re using are just too technical - sounds like something a Terminator will do - simplify it!&amp;quot;. He made it sound funny but he was super sarcastic about it.&lt;/p&gt;

&lt;p&gt;Any advice on how to get through this? 
We just want to tell them ML is good for certain things, and we need the right tabular data. But we&amp;#39;re not so sure how to get through the ML models e.g. neural networks, KNN, etc. One of the tech guys said to just drop the ML model explanation and go straight to just super generic description - one is worried that it may sound too simple.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdgzaw,runnersgo,6,/r/datascience/comments/hdgzaw/getting_business_people_to_understand_your_ds/,https://www.reddit.com/r/datascience/comments/hdgzaw/getting_business_people_to_understand_your_ds/,1592782402.0
r/datascience,"Has anyone done this? What was your experience? I currently work as a data scientist but have always enjoyed forecasting problems the most. Things I like about data science are predictive modeling, R/Python programming, big data techniques, and putting models/solutions into production. Could I expect similar work as a demand planner?",t2_1q6oq5dl,Moving from data science into demand planning,career,t3_hdlico,0.63,2,Career,2,1592830143.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Has anyone done this? What was your experience? I currently work as a data scientist but have always enjoyed forecasting problems the most. Things I like about data science are predictive modeling, R/Python programming, big data techniques, and putting models/solutions into production. Could I expect similar work as a demand planner?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdlico,dmorris87,2,/r/datascience/comments/hdlico/moving_from_data_science_into_demand_planning/,https://www.reddit.com/r/datascience/comments/hdlico/moving_from_data_science_into_demand_planning/,1592801343.0
r/datascience,"A bit of a rant about hiring new talent right now, and a few questions for those that have been/are maybe going through the same right now due to Covid19.

We're looking to hire a new junior data scientist at a small consulting firm, so we  posted an ad on LinkedIn. We made sure that the applicants knew that they had to be a US citizen or green card holder and we would not sponsor H1b nor participate in OPT. This was done with filter questions, and all caps bolded text in the job description BOTH at the beginning and end of the job description. We received around 1500 resumes in about 72 hours.

We've been going through these resumes and doing a basic phone screen on the potential candidates, but so far all of them lied about their US immigration status on our filter questions. From 200 calls, all 200 lied about their status.

Does anyone have any recommendations on how to avoid this problem, so we're not wasting about a week chasing down potential candidates that we'll never hire?

We hired before about six months ago and only had about a hand full of these cases. I know times are tough due to COVID and these applicants want to stay in the USA, but we can't take them. It's  frustrating to say the least, and a huge waste of time.

Thank you in advance for any ideas you may have.",t2_2tn6wrbm,Hiring frustrations,discussion,t3_hd9ne6,0.88,20,Discussion,20,1592785344.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A bit of a rant about hiring new talent right now, and a few questions for those that have been/are maybe going through the same right now due to Covid19.&lt;/p&gt;

&lt;p&gt;We&amp;#39;re looking to hire a new junior data scientist at a small consulting firm, so we  posted an ad on LinkedIn. We made sure that the applicants knew that they had to be a US citizen or green card holder and we would not sponsor H1b nor participate in OPT. This was done with filter questions, and all caps bolded text in the job description BOTH at the beginning and end of the job description. We received around 1500 resumes in about 72 hours.&lt;/p&gt;

&lt;p&gt;We&amp;#39;ve been going through these resumes and doing a basic phone screen on the potential candidates, but so far all of them lied about their US immigration status on our filter questions. From 200 calls, all 200 lied about their status.&lt;/p&gt;

&lt;p&gt;Does anyone have any recommendations on how to avoid this problem, so we&amp;#39;re not wasting about a week chasing down potential candidates that we&amp;#39;ll never hire?&lt;/p&gt;

&lt;p&gt;We hired before about six months ago and only had about a hand full of these cases. I know times are tough due to COVID and these applicants want to stay in the USA, but we can&amp;#39;t take them. It&amp;#39;s  frustrating to say the least, and a huge waste of time.&lt;/p&gt;

&lt;p&gt;Thank you in advance for any ideas you may have.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hd9ne6,hummus_homeboy,24,/r/datascience/comments/hd9ne6/hiring_frustrations/,https://www.reddit.com/r/datascience/comments/hd9ne6/hiring_frustrations/,1592756544.0
r/datascience,Does anyone have any examples of how you have used Monte Carlo Simulation or Queuing Theory in your work or personal life? How has it helped you?,t2_5crc3ixf,Examples of using Monte Carlo Simulation or Queuing Theory in work or personal life?,discussion,t3_hdgimz,0.72,3,Discussion,3,1592809393.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone have any examples of how you have used Monte Carlo Simulation or Queuing Theory in your work or personal life? How has it helped you?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdgimz,hallelu2u,5,/r/datascience/comments/hdgimz/examples_of_using_monte_carlo_simulation_or/,https://www.reddit.com/r/datascience/comments/hdgimz/examples_of_using_monte_carlo_simulation_or/,1592780593.0
r/datascience,"I've been struggling to find good third party news that collate first-party sources in respect to Data Science, Machine Learning, or AI. Are there any places that specialize in analytics on par with news sites and communities like HackerNews or Lobsters? 

I've looked at communities like data science central or towardsdatascience, but it's hard to filter out a lot of the fluff. Ideally I'd like a place that top data science blog posts eventually bubble up to, like Netflix or Airbnb, as well as news in the industry or advances in research / technology. Would love to hear what alternatives you all have to this subreddit!",t2_n3emn,Equivalents to HackerNews or Lobsters for Data Science / Machine Learning / AI?,discussion,t3_hd931t,0.67,7,Discussion,7,1592783297.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been struggling to find good third party news that collate first-party sources in respect to Data Science, Machine Learning, or AI. Are there any places that specialize in analytics on par with news sites and communities like HackerNews or Lobsters? &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve looked at communities like data science central or towardsdatascience, but it&amp;#39;s hard to filter out a lot of the fluff. Ideally I&amp;#39;d like a place that top data science blog posts eventually bubble up to, like Netflix or Airbnb, as well as news in the industry or advances in research / technology. Would love to hear what alternatives you all have to this subreddit!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hd931t,Rhubarrbb,8,/r/datascience/comments/hd931t/equivalents_to_hackernews_or_lobsters_for_data/,https://www.reddit.com/r/datascience/comments/hd931t/equivalents_to_hackernews_or_lobsters_for_data/,1592754497.0
r/datascience,"Hello all,

I am a Data Scientist at a Fortune 500 company, with a PhD in Electrical Engineering. For the last 5 years, I thought myself Python and Data Science and progressed a lot in that arena. I wanted some change after 5 years in the same company and wanted to explore options. Amazon AWS Pro Serve sounded interesting as you get to work with different companies. I did not want to work on a deep Machine Learning Problem on my cubicle (after corona, for now home desk :) ). I was excited about meeting new people and potentially solving data problems for different industries.

Am I making a right choice? Is Pro-serve considered to be same with, say ""Applied scientist"" role in AWS (asking in regards to: 1) career growth, 2) reputation and 3) financial) ? Is meeting new people and potentially gaining more exposure to different industries in Pro-serve a naive way of thinking? As we all know customer's behaviors can vary.

All in all I thought, exposing myself to different people and industries, in the future can help me even become an independent consultant, yes? Whereas If I am an applied scientist, I need to be deeply involved in ""creating the AWS tools from scratch"" vs using them in the AWS Pro-serve role.

If you have any experience with AWS Pro-serve data scientist roles, please chime in. Thanks in advance.

Edit: Also I want to mention the bad work/life balance rumors AWS has. I, for some reason, assumed AWS pro-serve may be different, and hopefully more balanced. But I do not have enough evidence to say neither for sure.

Edit2: thank you for the comments, I am blown away by your help and willingness to share experiences.",t2_1jwhofnt,Amazon AWS Pro-Serve Data Scientist is it a good role?,career,t3_hcxeno,0.94,97,Career,97,1592729045.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,&lt;/p&gt;

&lt;p&gt;I am a Data Scientist at a Fortune 500 company, with a PhD in Electrical Engineering. For the last 5 years, I thought myself Python and Data Science and progressed a lot in that arena. I wanted some change after 5 years in the same company and wanted to explore options. Amazon AWS Pro Serve sounded interesting as you get to work with different companies. I did not want to work on a deep Machine Learning Problem on my cubicle (after corona, for now home desk :) ). I was excited about meeting new people and potentially solving data problems for different industries.&lt;/p&gt;

&lt;p&gt;Am I making a right choice? Is Pro-serve considered to be same with, say &amp;quot;Applied scientist&amp;quot; role in AWS (asking in regards to: 1) career growth, 2) reputation and 3) financial) ? Is meeting new people and potentially gaining more exposure to different industries in Pro-serve a naive way of thinking? As we all know customer&amp;#39;s behaviors can vary.&lt;/p&gt;

&lt;p&gt;All in all I thought, exposing myself to different people and industries, in the future can help me even become an independent consultant, yes? Whereas If I am an applied scientist, I need to be deeply involved in &amp;quot;creating the AWS tools from scratch&amp;quot; vs using them in the AWS Pro-serve role.&lt;/p&gt;

&lt;p&gt;If you have any experience with AWS Pro-serve data scientist roles, please chime in. Thanks in advance.&lt;/p&gt;

&lt;p&gt;Edit: Also I want to mention the bad work/life balance rumors AWS has. I, for some reason, assumed AWS pro-serve may be different, and hopefully more balanced. But I do not have enough evidence to say neither for sure.&lt;/p&gt;

&lt;p&gt;Edit2: thank you for the comments, I am blown away by your help and willingness to share experiences.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcxeno,GreenerCar,26,/r/datascience/comments/hcxeno/amazon_aws_proserve_data_scientist_is_it_a_good/,https://www.reddit.com/r/datascience/comments/hcxeno/amazon_aws_proserve_data_scientist_is_it_a_good/,1592700245.0
r/datascience,"I've vaguely heard this type of tool called a SQL runner. The common tasks this kind of tool solves:

* A scratch workspace to write multi-line sql queries and test them out
*  Ability to get metadata for tables/ queries, such as number of rows, indexes, timing information, constraints
*  Be able to inspect the columns, their types, and some row values
* Being able to print the ERD diagram of a database
* Exporting a SQL result set as a CSV or other types
* Autocomplete a SQL query with valid options for clauses
* Useful error tracing for syntax issues

&amp;#x200B;

I've used and tried out a variety of tools over the years, and for one reason or another end up switching between them. Some of the tools I've used:

* plain PSQL: honestly a very fast tool, and some of the options work well in a terminal. Terrible for multi-line query editing
*  [PgCLI](https://www.pgcli.com/docs): superior to plain psql as it provides auto-completion + multi-line editing similar to an iPython terminal
* (paid) [DataGrip](https://www.jetbrains.com/datagrip/): slower and bulkier than pgCLI, but provides scratch workspace + exporting to CSV as options
* [Sequel Pro](http://sequelpro.com/): I used this a lot for MYSQL databases, it was so much better than the Mysql Workbench
* [Mysql Workbench](https://www.mysql.com/products/workbench/): I only used this to print out the ERD diagrams, it was too slow to be useful
* [PopSQL](https://popsql.com/): a gorgeous editor, but honestly the whole program would freeze (and need to be killed by a process manager)  when we loaded in too many rows in a single query. Kind of a deal breaker lol.

&amp;#x200B;

I've just run across [dbeaver](https://dbeaver.io/) \-- is it worth it? Is there a tool that fits the holy grail of all the criteria that I am missing? Please share your wisdom!",t2_4cdvj,"Ask DataScience: What tools do you use to write, test, and build SQL queries?",tooling,t3_hdekd7,0.76,2,Tooling,2,1592802464.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve vaguely heard this type of tool called a SQL runner. The common tasks this kind of tool solves:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A scratch workspace to write multi-line sql queries and test them out&lt;/li&gt;
&lt;li&gt; Ability to get metadata for tables/ queries, such as number of rows, indexes, timing information, constraints&lt;/li&gt;
&lt;li&gt; Be able to inspect the columns, their types, and some row values&lt;/li&gt;
&lt;li&gt;Being able to print the ERD diagram of a database&lt;/li&gt;
&lt;li&gt;Exporting a SQL result set as a CSV or other types&lt;/li&gt;
&lt;li&gt;Autocomplete a SQL query with valid options for clauses&lt;/li&gt;
&lt;li&gt;Useful error tracing for syntax issues&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve used and tried out a variety of tools over the years, and for one reason or another end up switching between them. Some of the tools I&amp;#39;ve used:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;plain PSQL: honestly a very fast tool, and some of the options work well in a terminal. Terrible for multi-line query editing&lt;/li&gt;
&lt;li&gt; &lt;a href=""https://www.pgcli.com/docs""&gt;PgCLI&lt;/a&gt;: superior to plain psql as it provides auto-completion + multi-line editing similar to an iPython terminal&lt;/li&gt;
&lt;li&gt;(paid) &lt;a href=""https://www.jetbrains.com/datagrip/""&gt;DataGrip&lt;/a&gt;: slower and bulkier than pgCLI, but provides scratch workspace + exporting to CSV as options&lt;/li&gt;
&lt;li&gt;&lt;a href=""http://sequelpro.com/""&gt;Sequel Pro&lt;/a&gt;: I used this a lot for MYSQL databases, it was so much better than the Mysql Workbench&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://www.mysql.com/products/workbench/""&gt;Mysql Workbench&lt;/a&gt;: I only used this to print out the ERD diagrams, it was too slow to be useful&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://popsql.com/""&gt;PopSQL&lt;/a&gt;: a gorgeous editor, but honestly the whole program would freeze (and need to be killed by a process manager)  when we loaded in too many rows in a single query. Kind of a deal breaker lol.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve just run across &lt;a href=""https://dbeaver.io/""&gt;dbeaver&lt;/a&gt; -- is it worth it? Is there a tool that fits the holy grail of all the criteria that I am missing? Please share your wisdom!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdekd7,nvdnadj92,7,/r/datascience/comments/hdekd7/ask_datascience_what_tools_do_you_use_to_write/,https://www.reddit.com/r/datascience/comments/hdekd7/ask_datascience_what_tools_do_you_use_to_write/,1592773664.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 21 Jun 2020 - 28 Jun 2020,,t3_hd5t6m,0.92,11,Discussion,11,1592769631.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hd5t6m,datascience-bot,183,/r/datascience/comments/hd5t6m/weekly_entering_transitioning_thread_21_jun_2020/,https://www.reddit.com/r/datascience/comments/hd5t6m/weekly_entering_transitioning_thread_21_jun_2020/,1592740831.0
r/datascience,"I'm curious as im at the beginning of my data analytical career with an entry level position,
I've learned that I really enjoy the data visualization side of things,
Im sure it's possible, but is it ""normal"" for companies to have a data visualization specialist specifically building dashboards and what not?
Or is dataviz more a skill just expected of Business Intelligence/Analysts within a company",t2_hi9hq0f,Data Viz Careers.,discussion,t3_hd9jms,0.81,3,Discussion,3,1592784969.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m curious as im at the beginning of my data analytical career with an entry level position,
I&amp;#39;ve learned that I really enjoy the data visualization side of things,
Im sure it&amp;#39;s possible, but is it &amp;quot;normal&amp;quot; for companies to have a data visualization specialist specifically building dashboards and what not?
Or is dataviz more a skill just expected of Business Intelligence/Analysts within a company&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hd9jms,yekim_remok,2,/r/datascience/comments/hd9jms/data_viz_careers/,https://www.reddit.com/r/datascience/comments/hd9jms/data_viz_careers/,1592756169.0
r/datascience,"Planning a move from Toronto - I've heard salaries are lower and taxes higher?

Glassdoor has proven to be inaccurate in the past so looking to hear from people working in mtl

Edit: Looking for numbers/ranges",t2_6ltcva0l,How are data science salaries in Montreal for 0-5 YoE + Master's?,,t3_hcyrod,0.78,16,Job Search,16,1592734319.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Planning a move from Toronto - I&amp;#39;ve heard salaries are lower and taxes higher?&lt;/p&gt;

&lt;p&gt;Glassdoor has proven to be inaccurate in the past so looking to hear from people working in mtl&lt;/p&gt;

&lt;p&gt;Edit: Looking for numbers/ranges&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcyrod,remembr_this,20,/r/datascience/comments/hcyrod/how_are_data_science_salaries_in_montreal_for_05/,https://www.reddit.com/r/datascience/comments/hcyrod/how_are_data_science_salaries_in_montreal_for_05/,1592705519.0
r/datascience,"Since completing my undergrad in mathematics four years ago, I have worked at a tech company in the Bay Area (non FAANG) as a data scientist, and my total compensation is now at about 190K. I’m doing mostly analytics, with a little bit of ML mixed in, but would like to build a better foundation to pursue more ML-focused opportunities. I have been accepted to a top 10, full-time Masters in Data Science program, and am trying to decide whether it’s worth the opportunity costs and the tuition of 25K/semester for 4 semesters to boost my career. 

Has anyone here who is already established as a data scientist with only an undergrad degree gone back for a Masters? Could this be worth it, and are there other factors I should be considering when making this decision?",t2_1y0mchcy,Current Data Scientist Considering a Return to Academia,education,t3_hdaaoo,0.5,0,Education,0,1592787612.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Since completing my undergrad in mathematics four years ago, I have worked at a tech company in the Bay Area (non FAANG) as a data scientist, and my total compensation is now at about 190K. I’m doing mostly analytics, with a little bit of ML mixed in, but would like to build a better foundation to pursue more ML-focused opportunities. I have been accepted to a top 10, full-time Masters in Data Science program, and am trying to decide whether it’s worth the opportunity costs and the tuition of 25K/semester for 4 semesters to boost my career. &lt;/p&gt;

&lt;p&gt;Has anyone here who is already established as a data scientist with only an undergrad degree gone back for a Masters? Could this be worth it, and are there other factors I should be considering when making this decision?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hdaaoo,amphrit,8,/r/datascience/comments/hdaaoo/current_data_scientist_considering_a_return_to/,https://www.reddit.com/r/datascience/comments/hdaaoo/current_data_scientist_considering_a_return_to/,1592758812.0
r/datascience,"Hi All!

At my job, I get a decent amount of ad hoc wrangling requests where I write some SQL queries to get a certain data set. For the most part these are one-off (larger ones or ones with more than data wrangling I will create a git repo).

For the one-off ones, I currently just throw all of them into a single repo (like my username_sql_queries) but we also use Agile and so each ad hoc request is basically just assigned as a story. 

Anyone have maybe a better way of organizing stuff like this? Creating a branch for different requests and then merging into the main branch after it's accepted? A different tool for organization? 

Thanks!",t2_eefnw,Storing ad hoc data wrangling requests in GitHub?,discussion,t3_hd9ucy,0.67,1,Discussion,1,1592786023.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All!&lt;/p&gt;

&lt;p&gt;At my job, I get a decent amount of ad hoc wrangling requests where I write some SQL queries to get a certain data set. For the most part these are one-off (larger ones or ones with more than data wrangling I will create a git repo).&lt;/p&gt;

&lt;p&gt;For the one-off ones, I currently just throw all of them into a single repo (like my username_sql_queries) but we also use Agile and so each ad hoc request is basically just assigned as a story. &lt;/p&gt;

&lt;p&gt;Anyone have maybe a better way of organizing stuff like this? Creating a branch for different requests and then merging into the main branch after it&amp;#39;s accepted? A different tool for organization? &lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hd9ucy,RealAnalyst,9,/r/datascience/comments/hd9ucy/storing_ad_hoc_data_wrangling_requests_in_github/,https://www.reddit.com/r/datascience/comments/hd9ucy/storing_ad_hoc_data_wrangling_requests_in_github/,1592757223.0
r/datascience,"1) Find several examples of plagiarism in his YouTube channel

2) Message the actual creators asking them to file a copyright complaint

3) If the channel receives 3 strikes it will be terminated by YouTube.

Siraj's videos with plagiarised content are still on YouTube bringing him views, subscribers, and $$$. And they're taking away views from content creators with integrity.

Edit: yes, he is still doing this, as of 2020. see e.g. https://www.reddit.com/r/MachineLearning/comments/ex2sks/d_siraj_is_still_plagiarizing/",t2_2nfmjv1f,Tired of Siraj Raval's plagiarism? Here's what you can do,,t3_hcf4i7,0.95,555,,555,1592653386.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;1) Find several examples of plagiarism in his YouTube channel&lt;/p&gt;

&lt;p&gt;2) Message the actual creators asking them to file a copyright complaint&lt;/p&gt;

&lt;p&gt;3) If the channel receives 3 strikes it will be terminated by YouTube.&lt;/p&gt;

&lt;p&gt;Siraj&amp;#39;s videos with plagiarised content are still on YouTube bringing him views, subscribers, and $$$. And they&amp;#39;re taking away views from content creators with integrity.&lt;/p&gt;

&lt;p&gt;Edit: yes, he is still doing this, as of 2020. see e.g. &lt;a href=""https://www.reddit.com/r/MachineLearning/comments/ex2sks/d_siraj_is_still_plagiarizing/""&gt;https://www.reddit.com/r/MachineLearning/comments/ex2sks/d_siraj_is_still_plagiarizing/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcf4i7,tl_throw,62,/r/datascience/comments/hcf4i7/tired_of_siraj_ravals_plagiarism_heres_what_you/,https://www.reddit.com/r/datascience/comments/hcf4i7/tired_of_siraj_ravals_plagiarism_heres_what_you/,1592624586.0
r/datascience,"I've been watching a lot of stats videos to solidify some ML concepts and every study session I'm served several ads for men's soap. At first I thought nothing of it until I realized I don't get those ads when I watch non-stats videos on a different YouTube account. (I tend to watch entertainment on one account on my phone and stats/DS/ML videos on a different one on my mbp). Feels quite sexist to assume someone watching a stats video is male and offensive since I am a female data scientist. 

Anyone else have this experience?

Wouldn't be surprised that Youtube would have bias in their ad algorithm, considering all the problems that have popped up in their search algo and google translate. See autofill for Why are black women... \[angry\] , or translating a gender neutral pronoun from a different language in a sentence with doctor to he and she when paired with nurse.",t2_cu0co,Algo Bias - Female data scientist frequently getting ads for men's soap before watching stat videos,discussion,t3_hd7b4j,0.51,1,Discussion,1,1592776503.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been watching a lot of stats videos to solidify some ML concepts and every study session I&amp;#39;m served several ads for men&amp;#39;s soap. At first I thought nothing of it until I realized I don&amp;#39;t get those ads when I watch non-stats videos on a different YouTube account. (I tend to watch entertainment on one account on my phone and stats/DS/ML videos on a different one on my mbp). Feels quite sexist to assume someone watching a stats video is male and offensive since I am a female data scientist. &lt;/p&gt;

&lt;p&gt;Anyone else have this experience?&lt;/p&gt;

&lt;p&gt;Wouldn&amp;#39;t be surprised that Youtube would have bias in their ad algorithm, considering all the problems that have popped up in their search algo and google translate. See autofill for Why are black women... [angry] , or translating a gender neutral pronoun from a different language in a sentence with doctor to he and she when paired with nurse.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hd7b4j,mock6993,22,/r/datascience/comments/hd7b4j/algo_bias_female_data_scientist_frequently/,https://www.reddit.com/r/datascience/comments/hd7b4j/algo_bias_female_data_scientist_frequently/,1592747703.0
r/datascience,"Hi all, I know python and r are the big languages for machine learning, but I wondered if anyone uses JavaScript/tensorflow.js? 

If so how do you get on?

Thanks",t2_11wf5w,JavaScript anyone?,discussion,t3_hd3dw3,0.67,1,Discussion,1,1592756882.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I know python and r are the big languages for machine learning, but I wondered if anyone uses JavaScript/tensorflow.js? &lt;/p&gt;

&lt;p&gt;If so how do you get on?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hd3dw3,matt3526,5,/r/datascience/comments/hd3dw3/javascript_anyone/,https://www.reddit.com/r/datascience/comments/hd3dw3/javascript_anyone/,1592728082.0
r/datascience,"This is likely a silly question... but what are some recommended methods for ensuring you can easily switch between a laptop or desktop PC and having easy access to your files, libraries, packages, etc.?

GitHub? Just transferring your environment files (how)?",t2_1k7qhdhf,Code Management,discussion,t3_hcv2oe,0.76,4,Discussion,4,1592720683.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is likely a silly question... but what are some recommended methods for ensuring you can easily switch between a laptop or desktop PC and having easy access to your files, libraries, packages, etc.?&lt;/p&gt;

&lt;p&gt;GitHub? Just transferring your environment files (how)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcv2oe,Siba911,18,/r/datascience/comments/hcv2oe/code_management/,https://www.reddit.com/r/datascience/comments/hcv2oe/code_management/,1592691883.0
r/datascience,"Hey Redditors, 
 
Please help me figure out which statistical methods to use to solve this problem (and if possible, please point me towards resources)

Imagine that I have rich interaction data (video, audio, location, heart rate, etc.) for hundreds of teams with 6-ish people in each team.
I want to be able to use all of the data that I have to predict a team's general happiness level, and ideally, the happiness level of each individual team member. Each team member has completed a happiness survey, so I have their actual ratings, which is ratio data.

I have also analyzed all of the audio and video, and extracted features that I predict will be related to their general happiness ratings (e.g., number of compliments they give each other, performance, text-based sentiment analysis, and 40 other potential predictors).

What statistical methods should I use to explore those 40 streams of data to provide an ""Estimated Happiness Rating.""

Would it be possible to run a multiple regression to find the weights of each of the potential predictors using half of the data, and then use that model to predict happiness ratings on the other half of the data to validate it? If so, what tools would I need to do this?",t2_i56x7,How should I approach this problem? (Digging through many streams of data to predict a value),discussion,t3_hd1nf7,1.0,1,Discussion,1,1592747298.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey Redditors, &lt;/p&gt;

&lt;p&gt;Please help me figure out which statistical methods to use to solve this problem (and if possible, please point me towards resources)&lt;/p&gt;

&lt;p&gt;Imagine that I have rich interaction data (video, audio, location, heart rate, etc.) for hundreds of teams with 6-ish people in each team.
I want to be able to use all of the data that I have to predict a team&amp;#39;s general happiness level, and ideally, the happiness level of each individual team member. Each team member has completed a happiness survey, so I have their actual ratings, which is ratio data.&lt;/p&gt;

&lt;p&gt;I have also analyzed all of the audio and video, and extracted features that I predict will be related to their general happiness ratings (e.g., number of compliments they give each other, performance, text-based sentiment analysis, and 40 other potential predictors).&lt;/p&gt;

&lt;p&gt;What statistical methods should I use to explore those 40 streams of data to provide an &amp;quot;Estimated Happiness Rating.&amp;quot;&lt;/p&gt;

&lt;p&gt;Would it be possible to run a multiple regression to find the weights of each of the potential predictors using half of the data, and then use that model to predict happiness ratings on the other half of the data to validate it? If so, what tools would I need to do this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hd1nf7,ZachRahner,3,/r/datascience/comments/hd1nf7/how_should_i_approach_this_problem_digging/,https://www.reddit.com/r/datascience/comments/hd1nf7/how_should_i_approach_this_problem_digging/,1592718498.0
r/datascience,I'm currently looking into the education technology (edtech) field and am interested in how data science and AI could be used. I've found some companies like Knewton that focus on adaptive learning. Would anyone know any other applications there are of AI in education and where I could learn more about the underlying algorithms used in such applications?,t2_r3o1g,What applications of Data Science or AI are there in Education?,discussion,t3_hcuo4d,0.63,2,Discussion,2,1592719301.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently looking into the education technology (edtech) field and am interested in how data science and AI could be used. I&amp;#39;ve found some companies like Knewton that focus on adaptive learning. Would anyone know any other applications there are of AI in education and where I could learn more about the underlying algorithms used in such applications?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcuo4d,krtcl,4,/r/datascience/comments/hcuo4d/what_applications_of_data_science_or_ai_are_there/,https://www.reddit.com/r/datascience/comments/hcuo4d/what_applications_of_data_science_or_ai_are_there/,1592690501.0
r/datascience,"Comment:

&gt; [user 1]
I currently go into my FANG co, write a few SQL scripts, and call it a day by 4ish. Pays $250k/yr with a ton of amazing benefits. No MBA needed :)

&gt; [user 2]
Data scientist?

This was found on a business careers related subreddit. I thought this claim was crazy and outlandish, but maybe this sub could confirm. Are data scientist jobs so lax you can casually write SQL and make 250k/year?

I was always under the impression you needed a masters/PHD in stats and had to know a whole bunch of complicated math just to even break six figures, much less 250k.",t2_2xq54evf,"User claims he is a ""data scientist"" that makes 250k/year for just writing a few SQL scripts a day. Is this false?",career,t3_hcactj,0.93,97,Career,97,1592634778.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Comment:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[user 1]
I currently go into my FANG co, write a few SQL scripts, and call it a day by 4ish. Pays $250k/yr with a ton of amazing benefits. No MBA needed :)&lt;/p&gt;

&lt;p&gt;[user 2]
Data scientist?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This was found on a business careers related subreddit. I thought this claim was crazy and outlandish, but maybe this sub could confirm. Are data scientist jobs so lax you can casually write SQL and make 250k/year?&lt;/p&gt;

&lt;p&gt;I was always under the impression you needed a masters/PHD in stats and had to know a whole bunch of complicated math just to even break six figures, much less 250k.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcactj,Past_Sir,114,/r/datascience/comments/hcactj/user_claims_he_is_a_data_scientist_that_makes/,https://www.reddit.com/r/datascience/comments/hcactj/user_claims_he_is_a_data_scientist_that_makes/,1592605978.0
r/datascience,"I have had some experience working as a machine learning engineer but if I am honest with myself, I barely did much. I am 24 with 2 years of experience. Got laid off, rightfully so.

I have been struggling with myself and I keep on preparing, studying... But the result is a loop of painful rejections. You know, the kind of rejections where the company was interested in you, set the bar reasonably not high and expected me to pass through it

&amp;#x200B;

And yet I didn't. My profile looks good on paper but I feel like a fraud. Like someone who can try all he wants to but let's be honest, who is he kidding ? He doesn't know shit. He can't take up REAL responsibilities without having someone look over his shoulder. And even then he is lazy, mediocre.

Tried doing projects, watching videos, kaggle (that's a lie, I tried like 2 or 3 competitions that too I followed what others did)

I guess the gist of it is that I think I am a fraud. A phony. **I can have the bookish knowledge but I will forget it when I need it or would be unable to apply it.**

I'll never have what it takes to be an actual data scientist. It is just an unsophisticated fantasy.  And at the same I don't see myself doing anything else so I guess I am useless to the society\~ No one will hire me cause I can do nothing.

Just wanted to let it out after yet another disastrous interview which I knew everything about(as in, the answers to the questions), yet I messed it up. They threw a low ball and I missed my swing. Looked like a fool. &amp; Now I am binging on the Office (TV show) to numb it up

&amp;#x200B;

🏃‍♂️

&amp;#x200B;

Update: I am so overwhelmed by this response.. speechless to how good people are on here. I couldn't reply yet because I have a take home assignment to solve which is due tomorrow. Hope for the best and thank you everyone, it really made me feel better about my situation :)",t2_3s7m89g0,Forever a fraud ? Keep having horrific interviews and feel like I can never become a Data Scientist,,t3_hbxj93,0.93,349,Job Search,349,1592587108.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have had some experience working as a machine learning engineer but if I am honest with myself, I barely did much. I am 24 with 2 years of experience. Got laid off, rightfully so.&lt;/p&gt;

&lt;p&gt;I have been struggling with myself and I keep on preparing, studying... But the result is a loop of painful rejections. You know, the kind of rejections where the company was interested in you, set the bar reasonably not high and expected me to pass through it&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;And yet I didn&amp;#39;t. My profile looks good on paper but I feel like a fraud. Like someone who can try all he wants to but let&amp;#39;s be honest, who is he kidding ? He doesn&amp;#39;t know shit. He can&amp;#39;t take up REAL responsibilities without having someone look over his shoulder. And even then he is lazy, mediocre.&lt;/p&gt;

&lt;p&gt;Tried doing projects, watching videos, kaggle (that&amp;#39;s a lie, I tried like 2 or 3 competitions that too I followed what others did)&lt;/p&gt;

&lt;p&gt;I guess the gist of it is that I think I am a fraud. A phony. &lt;strong&gt;I can have the bookish knowledge but I will forget it when I need it or would be unable to apply it.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I&amp;#39;ll never have what it takes to be an actual data scientist. It is just an unsophisticated fantasy.  And at the same I don&amp;#39;t see myself doing anything else so I guess I am useless to the society~ No one will hire me cause I can do nothing.&lt;/p&gt;

&lt;p&gt;Just wanted to let it out after yet another disastrous interview which I knew everything about(as in, the answers to the questions), yet I messed it up. They threw a low ball and I missed my swing. Looked like a fool. &amp;amp; Now I am binging on the Office (TV show) to numb it up&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;🏃‍♂️&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Update: I am so overwhelmed by this response.. speechless to how good people are on here. I couldn&amp;#39;t reply yet because I have a take home assignment to solve which is due tomorrow. Hope for the best and thank you everyone, it really made me feel better about my situation :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hbxj93,__in_control,135,/r/datascience/comments/hbxj93/forever_a_fraud_keep_having_horrific_interviews/,https://www.reddit.com/r/datascience/comments/hbxj93/forever_a_fraud_keep_having_horrific_interviews/,1592558308.0
r/datascience,"I looked through the wiki and couldn't find one. Is there a group where it'll be okay to ask newbie questions on DS, libraries, tools, etc?",t2_fxs1u,Discord/Group for aspiring data scientists?,discussion,t3_hcne52,0.29,0,Discussion,0,1592693028.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I looked through the wiki and couldn&amp;#39;t find one. Is there a group where it&amp;#39;ll be okay to ask newbie questions on DS, libraries, tools, etc?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcne52,nemean_lion,2,/r/datascience/comments/hcne52/discordgroup_for_aspiring_data_scientists/,https://www.reddit.com/r/datascience/comments/hcne52/discordgroup_for_aspiring_data_scientists/,1592664228.0
r/datascience,"Saw another post the other day that bought Jupyter Lab to my attention and I thought I’d switch full time. 

My understanding is that there shouldn’t be much differences between the two, but the iplot graph didn’t show up in Lab whereas it did in notebook.",t2_2o20ryos,Jupyter Lab supports for pandas.iplot?,tooling,t3_hcj56k,0.67,1,Tooling,1,1592673571.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Saw another post the other day that bought Jupyter Lab to my attention and I thought I’d switch full time. &lt;/p&gt;

&lt;p&gt;My understanding is that there shouldn’t be much differences between the two, but the iplot graph didn’t show up in Lab whereas it did in notebook.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcj56k,WapyWonton,2,/r/datascience/comments/hcj56k/jupyter_lab_supports_for_pandasiplot/,https://www.reddit.com/r/datascience/comments/hcj56k/jupyter_lab_supports_for_pandasiplot/,1592644771.0
r/datascience,"I have a full web app ready to go that I made with Flask and HTML/Javascript. I tried to deploy it on Heroku, but they only allow files of up to 500mb and just importing TensorFlow via the requirements.txt file is already around there, not including the two 100+mb trained models I need to add. Would elastic beanstalk be a good place to deploy it? I also came across FloydHub which seems like an option. Wondering if anyone has any advice here. Thanks!",t2_93q3vyj,Best place to deploy deep learning web app?,projects,t3_hcdfp6,1.0,4,Projects,4,1592646062.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a full web app ready to go that I made with Flask and HTML/Javascript. I tried to deploy it on Heroku, but they only allow files of up to 500mb and just importing TensorFlow via the requirements.txt file is already around there, not including the two 100+mb trained models I need to add. Would elastic beanstalk be a good place to deploy it? I also came across FloydHub which seems like an option. Wondering if anyone has any advice here. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcdfp6,godismysavior69,5,/r/datascience/comments/hcdfp6/best_place_to_deploy_deep_learning_web_app/,https://www.reddit.com/r/datascience/comments/hcdfp6/best_place_to_deploy_deep_learning_web_app/,1592617262.0
r/datascience,"Hello everyone ! 

I was wondering what you find the best IDE for python, and why it is, in your opinion. 

I'm asking that because I find Jupyter to be lackluster when it comes to anything bigger than a small testing script. The autocompletion almost never works for me when I'm calling packages functions or that kind of stuff and I don't remember all of them each time I run a new project. 

I really liked VSCode personally but never found the option to run code sequentially (line by line) which makes me very sad because I'm sure there's a way to do it.",t2_mi18lm4,What is your favorite developping tool/IDE for python ?,discussion,t3_hcit68,0.5,0,Discussion,0,1592671927.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone ! &lt;/p&gt;

&lt;p&gt;I was wondering what you find the best IDE for python, and why it is, in your opinion. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m asking that because I find Jupyter to be lackluster when it comes to anything bigger than a small testing script. The autocompletion almost never works for me when I&amp;#39;m calling packages functions or that kind of stuff and I don&amp;#39;t remember all of them each time I run a new project. &lt;/p&gt;

&lt;p&gt;I really liked VSCode personally but never found the option to run code sequentially (line by line) which makes me very sad because I&amp;#39;m sure there&amp;#39;s a way to do it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hcit68,GuinsooIsOverrated,10,/r/datascience/comments/hcit68/what_is_your_favorite_developping_toolide_for/,https://www.reddit.com/r/datascience/comments/hcit68/what_is_your_favorite_developping_toolide_for/,1592643127.0
r/datascience,"Hey everybody! I noticed that all the cool kids in data science are leaning heavily into using Docker. I'm planning on going through the [tutorial](https://www.docker.com/play-with-docker), but was wondering if anybody here had any resources they recommend for becoming a Docker pro. Thanks!",t2_449o1xbf,How to become proficient using Docker?,tooling,t3_hc070m,0.92,25,Tooling,25,1592600117.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everybody! I noticed that all the cool kids in data science are leaning heavily into using Docker. I&amp;#39;m planning on going through the &lt;a href=""https://www.docker.com/play-with-docker""&gt;tutorial&lt;/a&gt;, but was wondering if anybody here had any resources they recommend for becoming a Docker pro. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hc070m,Neat_Caterpillar,17,/r/datascience/comments/hc070m/how_to_become_proficient_using_docker/,https://www.reddit.com/r/datascience/comments/hc070m/how_to_become_proficient_using_docker/,1592571317.0
r/datascience,"I'm trying to port some R code to python and it's just a simple logistic regression.

I managed to get the model to run in python (after I realized I needed to get\_dummies), and the model ran, but it just doesn't seem as ""simple"" as R.

For example, scikit-learn doesn't have statistical outputs, so I'm using statsmodels instead.  The model converged but I'm getting nan on some pvalues for a couple of predictors.  Also, It appears to be using the intercept as the basis of interpretation when it comes to categorical predictors?

It's all new to me, so not sure if i'm just not good at python.......",t2_i6go6an,Do you guys use Python for regression (statistical outputs dont seem to come easily),tooling,t3_hc7exd,1.0,3,Tooling,3,1592624828.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to port some R code to python and it&amp;#39;s just a simple logistic regression.&lt;/p&gt;

&lt;p&gt;I managed to get the model to run in python (after I realized I needed to get_dummies), and the model ran, but it just doesn&amp;#39;t seem as &amp;quot;simple&amp;quot; as R.&lt;/p&gt;

&lt;p&gt;For example, scikit-learn doesn&amp;#39;t have statistical outputs, so I&amp;#39;m using statsmodels instead.  The model converged but I&amp;#39;m getting nan on some pvalues for a couple of predictors.  Also, It appears to be using the intercept as the basis of interpretation when it comes to categorical predictors?&lt;/p&gt;

&lt;p&gt;It&amp;#39;s all new to me, so not sure if i&amp;#39;m just not good at python.......&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hc7exd,mrdlau,7,/r/datascience/comments/hc7exd/do_you_guys_use_python_for_regression_statistical/,https://www.reddit.com/r/datascience/comments/hc7exd/do_you_guys_use_python_for_regression_statistical/,1592596028.0
r/datascience,"I'm a Technology Consultant, and while I feel like I can use many different tools (Power BI/SQL Server/R/Python etc), I don't have a ton of knowledge about the current best practices for stitching them all together to form an end-to-end productionalized enterprise process. I'd like to maybe find a course/book that touches on these higher-level aspects, if possible. I tried to look on Udemy, but they all seemed pretty specific to a particular technology.",t2_bvwmh,Where to learn about best practices for End-to-End Data Analytics Process?,education,t3_hc3vcl,0.81,3,Education,3,1592613169.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a Technology Consultant, and while I feel like I can use many different tools (Power BI/SQL Server/R/Python etc), I don&amp;#39;t have a ton of knowledge about the current best practices for stitching them all together to form an end-to-end productionalized enterprise process. I&amp;#39;d like to maybe find a course/book that touches on these higher-level aspects, if possible. I tried to look on Udemy, but they all seemed pretty specific to a particular technology.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hc3vcl,topographical,6,/r/datascience/comments/hc3vcl/where_to_learn_about_best_practices_for_endtoend/,https://www.reddit.com/r/datascience/comments/hc3vcl/where_to_learn_about_best_practices_for_endtoend/,1592584369.0
r/datascience,"Hey everyone,

I work as a DS for a fortune 100 company. It’s my first data science role and I’ve been here a little short of a year. We have no way of implementing models and I’ve built a few production worthy scoring engines. The company is trying to get up to speed with analytics and data science but is still behind in the curve in terms of technology and utilizing data and their data scientists.

This leads to my question. Is anyone else in a role where you are “looking for drivers” or “key factors” regularly. It seems as though this is a huge majority of the work and all people care about. “Looking for segments” or “tell stories”. It seems extremely trivial and the amount of work reducing extremely wide datasets to a selection of variables that can tell a story is a relatively big task. They’re so open ended and can tend to be misleading. This feels like more of a business analytics role (even though so many titles seem arbitrary). They’re looking to have a production ready environment by the end of this year but it seems that actually having the business utilize scoring engines is unlikely. 

Doing these segmentations or “drivers” of events is what stakeholders care about. Is this very common in data science? Am I looking at this position wrong?

Thanks.",t2_21dzr6tr,Position focuses mainly on “explaining drivers”,career,t3_hc55m5,0.81,3,Career,3,1592617379.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;

&lt;p&gt;I work as a DS for a fortune 100 company. It’s my first data science role and I’ve been here a little short of a year. We have no way of implementing models and I’ve built a few production worthy scoring engines. The company is trying to get up to speed with analytics and data science but is still behind in the curve in terms of technology and utilizing data and their data scientists.&lt;/p&gt;

&lt;p&gt;This leads to my question. Is anyone else in a role where you are “looking for drivers” or “key factors” regularly. It seems as though this is a huge majority of the work and all people care about. “Looking for segments” or “tell stories”. It seems extremely trivial and the amount of work reducing extremely wide datasets to a selection of variables that can tell a story is a relatively big task. They’re so open ended and can tend to be misleading. This feels like more of a business analytics role (even though so many titles seem arbitrary). They’re looking to have a production ready environment by the end of this year but it seems that actually having the business utilize scoring engines is unlikely. &lt;/p&gt;

&lt;p&gt;Doing these segmentations or “drivers” of events is what stakeholders care about. Is this very common in data science? Am I looking at this position wrong?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hc55m5,TheGasBoi,8,/r/datascience/comments/hc55m5/position_focuses_mainly_on_explaining_drivers/,https://www.reddit.com/r/datascience/comments/hc55m5/position_focuses_mainly_on_explaining_drivers/,1592588579.0
r/datascience,"Hey everyone.

I'm about to graduate and get my masters degree next week and I have a tough decision to make. I've been working full time job for the last year in one of the biggest IT consulting companies out there as a big data intern, however my academic background is also more about analytics and statistics (i'm graduating in ""Computer Science and Econometrics"").

My main repsopnsibilites in current position are: building a star schema data warehouse (using SQL and Spark), bugfixes in existing tables, adding new source tables etc. I have never done any Kafka related stuff nor some extreamly-advanced pipelines using Spark Streaming or other tools. Most of them were quite complicated SQL queries (with over 1k lines of code). Within next 3 months the client I'm working for is going to be migrating from Hive to Snowflake and Wherscape, do you think knowing those would be benefitial to add to my resume? I would also learn some Amazon Athena and S3.

In my free time I often do kaagle competitions (just to test my skills and have some portfolio projects), prepare some ML models, try to do some predictive analysis. I really dont want to let those skills ""fade"" and develop in analytics as well.

All the technologies/languages I have worked with are: SQL, Python (more analytical python, so libraries like: numpy, seaborn, scikit-learn, pandas etc.), R (although I hate it), Scala (basic scala to understand Spark better), Spark (also pySpark), Hive (Hive-QL), Apache Ariflow (althow I know how to trigger a job and read logs, not really how to write complicated scheduling scripts), Jenkins, Git, Jira.

Now, I really have a tough decision to make. Should I stay in my current job as data engineer (with promotion to regular engineer, not an intern anymore) or look into more data science field. What do you guys think would be more lucrative within the next 5-10 years? Is there any way I could lets say, within a year or two, easily change fields from data engineering to data science? I guess I would be pretty good at data preparation and cleaning in that time. Is knowlege of those technologies mentioned above superficial in case I wanted to change? Should I learn anything specific? Also, if I decide to stay in the current position, I can take certification exams in SQL and Spark. Would it be benefitial in data science? What would be the best path to take?

Kind regards",t2_wbrn7,How to combine data science with data engineering?,career,t3_hc83zi,0.4,0,Career,0,1592627208.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m about to graduate and get my masters degree next week and I have a tough decision to make. I&amp;#39;ve been working full time job for the last year in one of the biggest IT consulting companies out there as a big data intern, however my academic background is also more about analytics and statistics (i&amp;#39;m graduating in &amp;quot;Computer Science and Econometrics&amp;quot;).&lt;/p&gt;

&lt;p&gt;My main repsopnsibilites in current position are: building a star schema data warehouse (using SQL and Spark), bugfixes in existing tables, adding new source tables etc. I have never done any Kafka related stuff nor some extreamly-advanced pipelines using Spark Streaming or other tools. Most of them were quite complicated SQL queries (with over 1k lines of code). Within next 3 months the client I&amp;#39;m working for is going to be migrating from Hive to Snowflake and Wherscape, do you think knowing those would be benefitial to add to my resume? I would also learn some Amazon Athena and S3.&lt;/p&gt;

&lt;p&gt;In my free time I often do kaagle competitions (just to test my skills and have some portfolio projects), prepare some ML models, try to do some predictive analysis. I really dont want to let those skills &amp;quot;fade&amp;quot; and develop in analytics as well.&lt;/p&gt;

&lt;p&gt;All the technologies/languages I have worked with are: SQL, Python (more analytical python, so libraries like: numpy, seaborn, scikit-learn, pandas etc.), R (although I hate it), Scala (basic scala to understand Spark better), Spark (also pySpark), Hive (Hive-QL), Apache Ariflow (althow I know how to trigger a job and read logs, not really how to write complicated scheduling scripts), Jenkins, Git, Jira.&lt;/p&gt;

&lt;p&gt;Now, I really have a tough decision to make. Should I stay in my current job as data engineer (with promotion to regular engineer, not an intern anymore) or look into more data science field. What do you guys think would be more lucrative within the next 5-10 years? Is there any way I could lets say, within a year or two, easily change fields from data engineering to data science? I guess I would be pretty good at data preparation and cleaning in that time. Is knowlege of those technologies mentioned above superficial in case I wanted to change? Should I learn anything specific? Also, if I decide to stay in the current position, I can take certification exams in SQL and Spark. Would it be benefitial in data science? What would be the best path to take?&lt;/p&gt;

&lt;p&gt;Kind regards&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hc83zi,Alghatron,3,/r/datascience/comments/hc83zi/how_to_combine_data_science_with_data_engineering/,https://www.reddit.com/r/datascience/comments/hc83zi/how_to_combine_data_science_with_data_engineering/,1592598408.0
r/datascience,"I am writing a proposal for a data science challenge for the first time. The proposal isn't academic in nature and it is aimed to serve as a white-paper for my idea. To keep things general the purpose of the challenge is to utilize data science skills for social good. Phase 1 proposals should only be one page in length, so should I focus more on the technicalities or on the vision? I can be very general when writing about the process, but I would like to hear what others have done in the past when trying to convey complex data science problems while focusing on the task at hand.",t2_14nsfu,What to include when writing a phase 1 proposal?,projects,t3_hc80nv,0.67,1,Projects,1,1592626885.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am writing a proposal for a data science challenge for the first time. The proposal isn&amp;#39;t academic in nature and it is aimed to serve as a white-paper for my idea. To keep things general the purpose of the challenge is to utilize data science skills for social good. Phase 1 proposals should only be one page in length, so should I focus more on the technicalities or on the vision? I can be very general when writing about the process, but I would like to hear what others have done in the past when trying to convey complex data science problems while focusing on the task at hand.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hc80nv,casual_cocaine,2,/r/datascience/comments/hc80nv/what_to_include_when_writing_a_phase_1_proposal/,https://www.reddit.com/r/datascience/comments/hc80nv/what_to_include_when_writing_a_phase_1_proposal/,1592598085.0
r/datascience,"I'm new so maybe this'll be something that changes as i get better.
I find alot of my code to be ineffecient when i go back through it. The code works and completes the tasks, but when looking through it always looks like it could be simpler and less convoluted. 

Is this just a me thing or a feild thing that will always happen?",t2_g9nl2yr,How often do you go back to clea up your code?,discussion,t3_hc30gj,1.0,2,Discussion,2,1592610338.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m new so maybe this&amp;#39;ll be something that changes as i get better.
I find alot of my code to be ineffecient when i go back through it. The code works and completes the tasks, but when looking through it always looks like it could be simpler and less convoluted. &lt;/p&gt;

&lt;p&gt;Is this just a me thing or a feild thing that will always happen?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hc30gj,NotSodiumFree,8,/r/datascience/comments/hc30gj/how_often_do_you_go_back_to_clea_up_your_code/,https://www.reddit.com/r/datascience/comments/hc30gj/how_often_do_you_go_back_to_clea_up_your_code/,1592581538.0
r/datascience,"Hi all, i'm a data scientist working primarily with R &amp; R Markdown and am looking at building a PC for gaming and data science work and I began to realize I know a fair amount about optimizing for gaming performance but almost nothing about what speeds up predictive modeling and other stages of a data scientists workflow.

For example:

* Is base CPU speed important? Number of cores? Threads? Cache?
* I know with R, enough RAM to fit datasets into memory and work with them isimportant, but does additional RAM beyond that help? What about RAM speed? (e.g. would 2400MHz -&gt; 3200MHz make any difference?)
* Does the motherboard matter at all, aside from having enough space for future RAM upgrades if needed?
* Does the GPU matter if you're not doing deep learning?

I'm not working on cutting-edge stuff really but what things should I bear in mind for speeding up 'normal' data science work, e.g. data manipulation, statistical tests, visualizations, cross-validation &amp; grid-searching (I use some boosting like xgboost &amp; lightgbm but a lot of more standard linear/tree-based approaches)

Thanks and I hope someone can help, i'm really struggling to find information on /r/buildapc outside of the fact that GPU's are important for deep learning, which I don't really do!",t2_e6iwm,What PC components are a priority for speeding up predictive modelling?,tooling,t3_hby6qg,0.6,2,Tooling,2,1592590707.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, i&amp;#39;m a data scientist working primarily with R &amp;amp; R Markdown and am looking at building a PC for gaming and data science work and I began to realize I know a fair amount about optimizing for gaming performance but almost nothing about what speeds up predictive modeling and other stages of a data scientists workflow.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Is base CPU speed important? Number of cores? Threads? Cache?&lt;/li&gt;
&lt;li&gt;I know with R, enough RAM to fit datasets into memory and work with them isimportant, but does additional RAM beyond that help? What about RAM speed? (e.g. would 2400MHz -&amp;gt; 3200MHz make any difference?)&lt;/li&gt;
&lt;li&gt;Does the motherboard matter at all, aside from having enough space for future RAM upgrades if needed?&lt;/li&gt;
&lt;li&gt;Does the GPU matter if you&amp;#39;re not doing deep learning?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;#39;m not working on cutting-edge stuff really but what things should I bear in mind for speeding up &amp;#39;normal&amp;#39; data science work, e.g. data manipulation, statistical tests, visualizations, cross-validation &amp;amp; grid-searching (I use some boosting like xgboost &amp;amp; lightgbm but a lot of more standard linear/tree-based approaches)&lt;/p&gt;

&lt;p&gt;Thanks and I hope someone can help, i&amp;#39;m really struggling to find information on &lt;a href=""/r/buildapc""&gt;/r/buildapc&lt;/a&gt; outside of the fact that GPU&amp;#39;s are important for deep learning, which I don&amp;#39;t really do!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hby6qg,supra95,14,/r/datascience/comments/hby6qg/what_pc_components_are_a_priority_for_speeding_up/,https://www.reddit.com/r/datascience/comments/hby6qg/what_pc_components_are_a_priority_for_speeding_up/,1592561907.0
r/datascience,"Ranges you can find online are very broad, to the point of little value.",t2_de5yq,Data science salaries in Canada?,,t3_hbdhxj,0.89,54,Job Search,54,1592511410.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Ranges you can find online are very broad, to the point of little value.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hbdhxj,Optimesh,28,/r/datascience/comments/hbdhxj/data_science_salaries_in_canada/,https://www.reddit.com/r/datascience/comments/hbdhxj/data_science_salaries_in_canada/,1592482610.0
r/datascience,"I have ~520 days with some data (visitors, weather, etc.) and some missing days (3-7 days) in between every 1-2 months.

I want to predict future visitor numbers for a few weeks in the future.

How do I best split up test &amp; training data so that nothing leaks from test to traning? I've read that I should take ~80% of the time span for training, leave a month empty, then the rest of the days (~20%) for test?

Is there a best practice? And are the empty 3-7 days a problem?",t2_kn00t,Random Forest with Time Series data - how to best split test &amp; training data?,discussion,t3_hbbcxa,0.89,74,Discussion,74,1592501140.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have ~520 days with some data (visitors, weather, etc.) and some missing days (3-7 days) in between every 1-2 months.&lt;/p&gt;

&lt;p&gt;I want to predict future visitor numbers for a few weeks in the future.&lt;/p&gt;

&lt;p&gt;How do I best split up test &amp;amp; training data so that nothing leaks from test to traning? I&amp;#39;ve read that I should take ~80% of the time span for training, leave a month empty, then the rest of the days (~20%) for test?&lt;/p&gt;

&lt;p&gt;Is there a best practice? And are the empty 3-7 days a problem?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hbbcxa,Yojihito,26,/r/datascience/comments/hbbcxa/random_forest_with_time_series_data_how_to_best/,https://www.reddit.com/r/datascience/comments/hbbcxa/random_forest_with_time_series_data_how_to_best/,1592472340.0
r/datascience,"This use-case suddenly came up at work. I can understand why this was partially delegated to me, because I'm one of the few people who works with data in our company of less than 20. 

But it brought to light a woefully lacking skillset. I'm sure there's other people in this sub who have found themselves in the position of starting from experience in mostly just Python libraries, to suddenly having to pick up some JavaScript front-end libraries for visualization purposes. Eager to hear advice/tool recommendations from people in this position.",t2_k01zajj,Having to suddenly fill an alarming skill-gap in the area of front-end development - from Python/SQL knowledge to embedding real-time visuals on web pages using JavaScript libraries (e.g. d3.js),discussion,t3_hbfva4,0.92,10,Discussion,10,1592520066.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This use-case suddenly came up at work. I can understand why this was partially delegated to me, because I&amp;#39;m one of the few people who works with data in our company of less than 20. &lt;/p&gt;

&lt;p&gt;But it brought to light a woefully lacking skillset. I&amp;#39;m sure there&amp;#39;s other people in this sub who have found themselves in the position of starting from experience in mostly just Python libraries, to suddenly having to pick up some JavaScript front-end libraries for visualization purposes. Eager to hear advice/tool recommendations from people in this position.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hbfva4,Lostwhispers05,19,/r/datascience/comments/hbfva4/having_to_suddenly_fill_an_alarming_skillgap_in/,https://www.reddit.com/r/datascience/comments/hbfva4/having_to_suddenly_fill_an_alarming_skillgap_in/,1592491266.0
r/datascience,"I've been working as a data scientist/ml engineer for the past 5 years. I graduated with a bachelor's of mechanical engineering and managed to push my way into a full-time DS position through some online certifications and private projects.

I realized I have the bandwidth to pursue a master's but don't want to quit my job so I'm seriously considering getting an online masters to do on the side.

First question: can anyone reccomend a good online masters program related to DS?

Second question: is it even worth pursuing if I can't attend an on-campus masters at a potentially more reputable institution?

Thanks!",t2_1hy2flk,DS Online Masters,,t3_hb1h64,0.95,118,,118,1592460962.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been working as a data scientist/ml engineer for the past 5 years. I graduated with a bachelor&amp;#39;s of mechanical engineering and managed to push my way into a full-time DS position through some online certifications and private projects.&lt;/p&gt;

&lt;p&gt;I realized I have the bandwidth to pursue a master&amp;#39;s but don&amp;#39;t want to quit my job so I&amp;#39;m seriously considering getting an online masters to do on the side.&lt;/p&gt;

&lt;p&gt;First question: can anyone reccomend a good online masters program related to DS?&lt;/p&gt;

&lt;p&gt;Second question: is it even worth pursuing if I can&amp;#39;t attend an on-campus masters at a potentially more reputable institution?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hb1h64,weareglenn,106,/r/datascience/comments/hb1h64/ds_online_masters/,https://www.reddit.com/r/datascience/comments/hb1h64/ds_online_masters/,1592432162.0
r/datascience,"Does anyone have any good books or resources on agile Data science Management. Or really just agile project management would work maybe with a focus on data.

I am trying to move my team away from a waterfall approach and adopt scrum processes. Were focusing on trying the Team Data Science Process from Microsoft But it's hard to get people on board with sprints, and stand ups, and stories when I only understand foundation and concepts. 

Is anyone currently using an agile Data science delivery method?",t2_1n8owavv,Agile Data Science Management,discussion,t3_hb68sh,0.84,21,Discussion,21,1592477652.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone have any good books or resources on agile Data science Management. Or really just agile project management would work maybe with a focus on data.&lt;/p&gt;

&lt;p&gt;I am trying to move my team away from a waterfall approach and adopt scrum processes. Were focusing on trying the Team Data Science Process from Microsoft But it&amp;#39;s hard to get people on board with sprints, and stand ups, and stories when I only understand foundation and concepts. &lt;/p&gt;

&lt;p&gt;Is anyone currently using an agile Data science delivery method?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hb68sh,DS_throwitaway,14,/r/datascience/comments/hb68sh/agile_data_science_management/,https://www.reddit.com/r/datascience/comments/hb68sh/agile_data_science_management/,1592448852.0
r/datascience,"I don’t mean this as a meme. Literally just got hit with this at work today. Their 2-3 year outlay involves implementing a full service customer facing chatbot. We have no data infrastructure, which means no historic data or anything. They have some new chat mobile app for customers to communicate through and from what I’ve gathered so far, they intend these messages to be sufficient for training after two years? I mean, yeah NLP is going to make huge advancements in that span of time, but I don’t suspect it will be “smart” enough to devise its own methods to answer any type of question about a customers account by then. I foresee a nightmare of declarative rules driving hobbled together screen scraped-key logged RPA trying to interact with our 35 year old customer transaction database. Thing isn’t even relational and doesn’t support https or other interactive protocols. I mean, our IT department keeps pulling corrupt RAM on VM host hardware that out of warranty with nothing to replace it with. They don’t have the budget and we can’t get budget for cloud instances. They have no RDBMS at all. We’re regulated too. We have to verify customer identities before account access. They call about all kinds of stuff. Oh, and we support three different spoken and written languages. There are all sorts of formalities our call center has to go through. We don’t even have menu based ID verification for call ins. It’s all done by humans talking to each other. 

Yeah, we ain’t getting full human passing customer service automatons by 2023. I hope I’m out of this dumpster fire before December. Is it that tempting to replace ones workforce with robots that they’re completely blind to the actual reality of doing it?",t2_6nx6nyfy,What’s the deal with executives wanting chatbots?,discussion,t3_hb5lzl,0.81,12,Discussion,12,1592475163.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I don’t mean this as a meme. Literally just got hit with this at work today. Their 2-3 year outlay involves implementing a full service customer facing chatbot. We have no data infrastructure, which means no historic data or anything. They have some new chat mobile app for customers to communicate through and from what I’ve gathered so far, they intend these messages to be sufficient for training after two years? I mean, yeah NLP is going to make huge advancements in that span of time, but I don’t suspect it will be “smart” enough to devise its own methods to answer any type of question about a customers account by then. I foresee a nightmare of declarative rules driving hobbled together screen scraped-key logged RPA trying to interact with our 35 year old customer transaction database. Thing isn’t even relational and doesn’t support https or other interactive protocols. I mean, our IT department keeps pulling corrupt RAM on VM host hardware that out of warranty with nothing to replace it with. They don’t have the budget and we can’t get budget for cloud instances. They have no RDBMS at all. We’re regulated too. We have to verify customer identities before account access. They call about all kinds of stuff. Oh, and we support three different spoken and written languages. There are all sorts of formalities our call center has to go through. We don’t even have menu based ID verification for call ins. It’s all done by humans talking to each other. &lt;/p&gt;

&lt;p&gt;Yeah, we ain’t getting full human passing customer service automatons by 2023. I hope I’m out of this dumpster fire before December. Is it that tempting to replace ones workforce with robots that they’re completely blind to the actual reality of doing it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hb5lzl,decucar,10,/r/datascience/comments/hb5lzl/whats_the_deal_with_executives_wanting_chatbots/,https://www.reddit.com/r/datascience/comments/hb5lzl/whats_the_deal_with_executives_wanting_chatbots/,1592446363.0
r/datascience,"If you had to work out of the office, what is the best laptop to get at the lowest price where you can still get all data science stuff done? I expect that these tasks would involve opening and processing heavy excel files, coding, visualizing data, accommodating video calls properly, and anything else I forgot to mention.

If I am correct in my assumption I would say this laptop would have at least 16GB RAM and at least an i7 processor. But correct me if I am wrong.

Also of course, this laptop should be dependable and thus durable. Do you have any suggestions?


P.S.
I am familiar with services that allow laptop customization, however this is not yet being done in my country and thus, the reason I am asking.


Edit: oh yeah, and a good screen!",t2_4l4vpkbp,What laptop is the most optimal one to get that is just enough to get anything done within data science?,discussion,t3_hb4vr7,0.71,11,Discussion,11,1592472497.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If you had to work out of the office, what is the best laptop to get at the lowest price where you can still get all data science stuff done? I expect that these tasks would involve opening and processing heavy excel files, coding, visualizing data, accommodating video calls properly, and anything else I forgot to mention.&lt;/p&gt;

&lt;p&gt;If I am correct in my assumption I would say this laptop would have at least 16GB RAM and at least an i7 processor. But correct me if I am wrong.&lt;/p&gt;

&lt;p&gt;Also of course, this laptop should be dependable and thus durable. Do you have any suggestions?&lt;/p&gt;

&lt;p&gt;P.S.
I am familiar with services that allow laptop customization, however this is not yet being done in my country and thus, the reason I am asking.&lt;/p&gt;

&lt;p&gt;Edit: oh yeah, and a good screen!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hb4vr7,adykinskywalker,26,/r/datascience/comments/hb4vr7/what_laptop_is_the_most_optimal_one_to_get_that/,https://www.reddit.com/r/datascience/comments/hb4vr7/what_laptop_is_the_most_optimal_one_to_get_that/,1592443697.0
r/datascience,"So I'm deep in my career, which when I was hired was mostly focuses on analytics.  I.E.  Excel charting.  

As a programmer, I migrated away from excel and have a lot of automation using things like Jenkins for devops/data pipeline things and R Studio and Shiny apps to create apps for visualizing and working with data.  I do a lot of data engineering in oracle, creating repositories for internal apps and to serve to other enterprise apps outside of my department.  And lots of analysis via PLSQL queries against our database that runs our business.

I have practically no experience in Machine Learning or Neural Networks.

Most folks are classified as business analysts here.  Which is a range of people who use the gui of our business system and configure it via gui prompts, to devOps and our front and back end developers.

I tapped out of the front end game as data was my thing.  (Im way above average with my SQL and subject matter expertise of Oracle systems) And over the last year have really been learning R and Shiny apps to where we have a lot of real time dashboards and metrics to view (some on always on wall displays).

Do you think I can sell the 'Data Scientist' role to help reclassify myself here?   I.E.  Can I refer to myself in practice as a data scientist without have Deep learning/machine learning/neural network skills in my toolbox?",t2_43tie,Another 'Am I a data scientist' question,career,t3_hbjsrg,0.25,0,Career,0,1592532409.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I&amp;#39;m deep in my career, which when I was hired was mostly focuses on analytics.  I.E.  Excel charting.  &lt;/p&gt;

&lt;p&gt;As a programmer, I migrated away from excel and have a lot of automation using things like Jenkins for devops/data pipeline things and R Studio and Shiny apps to create apps for visualizing and working with data.  I do a lot of data engineering in oracle, creating repositories for internal apps and to serve to other enterprise apps outside of my department.  And lots of analysis via PLSQL queries against our database that runs our business.&lt;/p&gt;

&lt;p&gt;I have practically no experience in Machine Learning or Neural Networks.&lt;/p&gt;

&lt;p&gt;Most folks are classified as business analysts here.  Which is a range of people who use the gui of our business system and configure it via gui prompts, to devOps and our front and back end developers.&lt;/p&gt;

&lt;p&gt;I tapped out of the front end game as data was my thing.  (Im way above average with my SQL and subject matter expertise of Oracle systems) And over the last year have really been learning R and Shiny apps to where we have a lot of real time dashboards and metrics to view (some on always on wall displays).&lt;/p&gt;

&lt;p&gt;Do you think I can sell the &amp;#39;Data Scientist&amp;#39; role to help reclassify myself here?   I.E.  Can I refer to myself in practice as a data scientist without have Deep learning/machine learning/neural network skills in my toolbox?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hbjsrg,YoYo-Pete,11,/r/datascience/comments/hbjsrg/another_am_i_a_data_scientist_question/,https://www.reddit.com/r/datascience/comments/hbjsrg/another_am_i_a_data_scientist_question/,1592503609.0
r/datascience,"i'm a full-time data ""scientist"" and my work is basically split between SWE/Data Engineering and business analytics with some modelling thrown in. most data scientists don't do research and don't follow the scientific method. i know the job title today is basically a misnomer, but what were people thinking when they thought this kind of work resembled ""science""? what did OG data scientists do that made their work scientific?",t2_ro6x3qw,"Why is Data Science considered a ""science""",discussion,t3_haku70,0.87,159,Discussion,159,1592400214.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;i&amp;#39;m a full-time data &amp;quot;scientist&amp;quot; and my work is basically split between SWE/Data Engineering and business analytics with some modelling thrown in. most data scientists don&amp;#39;t do research and don&amp;#39;t follow the scientific method. i know the job title today is basically a misnomer, but what were people thinking when they thought this kind of work resembled &amp;quot;science&amp;quot;? what did OG data scientists do that made their work scientific?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",haku70,1083545,71,/r/datascience/comments/haku70/why_is_data_science_considered_a_science/,https://www.reddit.com/r/datascience/comments/haku70/why_is_data_science_considered_a_science/,1592371414.0
r/datascience,"**What standard data categories or metrics proxy a phenomenon and shape our understanding of it?**

  
I am thinking of standardized measurements or categories often used in databases/algorithms to proxy phenomena and which shape our understanding of the concept. 

  
One example would be the IQ score, which proxies intelligence and shaped our understanding of intelligence as unilaterally comparable and one-dimensional.

  
What other, **more widely used metrics** or categories can you think of that have an impact on how we understand the concept they proxy?

  
The question is a bit off-topic, but you would help me so much if you could give me some real-life examples, actually used.",t2_4hgjxbzz,Examples of data categories or metrics that shape our understanding of the concept they proxy,discussion,t3_hazvk7,0.63,2,Discussion,2,1592455907.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;What standard data categories or metrics proxy a phenomenon and shape our understanding of it?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I am thinking of standardized measurements or categories often used in databases/algorithms to proxy phenomena and which shape our understanding of the concept. &lt;/p&gt;

&lt;p&gt;One example would be the IQ score, which proxies intelligence and shaped our understanding of intelligence as unilaterally comparable and one-dimensional.&lt;/p&gt;

&lt;p&gt;What other, &lt;strong&gt;more widely used metrics&lt;/strong&gt; or categories can you think of that have an impact on how we understand the concept they proxy?&lt;/p&gt;

&lt;p&gt;The question is a bit off-topic, but you would help me so much if you could give me some real-life examples, actually used.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hazvk7,philosofication,5,/r/datascience/comments/hazvk7/examples_of_data_categories_or_metrics_that_shape/,https://www.reddit.com/r/datascience/comments/hazvk7/examples_of_data_categories_or_metrics_that_shape/,1592427107.0
r/datascience,"[https://jupyter.org/](https://jupyter.org/)

It receives a lot less press than Jupyter Notebooks (I wasn't aware of it because everyone just talks about Notebooks), but it seems that JupyterLab is more modern, and it's installed/invoked in mostly the same way as the notebooks after installation. (just type `jupyter lab` instead of `jupyter notebook` in the CL)

A few relevant productivity features after playing with it for a bit:

* IDE-like interface, w/ persistent file browser and tabs.
* Seems faster, especially when restarting a kernel
* Dark Mode (correctly implemented)",t2_5f2eg,You probably should be using JupyterLab instead of Jupyter Notebooks,tooling,t3_ha6laa,0.97,627,Tooling,627,1592351462.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://jupyter.org/""&gt;https://jupyter.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It receives a lot less press than Jupyter Notebooks (I wasn&amp;#39;t aware of it because everyone just talks about Notebooks), but it seems that JupyterLab is more modern, and it&amp;#39;s installed/invoked in mostly the same way as the notebooks after installation. (just type &lt;code&gt;jupyter lab&lt;/code&gt; instead of &lt;code&gt;jupyter notebook&lt;/code&gt; in the CL)&lt;/p&gt;

&lt;p&gt;A few relevant productivity features after playing with it for a bit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;IDE-like interface, w/ persistent file browser and tabs.&lt;/li&gt;
&lt;li&gt;Seems faster, especially when restarting a kernel&lt;/li&gt;
&lt;li&gt;Dark Mode (correctly implemented)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ha6laa,minimaxir,202,/r/datascience/comments/ha6laa/you_probably_should_be_using_jupyterlab_instead/,https://www.reddit.com/r/datascience/comments/ha6laa/you_probably_should_be_using_jupyterlab_instead/,1592322662.0
r/datascience,"I've worked a few jobs as a Data Scientist researching complex problems and finding solutions to those difficult problems for tech startups.  I'm often at the heart of if a company succeeds of fails.

However, after I'm done with those projects, I often have nothing left to do at the company.  Specifically, I do not know how else I can help out.  I'm coming to the same crossroads at the current company I'm at worrying if there will be work for me a couple of months from now.

How do you guys find projects to pitch to the company?  I'm currently in the engineering department which is separated from other departments of the company, making it hard for me to know if I can help out in sales or marketing or elsewhere.  I don't want to get laid off.  Has anyone else been in this position?  What did you do?",t2_wu2e3,Data Science: Anyone run out of projects to do in the work place?,projects,t3_haojt0,0.68,8,Projects,8,1592418173.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve worked a few jobs as a Data Scientist researching complex problems and finding solutions to those difficult problems for tech startups.  I&amp;#39;m often at the heart of if a company succeeds of fails.&lt;/p&gt;

&lt;p&gt;However, after I&amp;#39;m done with those projects, I often have nothing left to do at the company.  Specifically, I do not know how else I can help out.  I&amp;#39;m coming to the same crossroads at the current company I&amp;#39;m at worrying if there will be work for me a couple of months from now.&lt;/p&gt;

&lt;p&gt;How do you guys find projects to pitch to the company?  I&amp;#39;m currently in the engineering department which is separated from other departments of the company, making it hard for me to know if I can help out in sales or marketing or elsewhere.  I don&amp;#39;t want to get laid off.  Has anyone else been in this position?  What did you do?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",haojt0,proverbialbunny,25,/r/datascience/comments/haojt0/data_science_anyone_run_out_of_projects_to_do_in/,https://www.reddit.com/r/datascience/comments/haojt0/data_science_anyone_run_out_of_projects_to_do_in/,1592389373.0
r/datascience,"From a NLP application stand point, I don't see much utility in Q/A models, Text summarizer models and text generation models. 

Let me elaborate case wise:

Q/A model: We all know it can never reach human level answering. One tricky question we can get to know whether it is human / chat bot.

Text summarizer : Often a lot of key sentences that form the context are ignored. Summarized yes, but at the cost of information loss. 

Text generation : We all have seen GPT2, GPT3. Honestly, the texts generated are incoherent most of the time. 

Can somebody explain whether they are useful and how?",t2_1umdosna,"Are Q/A models, Text summarizer models and text generation models useful from an NLP application standpoint ?",discussion,t3_havd3m,1.0,2,Discussion,2,1592442359.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;From a NLP application stand point, I don&amp;#39;t see much utility in Q/A models, Text summarizer models and text generation models. &lt;/p&gt;

&lt;p&gt;Let me elaborate case wise:&lt;/p&gt;

&lt;p&gt;Q/A model: We all know it can never reach human level answering. One tricky question we can get to know whether it is human / chat bot.&lt;/p&gt;

&lt;p&gt;Text summarizer : Often a lot of key sentences that form the context are ignored. Summarized yes, but at the cost of information loss. &lt;/p&gt;

&lt;p&gt;Text generation : We all have seen GPT2, GPT3. Honestly, the texts generated are incoherent most of the time. &lt;/p&gt;

&lt;p&gt;Can somebody explain whether they are useful and how?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",havd3m,venkarafa,1,/r/datascience/comments/havd3m/are_qa_models_text_summarizer_models_and_text/,https://www.reddit.com/r/datascience/comments/havd3m/are_qa_models_text_summarizer_models_and_text/,1592413559.0
r/datascience,"Hey there,

How exactly do you spot opportunities to apply data science within your current job if you don't have a data science team yet ? Is there any mental models or checklists you keep to spot such ""data"" or ""problem"" ? 

Thanks.",t2_1a5fk0d4,How do you find data science opportunities within your job ?,career,t3_hat806,0.56,1,Career,1,1592436080.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there,&lt;/p&gt;

&lt;p&gt;How exactly do you spot opportunities to apply data science within your current job if you don&amp;#39;t have a data science team yet ? Is there any mental models or checklists you keep to spot such &amp;quot;data&amp;quot; or &amp;quot;problem&amp;quot; ? &lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hat806,HeyIAmKP,3,/r/datascience/comments/hat806/how_do_you_find_data_science_opportunities_within/,https://www.reddit.com/r/datascience/comments/hat806/how_do_you_find_data_science_opportunities_within/,1592407280.0
r/datascience,"Hello all! 

I hope everyone is having a good day! I’m currently doing research on data cleaning and trying to find any set of guidelines to do it etc (if you have any good sources please link them below!). I was warned by my professor not to get data wrangling and data cleaning confused with one another, but it happened to me and now I don’t know how to UN-confuse myself! If someone can please distinguish these two concepts for me that would help a lot! Thanks so much!",t2_33pq09oy,Can someone help explain the difference between data wrangling and data cleaning?,education,t3_haadzq,0.88,6,Education,6,1592363098.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all! &lt;/p&gt;

&lt;p&gt;I hope everyone is having a good day! I’m currently doing research on data cleaning and trying to find any set of guidelines to do it etc (if you have any good sources please link them below!). I was warned by my professor not to get data wrangling and data cleaning confused with one another, but it happened to me and now I don’t know how to UN-confuse myself! If someone can please distinguish these two concepts for me that would help a lot! Thanks so much!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",haadzq,Mandypandie,8,/r/datascience/comments/haadzq/can_someone_help_explain_the_difference_between/,https://www.reddit.com/r/datascience/comments/haadzq/can_someone_help_explain_the_difference_between/,1592334298.0
r/datascience,"I must warn before I begin that I am coming from the hard science sphere (and am trying to integrate some novel data science) so some of the things I talk about might make no sense. Please ask questions!

I have a database of \~20 variables that are collected continuously over time. This database is essentially measuring the conditions of the interplanetary magnetic field (too complex to model) which drives numerous phenomena that occur in the Earth's atmosphere, etc. These phenomena are of interest to researchers but only occur ever so often. To find these, you have to manually search years and years of data, something that is simply not too practical.

I want to develop some sort of method to take a number of instances of a phenomenon and search the continuous database for more instances. I think that this needs to be split into two tasks.

1. Discover common patterns (dips, spikes, sign changes, or even more complex ""shapes"") between the inputted instances. It will also have to discern the variables of interest because not all in the database will drive a single phenomenon. Moreover, if the program can then output these relationships (such as variables appear to drive the phenomenon) this will be of interest to users.
2. Use these relationships to search the continuous stream for more instances.

Like I mentioned, I am not very experienced in data science. Of course, I am not asking anyone here to develop this for me or anything, but it would be really helpful if someone could point me in the right direction. Eventually, I would like to develop some sort of robust methodology that can be applied to many scientific fields.

&amp;#x200B;

Edit: A lot of people are linking great methods to detect anomalies, but this is not quite what I want. I need pattern recognition, and to be able to detect things like sign changes, not just large spikes/dips.",t2_t8bq8,Identifying Patterns in Time Series Data With Multiple Variables,projects,t3_ha71r6,0.86,10,Projects,10,1592352928.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I must warn before I begin that I am coming from the hard science sphere (and am trying to integrate some novel data science) so some of the things I talk about might make no sense. Please ask questions!&lt;/p&gt;

&lt;p&gt;I have a database of ~20 variables that are collected continuously over time. This database is essentially measuring the conditions of the interplanetary magnetic field (too complex to model) which drives numerous phenomena that occur in the Earth&amp;#39;s atmosphere, etc. These phenomena are of interest to researchers but only occur ever so often. To find these, you have to manually search years and years of data, something that is simply not too practical.&lt;/p&gt;

&lt;p&gt;I want to develop some sort of method to take a number of instances of a phenomenon and search the continuous database for more instances. I think that this needs to be split into two tasks.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Discover common patterns (dips, spikes, sign changes, or even more complex &amp;quot;shapes&amp;quot;) between the inputted instances. It will also have to discern the variables of interest because not all in the database will drive a single phenomenon. Moreover, if the program can then output these relationships (such as variables appear to drive the phenomenon) this will be of interest to users.&lt;/li&gt;
&lt;li&gt;Use these relationships to search the continuous stream for more instances.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Like I mentioned, I am not very experienced in data science. Of course, I am not asking anyone here to develop this for me or anything, but it would be really helpful if someone could point me in the right direction. Eventually, I would like to develop some sort of robust methodology that can be applied to many scientific fields.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Edit: A lot of people are linking great methods to detect anomalies, but this is not quite what I want. I need pattern recognition, and to be able to detect things like sign changes, not just large spikes/dips.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ha71r6,aptitudes,23,/r/datascience/comments/ha71r6/identifying_patterns_in_time_series_data_with/,https://www.reddit.com/r/datascience/comments/ha71r6/identifying_patterns_in_time_series_data_with/,1592324128.0
r/datascience,"I'm currently working as a Data Scientist and would like to move full time to Machine Learning Engineer roles. What is MLEngineer's day to day like and more importantly how can I bridge the current gap. You can consider my skillset as Data Scientist specializing in Machine Learning. I used to deal with AWS, ML.

It would be great if you can provide some resources for those skills too. While my current role is like Data Analyst on steroids, my previous role was primarily ML.

One of the gaps that I identified personally is ML system design. I have never heard of it before and haven't seen any resources. It would be great if you can provide some resources for that.",t2_15svk7,From Data Scientist to Machine Learning Engineer,career,t3_h9p4kl,0.95,218,Career,218,1592284700.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently working as a Data Scientist and would like to move full time to Machine Learning Engineer roles. What is MLEngineer&amp;#39;s day to day like and more importantly how can I bridge the current gap. You can consider my skillset as Data Scientist specializing in Machine Learning. I used to deal with AWS, ML.&lt;/p&gt;

&lt;p&gt;It would be great if you can provide some resources for those skills too. While my current role is like Data Analyst on steroids, my previous role was primarily ML.&lt;/p&gt;

&lt;p&gt;One of the gaps that I identified personally is ML system design. I have never heard of it before and haven&amp;#39;t seen any resources. It would be great if you can provide some resources for that.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h9p4kl,puttasaikiran,71,/r/datascience/comments/h9p4kl/from_data_scientist_to_machine_learning_engineer/,https://www.reddit.com/r/datascience/comments/h9p4kl/from_data_scientist_to_machine_learning_engineer/,1592255900.0
r/datascience,"Every day is an opportunity to learn something new. I learned an important painful lesson today: Make sure you commit and save your code regularly. 

I was working on a project for the past week I didn''t save my progress, nor committed anything. 15 minutes before my meeting with my VP, I decided to restart my computer. My idiot self didn't click on save. Imagine my face when I couldn't find all the things I spent all last week developing.

Luckily, I had other projects to present, and we didn't make it to the part that I completely fucked up. 

SAVE and COMMIT Your code. PLEASE!!!! don't be like me. 

&amp;#x200B;

What are some lessons you learned this week?",t2_1o26bmw3,Important Lesson Learned: Commit and Save your Code Regularly !!!!!!!!!!,discussion,t3_hahauf,0.5,0,Discussion,0,1592386086.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Every day is an opportunity to learn something new. I learned an important painful lesson today: Make sure you commit and save your code regularly. &lt;/p&gt;

&lt;p&gt;I was working on a project for the past week I didn&amp;#39;&amp;#39;t save my progress, nor committed anything. 15 minutes before my meeting with my VP, I decided to restart my computer. My idiot self didn&amp;#39;t click on save. Imagine my face when I couldn&amp;#39;t find all the things I spent all last week developing.&lt;/p&gt;

&lt;p&gt;Luckily, I had other projects to present, and we didn&amp;#39;t make it to the part that I completely fucked up. &lt;/p&gt;

&lt;p&gt;SAVE and COMMIT Your code. PLEASE!!!! don&amp;#39;t be like me. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;What are some lessons you learned this week?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hahauf,da_chosen1,20,/r/datascience/comments/hahauf/important_lesson_learned_commit_and_save_your/,https://www.reddit.com/r/datascience/comments/hahauf/important_lesson_learned_commit_and_save_your/,1592357286.0
r/datascience,"Does anyone know where I can find a powerful virtual/cloud CPU (free or low-cost) to run ipython scripts?

I checked Google Colab and Kaggle notebooks but those CPUs are even slower than my own personal $500 laptop (intel i5).

I also checked the $9.99/month Google Colab Pro but it only has GPU speed up and not more CPU power.

I'm trying to run my machine learning pipeline which does step-wise forward feature selection, cross-validation, and grid search on a large dataset. It is taking 2-3 hours to run my ML pipeline from start to finish on my own laptop right now

Any advice would be appreciated, thanks you guys!",t2_d30qo,Cloud/virtual CPUs for machine learning pipelines?,tooling,t3_hagidj,1.0,1,Tooling,1,1592382996.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone know where I can find a powerful virtual/cloud CPU (free or low-cost) to run ipython scripts?&lt;/p&gt;

&lt;p&gt;I checked Google Colab and Kaggle notebooks but those CPUs are even slower than my own personal $500 laptop (intel i5).&lt;/p&gt;

&lt;p&gt;I also checked the $9.99/month Google Colab Pro but it only has GPU speed up and not more CPU power.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to run my machine learning pipeline which does step-wise forward feature selection, cross-validation, and grid search on a large dataset. It is taking 2-3 hours to run my ML pipeline from start to finish on my own laptop right now&lt;/p&gt;

&lt;p&gt;Any advice would be appreciated, thanks you guys!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",hagidj,Ryien,6,/r/datascience/comments/hagidj/cloudvirtual_cpus_for_machine_learning_pipelines/,https://www.reddit.com/r/datascience/comments/hagidj/cloudvirtual_cpus_for_machine_learning_pipelines/,1592354196.0
r/datascience,"Weird title but hear me out.

**THE PROBLEM**

I have a sample product that is comprised of let's say 3 ingredients, each with concentrations listed in ranges of the total product composition:

&amp;#x200B;

|Ingredient|min concentration (%)|max concentration (%)|
|:-|:-|:-|
|x|25|50|
|y|25|50|
|z|25|50|

Now based on the concentration of each ingredient, the overall product is going to have a different toxicity profile.

If x = 50% y = 25% and z = 25%, then the product has a toxicity score of say 100.

But if x = 25%, y = 50% and z = 25%, then the product has a toxicity score of perhaps 75.

This is a real world problem (ingredients are often listed in ranges), so I guess I can assume normality of the distribution of each ingredient range (or uniformity?).

**WHAT I WANT**

I want to show a probability distribution of overall toxicity, based on some simulated concentration values. Maybe making 1000 potential ingredient ""configurations"" and then running the resulting calculations.

Python &amp; R related solutions are ideal.",t2_6i6uz9kq,Monte Carlo (or other methods) for Ingredient Concentration Estimation,projects,t3_ha85yi,0.75,2,Projects,2,1592356345.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Weird title but hear me out.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;THE PROBLEM&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I have a sample product that is comprised of let&amp;#39;s say 3 ingredients, each with concentrations listed in ranges of the total product composition:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=""left""&gt;Ingredient&lt;/th&gt;
&lt;th align=""left""&gt;min concentration (%)&lt;/th&gt;
&lt;th align=""left""&gt;max concentration (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;x&lt;/td&gt;
&lt;td align=""left""&gt;25&lt;/td&gt;
&lt;td align=""left""&gt;50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;y&lt;/td&gt;
&lt;td align=""left""&gt;25&lt;/td&gt;
&lt;td align=""left""&gt;50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;z&lt;/td&gt;
&lt;td align=""left""&gt;25&lt;/td&gt;
&lt;td align=""left""&gt;50&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;Now based on the concentration of each ingredient, the overall product is going to have a different toxicity profile.&lt;/p&gt;

&lt;p&gt;If x = 50% y = 25% and z = 25%, then the product has a toxicity score of say 100.&lt;/p&gt;

&lt;p&gt;But if x = 25%, y = 50% and z = 25%, then the product has a toxicity score of perhaps 75.&lt;/p&gt;

&lt;p&gt;This is a real world problem (ingredients are often listed in ranges), so I guess I can assume normality of the distribution of each ingredient range (or uniformity?).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;WHAT I WANT&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I want to show a probability distribution of overall toxicity, based on some simulated concentration values. Maybe making 1000 potential ingredient &amp;quot;configurations&amp;quot; and then running the resulting calculations.&lt;/p&gt;

&lt;p&gt;Python &amp;amp; R related solutions are ideal.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ha85yi,texan_spaghet,6,/r/datascience/comments/ha85yi/monte_carlo_or_other_methods_for_ingredient/,https://www.reddit.com/r/datascience/comments/ha85yi/monte_carlo_or_other_methods_for_ingredient/,1592327545.0
r/datascience,"These past weeks I've been working on an ML web app as a side project. Being a Data Scientist, I decided to take on this project for two reasons. First, it would make for a good learning experience for the things I'm not very comfortable with like Design/Front-end and Deployment tasks. Second, as I found most of the materials lacking, I thought I could gather some useful information to write a blog post about it.

I made a web app that tracks the sentiment on twitter towards the leaders of the top political parties in Spain. It works —more or less— in real-time. The site is live here: [https://polituits.com/](https://polituits.com/)

Some things went well, others that I could have done better, and others that at this point I'm not sure haha (e.g., How much traffic would it handle?). I thought I could share those things before getting to work on the blog post.

I'll start with the **things that made my life easier:**

1. [End-to-end Machine Learning App](https://www.ahmedbesbes.com/case-studies/end-to-end-ml-app). This is a great resource. It goes through the full process of building a Machine Learning application in a realistic setting. Most of the materials you'll find out there will skip deployment or work with simple data sets. This one goes from scraping to deploying in AWS. A few days ago, I also read [this one](http://veekaybee.github.io/2020/06/09/ml-in-prod/), which I also recommend.
2. [Dash](https://plotly.com/dash/). I compared Streamlit and Dash and went with the latter for better documentation and a more significant community. The deployment part was especially painful, so proper documentation was critical to get the job done.
3. [HugginFace's Transformers](https://huggingface.co/). If you are working with NLP tasks in languages other than English, check HuggingFace's repository of community models. Furthermore, it is relatively easy to integrate into an inference service built with Pytorch/Flask.
4. [Abhishek Thakur's tutorials](https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A) and [Kaggle Notebooks](https://www.kaggle.com/abhishek/notebooks) for fine-tuning BERT. Fantastic resources that saved me a lot of time. Especially when using those ideas with a pre-trained BERT in Spanish from HuggingFace's transformers.
5. More generally, I benefited from keeping the toolset simple. I used PowerPoint when I started designing the app (see the initial design [here](https://twitter.com/_dylancastillo/status/1272238506916675591)), SQLite as a database, and Python/Dash (instead of JavaScript).

Now, the **things that I wish I had done differently:**

1. Contain the scope. I started with a straightforward idea and then started adding stuff that just made my life harder. Most of the time, I think it was because I felt the app was not ""complex"" enough for publishing it.
2. Deployment. Ha! The only good thing about it's that it ""works"". Right now, it is a painfully manual process. I should have gotten to a better deployment process from the beginning. By the time I started deploying, it felt like too much work.
3. Sacrificed code quality. I wanted to ship this quickly. So the code is not DRY. It's more like CRY yourself to sleep. Refactoring is among my top priorities now.
4. Model. It's not great right now. It only gets the job done. I did not dedicate that much time to labeling data for fine-tuning the model. This is also a priority for me right now.

Finally, there are many things for which I don't know if I was following the ""best practices."" In particular, setting up NGINX and Gunicorn felt a bit *hacky*. Sooner or later, I guess I'll find out.

EDIT: Just noticed the big typo on the title. Sorry! haha",t2_yylgy,Things I Learned while building Machine Learning web app,projects,t3_h9q7im,0.95,41,Projects,41,1592288306.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;These past weeks I&amp;#39;ve been working on an ML web app as a side project. Being a Data Scientist, I decided to take on this project for two reasons. First, it would make for a good learning experience for the things I&amp;#39;m not very comfortable with like Design/Front-end and Deployment tasks. Second, as I found most of the materials lacking, I thought I could gather some useful information to write a blog post about it.&lt;/p&gt;

&lt;p&gt;I made a web app that tracks the sentiment on twitter towards the leaders of the top political parties in Spain. It works —more or less— in real-time. The site is live here: &lt;a href=""https://polituits.com/""&gt;https://polituits.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Some things went well, others that I could have done better, and others that at this point I&amp;#39;m not sure haha (e.g., How much traffic would it handle?). I thought I could share those things before getting to work on the blog post.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ll start with the &lt;strong&gt;things that made my life easier:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=""https://www.ahmedbesbes.com/case-studies/end-to-end-ml-app""&gt;End-to-end Machine Learning App&lt;/a&gt;. This is a great resource. It goes through the full process of building a Machine Learning application in a realistic setting. Most of the materials you&amp;#39;ll find out there will skip deployment or work with simple data sets. This one goes from scraping to deploying in AWS. A few days ago, I also read &lt;a href=""http://veekaybee.github.io/2020/06/09/ml-in-prod/""&gt;this one&lt;/a&gt;, which I also recommend.&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://plotly.com/dash/""&gt;Dash&lt;/a&gt;. I compared Streamlit and Dash and went with the latter for better documentation and a more significant community. The deployment part was especially painful, so proper documentation was critical to get the job done.&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://huggingface.co/""&gt;HugginFace&amp;#39;s Transformers&lt;/a&gt;. If you are working with NLP tasks in languages other than English, check HuggingFace&amp;#39;s repository of community models. Furthermore, it is relatively easy to integrate into an inference service built with Pytorch/Flask.&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A""&gt;Abhishek Thakur&amp;#39;s tutorials&lt;/a&gt; and &lt;a href=""https://www.kaggle.com/abhishek/notebooks""&gt;Kaggle Notebooks&lt;/a&gt; for fine-tuning BERT. Fantastic resources that saved me a lot of time. Especially when using those ideas with a pre-trained BERT in Spanish from HuggingFace&amp;#39;s transformers.&lt;/li&gt;
&lt;li&gt;More generally, I benefited from keeping the toolset simple. I used PowerPoint when I started designing the app (see the initial design &lt;a href=""https://twitter.com/_dylancastillo/status/1272238506916675591""&gt;here&lt;/a&gt;), SQLite as a database, and Python/Dash (instead of JavaScript).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now, the &lt;strong&gt;things that I wish I had done differently:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Contain the scope. I started with a straightforward idea and then started adding stuff that just made my life harder. Most of the time, I think it was because I felt the app was not &amp;quot;complex&amp;quot; enough for publishing it.&lt;/li&gt;
&lt;li&gt;Deployment. Ha! The only good thing about it&amp;#39;s that it &amp;quot;works&amp;quot;. Right now, it is a painfully manual process. I should have gotten to a better deployment process from the beginning. By the time I started deploying, it felt like too much work.&lt;/li&gt;
&lt;li&gt;Sacrificed code quality. I wanted to ship this quickly. So the code is not DRY. It&amp;#39;s more like CRY yourself to sleep. Refactoring is among my top priorities now.&lt;/li&gt;
&lt;li&gt;Model. It&amp;#39;s not great right now. It only gets the job done. I did not dedicate that much time to labeling data for fine-tuning the model. This is also a priority for me right now.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Finally, there are many things for which I don&amp;#39;t know if I was following the &amp;quot;best practices.&amp;quot; In particular, setting up NGINX and Gunicorn felt a bit &lt;em&gt;hacky&lt;/em&gt;. Sooner or later, I guess I&amp;#39;ll find out.&lt;/p&gt;

&lt;p&gt;EDIT: Just noticed the big typo on the title. Sorry! haha&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h9q7im,dcastm,20,/r/datascience/comments/h9q7im/things_i_learned_while_building_machine_learning/,https://www.reddit.com/r/datascience/comments/h9q7im/things_i_learned_while_building_machine_learning/,1592259506.0
r/datascience,"so here is an example of what i'm trying to do.  suppose this is cell phones:  From a sales standpoint, theres Quotes, sales, and upgrades.

if I want to predict sales (sold/not sold), I can use my quote leads and do a model on probability of sold/not sold.  if I want to predict who upgraded their product, I can use my sold data and predict upgrade/no upgrade.

What if, I want to predict the following:  What impact does upgrades have on my conversion?  I cant model sold/not sold using upgrades because all upgrades are ""sold"".  I'm trying measure if high rate of upgrade also means high rate of conversion, etc etc",t2_i6go6an,hard to explain in a topic...but how to model on conversion based on upgrades (when upgrades are 100% converted),projects,t3_ha6hmz,1.0,1,Projects,1,1592351132.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;so here is an example of what i&amp;#39;m trying to do.  suppose this is cell phones:  From a sales standpoint, theres Quotes, sales, and upgrades.&lt;/p&gt;

&lt;p&gt;if I want to predict sales (sold/not sold), I can use my quote leads and do a model on probability of sold/not sold.  if I want to predict who upgraded their product, I can use my sold data and predict upgrade/no upgrade.&lt;/p&gt;

&lt;p&gt;What if, I want to predict the following:  What impact does upgrades have on my conversion?  I cant model sold/not sold using upgrades because all upgrades are &amp;quot;sold&amp;quot;.  I&amp;#39;m trying measure if high rate of upgrade also means high rate of conversion, etc etc&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ha6hmz,mrdlau,0,/r/datascience/comments/ha6hmz/hard_to_explain_in_a_topicbut_how_to_model_on/,https://www.reddit.com/r/datascience/comments/ha6hmz/hard_to_explain_in_a_topicbut_how_to_model_on/,1592322332.0
r/datascience,"I've been reading through recent career thread on this sub, namely [I'm offered a data engineer role instead of data science, should I take it?](https://www.reddit.com/r/datascience/comments/h8yjdf/im_offered_a_data_engineer_role_instead_of_data/) and [From Data Scientist to Machine Learning Engineer](https://www.reddit.com/r/datascience/comments/h9p4kl/from_data_scientist_to_machine_learning_engineer/), and it seems like there are a couple overarching themes: that nowadays, data science and ML jobs are largely about  building pipelines, deploying models and other engineering things related to building out an ML system; that the modeling is only a small part of the job. 

So is knowing all the math and statistical theory behind models becoming less important as more and more data science jobs become more engineering-focused roles? I understand that it obviously doesn't hurt to have a strong math background, and my question is NOT whether the math/stats stopped becoming important. My question is, has the emphasis and the importance of the math/stats *waned* for many data science jobs, as needs shift toward deployment or pipelines?",t2_5xux0a4p,Is statistics and the math behind data science and ML increasingly becoming less important?,discussion,t3_ha6ffm,0.47,0,Discussion,0,1592350939.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been reading through recent career thread on this sub, namely &lt;a href=""https://www.reddit.com/r/datascience/comments/h8yjdf/im_offered_a_data_engineer_role_instead_of_data/""&gt;I&amp;#39;m offered a data engineer role instead of data science, should I take it?&lt;/a&gt; and &lt;a href=""https://www.reddit.com/r/datascience/comments/h9p4kl/from_data_scientist_to_machine_learning_engineer/""&gt;From Data Scientist to Machine Learning Engineer&lt;/a&gt;, and it seems like there are a couple overarching themes: that nowadays, data science and ML jobs are largely about  building pipelines, deploying models and other engineering things related to building out an ML system; that the modeling is only a small part of the job. &lt;/p&gt;

&lt;p&gt;So is knowing all the math and statistical theory behind models becoming less important as more and more data science jobs become more engineering-focused roles? I understand that it obviously doesn&amp;#39;t hurt to have a strong math background, and my question is NOT whether the math/stats stopped becoming important. My question is, has the emphasis and the importance of the math/stats &lt;em&gt;waned&lt;/em&gt; for many data science jobs, as needs shift toward deployment or pipelines?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ha6ffm,___24601,6,/r/datascience/comments/ha6ffm/is_statistics_and_the_math_behind_data_science/,https://www.reddit.com/r/datascience/comments/ha6ffm/is_statistics_and_the_math_behind_data_science/,1592322139.0
r/datascience,"Hi everyone,

Thought I'd share some advice that has helped me so far in my Data Science career. It has to do with recording your wins at work - hope you like it!

\-----

The human brain is terrible at remembering information.

When we try to use the past to predict the future, we end up using *our memory* of the past. And our memory is extremely flawed, subject to whims and emotions.

One of the biggest consequences of this is at work.

You clock in 9-5 for days on days and then when you look back at what you did a year ago, you think “Where did all that time go?”

Even worse, if YOU can’t remember what the hell you did, how will your boss?

In an ideal world: you do a great job, your company rewards you. They’ll notice all the hard work you’re putting in. All the beautiful lines of code you’ve written.

But we don’t live in an ideal world. And the costliest mistake you can make in your career is not being proactive about recording your achievements and your little wins.

**Enter The Brag Document**

I first read about a Brag Document on [Julia Evan’s blog](https://jvns.ca/blog/brag-documents/#template).

By recording your small wins and accomplishments on a weekly basis, you accumulate concrete evidence of what you’ve achieved.

And these “wins” don’t need to be Olympic Gold Medals.

Did you help a coworker understand how to use an API? Jot it down.

Did you anticipate a nasty bug and proactively reach out about it? It goes on there.

Did you help mentor a junior employee? That’s definitely part of it.

Over time, I promise you, your brag document will do wonders for your career.

Sure - negotiating a raise or getting a promotion will become easier. In fact, come performance review time, even your boss will thank you for it. Those things are hard to write from pure memory. More on this a bit later.

But the biggest benefit of a brag document lies in identifying *what you enjoy doing*.

Your wins are likely a representation of tasks you enjoyed. And you should be very proactive about focusing on those tasks going forward.

Use your Brag Document to ruthlessly identify the tasks you want to spend more time on, as well as the tasks you don’t want to do anymore.

**The Pareto Principle**

The Pareto Principle states that 80% of the effects come from 20% of the causes.

At work, 80% of what you can feel proud about will stem from 20% of what you do. You can think of your Brag Document as representing that 20%.

Use this 20% to ask yourself questions like:

* Is there a common theme amongst this work?
* Are there topics here that I thought I didn’t actually like but turns out I do?
* How much of this work involves collaboration with other departments / teams?
* How can I do more of this work?

**Frequency**

Update your brag document on a weekly basis. You can set it as a recurring event on your calendar.

The biggest benefit of this is that it forces you to scrutinize your output on a regular basis and allows you to be proactive about focusing on the work you want to do.

Let’s say that after a few weeks of work, you genuinely have nothing to put on your brag document.

There’s a chance you had a bit of a slow period at work, but maybe you’re just stuck somewhere you don’t want to be?

**Collaborate**

Talk about your brag document with co-workers. Ask them what you think you should put on yours.

You’ll often find that they’re able to mention things you completely forgot or didn’t even seem to think about.

Remember - just because something seems easy *to you* doesn’t mean it’s easy in general. 5 minutes of work may have taken you 10 years to learn.

You should also encourage your team to keep their own brag documents. Help each other be accountable and celebrate each other’s wins. This builds a strong team culture.

**Your Manager**

You should try to share your brag document with your manager once a quarter.

It might seem **weird** or **unnatural** \- you’re basically dumping all your achievements into their lap. But this actually really makes their life easier.

If your manager ever needs to vouch for you internally, then boom - they have direct evidence they can use. If your manager needs to reshuffle workload, then they know what you’re good at and what you can improve on.

Even better, you and your manager should go through your brag document together.

Tell them what you want to do more of. Tell them what you wish was on there more.

You’ll both be able to identify areas in which you’re doing a great job and also areas in which your manager perhaps wants you to focus on more.

Another aspect that’s helpful here is with goal setting - your manager and you likely work together anyway to determine quarterly goals.

You should use your brag document to help you identify what type of goals you need to be hitting. Very often, we will achieve goals and then think “Wait..what was the point again?”

By using your brag document to set goals, you’ll be much more likely to be working towards something that you find rewarding.

**Ending thoughts**

Once you start getting in the habit of using a brag document, operating without one will feel like doing your work in the dark.

Over time, you’ll develop a much clearer picture of the type of work that you want to focus on for your career.

If you liked this post, feel free to check out the whole article with nice illustrations [here](https://www.careerfair.io/reviews/howtobragatwork). I give [practical career advice](https://www.careerfair.io/) for tech professionals through a newsletter, would love it if you checked it out :)",t2_qr5uf,Keep a Brag Document,career,t3_h96nz8,0.98,634,Career,634,1592214886.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;Thought I&amp;#39;d share some advice that has helped me so far in my Data Science career. It has to do with recording your wins at work - hope you like it!&lt;/p&gt;

&lt;p&gt;-----&lt;/p&gt;

&lt;p&gt;The human brain is terrible at remembering information.&lt;/p&gt;

&lt;p&gt;When we try to use the past to predict the future, we end up using &lt;em&gt;our memory&lt;/em&gt; of the past. And our memory is extremely flawed, subject to whims and emotions.&lt;/p&gt;

&lt;p&gt;One of the biggest consequences of this is at work.&lt;/p&gt;

&lt;p&gt;You clock in 9-5 for days on days and then when you look back at what you did a year ago, you think “Where did all that time go?”&lt;/p&gt;

&lt;p&gt;Even worse, if YOU can’t remember what the hell you did, how will your boss?&lt;/p&gt;

&lt;p&gt;In an ideal world: you do a great job, your company rewards you. They’ll notice all the hard work you’re putting in. All the beautiful lines of code you’ve written.&lt;/p&gt;

&lt;p&gt;But we don’t live in an ideal world. And the costliest mistake you can make in your career is not being proactive about recording your achievements and your little wins.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Enter The Brag Document&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I first read about a Brag Document on &lt;a href=""https://jvns.ca/blog/brag-documents/#template""&gt;Julia Evan’s blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;By recording your small wins and accomplishments on a weekly basis, you accumulate concrete evidence of what you’ve achieved.&lt;/p&gt;

&lt;p&gt;And these “wins” don’t need to be Olympic Gold Medals.&lt;/p&gt;

&lt;p&gt;Did you help a coworker understand how to use an API? Jot it down.&lt;/p&gt;

&lt;p&gt;Did you anticipate a nasty bug and proactively reach out about it? It goes on there.&lt;/p&gt;

&lt;p&gt;Did you help mentor a junior employee? That’s definitely part of it.&lt;/p&gt;

&lt;p&gt;Over time, I promise you, your brag document will do wonders for your career.&lt;/p&gt;

&lt;p&gt;Sure - negotiating a raise or getting a promotion will become easier. In fact, come performance review time, even your boss will thank you for it. Those things are hard to write from pure memory. More on this a bit later.&lt;/p&gt;

&lt;p&gt;But the biggest benefit of a brag document lies in identifying &lt;em&gt;what you enjoy doing&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Your wins are likely a representation of tasks you enjoyed. And you should be very proactive about focusing on those tasks going forward.&lt;/p&gt;

&lt;p&gt;Use your Brag Document to ruthlessly identify the tasks you want to spend more time on, as well as the tasks you don’t want to do anymore.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Pareto Principle&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The Pareto Principle states that 80% of the effects come from 20% of the causes.&lt;/p&gt;

&lt;p&gt;At work, 80% of what you can feel proud about will stem from 20% of what you do. You can think of your Brag Document as representing that 20%.&lt;/p&gt;

&lt;p&gt;Use this 20% to ask yourself questions like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Is there a common theme amongst this work?&lt;/li&gt;
&lt;li&gt;Are there topics here that I thought I didn’t actually like but turns out I do?&lt;/li&gt;
&lt;li&gt;How much of this work involves collaboration with other departments / teams?&lt;/li&gt;
&lt;li&gt;How can I do more of this work?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Frequency&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Update your brag document on a weekly basis. You can set it as a recurring event on your calendar.&lt;/p&gt;

&lt;p&gt;The biggest benefit of this is that it forces you to scrutinize your output on a regular basis and allows you to be proactive about focusing on the work you want to do.&lt;/p&gt;

&lt;p&gt;Let’s say that after a few weeks of work, you genuinely have nothing to put on your brag document.&lt;/p&gt;

&lt;p&gt;There’s a chance you had a bit of a slow period at work, but maybe you’re just stuck somewhere you don’t want to be?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Collaborate&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Talk about your brag document with co-workers. Ask them what you think you should put on yours.&lt;/p&gt;

&lt;p&gt;You’ll often find that they’re able to mention things you completely forgot or didn’t even seem to think about.&lt;/p&gt;

&lt;p&gt;Remember - just because something seems easy &lt;em&gt;to you&lt;/em&gt; doesn’t mean it’s easy in general. 5 minutes of work may have taken you 10 years to learn.&lt;/p&gt;

&lt;p&gt;You should also encourage your team to keep their own brag documents. Help each other be accountable and celebrate each other’s wins. This builds a strong team culture.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Your Manager&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;You should try to share your brag document with your manager once a quarter.&lt;/p&gt;

&lt;p&gt;It might seem &lt;strong&gt;weird&lt;/strong&gt; or &lt;strong&gt;unnatural&lt;/strong&gt; - you’re basically dumping all your achievements into their lap. But this actually really makes their life easier.&lt;/p&gt;

&lt;p&gt;If your manager ever needs to vouch for you internally, then boom - they have direct evidence they can use. If your manager needs to reshuffle workload, then they know what you’re good at and what you can improve on.&lt;/p&gt;

&lt;p&gt;Even better, you and your manager should go through your brag document together.&lt;/p&gt;

&lt;p&gt;Tell them what you want to do more of. Tell them what you wish was on there more.&lt;/p&gt;

&lt;p&gt;You’ll both be able to identify areas in which you’re doing a great job and also areas in which your manager perhaps wants you to focus on more.&lt;/p&gt;

&lt;p&gt;Another aspect that’s helpful here is with goal setting - your manager and you likely work together anyway to determine quarterly goals.&lt;/p&gt;

&lt;p&gt;You should use your brag document to help you identify what type of goals you need to be hitting. Very often, we will achieve goals and then think “Wait..what was the point again?”&lt;/p&gt;

&lt;p&gt;By using your brag document to set goals, you’ll be much more likely to be working towards something that you find rewarding.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ending thoughts&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Once you start getting in the habit of using a brag document, operating without one will feel like doing your work in the dark.&lt;/p&gt;

&lt;p&gt;Over time, you’ll develop a much clearer picture of the type of work that you want to focus on for your career.&lt;/p&gt;

&lt;p&gt;If you liked this post, feel free to check out the whole article with nice illustrations &lt;a href=""https://www.careerfair.io/reviews/howtobragatwork""&gt;here&lt;/a&gt;. I give &lt;a href=""https://www.careerfair.io/""&gt;practical career advice&lt;/a&gt; for tech professionals through a newsletter, would love it if you checked it out :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h96nz8,ibsurvivors,30,/r/datascience/comments/h96nz8/keep_a_brag_document/,https://www.reddit.com/r/datascience/comments/h96nz8/keep_a_brag_document/,1592186086.0
r/datascience,"With all the cloud sources like AWS and Microsoft Azure, what do you think of using a Macbook Air 2020 for data analysis? (I am an undergraduate physics student and I won't be dealing with very large datasets)

Do you have any other suggestions? (I currently use a 2012 model ASUS K56CM and a Samsung Galaxy Tab S6 with Jupyter Notebook. I can even use Tensorflow in this tablet)",t2_9xsnzh4,Using Macbook Air for Data Analysis,discussion,t3_ha1j1m,0.5,0,Discussion,0,1592332782.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;With all the cloud sources like AWS and Microsoft Azure, what do you think of using a Macbook Air 2020 for data analysis? (I am an undergraduate physics student and I won&amp;#39;t be dealing with very large datasets)&lt;/p&gt;

&lt;p&gt;Do you have any other suggestions? (I currently use a 2012 model ASUS K56CM and a Samsung Galaxy Tab S6 with Jupyter Notebook. I can even use Tensorflow in this tablet)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",ha1j1m,yertorer,10,/r/datascience/comments/ha1j1m/using_macbook_air_for_data_analysis/,https://www.reddit.com/r/datascience/comments/ha1j1m/using_macbook_air_for_data_analysis/,1592303982.0
r/datascience,"Going to be starting as a business analyst on a newly created data science team and I was wondering what makes a good BA? We are just starting out and the industry we are in is for the most part just now dabbling with the applications outside of engineering. We are small, so just myself and a data scientist along with our manager.

Thanks!",t2_4ucur1ef,What makes a good business analyst in data science?,career,t3_h9tdit,0.73,5,Career,5,1592298836.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Going to be starting as a business analyst on a newly created data science team and I was wondering what makes a good BA? We are just starting out and the industry we are in is for the most part just now dabbling with the applications outside of engineering. We are small, so just myself and a data scientist along with our manager.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h9tdit,shrekstastyforeskin,3,/r/datascience/comments/h9tdit/what_makes_a_good_business_analyst_in_data_science/,https://www.reddit.com/r/datascience/comments/h9tdit/what_makes_a_good_business_analyst_in_data_science/,1592270036.0
r/datascience,"I am conducting a literature review right now and it occurred to me a lot of you guys must be using data science to accelerate this process e.g. using techniques to identify keywords which could help explore new areas.

So I wanted to ask:  What ways are you using data science to conduct a literature review?",t2_11egzf,Conducting a literature review - how do you guys use data science techniques to accelerate your exploration of a domain?,discussion,t3_h9j7rq,0.93,12,Discussion,12,1592266042.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am conducting a literature review right now and it occurred to me a lot of you guys must be using data science to accelerate this process e.g. using techniques to identify keywords which could help explore new areas.&lt;/p&gt;

&lt;p&gt;So I wanted to ask:  What ways are you using data science to conduct a literature review?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h9j7rq,DataScientologist,3,/r/datascience/comments/h9j7rq/conducting_a_literature_review_how_do_you_guys/,https://www.reddit.com/r/datascience/comments/h9j7rq/conducting_a_literature_review_how_do_you_guys/,1592237242.0
r/datascience,"I am searching for a data science role but got offered a data engineer role. As I understanding, there is little modeling in this role, but I get exposure to AWS, noSQL databases, and ""deploying"" the models. 

Should I take it to gain experience that may transfer over to a data science role later? Because i feel i might be in a long wait to find a data scientist position. (I'm currently employed, but I'm in a different field than data analytics, and I want to get in data analytics).

&amp;#x200B;

thanks",t2_33bizuj,"I'm offered a data engineer role instead of data science, should I take it?",,t3_h8yjdf,0.94,202,Job Search,202,1592186725.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am searching for a data science role but got offered a data engineer role. As I understanding, there is little modeling in this role, but I get exposure to AWS, noSQL databases, and &amp;quot;deploying&amp;quot; the models. &lt;/p&gt;

&lt;p&gt;Should I take it to gain experience that may transfer over to a data science role later? Because i feel i might be in a long wait to find a data scientist position. (I&amp;#39;m currently employed, but I&amp;#39;m in a different field than data analytics, and I want to get in data analytics).&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h8yjdf,engineheat,94,/r/datascience/comments/h8yjdf/im_offered_a_data_engineer_role_instead_of_data/,https://www.reddit.com/r/datascience/comments/h8yjdf/im_offered_a_data_engineer_role_instead_of_data/,1592157925.0
r/datascience,"I'm working for an R&amp;D tech company, and my team is developing a niche NLP product. I have developed a serious interest in NLP, but I secretly wish I could use NLP for my personal projects (of which I have plenty of ideas), rather than my job. Some of my frustrations of the latter include:

- Having to read so many badly-written papers and repos. Furthermore, I find the leaderboard chasing and the Frankenstein deep learning models quite off-putting (do we really need transformer + CNN + multi-task learning + multi-lingual model + dual-encoder evaluated on 10 different datasets without any deeper analysis within a single paper?).
- Many of the deep learning models might work well in some leaderboard, but incorporating them to our data is rife with logistical and performance issues. Worse is that most of them are just black-box models with little means to debug if they return a wrong result.
- I'm not really interested in the product that we're building so much that I'm willing to go all in with regard to the above two points. I keep day-dreaming about the NLP projects that *I* want to build and the interesting NLP papers that *I* want to read. Worse is that I'm often so burned out at work that I find little motivation to do any further work on NLP after work.

Perhaps my grievances are with the R&amp;D nature of my job, rather than data science itself. I recently interviewed for a product-focused data scientist role at another company, and my secret wish is that I could do the more ""routine"" data science at work (think regression, clustering, etc.) and do the more cutting-edge data science as a hobby. Does anyone share similar sentiments to mine?",t2_krk6q2t,Do you sometimes wish you could do data science as a hobby rather than a job?,career,t3_h9g8z1,0.75,4,Career,4,1592256138.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working for an R&amp;amp;D tech company, and my team is developing a niche NLP product. I have developed a serious interest in NLP, but I secretly wish I could use NLP for my personal projects (of which I have plenty of ideas), rather than my job. Some of my frustrations of the latter include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Having to read so many badly-written papers and repos. Furthermore, I find the leaderboard chasing and the Frankenstein deep learning models quite off-putting (do we really need transformer + CNN + multi-task learning + multi-lingual model + dual-encoder evaluated on 10 different datasets without any deeper analysis within a single paper?).&lt;/li&gt;
&lt;li&gt;Many of the deep learning models might work well in some leaderboard, but incorporating them to our data is rife with logistical and performance issues. Worse is that most of them are just black-box models with little means to debug if they return a wrong result.&lt;/li&gt;
&lt;li&gt;I&amp;#39;m not really interested in the product that we&amp;#39;re building so much that I&amp;#39;m willing to go all in with regard to the above two points. I keep day-dreaming about the NLP projects that &lt;em&gt;I&lt;/em&gt; want to build and the interesting NLP papers that &lt;em&gt;I&lt;/em&gt; want to read. Worse is that I&amp;#39;m often so burned out at work that I find little motivation to do any further work on NLP after work.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Perhaps my grievances are with the R&amp;amp;D nature of my job, rather than data science itself. I recently interviewed for a product-focused data scientist role at another company, and my secret wish is that I could do the more &amp;quot;routine&amp;quot; data science at work (think regression, clustering, etc.) and do the more cutting-edge data science as a hobby. Does anyone share similar sentiments to mine?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h9g8z1,seismatica,3,/r/datascience/comments/h9g8z1/do_you_sometimes_wish_you_could_do_data_science/,https://www.reddit.com/r/datascience/comments/h9g8z1/do_you_sometimes_wish_you_could_do_data_science/,1592227338.0
r/datascience,"Has anyone had this discussion before? Is there a field threshold for what would be considered fraud? Sure, some people make mistakes and the empirical method always allows for correction, but what about people working in the field who are literal hucksters? Does anyone have examples besides mine below?

I’m talking about the likes of Siraj Raval, or worse, the nobodies at small to medium firms who fakes their way into roles and have no qualifications or backgrounds.

Example, an analyst where I work said this to me and firmly believes it, “statistics is just for making the data look good, the way you want.” When I heard that my jaw dropped. Here is a person working as a data analyst who believes all statistics is meant for it manipulating data to make it look “good.” I’ve also witnessed this analyst, in a presentation to management, display a bar chart with manipulated bins to make them rise along side another series, and then claim correlation! Also, they’ve used that word when comparing two separate pie charts! Manipulating bins to hold different ranges in this manner is surely fraud. Leaning on “correlation” for every chart you produce is just negligent. 

How does someone like that get into a role? The person who is their manager doesn’t know anything beyond that data science is the hottest thing and he needs one in his department.",t2_6nx6nyfy,Analysts Committing Data Science Fraud,discussion,t3_h90bpz,0.84,33,Discussion,33,1592192727.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Has anyone had this discussion before? Is there a field threshold for what would be considered fraud? Sure, some people make mistakes and the empirical method always allows for correction, but what about people working in the field who are literal hucksters? Does anyone have examples besides mine below?&lt;/p&gt;

&lt;p&gt;I’m talking about the likes of Siraj Raval, or worse, the nobodies at small to medium firms who fakes their way into roles and have no qualifications or backgrounds.&lt;/p&gt;

&lt;p&gt;Example, an analyst where I work said this to me and firmly believes it, “statistics is just for making the data look good, the way you want.” When I heard that my jaw dropped. Here is a person working as a data analyst who believes all statistics is meant for it manipulating data to make it look “good.” I’ve also witnessed this analyst, in a presentation to management, display a bar chart with manipulated bins to make them rise along side another series, and then claim correlation! Also, they’ve used that word when comparing two separate pie charts! Manipulating bins to hold different ranges in this manner is surely fraud. Leaning on “correlation” for every chart you produce is just negligent. &lt;/p&gt;

&lt;p&gt;How does someone like that get into a role? The person who is their manager doesn’t know anything beyond that data science is the hottest thing and he needs one in his department.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h90bpz,decucar,19,/r/datascience/comments/h90bpz/analysts_committing_data_science_fraud/,https://www.reddit.com/r/datascience/comments/h90bpz/analysts_committing_data_science_fraud/,1592163927.0
r/datascience," I just finished an introductory data science course and now I am looking to get into deep learning. Is there any point learning TensorFlow or should I skip it and learn 2.0? Also, what's the difference between TensorFlow and Pytorch? I know TensorFlow is preferred in the industry whereas PyTorch is preferred in academia, but is it worth learning both if I prefer to go to industry? I am very confused, please provide some clarity. Thanks in advance!",t2_58bpad3j,Tensorflow vs. Tensorflow 2.0 vs. Pytorch,projects,t3_h8smv7,0.94,100,Projects,100,1592165073.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just finished an introductory data science course and now I am looking to get into deep learning. Is there any point learning TensorFlow or should I skip it and learn 2.0? Also, what&amp;#39;s the difference between TensorFlow and Pytorch? I know TensorFlow is preferred in the industry whereas PyTorch is preferred in academia, but is it worth learning both if I prefer to go to industry? I am very confused, please provide some clarity. Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h8smv7,mythrowaway0852,25,/r/datascience/comments/h8smv7/tensorflow_vs_tensorflow_20_vs_pytorch/,https://www.reddit.com/r/datascience/comments/h8smv7/tensorflow_vs_tensorflow_20_vs_pytorch/,1592136273.0
r/datascience,"I saw that R Studio was certifying people to become R studio trainers.

Can anyone speak to the demand of this as a side business? I would mostly be interested in running workshops on evenings/weekends. What kind of demand can one expect? I know it's hard to answer  this question backed by data so please feel free to share anecdotes, stories and opinions.",t2_7i3k1,How much demand is there for Rstudio Trainer?,discussion,t3_h96e3t,1.0,6,Discussion,6,1592213842.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I saw that R Studio was certifying people to become R studio trainers.&lt;/p&gt;

&lt;p&gt;Can anyone speak to the demand of this as a side business? I would mostly be interested in running workshops on evenings/weekends. What kind of demand can one expect? I know it&amp;#39;s hard to answer  this question backed by data so please feel free to share anecdotes, stories and opinions.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h96e3t,bobthemagiccan,4,/r/datascience/comments/h96e3t/how_much_demand_is_there_for_rstudio_trainer/,https://www.reddit.com/r/datascience/comments/h96e3t/how_much_demand_is_there_for_rstudio_trainer/,1592185042.0
r/datascience,"I remember a couple, like one was ""AustinPowers"" (in promotion of the movie), and the bot would respond so impressively well. I'm curious what methods they used to make them.",t2_3w7nyom5,Anyone have an idea how they made those old AIM chat bots?,fun,t3_h8n6mi,0.91,80,Fun/Trivia,80,1592137673.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I remember a couple, like one was &amp;quot;AustinPowers&amp;quot; (in promotion of the movie), and the bot would respond so impressively well. I&amp;#39;m curious what methods they used to make them.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h8n6mi,anthologyxxviii,19,/r/datascience/comments/h8n6mi/anyone_have_an_idea_how_they_made_those_old_aim/,https://www.reddit.com/r/datascience/comments/h8n6mi/anyone_have_an_idea_how_they_made_those_old_aim/,1592108873.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 14 Jun 2020 - 21 Jun 2020,,t3_h8skw3,0.88,6,Discussion,6,1592164830.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h8skw3,datascience-bot,180,/r/datascience/comments/h8skw3/weekly_entering_transitioning_thread_14_jun_2020/,https://www.reddit.com/r/datascience/comments/h8skw3/weekly_entering_transitioning_thread_14_jun_2020/,1592136030.0
r/datascience,"Hey folks,

I'm working on a small dataset of audio wav files (about 8000 new audio files a day). There's a set of preprocessing and augmentation tasks that we perform on top of each of these audio files which in total take about 10s per audio file (we're using librosa for our audio processing tasks).   


Would like to make this applicable as a general discussion but with the following added notes

\- Assume that obtaining additional compute resources (on-premise or on the cloud) is not a problem 

\- Preprocessing must happen when all new files are collected and not as they are obtained

&amp;#x200B;

What would be a reasonable set of technologies to use for a Data Pipeline in this scenario with the goal of reducing the total preprocessing time to under an hour (currently sitting at around 22 hours)?  


Thanks!",t2_5ylxcvk7,Data Preprocessing Technologies Question,tooling,t3_h924uy,0.5,0,Tooling,0,1592198883.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey folks,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m working on a small dataset of audio wav files (about 8000 new audio files a day). There&amp;#39;s a set of preprocessing and augmentation tasks that we perform on top of each of these audio files which in total take about 10s per audio file (we&amp;#39;re using librosa for our audio processing tasks).   &lt;/p&gt;

&lt;p&gt;Would like to make this applicable as a general discussion but with the following added notes&lt;/p&gt;

&lt;p&gt;- Assume that obtaining additional compute resources (on-premise or on the cloud) is not a problem &lt;/p&gt;

&lt;p&gt;- Preprocessing must happen when all new files are collected and not as they are obtained&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;What would be a reasonable set of technologies to use for a Data Pipeline in this scenario with the goal of reducing the total preprocessing time to under an hour (currently sitting at around 22 hours)?  &lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h924uy,dekoacnh,2,/r/datascience/comments/h924uy/data_preprocessing_technologies_question/,https://www.reddit.com/r/datascience/comments/h924uy/data_preprocessing_technologies_question/,1592170083.0
r/datascience,"I’m starting a masters in data science program this year. My personal laptop is on its last legs so I’m looking to replace it before I start the program. I used to be a Mac person but have drifted away from Macs because my work laptops for the last 4 years have been windows/Linux machines. 90% of my work is done in the cloud so it’s really just a terminal but I’d like something decent still if I end up doing anything local like simulation work. 

My requirements are 16 gb ram,  nice ish screen, great keyboard, and maybe able to play a few light steam games. Right now my top choice is the  ThinkPad X1 Carbon Gen 7 (14”) laptop. It’s last gen model But I’m looking at the model on sale for $1499.99. They seems to be having big sales right now. Anything else I should look for at that price. There are so many options out there just not sure how to narrow it down.

https://www.lenovo.com/us/en/laptops/thinkpad/thinkpad-x1/X1-Carbon-Gen-7/p/22TP2TXX17G",t2_qjqlj,Laptop for a Data Science Program,discussion,t3_h92wj9,0.43,0,Discussion,0,1592201408.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m starting a masters in data science program this year. My personal laptop is on its last legs so I’m looking to replace it before I start the program. I used to be a Mac person but have drifted away from Macs because my work laptops for the last 4 years have been windows/Linux machines. 90% of my work is done in the cloud so it’s really just a terminal but I’d like something decent still if I end up doing anything local like simulation work. &lt;/p&gt;

&lt;p&gt;My requirements are 16 gb ram,  nice ish screen, great keyboard, and maybe able to play a few light steam games. Right now my top choice is the  ThinkPad X1 Carbon Gen 7 (14”) laptop. It’s last gen model But I’m looking at the model on sale for $1499.99. They seems to be having big sales right now. Anything else I should look for at that price. There are so many options out there just not sure how to narrow it down.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.lenovo.com/us/en/laptops/thinkpad/thinkpad-x1/X1-Carbon-Gen-7/p/22TP2TXX17G""&gt;https://www.lenovo.com/us/en/laptops/thinkpad/thinkpad-x1/X1-Carbon-Gen-7/p/22TP2TXX17G&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h92wj9,bikewookie,7,/r/datascience/comments/h92wj9/laptop_for_a_data_science_program/,https://www.reddit.com/r/datascience/comments/h92wj9/laptop_for_a_data_science_program/,1592172608.0
r/datascience,What inspired you to work with animals and how did DS play a role?,t2_5e34w9d2,Anyone working in conservation / wildlife?,career,t3_h8bz3b,0.91,62,Career,62,1592098917.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What inspired you to work with animals and how did DS play a role?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h8bz3b,expatwithajetpack,25,/r/datascience/comments/h8bz3b/anyone_working_in_conservation_wildlife/,https://www.reddit.com/r/datascience/comments/h8bz3b/anyone_working_in_conservation_wildlife/,1592070117.0
r/datascience,,t2_ucebw,What technical skills did you have when you first became a data scientist?,discussion,t3_h7w3av,0.97,227,Discussion,227,1592034538.0,,h7w3av,Megatheorist,125,/r/datascience/comments/h7w3av/what_technical_skills_did_you_have_when_you_first/,https://www.reddit.com/r/datascience/comments/h7w3av/what_technical_skills_did_you_have_when_you_first/,1592005738.0
r/datascience,"By CLTV I mean customer life time value.

I recently started a project to profile our customers. Essentially I'm trying to segment them based on behavior as well as create CLTV around each customer.

This is the second time I encounter this type of project and much similar to the last time, I don't have a good use case for segmentation and CLTV, other than looking pretty on the report.

In logic, high value customers should get better service, but in practice we don't differentiate customers because they all receive the best service we could (or try to) offer. And if we hope to identify potential high CLTV, then we run into the chicken-and-egg thing. Is it because we go the extra mile that turn a customer into high CLTV?

So I'm just curious if anyone also does CLTV and customer segmentation and what the use case for them would be.",t2_qinw9,How do you make use of CLTV?,discussion,t3_h8dmfq,0.81,3,Discussion,3,1592104253.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;By CLTV I mean customer life time value.&lt;/p&gt;

&lt;p&gt;I recently started a project to profile our customers. Essentially I&amp;#39;m trying to segment them based on behavior as well as create CLTV around each customer.&lt;/p&gt;

&lt;p&gt;This is the second time I encounter this type of project and much similar to the last time, I don&amp;#39;t have a good use case for segmentation and CLTV, other than looking pretty on the report.&lt;/p&gt;

&lt;p&gt;In logic, high value customers should get better service, but in practice we don&amp;#39;t differentiate customers because they all receive the best service we could (or try to) offer. And if we hope to identify potential high CLTV, then we run into the chicken-and-egg thing. Is it because we go the extra mile that turn a customer into high CLTV?&lt;/p&gt;

&lt;p&gt;So I&amp;#39;m just curious if anyone also does CLTV and customer segmentation and what the use case for them would be.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h8dmfq,monkeyunited,4,/r/datascience/comments/h8dmfq/how_do_you_make_use_of_cltv/,https://www.reddit.com/r/datascience/comments/h8dmfq/how_do_you_make_use_of_cltv/,1592075453.0
r/datascience,"I've read a few articles here and there about the benefit of doing data science on the command line.  I'm fairly new to this, but my impression is that they are talking about data cleaning, exploring and even running the models just on the command line.

Does anyone do this and can someone explain to me the benefit.  My use case for data science is building the models (more for exploratory analysis, trying to understand business impacts), but I dont push it into production or anything, so i'm trying to understand if this is something I should consider",t2_i6go6an,what's the benefit of doing data science on the command line?,tooling,t3_h8jql3,0.29,0,Tooling,0,1592124422.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve read a few articles here and there about the benefit of doing data science on the command line.  I&amp;#39;m fairly new to this, but my impression is that they are talking about data cleaning, exploring and even running the models just on the command line.&lt;/p&gt;

&lt;p&gt;Does anyone do this and can someone explain to me the benefit.  My use case for data science is building the models (more for exploratory analysis, trying to understand business impacts), but I dont push it into production or anything, so i&amp;#39;m trying to understand if this is something I should consider&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h8jql3,mrdlau,8,/r/datascience/comments/h8jql3/whats_the_benefit_of_doing_data_science_on_the/,https://www.reddit.com/r/datascience/comments/h8jql3/whats_the_benefit_of_doing_data_science_on_the/,1592095622.0
r/datascience,,t2_5t9axiav,"Does any data scientist here have an unusual job? Scientific research, weird company...",,t3_h832dt,0.7,9,Job Search,9,1592062939.0,,h832dt,atheistmonty,12,/r/datascience/comments/h832dt/does_any_data_scientist_here_have_an_unusual_job/,https://www.reddit.com/r/datascience/comments/h832dt/does_any_data_scientist_here_have_an_unusual_job/,1592034139.0
r/datascience,,t2_wf68kb,TIME’s “Superforecasters”... See if you can make it through without an eye-roll,discussion,t3_h883pd,0.53,2,Discussion,2,1592085765.0,,h883pd,csmidwest,24,/r/datascience/comments/h883pd/times_superforecasters_see_if_you_can_make_it/,https://time.com/5848271/superforecasters-covid-19/,1592056965.0
r/datascience,"I will be working at a HFT firm in August out of undergrad as a data scientist and want to prepare myself by studying Time Series Analysis. The company uses python pretty unanimously and it is also my preferred language, so it would be helpful to have a textbook or some sort of resource that teaches both the theoretical fundamentals of Time Series Analysis as well as implementation using Python.

Is there anything out there like this? As far as math/stats goes, although im decent at math, i'd prefer a book that isn't too advanced. If there isn't a great resource out there, would there be a good one for R that I can use? More concerned with the theoretical steps than the programming since I can always google which libraries to use.

&amp;#x200B;

P.S. I took intro and intermediate level stats courses (and was a TA for intermediate stats) as well as practical Linear Algebra and probability courses. Unfortunately none of these covered much Time Series material other than some basic stuff like DW tests, ACF, patterns (cyclical, seasonal), etc;",t2_20fmlr1a,Any great textbooks/resources on Time Series Analysis for Python?,education,t3_h7ufun,0.88,21,Education,21,1592029146.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I will be working at a HFT firm in August out of undergrad as a data scientist and want to prepare myself by studying Time Series Analysis. The company uses python pretty unanimously and it is also my preferred language, so it would be helpful to have a textbook or some sort of resource that teaches both the theoretical fundamentals of Time Series Analysis as well as implementation using Python.&lt;/p&gt;

&lt;p&gt;Is there anything out there like this? As far as math/stats goes, although im decent at math, i&amp;#39;d prefer a book that isn&amp;#39;t too advanced. If there isn&amp;#39;t a great resource out there, would there be a good one for R that I can use? More concerned with the theoretical steps than the programming since I can always google which libraries to use.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;P.S. I took intro and intermediate level stats courses (and was a TA for intermediate stats) as well as practical Linear Algebra and probability courses. Unfortunately none of these covered much Time Series material other than some basic stuff like DW tests, ACF, patterns (cyclical, seasonal), etc;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h7ufun,kid-cudeep,20,/r/datascience/comments/h7ufun/any_great_textbooksresources_on_time_series/,https://www.reddit.com/r/datascience/comments/h7ufun/any_great_textbooksresources_on_time_series/,1592000346.0
r/datascience,"Let's skip basic data cleaning (e.g.,  handling missing data, removing duplicates, doing type conversions,  standardizing values, etc.).   I'm more curious about what steps you follow to try to get useful insights from data as quickly as possible.  A few guiding questions I thought of:

* Do you have a mental or physical checklist that you follow?  If so, what's on it?

* What corners do you cut to try to get a quicker answer?

* What kind of exploratory data analysis is essential to your process?",t2_3pnmt3n,You've just been given a dataset with 500k records and 50+ columns to build a predictive model by the end of the day. What mental checklist do you go through to build a model as quickly and accurately as possible?,discussion,t3_h7dtrq,0.97,591,Discussion,591,1591964321.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Let&amp;#39;s skip basic data cleaning (e.g.,  handling missing data, removing duplicates, doing type conversions,  standardizing values, etc.).   I&amp;#39;m more curious about what steps you follow to try to get useful insights from data as quickly as possible.  A few guiding questions I thought of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Do you have a mental or physical checklist that you follow?  If so, what&amp;#39;s on it?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What corners do you cut to try to get a quicker answer?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What kind of exploratory data analysis is essential to your process?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h7dtrq,im_most_likely_lyin,204,/r/datascience/comments/h7dtrq/youve_just_been_given_a_dataset_with_500k_records/,https://www.reddit.com/r/datascience/comments/h7dtrq/youve_just_been_given_a_dataset_with_500k_records/,1591935521.0
r/datascience,"I am just getting into a data science researcher position after graduation from a maths and cs degree. Just wanted to know what the career paths usually look like for a data science guy when he reaches 40 or 50. Do you move into consultancy/management then? Or just move out of data science to software engineering? 

I ask this as several people burnout due to coding and generally get upgraded positions in terms of time and money. 

I would also love getting some advice to build a stronger career. Taking advantage of the Covid situation to learn the math behind GAN’s and VAE’s right now. Thanks!",t2_5c8w6qot,Data Science Career Paths,career,t3_h7yo4o,0.75,4,Career,4,1592043841.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am just getting into a data science researcher position after graduation from a maths and cs degree. Just wanted to know what the career paths usually look like for a data science guy when he reaches 40 or 50. Do you move into consultancy/management then? Or just move out of data science to software engineering? &lt;/p&gt;

&lt;p&gt;I ask this as several people burnout due to coding and generally get upgraded positions in terms of time and money. &lt;/p&gt;

&lt;p&gt;I would also love getting some advice to build a stronger career. Taking advantage of the Covid situation to learn the math behind GAN’s and VAE’s right now. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h7yo4o,noir_geralt,9,/r/datascience/comments/h7yo4o/data_science_career_paths/,https://www.reddit.com/r/datascience/comments/h7yo4o/data_science_career_paths/,1592015041.0
r/datascience,"I'm in the process of building a python training program for some non-software engineers. I can make a really solid case for why they should learn Python + Numpy +Matplotlib, but I'm having a really hard time making the case for Pandas.

What are some killer features of the Pandas library that aren't easily achieved with python, matplotlib, and numpy?",t2_nqzw5,"Python + Matplotlib + Numpy + Pandas, but why Pandas?",discussion,t3_h7oir9,0.69,5,Discussion,5,1592009850.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m in the process of building a python training program for some non-software engineers. I can make a really solid case for why they should learn Python + Numpy +Matplotlib, but I&amp;#39;m having a really hard time making the case for Pandas.&lt;/p&gt;

&lt;p&gt;What are some killer features of the Pandas library that aren&amp;#39;t easily achieved with python, matplotlib, and numpy?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h7oir9,billFoldDog,32,/r/datascience/comments/h7oir9/python_matplotlib_numpy_pandas_but_why_pandas/,https://www.reddit.com/r/datascience/comments/h7oir9/python_matplotlib_numpy_pandas_but_why_pandas/,1591981050.0
r/datascience," Hi all, hope everyone is doing well. 

I've tinkered with data science for quite some time and encountered methodologies such as [SEMMA](https://documentation.sas.com/?docsetId=emref&amp;docsetTarget=n061bzurmej4j3n1jnj8bbjjm1a2.htm&amp;docsetVersion=14.3&amp;locale=en) or [CRISP-DM](https://www.datasciencecentral.com/profiles/blogs/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome) for data mining projects. However, I'm curious as to whether NLP-specific methodologies exist. My Google-Fu doesn't seem to reveal anything of the sort. I was hoping to pick your guys' brains on this. Do you know of anything relevant here?

And if NLP-specific methodologies doesn't exist, why is that? Is the field simply to broad for it?

Side note: Working on an NLP project, I was asked to describe the ""conceptual framework"", which apparently means ""concepts of relevance to research problem data analytics methods and techniques"". What the frick does that really mean?

Thanks for reading! Also posted in r/LanguageTechnology without much traction.",t2_26n50qtm,NLP Methodology,tooling,t3_h7lhgw,1.0,3,Tooling,3,1592000222.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, hope everyone is doing well. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve tinkered with data science for quite some time and encountered methodologies such as &lt;a href=""https://documentation.sas.com/?docsetId=emref&amp;amp;docsetTarget=n061bzurmej4j3n1jnj8bbjjm1a2.htm&amp;amp;docsetVersion=14.3&amp;amp;locale=en""&gt;SEMMA&lt;/a&gt; or &lt;a href=""https://www.datasciencecentral.com/profiles/blogs/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome""&gt;CRISP-DM&lt;/a&gt; for data mining projects. However, I&amp;#39;m curious as to whether NLP-specific methodologies exist. My Google-Fu doesn&amp;#39;t seem to reveal anything of the sort. I was hoping to pick your guys&amp;#39; brains on this. Do you know of anything relevant here?&lt;/p&gt;

&lt;p&gt;And if NLP-specific methodologies doesn&amp;#39;t exist, why is that? Is the field simply to broad for it?&lt;/p&gt;

&lt;p&gt;Side note: Working on an NLP project, I was asked to describe the &amp;quot;conceptual framework&amp;quot;, which apparently means &amp;quot;concepts of relevance to research problem data analytics methods and techniques&amp;quot;. What the frick does that really mean?&lt;/p&gt;

&lt;p&gt;Thanks for reading! Also posted in &lt;a href=""/r/LanguageTechnology""&gt;r/LanguageTechnology&lt;/a&gt; without much traction.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h7lhgw,Academy-,6,/r/datascience/comments/h7lhgw/nlp_methodology/,https://www.reddit.com/r/datascience/comments/h7lhgw/nlp_methodology/,1591971422.0
r/datascience,"Hey all (: I'm a non english speaker college student who needs some help

Since february I'm working at a big company as an intern in a brand new data team focused on analysing data to identify suspicious behaviour in user accounts and devices. We spent a few months searching and configuring some tools to help us (Jupyter, Spark, AWS EMR...) and finally we made progress and have a good set of tools and some data (soon even more)! But the problem is: actually, we have little idea of ​​what we're doing.

&amp;#x200B;

The ""data science"" people of the team are me and other intern. We have two backend developers and one data analytics who is learning DS too. It's amazing how the company gives almost total freedom to teams to build products and invest time on new ideas , including our, and I'm very grateful that my team trust and support yours interns to build something good, we even did some cool analysis recently, but the fact of we have no guidance or reference inside the company is very scary sometimes.

&amp;#x200B;

I have little knowledge about Data Science/Analysis/Engineering, most from a few courses (like ""Machine Learning"" by Andrew N.g.) and some college subjects. I'm really liking the company, the area, my team and the opportunity to build something, so my questions are:

Has anyone been in a similar situation here? What resources would you recommend to improve skills and become a self taught data scientist/analyst and start thinking as one? Any tips or advices? Or small and simple projects using data you made at your company to inspire us?

&amp;#x200B;

Thanks in advance :D",t2_13xh0m,I got a data science internship! But I have no guidance,discussion,t3_h7a5mz,0.81,12,Discussion,12,1591950185.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all (: I&amp;#39;m a non english speaker college student who needs some help&lt;/p&gt;

&lt;p&gt;Since february I&amp;#39;m working at a big company as an intern in a brand new data team focused on analysing data to identify suspicious behaviour in user accounts and devices. We spent a few months searching and configuring some tools to help us (Jupyter, Spark, AWS EMR...) and finally we made progress and have a good set of tools and some data (soon even more)! But the problem is: actually, we have little idea of ​​what we&amp;#39;re doing.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The &amp;quot;data science&amp;quot; people of the team are me and other intern. We have two backend developers and one data analytics who is learning DS too. It&amp;#39;s amazing how the company gives almost total freedom to teams to build products and invest time on new ideas , including our, and I&amp;#39;m very grateful that my team trust and support yours interns to build something good, we even did some cool analysis recently, but the fact of we have no guidance or reference inside the company is very scary sometimes.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have little knowledge about Data Science/Analysis/Engineering, most from a few courses (like &amp;quot;Machine Learning&amp;quot; by Andrew N.g.) and some college subjects. I&amp;#39;m really liking the company, the area, my team and the opportunity to build something, so my questions are:&lt;/p&gt;

&lt;p&gt;Has anyone been in a similar situation here? What resources would you recommend to improve skills and become a self taught data scientist/analyst and start thinking as one? Any tips or advices? Or small and simple projects using data you made at your company to inspire us?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks in advance :D&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h7a5mz,Aquatok,11,/r/datascience/comments/h7a5mz/i_got_a_data_science_internship_but_i_have_no/,https://www.reddit.com/r/datascience/comments/h7a5mz/i_got_a_data_science_internship_but_i_have_no/,1591921385.0
r/datascience,For past 2 week i am using Neovim for data analysis and frankly i love using it due to its extensive configurable nature.  With Neovim i am able to use terminal emulator within my editor. What are your thoughts on vim for data science? Also suggest some good plugins from data science perspective.,t2_4l272piv,How is your experience with Vim \ Neovim??,discussion,t3_h7gna8,0.5,0,Discussion,0,1591978097.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For past 2 week i am using Neovim for data analysis and frankly i love using it due to its extensive configurable nature.  With Neovim i am able to use terminal emulator within my editor. What are your thoughts on vim for data science? Also suggest some good plugins from data science perspective.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h7gna8,Nhasan25,10,/r/datascience/comments/h7gna8/how_is_your_experience_with_vim_neovim/,https://www.reddit.com/r/datascience/comments/h7gna8/how_is_your_experience_with_vim_neovim/,1591949297.0
r/datascience,"Hi all! I am a new data scientist (&lt; 1 YOE) who recently started a new role where I am the only data scientist on a team of devs/PMs … yes, I realized quickly the challenges working in isolation. Fortunately, I am at a company with many data scientists on other teams, so the isolation is not 100%.

I’ve already had helpful conversations where these data scientists \[outside my team\] share answers to questions like “what does your role look like”, “what’s something you knew when you first started” and other such broad topics. But these are one-time questions, and I am wondering how to maintain the relationship. **Specifically, are there more incisive topics that make sense to discuss over weeks/months? By make sense, I mean 1) enjoyable &amp; organic for an experienced data scientist to share and 2) beneficial to a newbie data scientist?**

Put another way, the conversations I’ve had in this role are either 1) super technical (“maybe change the X hyperparameter”) or 2) super high level “I wish I had known X when I started”. I wonder if there are topics that are at an in-between level of technicality that feel natural for both mentor &amp; mentee to talk about.

***I was thinking*** I could ask them to talk a bit about their current project, e.g. what kinds of data they rely on / what techniques have been most useful, surprises and pain points, etc. But I don't know if that is too much of an imposition, particularly since I'm not a team member and don't necessarily have full context of the problems they are solving (nor can I help them in return).

edited for formatting/clarity and to add: I realize I'm basically asking ""how do I talk?!"" but I am coming to learn that that's not such an obvious skill!",t2_ddno5vr,[as a mentee] How to get the most out of a mentoring conversation,career,t3_h78wsg,0.83,4,Career,4,1591945918.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all! I am a new data scientist (&amp;lt; 1 YOE) who recently started a new role where I am the only data scientist on a team of devs/PMs … yes, I realized quickly the challenges working in isolation. Fortunately, I am at a company with many data scientists on other teams, so the isolation is not 100%.&lt;/p&gt;

&lt;p&gt;I’ve already had helpful conversations where these data scientists [outside my team] share answers to questions like “what does your role look like”, “what’s something you knew when you first started” and other such broad topics. But these are one-time questions, and I am wondering how to maintain the relationship. &lt;strong&gt;Specifically, are there more incisive topics that make sense to discuss over weeks/months? By make sense, I mean 1) enjoyable &amp;amp; organic for an experienced data scientist to share and 2) beneficial to a newbie data scientist?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Put another way, the conversations I’ve had in this role are either 1) super technical (“maybe change the X hyperparameter”) or 2) super high level “I wish I had known X when I started”. I wonder if there are topics that are at an in-between level of technicality that feel natural for both mentor &amp;amp; mentee to talk about.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;I was thinking&lt;/em&gt;&lt;/strong&gt; I could ask them to talk a bit about their current project, e.g. what kinds of data they rely on / what techniques have been most useful, surprises and pain points, etc. But I don&amp;#39;t know if that is too much of an imposition, particularly since I&amp;#39;m not a team member and don&amp;#39;t necessarily have full context of the problems they are solving (nor can I help them in return).&lt;/p&gt;

&lt;p&gt;edited for formatting/clarity and to add: I realize I&amp;#39;m basically asking &amp;quot;how do I talk?!&amp;quot; but I am coming to learn that that&amp;#39;s not such an obvious skill!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h78wsg,raven__girl,5,/r/datascience/comments/h78wsg/as_a_mentee_how_to_get_the_most_out_of_a/,https://www.reddit.com/r/datascience/comments/h78wsg/as_a_mentee_how_to_get_the_most_out_of_a/,1591917118.0
r/datascience,"I have a dataset with counts of unique users per organization that use a product. The dataset spans \~4 years and is broken up by month/year. 

I want to calculate the % penetration (i.e. out of the total # of employees at an organization, what % use the product in a given month). Ultimately it would roll up to an analysis thats examines different points in time (i.e. 6 months after onboarding) and gives a % penetration number. 

This is an interesting problem because obviously headcounts for companies change over time. I was wondering if anyone has any interesting suggestions for how to navigate this? For headcount data I'm using data from Crunchbase, but again that's static in time and especially with corona that can change drastically.",t2_274x2ooe,Navigating Temporal vs. fixed data - interesting problem,discussion,t3_h77p8s,1.0,3,Discussion,3,1591942008.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a dataset with counts of unique users per organization that use a product. The dataset spans ~4 years and is broken up by month/year. &lt;/p&gt;

&lt;p&gt;I want to calculate the % penetration (i.e. out of the total # of employees at an organization, what % use the product in a given month). Ultimately it would roll up to an analysis thats examines different points in time (i.e. 6 months after onboarding) and gives a % penetration number. &lt;/p&gt;

&lt;p&gt;This is an interesting problem because obviously headcounts for companies change over time. I was wondering if anyone has any interesting suggestions for how to navigate this? For headcount data I&amp;#39;m using data from Crunchbase, but again that&amp;#39;s static in time and especially with corona that can change drastically.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h77p8s,supremedata,3,/r/datascience/comments/h77p8s/navigating_temporal_vs_fixed_data_interesting/,https://www.reddit.com/r/datascience/comments/h77p8s/navigating_temporal_vs_fixed_data_interesting/,1591913208.0
r/datascience,"I've been working with a group of younger folks who, due to COVID-19, want to transition from their current careers to data science. A lot of them have basic business/coding skills but don't have the full data science background or experience with tools like R, Jupiter, etc.   


My own background is in data science (Masters in math + 10 years in ML roles). I'd love to help them out by introducing them to building data sets, the realities of actually applying tech to business problems, then transitioning them to building models. 

&amp;#x200B;

Would you use a service where we can provide you with human labelling and management of your data sets? You pay a fee (similar to a VA) but we also provide job training to these folks. Of course, if they're really good you can even hire them directly.

&amp;#x200B;

Feedback would be immensely appreciated.",t2_4earp,Would you use a remote service to manage your human labeling / data prep?,discussion,t3_h14ies,0.83,4,Discussion,4,1591927599.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been working with a group of younger folks who, due to COVID-19, want to transition from their current careers to data science. A lot of them have basic business/coding skills but don&amp;#39;t have the full data science background or experience with tools like R, Jupiter, etc.   &lt;/p&gt;

&lt;p&gt;My own background is in data science (Masters in math + 10 years in ML roles). I&amp;#39;d love to help them out by introducing them to building data sets, the realities of actually applying tech to business problems, then transitioning them to building models. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Would you use a service where we can provide you with human labelling and management of your data sets? You pay a fee (similar to a VA) but we also provide job training to these folks. Of course, if they&amp;#39;re really good you can even hire them directly.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Feedback would be immensely appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h14ies,marabou_stork,6,/r/datascience/comments/h14ies/would_you_use_a_remote_service_to_manage_your/,https://www.reddit.com/r/datascience/comments/h14ies/would_you_use_a_remote_service_to_manage_your/,1591898799.0
r/datascience,"I’m looking to try bringing on a pair of DS/ML interns for this summer-fall. We’re a remote first company so as a whole we’re pretty comfortable working in an asynchronous fashion but internships are an entirely different can of worms. Has anyone here brought on remote interns this summer and if so, any words of advice or things that are/aren’t working? Know of any remote internship write-ups similar to GitLab’s remote work guide? Would really love to give some students the opportunity at an internship/results boost, but also don’t want to set them up for a terrible experience.",t2_gq2ce,How to support remote DS internships?,discussion,t3_h0h3p0,0.97,163,Discussion,163,1591843117.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m looking to try bringing on a pair of DS/ML interns for this summer-fall. We’re a remote first company so as a whole we’re pretty comfortable working in an asynchronous fashion but internships are an entirely different can of worms. Has anyone here brought on remote interns this summer and if so, any words of advice or things that are/aren’t working? Know of any remote internship write-ups similar to GitLab’s remote work guide? Would really love to give some students the opportunity at an internship/results boost, but also don’t want to set them up for a terrible experience.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h0h3p0,DrLionelRaymond,43,/r/datascience/comments/h0h3p0/how_to_support_remote_ds_internships/,https://www.reddit.com/r/datascience/comments/h0h3p0/how_to_support_remote_ds_internships/,1591814317.0
r/datascience,"Hi. COVID-19 aside, how much of your job is spent talking to colleagues compared to coding by yourself (or doing something else)?

I'm doing SQL grunt work and light data engineering, about two years since I changed careers (I'm in my 40s). It's fine for now. But even when we were working in the office, I had little face-to-face interaction with people. All the marketing analysts we work with/for are much more cheery and friendly with each other. I just spend a lot of time working on code by myself. 

I don't regret any career choices - just realizing that next year when I look for a new gig, I need to take this into account. 

So I'm asking how much face time you get, and what industry are you in? I'm in the marketing department of a big corporation, which I know for sure I will leave.",t2_2o0q5m4h,how much face-to-face interaction vs. coding do you get at work?,discussion,t3_h0zwvg,0.67,2,Discussion,2,1591913071.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. COVID-19 aside, how much of your job is spent talking to colleagues compared to coding by yourself (or doing something else)?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m doing SQL grunt work and light data engineering, about two years since I changed careers (I&amp;#39;m in my 40s). It&amp;#39;s fine for now. But even when we were working in the office, I had little face-to-face interaction with people. All the marketing analysts we work with/for are much more cheery and friendly with each other. I just spend a lot of time working on code by myself. &lt;/p&gt;

&lt;p&gt;I don&amp;#39;t regret any career choices - just realizing that next year when I look for a new gig, I need to take this into account. &lt;/p&gt;

&lt;p&gt;So I&amp;#39;m asking how much face time you get, and what industry are you in? I&amp;#39;m in the marketing department of a big corporation, which I know for sure I will leave.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h0zwvg,rotterdamn8,2,/r/datascience/comments/h0zwvg/how_much_facetoface_interaction_vs_coding_do_you/,https://www.reddit.com/r/datascience/comments/h0zwvg/how_much_facetoface_interaction_vs_coding_do_you/,1591884271.0
r/datascience,"Before I start, I should say I’m an engineer rather than a data scientist, so please excuse any ignorance on my part.

I’ve got a univariate time series - a bunch of physical measurements which describe the performance of a machine I’m working with. This data has a cyclical pattern. What I’ve seen is that the measurements are generally high during the middle of the day and low at night. Given my understanding of the equipment, I believe that the data is influenced by both the ambient temperature (it’s outside) and by its internal state or past performance. I’ve looked at PACF and ACF which supports the latter.

What I want to do is build a model which will estimate its performance at t0 given measurements at t-1 ... t-n and the ambient temperate at t0. That way, if the estimated performance is way out of whack from its actual measured performance, I know something unusual is happening and I can schedule a maintenance inspection.

A plain old AR model might be sufficient, but that doesn’t take into account temperature. I’m thinking about training an LSTM model, but that seems like overkill. Are there any other models I ought to consider? Some other way I can use temperature data to improve the estimate I’d get from an AR model?",t2_8tm08,Autoregressive model with an exogenous variable?,discussion,t3_h0thd1,1.0,2,Discussion,2,1591884780.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Before I start, I should say I’m an engineer rather than a data scientist, so please excuse any ignorance on my part.&lt;/p&gt;

&lt;p&gt;I’ve got a univariate time series - a bunch of physical measurements which describe the performance of a machine I’m working with. This data has a cyclical pattern. What I’ve seen is that the measurements are generally high during the middle of the day and low at night. Given my understanding of the equipment, I believe that the data is influenced by both the ambient temperature (it’s outside) and by its internal state or past performance. I’ve looked at PACF and ACF which supports the latter.&lt;/p&gt;

&lt;p&gt;What I want to do is build a model which will estimate its performance at t0 given measurements at t-1 ... t-n and the ambient temperate at t0. That way, if the estimated performance is way out of whack from its actual measured performance, I know something unusual is happening and I can schedule a maintenance inspection.&lt;/p&gt;

&lt;p&gt;A plain old AR model might be sufficient, but that doesn’t take into account temperature. I’m thinking about training an LSTM model, but that seems like overkill. Are there any other models I ought to consider? Some other way I can use temperature data to improve the estimate I’d get from an AR model?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h0thd1,Boootstraps,12,/r/datascience/comments/h0thd1/autoregressive_model_with_an_exogenous_variable/,https://www.reddit.com/r/datascience/comments/h0thd1/autoregressive_model_with_an_exogenous_variable/,1591855980.0
r/datascience,"I think I am having a mild panic now that I've landed my dream role as a data scientist. I felt like I was entering the job market as a strong candidate (engineering undergrad, analytics masters, 3 years work experience as a data analyst-y job, multiple data scientist interviews + offers). 

It's been just over a month in my new role in a new company. I'm the only data scientist in the organization, so I have no support and don't know if I'm doing things as I should, causing rework when I find a silly error. I feel like I'm missing out on valuable experience learning from a senior and am scared issues will come back to bite me when my models are put in production. I don't like feeling so lost and and I feel like I'm floundering. Any advice for an early career data scientist and how long do you think it will take for this feeling to go away?",t2_4o6v0,Early Career Data Scientist Pain Points,career,t3_h01j32,0.98,318,Career,318,1591783180.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I think I am having a mild panic now that I&amp;#39;ve landed my dream role as a data scientist. I felt like I was entering the job market as a strong candidate (engineering undergrad, analytics masters, 3 years work experience as a data analyst-y job, multiple data scientist interviews + offers). &lt;/p&gt;

&lt;p&gt;It&amp;#39;s been just over a month in my new role in a new company. I&amp;#39;m the only data scientist in the organization, so I have no support and don&amp;#39;t know if I&amp;#39;m doing things as I should, causing rework when I find a silly error. I feel like I&amp;#39;m missing out on valuable experience learning from a senior and am scared issues will come back to bite me when my models are put in production. I don&amp;#39;t like feeling so lost and and I feel like I&amp;#39;m floundering. Any advice for an early career data scientist and how long do you think it will take for this feeling to go away?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h01j32,Limebabies,75,/r/datascience/comments/h01j32/early_career_data_scientist_pain_points/,https://www.reddit.com/r/datascience/comments/h01j32/early_career_data_scientist_pain_points/,1591754380.0
r/datascience,"I've seen people talk about ""PhD by publication"" or ""by published work"" - essentially a PhD that is awarded for a body of works published in peer-reviewed journals, instead of one thesis. You can read a better explanation than I could write here: [https://www.findaphd.com/advice/phd-types/phd-by-publication.aspx](https://www.findaphd.com/advice/phd-types/phd-by-publication.aspx)

Anyway, I see this most often discussed in Arts/Humanities/Social Sciences. Do such degrees exist for Data Science or any of the tangential fields?

EDIT for context: I'm an MSc Data Science student, and I've decided to drop out of my programme. I've been miserable the entire 16 years of classroom education I've received, but it recently got way too bad due to how my department handled the COVID crisis.

The thing is that while I hate the education part of academia, I do want to do research. I already have one publication under my belt, which came from my Bachelor thesis. For now, my plan is to work in the field 0.6FTE and do research in my spare time - a PhD by publication would be a way for that to culminate in a PhD for me, without forcing me into a soul-crushing classroom.",t2_zfy7g,PhD by publication?,education,t3_h0hrme,0.94,14,Education,14,1591844963.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve seen people talk about &amp;quot;PhD by publication&amp;quot; or &amp;quot;by published work&amp;quot; - essentially a PhD that is awarded for a body of works published in peer-reviewed journals, instead of one thesis. You can read a better explanation than I could write here: &lt;a href=""https://www.findaphd.com/advice/phd-types/phd-by-publication.aspx""&gt;https://www.findaphd.com/advice/phd-types/phd-by-publication.aspx&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Anyway, I see this most often discussed in Arts/Humanities/Social Sciences. Do such degrees exist for Data Science or any of the tangential fields?&lt;/p&gt;

&lt;p&gt;EDIT for context: I&amp;#39;m an MSc Data Science student, and I&amp;#39;ve decided to drop out of my programme. I&amp;#39;ve been miserable the entire 16 years of classroom education I&amp;#39;ve received, but it recently got way too bad due to how my department handled the COVID crisis.&lt;/p&gt;

&lt;p&gt;The thing is that while I hate the education part of academia, I do want to do research. I already have one publication under my belt, which came from my Bachelor thesis. For now, my plan is to work in the field 0.6FTE and do research in my spare time - a PhD by publication would be a way for that to culminate in a PhD for me, without forcing me into a soul-crushing classroom.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h0hrme,Bob-Cho,24,/r/datascience/comments/h0hrme/phd_by_publication/,https://www.reddit.com/r/datascience/comments/h0hrme/phd_by_publication/,1591816163.0
r/datascience,"I am well versed in web development, so building a web dashboard won't be that difficult for me. But what technology is more used in the industry, do people use tableau or power bi to build dashboards or implement them from scratch on a web app.

Ps: the dashboard I'm building includes few KPIs and a sale forecasting part that uses a tensorflow trained model.",t2_h2akc,Building analytics dashboard as a web app or use softwares such as Tableau or Power BI?,discussion,t3_h0i4u5,0.72,3,Discussion,3,1591846016.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am well versed in web development, so building a web dashboard won&amp;#39;t be that difficult for me. But what technology is more used in the industry, do people use tableau or power bi to build dashboards or implement them from scratch on a web app.&lt;/p&gt;

&lt;p&gt;Ps: the dashboard I&amp;#39;m building includes few KPIs and a sale forecasting part that uses a tensorflow trained model.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h0i4u5,maroxtn,19,/r/datascience/comments/h0i4u5/building_analytics_dashboard_as_a_web_app_or_use/,https://www.reddit.com/r/datascience/comments/h0i4u5/building_analytics_dashboard_as_a_web_app_or_use/,1591817216.0
r/datascience,"I'm on my second job out of college making 160k not counting equity, etc. It's a rebranded data analyst job.

It feels too early in my career to feel burnt out, but I cannot overstate how bored I am. So much of the work is ""investigate why this metric moved in this direction"". It's not only incredibly boring, it's unrewarding: after hours or days of slicing the same data a dozen different ways, we rarely unearth an explanation, anyway. 

I'm tired of ad hoc analyses, but I don't want to go back to school for a master's to learn and/or be considered for ML jobs, either. It doesn't interest me.

I hear people talk about loving data visualization, or enjoying investigating and telling a story with data, and while I believe them, it's also kinda incomprehensible to me at this point.

**Have you ever felt burnt out? And/or have you ever considered leaving the industry?** 

What's stopping me is the thought of walking away from a (currently) successful career trajectory. I am unhappy, but I'm also aware that I'm privileged and may not be aware of the realities of other jobs. I would be very curious to hear how other people have weighed their options when considering leaving this industry (even if their desire to leave was motivated by something other than dissatisfaction).",t2_4vn7g5zh,Have you ever considered leaving the industry?,discussion,t3_h03s6t,0.88,45,Discussion,45,1591792362.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m on my second job out of college making 160k not counting equity, etc. It&amp;#39;s a rebranded data analyst job.&lt;/p&gt;

&lt;p&gt;It feels too early in my career to feel burnt out, but I cannot overstate how bored I am. So much of the work is &amp;quot;investigate why this metric moved in this direction&amp;quot;. It&amp;#39;s not only incredibly boring, it&amp;#39;s unrewarding: after hours or days of slicing the same data a dozen different ways, we rarely unearth an explanation, anyway. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m tired of ad hoc analyses, but I don&amp;#39;t want to go back to school for a master&amp;#39;s to learn and/or be considered for ML jobs, either. It doesn&amp;#39;t interest me.&lt;/p&gt;

&lt;p&gt;I hear people talk about loving data visualization, or enjoying investigating and telling a story with data, and while I believe them, it&amp;#39;s also kinda incomprehensible to me at this point.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Have you ever felt burnt out? And/or have you ever considered leaving the industry?&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;What&amp;#39;s stopping me is the thought of walking away from a (currently) successful career trajectory. I am unhappy, but I&amp;#39;m also aware that I&amp;#39;m privileged and may not be aware of the realities of other jobs. I would be very curious to hear how other people have weighed their options when considering leaving this industry (even if their desire to leave was motivated by something other than dissatisfaction).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h03s6t,wp_trash_acc,52,/r/datascience/comments/h03s6t/have_you_ever_considered_leaving_the_industry/,https://www.reddit.com/r/datascience/comments/h03s6t/have_you_ever_considered_leaving_the_industry/,1591763562.0
r/datascience,Thank you for your time and for sharing your experience visualizing data for engineers and business folks.,t2_hgnv4l1,"Dashboard. Do you hate it or love it? Is it useful, or a simple data dump?",discussion,t3_h0acw5,1.0,4,Discussion,4,1591822588.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Thank you for your time and for sharing your experience visualizing data for engineers and business folks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h0acw5,kamilkur,8,/r/datascience/comments/h0acw5/dashboard_do_you_hate_it_or_love_it_is_it_useful/,https://www.reddit.com/r/datascience/comments/h0acw5/dashboard_do_you_hate_it_or_love_it_is_it_useful/,1591793788.0
r/datascience,"Hello my fellow data science professionals, I hope you all are keeping safe and doing well.

So a bit of background to the question, one of my close friend runs a business which operates in the event &amp; entertainment industry.
He is a vendor that provides a niche service for large format events &amp; activations. let's call this service A for the sake of this post.

Service A requires a lot of equipment and people who are skilled in operating that equipment. He has his own large inventory of equipment but once in a while, he gets an event with a large scope, wherein to be able to provide that service, he has to purchase more inventory, which might be used immediately or can remain with him for a long time.
He has employees hired to manage and deliver the service, but again if the scope of an event is large, he hires freelance manpower to execute and provide the said service.  

As a nature of the industry itself, everything is need-based. the way it usually works is:
A client (can be corporate or a wealthy private client) sends out a brief of what he/they intend to celebrate or organize an event -&gt; This brief usually goes out to few event management companies -&gt; these companies propose a plan/theme/budget -&gt; client approves it/negotiates on a budget -&gt; event happens.

Now, the event management companies can approach my friend for service A, either during the proposal phase or after the proposal is approved in which case they have already factored in a service A in their proposal and budgeted a certain amount for it.
Each approach by the event company is considered as an incoming inquiry for hiring his services.

My friend approached me if I can help him out in some way using data science. I have been thinking about but cannot figure out a an idea to model for. Whatever I do I want to ensure that it helps his bottom line. As you can imagine, the current pandemic has destroyed the industry and his business altogether, and since he has some time, he asked me for my help in gathering some insights which will enable him to tweak his processes for the future.

I thought of modeling for his handling of inquiries, wherein I can glean some insight into the probability of an inquiry turning into a business which helps him focus his resources on something which has more probability of generating revenue, but again he and his business are blind to what is going on at the event manager side, he only sees what comes to him and he keeps track of it.

There are other aspects of his business where I believe something can be done, for example, Inventory management &amp; analysis, optimizing operational manpower (he uses inhouse and freelance manpower for his business), but these do not directly help in bottom line, they will help indirectly in a long term and I'm not discounting it, it's just not a priority for him.

So basically what I'm asking is, has anyone modeled for a business that is inherently unpredictable like stock markets and what would you even start looking at which will translate into the bottom line for the company. 

Any and all ideas are welcome.",t2_q4prej8,How or What do you model for in an inherently unpredictable field?,discussion,t3_h0iefy,1.0,1,Discussion,1,1591846767.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello my fellow data science professionals, I hope you all are keeping safe and doing well.&lt;/p&gt;

&lt;p&gt;So a bit of background to the question, one of my close friend runs a business which operates in the event &amp;amp; entertainment industry.
He is a vendor that provides a niche service for large format events &amp;amp; activations. let&amp;#39;s call this service A for the sake of this post.&lt;/p&gt;

&lt;p&gt;Service A requires a lot of equipment and people who are skilled in operating that equipment. He has his own large inventory of equipment but once in a while, he gets an event with a large scope, wherein to be able to provide that service, he has to purchase more inventory, which might be used immediately or can remain with him for a long time.
He has employees hired to manage and deliver the service, but again if the scope of an event is large, he hires freelance manpower to execute and provide the said service.  &lt;/p&gt;

&lt;p&gt;As a nature of the industry itself, everything is need-based. the way it usually works is:
A client (can be corporate or a wealthy private client) sends out a brief of what he/they intend to celebrate or organize an event -&amp;gt; This brief usually goes out to few event management companies -&amp;gt; these companies propose a plan/theme/budget -&amp;gt; client approves it/negotiates on a budget -&amp;gt; event happens.&lt;/p&gt;

&lt;p&gt;Now, the event management companies can approach my friend for service A, either during the proposal phase or after the proposal is approved in which case they have already factored in a service A in their proposal and budgeted a certain amount for it.
Each approach by the event company is considered as an incoming inquiry for hiring his services.&lt;/p&gt;

&lt;p&gt;My friend approached me if I can help him out in some way using data science. I have been thinking about but cannot figure out a an idea to model for. Whatever I do I want to ensure that it helps his bottom line. As you can imagine, the current pandemic has destroyed the industry and his business altogether, and since he has some time, he asked me for my help in gathering some insights which will enable him to tweak his processes for the future.&lt;/p&gt;

&lt;p&gt;I thought of modeling for his handling of inquiries, wherein I can glean some insight into the probability of an inquiry turning into a business which helps him focus his resources on something which has more probability of generating revenue, but again he and his business are blind to what is going on at the event manager side, he only sees what comes to him and he keeps track of it.&lt;/p&gt;

&lt;p&gt;There are other aspects of his business where I believe something can be done, for example, Inventory management &amp;amp; analysis, optimizing operational manpower (he uses inhouse and freelance manpower for his business), but these do not directly help in bottom line, they will help indirectly in a long term and I&amp;#39;m not discounting it, it&amp;#39;s just not a priority for him.&lt;/p&gt;

&lt;p&gt;So basically what I&amp;#39;m asking is, has anyone modeled for a business that is inherently unpredictable like stock markets and what would you even start looking at which will translate into the bottom line for the company. &lt;/p&gt;

&lt;p&gt;Any and all ideas are welcome.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h0iefy,rck-climb3r,4,/r/datascience/comments/h0iefy/how_or_what_do_you_model_for_in_an_inherently/,https://www.reddit.com/r/datascience/comments/h0iefy/how_or_what_do_you_model_for_in_an_inherently/,1591817967.0
r/datascience,"1. Flexible training and development environment 

2. Access to standard and emerging frameworks

3. Clear pathway to deployment

1) because development is key and some training tasks are lightweight while others require increased resources, 2) because frameworks for analytics, ML, and DL are important, and 3) because minimizing pain of deployments is good for everyone.

What  other basic resources would you data scientists need to be effective?",t2_1q6oq5dl,Basic resources data scientists need to be effective,discussion,t3_gzvvco,0.91,60,Discussion,60,1591764615.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Flexible training and development environment &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Access to standard and emerging frameworks&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Clear pathway to deployment&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1) because development is key and some training tasks are lightweight while others require increased resources, 2) because frameworks for analytics, ML, and DL are important, and 3) because minimizing pain of deployments is good for everyone.&lt;/p&gt;

&lt;p&gt;What  other basic resources would you data scientists need to be effective?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gzvvco,dmorris87,21,/r/datascience/comments/gzvvco/basic_resources_data_scientists_need_to_be/,https://www.reddit.com/r/datascience/comments/gzvvco/basic_resources_data_scientists_need_to_be/,1591735815.0
r/datascience,"Im working on a forecasting model dealing with call center data that is seasonal with about a years work of data. So far I've seen the data has a Coefficient of Variation (COV) of 25% across my monthly and weekly. I'm trying for precision so I want something lower. When I do ""day of the week"" averages, Mondays averaged with Mondays and Tuesdays averaged with Tuesdays..(etc) the COV drops to 11 - 15% now while I know COV isn't the be all end all and has a lot of assumptions caked into its use. I'm not familiar with a method to translate these with seasonal factors that are based on periods of time not in the daily form. 

Directionality is important. But if I have a clear significants issue I would like to know too. 

Anyone have any thoughts on how to achieve this or recommendations on alternatives that would yield more accurate results?",t2_og7kb,Forecasting seasonally with alternative averages other than monthly.,discussion,t3_h0hpnt,0.6,1,Discussion,1,1591844800.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im working on a forecasting model dealing with call center data that is seasonal with about a years work of data. So far I&amp;#39;ve seen the data has a Coefficient of Variation (COV) of 25% across my monthly and weekly. I&amp;#39;m trying for precision so I want something lower. When I do &amp;quot;day of the week&amp;quot; averages, Mondays averaged with Mondays and Tuesdays averaged with Tuesdays..(etc) the COV drops to 11 - 15% now while I know COV isn&amp;#39;t the be all end all and has a lot of assumptions caked into its use. I&amp;#39;m not familiar with a method to translate these with seasonal factors that are based on periods of time not in the daily form. &lt;/p&gt;

&lt;p&gt;Directionality is important. But if I have a clear significants issue I would like to know too. &lt;/p&gt;

&lt;p&gt;Anyone have any thoughts on how to achieve this or recommendations on alternatives that would yield more accurate results?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h0hpnt,siddartha08,1,/r/datascience/comments/h0hpnt/forecasting_seasonally_with_alternative_averages/,https://www.reddit.com/r/datascience/comments/h0hpnt/forecasting_seasonally_with_alternative_averages/,1591816000.0
r/datascience,"I am working on a pet project, where I am trying to find scope of improvement in services of a telecom company and also the customer care interactions. For a start, I have picked all interactions on relation to changing rate plan. Customers can use any channel to change their plan - web, app, call care support, chat with an agent, visit store etc. I am looking for a way to measure pain in their journey while changing plans - how much time did it take to browse plans and make a choice, was the app experience so bad that the customer had to call care center, were there any wrong expectations set or miscommunication that made the customer call back care after the change (issues with billing, device etc)

One way I thought made sense would be to use CSAT score, find correlation with features like time spent, number of calls or visits, number of times channels was switched, and try to come up with a way to quantify the pain experienced in each step. 


Let me know your thoughts on this, does the above approach makes sense? Is there a better way to do this?


Thanks a lot in advance!!!",t2_2uokwtur,"How do you measure experience, pain points customers have in interactions with customer care?",discussion,t3_gzlr90,0.92,83,Discussion,83,1591732831.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working on a pet project, where I am trying to find scope of improvement in services of a telecom company and also the customer care interactions. For a start, I have picked all interactions on relation to changing rate plan. Customers can use any channel to change their plan - web, app, call care support, chat with an agent, visit store etc. I am looking for a way to measure pain in their journey while changing plans - how much time did it take to browse plans and make a choice, was the app experience so bad that the customer had to call care center, were there any wrong expectations set or miscommunication that made the customer call back care after the change (issues with billing, device etc)&lt;/p&gt;

&lt;p&gt;One way I thought made sense would be to use CSAT score, find correlation with features like time spent, number of calls or visits, number of times channels was switched, and try to come up with a way to quantify the pain experienced in each step. &lt;/p&gt;

&lt;p&gt;Let me know your thoughts on this, does the above approach makes sense? Is there a better way to do this?&lt;/p&gt;

&lt;p&gt;Thanks a lot in advance!!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gzlr90,doktorstrange7,23,/r/datascience/comments/gzlr90/how_do_you_measure_experience_pain_points/,https://www.reddit.com/r/datascience/comments/gzlr90/how_do_you_measure_experience_pain_points/,1591704031.0
r/datascience,"Hey in my company we are currently trying to figure out which possible project to tackle next. What are some good questions to ask the ones who proposed the ideas in order judge the feasibility of a possible project? 

Some things I've gathered so far:

## Can It Generate Revenue?

## Can You Use Existing, Proven Technology?

## Is there enough support available by domain experts?

## Cost of data acquisition

- How hard is it to acquire data?

- How expensive is data labeling?

- How much data will be needed?

## Cost of wrong predictions

- How frequently does the system need to be right to be useful?

## Availability of good published work about similar problems

- Has the problem been reduced to practice?

- Is there sufficient literature on the problem?

## Computational resources available both for training and inference

- Will the model be deployed in a resource-constrained environment?",t2_89vti,Judging the feasibility of potential projects in a company?,discussion,t3_h091ug,1.0,1,Discussion,1,1591817432.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey in my company we are currently trying to figure out which possible project to tackle next. What are some good questions to ask the ones who proposed the ideas in order judge the feasibility of a possible project? &lt;/p&gt;

&lt;p&gt;Some things I&amp;#39;ve gathered so far:&lt;/p&gt;

&lt;h2&gt;Can It Generate Revenue?&lt;/h2&gt;

&lt;h2&gt;Can You Use Existing, Proven Technology?&lt;/h2&gt;

&lt;h2&gt;Is there enough support available by domain experts?&lt;/h2&gt;

&lt;h2&gt;Cost of data acquisition&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;How hard is it to acquire data?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How expensive is data labeling?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How much data will be needed?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Cost of wrong predictions&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;How frequently does the system need to be right to be useful?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Availability of good published work about similar problems&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Has the problem been reduced to practice?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Is there sufficient literature on the problem?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Computational resources available both for training and inference&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Will the model be deployed in a resource-constrained environment?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h091ug,selib,4,/r/datascience/comments/h091ug/judging_the_feasibility_of_potential_projects_in/,https://www.reddit.com/r/datascience/comments/h091ug/judging_the_feasibility_of_potential_projects_in/,1591788632.0
r/datascience,"College student here who is at an internship now working for a large company. This company is in the midst of transitioning into a more ""data driven approach"" and I was hired as an intern to aid in that. They do not have a data science team and most only have a vague idea of what they hope ""data science"" can acheive for them but not any practical applications.

 I am attached to a sales manager and tasked with identifying ways that I can help her with her job such as creating visualisations or improving her workflow. The issue is that the data she is working with is mostly financial statements or profit and loss statements that have been prepared for her, consisting of tens of rows of values such as ""revenue from food"", ""cost of salary"", ""cost of utitilities"", ""cost from bonuses"" etc. Her job is therefore to look through these numbers and identify points that can be improved on such as questioning why costs are rising even though revenue has fallen, or why there is still a cost for tv subscription when the restaurant has been doing delivery only. My experience is in data cleaning and visualisation in R and python. I am struggling to even read in the data that has been formatted to be in this format, and to visualise data that has so many variables that have to be looked at in such great detail.

 Any help would be appreciated!",t2_bn31a,Need help on applying data science/visualisation to profit and loss statements/ finance statements in general,discussion,t3_h01f27,0.81,3,Discussion,3,1591782758.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;College student here who is at an internship now working for a large company. This company is in the midst of transitioning into a more &amp;quot;data driven approach&amp;quot; and I was hired as an intern to aid in that. They do not have a data science team and most only have a vague idea of what they hope &amp;quot;data science&amp;quot; can acheive for them but not any practical applications.&lt;/p&gt;

&lt;p&gt;I am attached to a sales manager and tasked with identifying ways that I can help her with her job such as creating visualisations or improving her workflow. The issue is that the data she is working with is mostly financial statements or profit and loss statements that have been prepared for her, consisting of tens of rows of values such as &amp;quot;revenue from food&amp;quot;, &amp;quot;cost of salary&amp;quot;, &amp;quot;cost of utitilities&amp;quot;, &amp;quot;cost from bonuses&amp;quot; etc. Her job is therefore to look through these numbers and identify points that can be improved on such as questioning why costs are rising even though revenue has fallen, or why there is still a cost for tv subscription when the restaurant has been doing delivery only. My experience is in data cleaning and visualisation in R and python. I am struggling to even read in the data that has been formatted to be in this format, and to visualise data that has so many variables that have to be looked at in such great detail.&lt;/p&gt;

&lt;p&gt;Any help would be appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h01f27,144627,4,/r/datascience/comments/h01f27/need_help_on_applying_data_sciencevisualisation/,https://www.reddit.com/r/datascience/comments/h01f27/need_help_on_applying_data_sciencevisualisation/,1591753958.0
r/datascience,"I  am having a very difficult time in being able to connect the algorithms  we learned and implemented in school and solving practical problems at  work, mostly because the data in the industry is too noisy and  convoluted. But even if the data is better, in general, things taught in  school now seem to be really basic and worthless in comparison to the  level of difficulty in the industry.

After  having struggled for almost 8-9 months now, I turn to Reddit to seek  guidance from fellow community members on this topic. Can you guide me  on how to be able to handle messy data, apply and scale algorithms to  varied datasets and really build models based on the data statistics?",t2_ixzsdmh,Disconnect between course algorithms and industry work in Machine learning,discussion,t3_gzlg6z,0.97,46,Discussion,46,1591731527.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I  am having a very difficult time in being able to connect the algorithms  we learned and implemented in school and solving practical problems at  work, mostly because the data in the industry is too noisy and  convoluted. But even if the data is better, in general, things taught in  school now seem to be really basic and worthless in comparison to the  level of difficulty in the industry.&lt;/p&gt;

&lt;p&gt;After  having struggled for almost 8-9 months now, I turn to Reddit to seek  guidance from fellow community members on this topic. Can you guide me  on how to be able to handle messy data, apply and scale algorithms to  varied datasets and really build models based on the data statistics?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gzlg6z,whatever_you_absorb,22,/r/datascience/comments/gzlg6z/disconnect_between_course_algorithms_and_industry/,https://www.reddit.com/r/datascience/comments/gzlg6z/disconnect_between_course_algorithms_and_industry/,1591702727.0
r/datascience,"Hi all, I'm not even confident I can formulate and summarize my task objective, but I'll try.

I""m a software engineer who works on a very complicated custom enterprise software.  This software literally does a million different things in a business of 100 very complex business functions.

Currently, we are totally inundated with 'help desk tickets' that come in.  Software developers complain they need more staff, but managers demand metrics.  The developers find it near impossible to find any pattern or trend in the tickets because each on is so unique.

Nonetheless, management demands we go through the exercise.  I have no idea where to start.  How to categorize the tickets.  How to find the theme or the trend or anything.   


I need to make a pattern that is meaningful, obliviously, but no idea where to start.  It's kind of a ridiculous request, but I have to take a stab at it. 

So I guess my question is.  Is there a body of knowledge someone could point me towards?  Perhaps definition or a term that is going to assist me in building a structure?  I understand this may be a crap shoot and my question may be absurd, but thanks for your time!",t2_494dxuhf,"I'm not a data science, but I have been tasked with someone data related and I'm really hoping to get an idea on where to start - hoping you all can give me a hint.",discussion,t3_h00b5j,0.75,2,Discussion,2,1591778636.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;m not even confident I can formulate and summarize my task objective, but I&amp;#39;ll try.&lt;/p&gt;

&lt;p&gt;I&amp;quot;m a software engineer who works on a very complicated custom enterprise software.  This software literally does a million different things in a business of 100 very complex business functions.&lt;/p&gt;

&lt;p&gt;Currently, we are totally inundated with &amp;#39;help desk tickets&amp;#39; that come in.  Software developers complain they need more staff, but managers demand metrics.  The developers find it near impossible to find any pattern or trend in the tickets because each on is so unique.&lt;/p&gt;

&lt;p&gt;Nonetheless, management demands we go through the exercise.  I have no idea where to start.  How to categorize the tickets.  How to find the theme or the trend or anything.   &lt;/p&gt;

&lt;p&gt;I need to make a pattern that is meaningful, obliviously, but no idea where to start.  It&amp;#39;s kind of a ridiculous request, but I have to take a stab at it. &lt;/p&gt;

&lt;p&gt;So I guess my question is.  Is there a body of knowledge someone could point me towards?  Perhaps definition or a term that is going to assist me in building a structure?  I understand this may be a crap shoot and my question may be absurd, but thanks for your time!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",h00b5j,team_beluga,10,/r/datascience/comments/h00b5j/im_not_a_data_science_but_i_have_been_tasked_with/,https://www.reddit.com/r/datascience/comments/h00b5j/im_not_a_data_science_but_i_have_been_tasked_with/,1591749836.0
r/datascience,"I see everywhere an inflation of data science blog posts, Medium posts, Linkedin posts which are adding literally ZERO value to everybody in the field. If you think we need another explanation of why p-values are important, or how to read a CSV file in Pandas, you are wrong and you are wasting your and my time. Walk me through a nasty dataset cleaning process. Show me an end to end project of yours. Enlighten me with that new, weird, just-out-of-the-Academic-press new kind of Neural Network. But showing me how to make a line plot in Matplotlib? Thanks, there are 5000 tutorials out there for that. If you are doing this, and hoping that your reputation will improve as a consequence (and maybe your chances of getting hired) you are doing yourself a terrible service. Stop the noise, do ONE really new and impressive thing and you will have: (1) actually added value and (2) started to make a name for yourself out there. Thanks for watching.",t2_9yb4lav,Useless tutorials and blog post will NOT improve your CV but WILL waste our time,discussion,t3_gyv6to,0.94,1024,Discussion,1024,1591632655.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I see everywhere an inflation of data science blog posts, Medium posts, Linkedin posts which are adding literally ZERO value to everybody in the field. If you think we need another explanation of why p-values are important, or how to read a CSV file in Pandas, you are wrong and you are wasting your and my time. Walk me through a nasty dataset cleaning process. Show me an end to end project of yours. Enlighten me with that new, weird, just-out-of-the-Academic-press new kind of Neural Network. But showing me how to make a line plot in Matplotlib? Thanks, there are 5000 tutorials out there for that. If you are doing this, and hoping that your reputation will improve as a consequence (and maybe your chances of getting hired) you are doing yourself a terrible service. Stop the noise, do ONE really new and impressive thing and you will have: (1) actually added value and (2) started to make a name for yourself out there. Thanks for watching.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gyv6to,Alav81,150,/r/datascience/comments/gyv6to/useless_tutorials_and_blog_post_will_not_improve/,https://www.reddit.com/r/datascience/comments/gyv6to/useless_tutorials_and_blog_post_will_not_improve/,1591603855.0
r/datascience,"I'm working on a project with partners that require their data to be masked of any personally identifiable information before they're willing to allow analysis. These data are primarily long form texts that may include mentions of names, addresses, etc. that need to be procedurally detected and replaced (e.g. ""Brian"" becomes ""&lt;name&gt;"").

[Microsoft's Presidio](https://github.com/microsoft/presidio) seems to be a fantastic option, but I'm trying to find other solutions to weigh them for this specific application. Does anyone know of similar solutions/products I should consider? I get the sense that Amazon's Macie is similar, but that seems to be for tagging documents rather than masking text within those documents.",t2_v5npq,Identifying and masking personally identifiable information - any solutions/products similar to Microsoft's Presidio?,tooling,t3_gzt9s2,0.5,0,Tooling,0,1591757177.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working on a project with partners that require their data to be masked of any personally identifiable information before they&amp;#39;re willing to allow analysis. These data are primarily long form texts that may include mentions of names, addresses, etc. that need to be procedurally detected and replaced (e.g. &amp;quot;Brian&amp;quot; becomes &amp;quot;&amp;lt;name&amp;gt;&amp;quot;).&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/microsoft/presidio""&gt;Microsoft&amp;#39;s Presidio&lt;/a&gt; seems to be a fantastic option, but I&amp;#39;m trying to find other solutions to weigh them for this specific application. Does anyone know of similar solutions/products I should consider? I get the sense that Amazon&amp;#39;s Macie is similar, but that seems to be for tagging documents rather than masking text within those documents.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gzt9s2,brhkim,2,/r/datascience/comments/gzt9s2/identifying_and_masking_personally_identifiable/,https://www.reddit.com/r/datascience/comments/gzt9s2/identifying_and_masking_personally_identifiable/,1591728377.0
r/datascience,"Hello everyone,

I've seen variations of the question ""What is the future of data science?"" asked before, but I think mine is unique enough that it would make for a good discussion in its own post. It's based on a 2020 RStudio Conference presentation mentioned in some other posts, called ""[Value in Data Science Beyond Models in Production](https://rstudio.com/resources/rstudioconf-2020/value-in-data-science-beyond-models-in-production/)"".

In the presentation, the speaker makes the case for why Data Scientists should focus their efforts on providing value through things ***other than*** deploying machine learning to production. As an aside, I think the definition of ""Data Scientist"" he is using is more of a Decision Scientist. The gist of his message is:

* Machine Learning Engineers are likely going to take the ML work that Data Scientists currently do, and will create off-the-shelf ML tools (e.g. AutoML), hence decreasing the need for Data Scientists to do ML.
* Data Engineers are already better than Data Scientists at cleaning data, building pipelines, and warehousing, and so this part of the data science process will be owned by Data Engineers.
* What work does that leave for Data Scientists? What the speaker describes sounds like the work of a Product Analyst:
   * Business Intelligence-type work (metric design, measurement, goal-setting, creating self-service data tools)
   * A small amount of ad-hoc ML modeling
   * Inform business strategy / product design based on data analysis
   * Experimentation
   * The human side of data work - ethics and communication

Here are some questions that the presentation raised for me:

* Do you think his prediction is accurate?
* Will the work of tomorrow’s Data Scientist be more like today's Product Analyst?
* Do you think his prediction is only true of the tech industry, or does it apply to all industries?",t2_44cvaicq,The Future: Value in Data Science Beyond Models in Production,discussion,t3_gzcirb,0.9,21,Discussion,21,1591693035.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve seen variations of the question &amp;quot;What is the future of data science?&amp;quot; asked before, but I think mine is unique enough that it would make for a good discussion in its own post. It&amp;#39;s based on a 2020 RStudio Conference presentation mentioned in some other posts, called &amp;quot;&lt;a href=""https://rstudio.com/resources/rstudioconf-2020/value-in-data-science-beyond-models-in-production/""&gt;Value in Data Science Beyond Models in Production&lt;/a&gt;&amp;quot;.&lt;/p&gt;

&lt;p&gt;In the presentation, the speaker makes the case for why Data Scientists should focus their efforts on providing value through things &lt;strong&gt;&lt;em&gt;other than&lt;/em&gt;&lt;/strong&gt; deploying machine learning to production. As an aside, I think the definition of &amp;quot;Data Scientist&amp;quot; he is using is more of a Decision Scientist. The gist of his message is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Machine Learning Engineers are likely going to take the ML work that Data Scientists currently do, and will create off-the-shelf ML tools (e.g. AutoML), hence decreasing the need for Data Scientists to do ML.&lt;/li&gt;
&lt;li&gt;Data Engineers are already better than Data Scientists at cleaning data, building pipelines, and warehousing, and so this part of the data science process will be owned by Data Engineers.&lt;/li&gt;
&lt;li&gt;What work does that leave for Data Scientists? What the speaker describes sounds like the work of a Product Analyst:

&lt;ul&gt;
&lt;li&gt;Business Intelligence-type work (metric design, measurement, goal-setting, creating self-service data tools)&lt;/li&gt;
&lt;li&gt;A small amount of ad-hoc ML modeling&lt;/li&gt;
&lt;li&gt;Inform business strategy / product design based on data analysis&lt;/li&gt;
&lt;li&gt;Experimentation&lt;/li&gt;
&lt;li&gt;The human side of data work - ethics and communication&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here are some questions that the presentation raised for me:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Do you think his prediction is accurate?&lt;/li&gt;
&lt;li&gt;Will the work of tomorrow’s Data Scientist be more like today&amp;#39;s Product Analyst?&lt;/li&gt;
&lt;li&gt;Do you think his prediction is only true of the tech industry, or does it apply to all industries?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gzcirb,kintaloupe,11,/r/datascience/comments/gzcirb/the_future_value_in_data_science_beyond_models_in/,https://www.reddit.com/r/datascience/comments/gzcirb/the_future_value_in_data_science_beyond_models_in/,1591664235.0
r/datascience,"Im currently a Business Analytics student in college and I’m interested in getting better at R. I’ve taken a data management class which delved into R, so I am somewhat comfortable with ggplot and dplyr verbs. 

Any resources you guys would recommend for getting better at R, specifically for data analysis and predictive analytics. Thanks!",t2_ob70ld8,Recommendations to practice coding with R,discussion,t3_gzd84g,0.95,14,Discussion,14,1591695529.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im currently a Business Analytics student in college and I’m interested in getting better at R. I’ve taken a data management class which delved into R, so I am somewhat comfortable with ggplot and dplyr verbs. &lt;/p&gt;

&lt;p&gt;Any resources you guys would recommend for getting better at R, specifically for data analysis and predictive analytics. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gzd84g,boci7,18,/r/datascience/comments/gzd84g/recommendations_to_practice_coding_with_r/,https://www.reddit.com/r/datascience/comments/gzd84g/recommendations_to_practice_coding_with_r/,1591666729.0
r/datascience,"With no intentions of igniting the argument between R and python , users of R what’s jobs have you automated using what tools and on what platforms ?",t2_2upusef2,"Users of R , what kind of jobs do you automate ?",discussion,t3_gyrxi1,0.95,103,Discussion,103,1591619447.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;With no intentions of igniting the argument between R and python , users of R what’s jobs have you automated using what tools and on what platforms ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gyrxi1,sthills,54,/r/datascience/comments/gyrxi1/users_of_r_what_kind_of_jobs_do_you_automate/,https://www.reddit.com/r/datascience/comments/gyrxi1/users_of_r_what_kind_of_jobs_do_you_automate/,1591590647.0
r/datascience,"Using it for two-phase clustering but can't for the life of me figure out how to export the cluster results... I just want the cluster label next to the values for each observation. 

There's a save function but when I export all my cluster values show ""NA"".",t2_dw23q,"Does anyone have experience with the R ""stream"" package?",,t3_gz9gdm,1.0,2,,2,1591682887.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Using it for two-phase clustering but can&amp;#39;t for the life of me figure out how to export the cluster results... I just want the cluster label next to the values for each observation. &lt;/p&gt;

&lt;p&gt;There&amp;#39;s a save function but when I export all my cluster values show &amp;quot;NA&amp;quot;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gz9gdm,Piratefluffer,0,/r/datascience/comments/gz9gdm/does_anyone_have_experience_with_the_r_stream/,https://www.reddit.com/r/datascience/comments/gz9gdm/does_anyone_have_experience_with_the_r_stream/,1591654087.0
r/datascience,,t2_9rxzj,"Users of Python, what kind of jobs do you automate?",discussion,t3_gy92pt,0.97,328,Discussion,328,1591550358.0,,gy92pt,Kaudinya,132,/r/datascience/comments/gy92pt/users_of_python_what_kind_of_jobs_do_you_automate/,https://www.reddit.com/r/datascience/comments/gy92pt/users_of_python_what_kind_of_jobs_do_you_automate/,1591521558.0
r/datascience,"I'm working as a data scientist in AWS for the past few months. I have my interest and background in Machine Learning but the role seems like an analytics role. 

Given how fast paced AWS is, I'm lagging behind to catch up. The role needs a lot of SQL expertise, while I know SQL it was mostly for querying and creating data for ML needs, but not for analytics all together. 

I don't know what to do. I'm getting super anxious.",t2_15svk7,Miss hire for the current role,career,t3_gyy3n0,0.71,3,Career,3,1591646809.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working as a data scientist in AWS for the past few months. I have my interest and background in Machine Learning but the role seems like an analytics role. &lt;/p&gt;

&lt;p&gt;Given how fast paced AWS is, I&amp;#39;m lagging behind to catch up. The role needs a lot of SQL expertise, while I know SQL it was mostly for querying and creating data for ML needs, but not for analytics all together. &lt;/p&gt;

&lt;p&gt;I don&amp;#39;t know what to do. I&amp;#39;m getting super anxious.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gyy3n0,puttasaikiran,5,/r/datascience/comments/gyy3n0/miss_hire_for_the_current_role/,https://www.reddit.com/r/datascience/comments/gyy3n0/miss_hire_for_the_current_role/,1591618009.0
r/datascience,"Dear Data Magicians

'tis the time. Show me your DS Stack! Our field is going through rapid transitions, many of these focused on operationalization (yes it is a word). In a sense, how do we jump from the '*guy in the basement who comes up with cool models*' to '*well oiled machinery that spits out and maintains awesome models*'. 

Let's standardise the responses somewhat, then I'll collect the responses as much as I can at the end of this main post. 

I'd like people to simply list the technology they use at their firm. Some of us may use experiment tracking, others do not. Some may require high-frequent updates, others do not, and so forth.

Please add a link to the technology you refer to :-)

&amp;#x200B;

|Technology|Purpose|Open Source/Closed Source|Pricing|Comment|
|:-|:-|:-|:-|:-|
|[weights and biases](https://wandb.com/)|Experiment tracking and documentation|Closed source|Free (personal), 35/user, and 175/user (corp)|Really solid piece of software. Good support for most ML frameworks|
|[Data Version Control](https://dvc.org)|Data versioning|Open Source|Free|We use it in particular for Deep Learning|
|[AWS SageMaker](https://aws.amazon.com/sagemaker/)|Serving and training|Open Source (somewhat)|Depends on the tier (min. 0.08$/hr)|Not really great for custom models|

&amp;#x200B;

**Tech. challenges I've yet to find a solution for:**

* How to best manage models that read/write from DBs best way possible?
* Efficient ways to automatically run tests on X independent separate ML models
* Best way to store and access (large) flat files

**Curious to try or work with**

* Kubeflow
* MLflow
* GCP vs AWS vs Azure vs Bluemix - Pros/Cons?

**Best advice**

* If you don't have one already - Design a standardised best practices handbook for your team. You should have a template for a DL project, as well as smaller ML projects. The template should be designed in a way that allows for easy reproducibility and productisation (See previous post I've written [here](https://www.reddit.com/r/datascience/comments/gw8z13/do_you_code_in_object_oriented_way_in_python_when/fsu2p8p?utm_source=share&amp;utm_medium=web2x))
* The rest of your organisation is not necessarily interested in what you are interested in. **Do not focus on mathematical rigor but business objectives.** 
* **Fail fast:** If you cannot get some value relating to the business objective out of the data, post cleaning of course, move on. Summarise findings and what you think is needed to achieve the sought after business objective (Additional data / Other data / Qualitative analysis - Shadow a worker in a function), hypothesise on the reasons for why the relation is not there. Ie. Maybe customers are price insensitive? Maybe they churn due to factors we do not have in the dataset?",t2_xb67fiq,Walk me through your DS Stack - ML DevOps,tooling,t3_gz0xyp,0.5,0,Tooling,0,1591657334.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Dear Data Magicians&lt;/p&gt;

&lt;p&gt;&amp;#39;tis the time. Show me your DS Stack! Our field is going through rapid transitions, many of these focused on operationalization (yes it is a word). In a sense, how do we jump from the &amp;#39;&lt;em&gt;guy in the basement who comes up with cool models&lt;/em&gt;&amp;#39; to &amp;#39;&lt;em&gt;well oiled machinery that spits out and maintains awesome models&lt;/em&gt;&amp;#39;. &lt;/p&gt;

&lt;p&gt;Let&amp;#39;s standardise the responses somewhat, then I&amp;#39;ll collect the responses as much as I can at the end of this main post. &lt;/p&gt;

&lt;p&gt;I&amp;#39;d like people to simply list the technology they use at their firm. Some of us may use experiment tracking, others do not. Some may require high-frequent updates, others do not, and so forth.&lt;/p&gt;

&lt;p&gt;Please add a link to the technology you refer to :-)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=""left""&gt;Technology&lt;/th&gt;
&lt;th align=""left""&gt;Purpose&lt;/th&gt;
&lt;th align=""left""&gt;Open Source/Closed Source&lt;/th&gt;
&lt;th align=""left""&gt;Pricing&lt;/th&gt;
&lt;th align=""left""&gt;Comment&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;&lt;a href=""https://wandb.com/""&gt;weights and biases&lt;/a&gt;&lt;/td&gt;
&lt;td align=""left""&gt;Experiment tracking and documentation&lt;/td&gt;
&lt;td align=""left""&gt;Closed source&lt;/td&gt;
&lt;td align=""left""&gt;Free (personal), 35/user, and 175/user (corp)&lt;/td&gt;
&lt;td align=""left""&gt;Really solid piece of software. Good support for most ML frameworks&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;&lt;a href=""https://dvc.org""&gt;Data Version Control&lt;/a&gt;&lt;/td&gt;
&lt;td align=""left""&gt;Data versioning&lt;/td&gt;
&lt;td align=""left""&gt;Open Source&lt;/td&gt;
&lt;td align=""left""&gt;Free&lt;/td&gt;
&lt;td align=""left""&gt;We use it in particular for Deep Learning&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;&lt;a href=""https://aws.amazon.com/sagemaker/""&gt;AWS SageMaker&lt;/a&gt;&lt;/td&gt;
&lt;td align=""left""&gt;Serving and training&lt;/td&gt;
&lt;td align=""left""&gt;Open Source (somewhat)&lt;/td&gt;
&lt;td align=""left""&gt;Depends on the tier (min. 0.08$/hr)&lt;/td&gt;
&lt;td align=""left""&gt;Not really great for custom models&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tech. challenges I&amp;#39;ve yet to find a solution for:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How to best manage models that read/write from DBs best way possible?&lt;/li&gt;
&lt;li&gt;Efficient ways to automatically run tests on X independent separate ML models&lt;/li&gt;
&lt;li&gt;Best way to store and access (large) flat files&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Curious to try or work with&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kubeflow&lt;/li&gt;
&lt;li&gt;MLflow&lt;/li&gt;
&lt;li&gt;GCP vs AWS vs Azure vs Bluemix - Pros/Cons?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Best advice&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If you don&amp;#39;t have one already - Design a standardised best practices handbook for your team. You should have a template for a DL project, as well as smaller ML projects. The template should be designed in a way that allows for easy reproducibility and productisation (See previous post I&amp;#39;ve written &lt;a href=""https://www.reddit.com/r/datascience/comments/gw8z13/do_you_code_in_object_oriented_way_in_python_when/fsu2p8p?utm_source=share&amp;amp;utm_medium=web2x""&gt;here&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;The rest of your organisation is not necessarily interested in what you are interested in. &lt;strong&gt;Do not focus on mathematical rigor but business objectives.&lt;/strong&gt; &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fail fast:&lt;/strong&gt; If you cannot get some value relating to the business objective out of the data, post cleaning of course, move on. Summarise findings and what you think is needed to achieve the sought after business objective (Additional data / Other data / Qualitative analysis - Shadow a worker in a function), hypothesise on the reasons for why the relation is not there. Ie. Maybe customers are price insensitive? Maybe they churn due to factors we do not have in the dataset?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gz0xyp,tripple13,4,/r/datascience/comments/gz0xyp/walk_me_through_your_ds_stack_ml_devops/,https://www.reddit.com/r/datascience/comments/gz0xyp/walk_me_through_your_ds_stack_ml_devops/,1591628534.0
r/datascience,"Hi guys - I have been doing a lot of machine learning in my job as a data scientist, but am interested in becoming a more holistic mathematical modeller and recommend non-ML solutions?  My dream is to be able to look at a problem and be able to find the optimal solution balancing model fit with practical aspects e.g. training time and quality data availability.  I am particularly getting interested in the area of simulation as an oppotive.

I was wondering if anyone had any recommendations on:

1. Books on general mathematical modelling thinking
2. Introductory simulation books
3.  Other techniques to explore",t2_11egzf,Books on Mathematical Modelling Thinking and Simulation,education,t3_gyfp4x,1.0,22,Education,22,1591577072.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys - I have been doing a lot of machine learning in my job as a data scientist, but am interested in becoming a more holistic mathematical modeller and recommend non-ML solutions?  My dream is to be able to look at a problem and be able to find the optimal solution balancing model fit with practical aspects e.g. training time and quality data availability.  I am particularly getting interested in the area of simulation as an oppotive.&lt;/p&gt;

&lt;p&gt;I was wondering if anyone had any recommendations on:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Books on general mathematical modelling thinking&lt;/li&gt;
&lt;li&gt;Introductory simulation books&lt;/li&gt;
&lt;li&gt; Other techniques to explore&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gyfp4x,DataScientologist,5,/r/datascience/comments/gyfp4x/books_on_mathematical_modelling_thinking_and/,https://www.reddit.com/r/datascience/comments/gyfp4x/books_on_mathematical_modelling_thinking_and/,1591548272.0
r/datascience,"I'm trying to transition into Data Science (I'm a software engineer). I spend most of my free time learning DS and ML, doing own projects, reading textbooks, coding etc.

But I would also really like a book I can read without having to sit by a computer/notepad to follow along with code/math. Maybe a book about how to think about data science/data/analytics.

I spend 1 hour before sleep sitting in a sofa, reading books. Just want a book I can read without needing to constantly switch to a computer to test out code / do math.

Suggestions?

**Edit: Big thanks! My ""future reading list"" has enough material for a years worth of reading now I think :)**",t2_7and9,Any Data science books that one can read without needing a computer or pen &amp; paper?,education,t3_gxwntt,0.99,201,Education,201,1591498229.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to transition into Data Science (I&amp;#39;m a software engineer). I spend most of my free time learning DS and ML, doing own projects, reading textbooks, coding etc.&lt;/p&gt;

&lt;p&gt;But I would also really like a book I can read without having to sit by a computer/notepad to follow along with code/math. Maybe a book about how to think about data science/data/analytics.&lt;/p&gt;

&lt;p&gt;I spend 1 hour before sleep sitting in a sofa, reading books. Just want a book I can read without needing to constantly switch to a computer to test out code / do math.&lt;/p&gt;

&lt;p&gt;Suggestions?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit: Big thanks! My &amp;quot;future reading list&amp;quot; has enough material for a years worth of reading now I think :)&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gxwntt,drum_playing_twig,46,/r/datascience/comments/gxwntt/any_data_science_books_that_one_can_read_without/,https://www.reddit.com/r/datascience/comments/gxwntt/any_data_science_books_that_one_can_read_without/,1591469429.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 07 Jun 2020 - 14 Jun 2020,,t3_gyb2ph,0.86,5,Discussion,5,1591560030.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gyb2ph,datascience-bot,158,/r/datascience/comments/gyb2ph/weekly_entering_transitioning_thread_07_jun_2020/,https://www.reddit.com/r/datascience/comments/gyb2ph/weekly_entering_transitioning_thread_07_jun_2020/,1591531230.0
r/datascience,I just got Audible and was wondering if any of you had some data science/analysis related recommendations from there that you enjoyed.,t2_12neis,Audible suggestions?,discussion,t3_gy6mcr,1.0,5,Discussion,5,1591536609.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just got Audible and was wondering if any of you had some data science/analysis related recommendations from there that you enjoyed.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gy6mcr,morningmotherlover,8,/r/datascience/comments/gy6mcr/audible_suggestions/,https://www.reddit.com/r/datascience/comments/gy6mcr/audible_suggestions/,1591507809.0
r/datascience,"Hi,

I'm considering using airflow for my ML pipeline on AWS, and I have some questions about basic setup (perhaps noobish). 

I would prefer a serverless setup, but that seems out of the question in the cloud, since you have to host an airflow server?

The airflow server seems like a bit of an overkill, and I'm unsure how to control costs, scaling, python environments and memory/cpu/gpu requirements to each pipeline step?

Alternatively I thought about using it as 'command station', where the ML pipeline just delegates pipeline tasks to fargate and lambda functions - this seems nice, because I can get all the flexibility that I want using those other services, while keeping the server small.  


The reason I want to use airflow is of course because it seems awesome, and I would like to have that overview over the pipes etc. I could just setup a bunch of lambdas/containers, but I would never know if anything had failed.  


Much appreciated!",t2_kcjnq,Apache airflow,tooling,t3_gy9ff2,0.6,1,Tooling,1,1591552289.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m considering using airflow for my ML pipeline on AWS, and I have some questions about basic setup (perhaps noobish). &lt;/p&gt;

&lt;p&gt;I would prefer a serverless setup, but that seems out of the question in the cloud, since you have to host an airflow server?&lt;/p&gt;

&lt;p&gt;The airflow server seems like a bit of an overkill, and I&amp;#39;m unsure how to control costs, scaling, python environments and memory/cpu/gpu requirements to each pipeline step?&lt;/p&gt;

&lt;p&gt;Alternatively I thought about using it as &amp;#39;command station&amp;#39;, where the ML pipeline just delegates pipeline tasks to fargate and lambda functions - this seems nice, because I can get all the flexibility that I want using those other services, while keeping the server small.  &lt;/p&gt;

&lt;p&gt;The reason I want to use airflow is of course because it seems awesome, and I would like to have that overview over the pipes etc. I could just setup a bunch of lambdas/containers, but I would never know if anything had failed.  &lt;/p&gt;

&lt;p&gt;Much appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gy9ff2,djkaffe123,1,/r/datascience/comments/gy9ff2/apache_airflow/,https://www.reddit.com/r/datascience/comments/gy9ff2/apache_airflow/,1591523489.0
r/datascience,"I'm about to purchase a new laptop soon and I wonder if I should get a Macbook or a Windows PC (and install Ubuntu)?

I heard a lot of companies provide you with a work laptop so I wonder if it's even worth it spend a lot on a personal laptop.

My goal is to have the best tool for data analytics and maybe some software engineering down the road.

thanks",t2_33bizuj,Macbook or Windows for data science?,,t3_gxufr6,0.74,7,Job Search,7,1591490959.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m about to purchase a new laptop soon and I wonder if I should get a Macbook or a Windows PC (and install Ubuntu)?&lt;/p&gt;

&lt;p&gt;I heard a lot of companies provide you with a work laptop so I wonder if it&amp;#39;s even worth it spend a lot on a personal laptop.&lt;/p&gt;

&lt;p&gt;My goal is to have the best tool for data analytics and maybe some software engineering down the road.&lt;/p&gt;

&lt;p&gt;thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gxufr6,engineheat,20,/r/datascience/comments/gxufr6/macbook_or_windows_for_data_science/,https://www.reddit.com/r/datascience/comments/gxufr6/macbook_or_windows_for_data_science/,1591462159.0
r/datascience,"I realize this is a very broad question but I'm legitimately curious what else others are using to learn, code, and analyze data these days. 

I'm working towards a doctorate simultaneously so I've been spending more time learning about the theory behind things and how to assess statistical significance. I spend anywhere from 10 minutes to an hour browsing through google and cyber security blogs every day and I tend to come up with 90% fluff. 

Every once in a while I stumble across something major and amazing (Hello GANS!) but I can't seem to find some good reliable resources to stay up to date on things when I'm mostly not using the latest and greatest every day. So good people of reddit - what do you find the best resources?",t2_rq73otk,"As a part time data scientist (also working on my doctorate) who's been doing this for 10+ years, I'm starting to feel a bit like a dinosaur and my job has become 90% fluff and people management. What resources do you guys use to stay relevant and what new and cool things have you been using?",discussion,t3_gx5iww,0.98,382,Discussion,382,1591395859.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I realize this is a very broad question but I&amp;#39;m legitimately curious what else others are using to learn, code, and analyze data these days. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m working towards a doctorate simultaneously so I&amp;#39;ve been spending more time learning about the theory behind things and how to assess statistical significance. I spend anywhere from 10 minutes to an hour browsing through google and cyber security blogs every day and I tend to come up with 90% fluff. &lt;/p&gt;

&lt;p&gt;Every once in a while I stumble across something major and amazing (Hello GANS!) but I can&amp;#39;t seem to find some good reliable resources to stay up to date on things when I&amp;#39;m mostly not using the latest and greatest every day. So good people of reddit - what do you find the best resources?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gx5iww,savetherandomforests,38,/r/datascience/comments/gx5iww/as_a_part_time_data_scientist_also_working_on_my/,https://www.reddit.com/r/datascience/comments/gx5iww/as_a_part_time_data_scientist_also_working_on_my/,1591367059.0
r/datascience,"Hi guys,

I have been working in the data area as a Data Analyst and have always used jupyter lab to do my analyses. I'm trying to learn more about data engineering and I see that almost every tutorial I see people use other tools for code like IDE.

Why don't they usually use IDE for Data Analysis or Data Science?

Thanks for your help!",t2_50dlcxl3,IDE for Data Science,discussion,t3_gxfpim,0.75,4,Discussion,4,1591428804.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys,&lt;/p&gt;

&lt;p&gt;I have been working in the data area as a Data Analyst and have always used jupyter lab to do my analyses. I&amp;#39;m trying to learn more about data engineering and I see that almost every tutorial I see people use other tools for code like IDE.&lt;/p&gt;

&lt;p&gt;Why don&amp;#39;t they usually use IDE for Data Analysis or Data Science?&lt;/p&gt;

&lt;p&gt;Thanks for your help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gxfpim,bmrtex,19,/r/datascience/comments/gxfpim/ide_for_data_science/,https://www.reddit.com/r/datascience/comments/gxfpim/ide_for_data_science/,1591400004.0
r/datascience,"Hello!

I'm a junior data scientist, been working in the field for about a year after getting a professional master in this topic.

I work for a small startup, which means that I have no mentor and I have to figure out shit on my own, as well as deal with everything that is data related (not just data science, but also engineering, ETL and what not).

It's fun and challenging, but also at times very frustrating, because I have this constant feeling of *never knowing enough,* and given the complexity and depth of this field, and the pace at which it develops, it is really overwhelming.

Also, coming from a business / economics background, my math and stats skills are not exactly razor sharp.  
I compensate by being a massive nerd, so I learn stuff quickly, but that's about it.

Advice?",t2_zwbba,"Professional data scientists: did you overcome the feeling of never knowing enough? If so, how?",discussion,t3_gwt750,0.96,182,Discussion,182,1591343050.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello!&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a junior data scientist, been working in the field for about a year after getting a professional master in this topic.&lt;/p&gt;

&lt;p&gt;I work for a small startup, which means that I have no mentor and I have to figure out shit on my own, as well as deal with everything that is data related (not just data science, but also engineering, ETL and what not).&lt;/p&gt;

&lt;p&gt;It&amp;#39;s fun and challenging, but also at times very frustrating, because I have this constant feeling of &lt;em&gt;never knowing enough,&lt;/em&gt; and given the complexity and depth of this field, and the pace at which it develops, it is really overwhelming.&lt;/p&gt;

&lt;p&gt;Also, coming from a business / economics background, my math and stats skills are not exactly razor sharp.&lt;br/&gt;
I compensate by being a massive nerd, so I learn stuff quickly, but that&amp;#39;s about it.&lt;/p&gt;

&lt;p&gt;Advice?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwt750,wtfzambo,60,/r/datascience/comments/gwt750/professional_data_scientists_did_you_overcome_the/,https://www.reddit.com/r/datascience/comments/gwt750/professional_data_scientists_did_you_overcome_the/,1591314250.0
r/datascience,"As a Data Scientist, is it better to know multiple coding languages to an adequate level (i.e a jack-of-all-trades, but master of none) or to have a really in-depth knowledge of a single language?

I'm thinking in terms of job opportunities, the quality/salary of those opportunities and in general.

(Edit: typo)",t2_g8wyf,Jack-of-all-trades,discussion,t3_gwz8s9,0.86,31,Discussion,31,1591367230.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As a Data Scientist, is it better to know multiple coding languages to an adequate level (i.e a jack-of-all-trades, but master of none) or to have a really in-depth knowledge of a single language?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m thinking in terms of job opportunities, the quality/salary of those opportunities and in general.&lt;/p&gt;

&lt;p&gt;(Edit: typo)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwz8s9,MyKo101,17,/r/datascience/comments/gwz8s9/jackofalltrades/,https://www.reddit.com/r/datascience/comments/gwz8s9/jackofalltrades/,1591338430.0
r/datascience,"Some background: I have 6 years of DS experience, 2 masters degrees, and spent a few years as a data analyst as well. Laid off from a smaller company in the midwest due to COVID-19 cutbacks.

&amp;#x200B;

1. **""Data scientist"" is turning into a blanket term. So is ""data analyst"".** So many of the jobs I've looked at truly want a data engineer/DBA but ask for a data scientist. Or want a data scientist but ask for an entry level data analyst. Expand your search terms, but read the job description to figure out what the company really wants. This changes every time I'm on the job market even in my short tenure as a data scientist. When did ""Machine Learning Engineer"" become so big??
2. **On that note: ""Senior"" vs ""Lead"" vs ""Entry Level""**...the difference to me is huge, but most companies seem to be pretty flexible with what they're posting. Some entry level jobs have been open to changing to senior level, some lead/manager level would be fine with senior. If you like a job but are weary about the experience required, just ask the hiring manager/recruiter that posted it.
3. **Every company has a different way of testing your knowledge.** So far I've taken a data science timed assessment (no outside resources), completed a take-home assessment (48 hours and a dataset), and presented a past project for 30 minutes, all for different companies. Be prepared for just about anything, but use how they test you as a clue into their culture. For me, I love the take-home tests and presentations because they give me a chance to show what I know without as much of the pressure.
4. **Companies are starting to open back up.** Many job postings were taken down from March-May, but as of today the number of openings is expanding rapidly. Region may be a big factor. The companies I have interviewed with have stuck to either all virtual, or majority virtual with one in-person interview with masks and social distancing.

&amp;#x200B;

Best of luck to everyone in their job search!",t2_eajbu,My thoughts on the data science job hunt during COVID-19,,t3_gwibmc,0.97,403,Job Search,403,1591309167.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Some background: I have 6 years of DS experience, 2 masters degrees, and spent a few years as a data analyst as well. Laid off from a smaller company in the midwest due to COVID-19 cutbacks.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&amp;quot;Data scientist&amp;quot; is turning into a blanket term. So is &amp;quot;data analyst&amp;quot;.&lt;/strong&gt; So many of the jobs I&amp;#39;ve looked at truly want a data engineer/DBA but ask for a data scientist. Or want a data scientist but ask for an entry level data analyst. Expand your search terms, but read the job description to figure out what the company really wants. This changes every time I&amp;#39;m on the job market even in my short tenure as a data scientist. When did &amp;quot;Machine Learning Engineer&amp;quot; become so big??&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;On that note: &amp;quot;Senior&amp;quot; vs &amp;quot;Lead&amp;quot; vs &amp;quot;Entry Level&amp;quot;&lt;/strong&gt;...the difference to me is huge, but most companies seem to be pretty flexible with what they&amp;#39;re posting. Some entry level jobs have been open to changing to senior level, some lead/manager level would be fine with senior. If you like a job but are weary about the experience required, just ask the hiring manager/recruiter that posted it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Every company has a different way of testing your knowledge.&lt;/strong&gt; So far I&amp;#39;ve taken a data science timed assessment (no outside resources), completed a take-home assessment (48 hours and a dataset), and presented a past project for 30 minutes, all for different companies. Be prepared for just about anything, but use how they test you as a clue into their culture. For me, I love the take-home tests and presentations because they give me a chance to show what I know without as much of the pressure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Companies are starting to open back up.&lt;/strong&gt; Many job postings were taken down from March-May, but as of today the number of openings is expanding rapidly. Region may be a big factor. The companies I have interviewed with have stuck to either all virtual, or majority virtual with one in-person interview with masks and social distancing.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Best of luck to everyone in their job search!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwibmc,SpicyElephant,140,/r/datascience/comments/gwibmc/my_thoughts_on_the_data_science_job_hunt_during/,https://www.reddit.com/r/datascience/comments/gwibmc/my_thoughts_on_the_data_science_job_hunt_during/,1591280367.0
r/datascience,"So i am fairly new to Data science and  i have been using python 3.7 with atom and downloading the packages through pip command .

I want to try using anaconda and my main doubt is that if i should download the libraries like numpy,pandas again?

I heard that things like Tensor flow work on old version of python and in the anaconda download it says that V3.7 is being downloaded. So how is that managed?

And how does jupyter notebook work,like does it depend on the libraries you have in your computer (do i need pandas installed to use it in the notebook)?",t2_68l2ea9q,How does Anaconda manage libraries ?,education,t3_gx73yb,1.0,2,Education,2,1591401083.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So i am fairly new to Data science and  i have been using python 3.7 with atom and downloading the packages through pip command .&lt;/p&gt;

&lt;p&gt;I want to try using anaconda and my main doubt is that if i should download the libraries like numpy,pandas again?&lt;/p&gt;

&lt;p&gt;I heard that things like Tensor flow work on old version of python and in the anaconda download it says that V3.7 is being downloaded. So how is that managed?&lt;/p&gt;

&lt;p&gt;And how does jupyter notebook work,like does it depend on the libraries you have in your computer (do i need pandas installed to use it in the notebook)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gx73yb,arakkal_abu7,16,/r/datascience/comments/gx73yb/how_does_anaconda_manage_libraries/,https://www.reddit.com/r/datascience/comments/gx73yb/how_does_anaconda_manage_libraries/,1591372283.0
r/datascience,"I was recently offered a statistician (GS-12) role. I recently finished my master's degree and have had a bit of trouble landing a new job, even with a couple years experience.

The work sounds interesting, but I've been told government workers aren't really well respected/have a really bad reputation. My plan would be to stick with this position (since it's in the government and relatively stable I'd imagine) until the economy is better, but would I have trouble transferring back to the private industry due to the reputation of government workers? Not sure if statisticians have that same reputation...

Poking around on LinkedIn, it looks like most who work in the government stay in the government...",t2_3kvl7uqj,How respected are statisticians in the government?,career,t3_gwvnfx,0.87,16,Career,16,1591351979.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was recently offered a statistician (GS-12) role. I recently finished my master&amp;#39;s degree and have had a bit of trouble landing a new job, even with a couple years experience.&lt;/p&gt;

&lt;p&gt;The work sounds interesting, but I&amp;#39;ve been told government workers aren&amp;#39;t really well respected/have a really bad reputation. My plan would be to stick with this position (since it&amp;#39;s in the government and relatively stable I&amp;#39;d imagine) until the economy is better, but would I have trouble transferring back to the private industry due to the reputation of government workers? Not sure if statisticians have that same reputation...&lt;/p&gt;

&lt;p&gt;Poking around on LinkedIn, it looks like most who work in the government stay in the government...&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwvnfx,doyouevenbayes,14,/r/datascience/comments/gwvnfx/how_respected_are_statisticians_in_the_government/,https://www.reddit.com/r/datascience/comments/gwvnfx/how_respected_are_statisticians_in_the_government/,1591323179.0
r/datascience,"Interested in knowing what path some of you took that don't have a B.Sc./M.Sc. in data science, what were the challenges, was the degree somewhat related or entirely different, etc.",t2_4yqox6,How many of you work as data scientists but have a degree in something else than Data Science?,discussion,t3_gx24xs,0.75,4,Discussion,4,1591382200.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Interested in knowing what path some of you took that don&amp;#39;t have a B.Sc./M.Sc. in data science, what were the challenges, was the degree somewhat related or entirely different, etc.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gx24xs,judoberserk,26,/r/datascience/comments/gx24xs/how_many_of_you_work_as_data_scientists_but_have/,https://www.reddit.com/r/datascience/comments/gx24xs/how_many_of_you_work_as_data_scientists_but_have/,1591353400.0
r/datascience,"Hi everybody,  
I need some collective knowledge on collaborative data science. Mainly what I am looking for is to get a better overview over my teams experiments / training of models.  


Our current state:  
We are currently training NN for Computer Vision using jupyter notebooks, csv files for labels and operation systems directories to store the images. People execute their notebooks and they sometimes get errors because someone else is currently training on that gpu (of which we have 2).

  
So what am I looking for?  
1. A data store for our datasets with some kind of data lineage. (Can be solved by postgres or what ever. Fair enough.)  
2. Provisioning of some kind of execution queue so that people can queue up their notebooks and have the results 24h later.  
3. A multi tenant experiment store (like model db, ml flow -- but I would like it to have support for multiple users).  
4. The possibility to review and comment on experiments so that we can assist and teach each other. Similar to how gitlab handles pull / merge requests.  
5. OpenSource.  
6. Optional: self-hostable for free.   


Multi Tenancy is a must for me. We need open discussions on approaches to Data Science / ML Problems. So is open source -- mainly for the same reason.   


Technologies I looked into but am very happy about for comments:  
Kubeflow, OpenShit/OpenDataHub, Mlflow, VertaAi/modelDb  


I have a long list of tools, currently I try to deploy pachyderm to take a look at it. Meanwhile I would be happy about your views, suggestions.  


Best wishes",t2_10chz3,Professional Data Scientists: How do you track your experiments?,tooling,t3_gx04es,0.7,4,Tooling,4,1591371663.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everybody,&lt;br/&gt;
I need some collective knowledge on collaborative data science. Mainly what I am looking for is to get a better overview over my teams experiments / training of models.  &lt;/p&gt;

&lt;p&gt;Our current state:&lt;br/&gt;
We are currently training NN for Computer Vision using jupyter notebooks, csv files for labels and operation systems directories to store the images. People execute their notebooks and they sometimes get errors because someone else is currently training on that gpu (of which we have 2).&lt;/p&gt;

&lt;p&gt;So what am I looking for?&lt;br/&gt;
1. A data store for our datasets with some kind of data lineage. (Can be solved by postgres or what ever. Fair enough.)&lt;br/&gt;
2. Provisioning of some kind of execution queue so that people can queue up their notebooks and have the results 24h later.&lt;br/&gt;
3. A multi tenant experiment store (like model db, ml flow -- but I would like it to have support for multiple users).&lt;br/&gt;
4. The possibility to review and comment on experiments so that we can assist and teach each other. Similar to how gitlab handles pull / merge requests.&lt;br/&gt;
5. OpenSource.&lt;br/&gt;
6. Optional: self-hostable for free.   &lt;/p&gt;

&lt;p&gt;Multi Tenancy is a must for me. We need open discussions on approaches to Data Science / ML Problems. So is open source -- mainly for the same reason.   &lt;/p&gt;

&lt;p&gt;Technologies I looked into but am very happy about for comments:&lt;br/&gt;
Kubeflow, OpenShit/OpenDataHub, Mlflow, VertaAi/modelDb  &lt;/p&gt;

&lt;p&gt;I have a long list of tools, currently I try to deploy pachyderm to take a look at it. Meanwhile I would be happy about your views, suggestions.  &lt;/p&gt;

&lt;p&gt;Best wishes&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gx04es,pag07,5,/r/datascience/comments/gx04es/professional_data_scientists_how_do_you_track/,https://www.reddit.com/r/datascience/comments/gx04es/professional_data_scientists_how_do_you_track/,1591342863.0
r/datascience,"I just never got into the habit of writing object oriented code for data science, nor do I see a need. What's your thought?

The reason I'm asking is because someone asked to see my code for a data science role, and I'm starting to doubt myself. I might fix up my code a bit, and wants to hear some advice on what to watch out for.

thanks

PS: do you know where I can look at some good coding examples in data science?",t2_33bizuj,Do you code in Object Oriented way in Python when doing data analytics?,discussion,t3_gw8z13,0.97,273,Discussion,273,1591268780.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just never got into the habit of writing object oriented code for data science, nor do I see a need. What&amp;#39;s your thought?&lt;/p&gt;

&lt;p&gt;The reason I&amp;#39;m asking is because someone asked to see my code for a data science role, and I&amp;#39;m starting to doubt myself. I might fix up my code a bit, and wants to hear some advice on what to watch out for.&lt;/p&gt;

&lt;p&gt;thanks&lt;/p&gt;

&lt;p&gt;PS: do you know where I can look at some good coding examples in data science?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gw8z13,engineheat,150,/r/datascience/comments/gw8z13/do_you_code_in_object_oriented_way_in_python_when/,https://www.reddit.com/r/datascience/comments/gw8z13/do_you_code_in_object_oriented_way_in_python_when/,1591239980.0
r/datascience,"What are some of the things you do after fitting a model (i.e. regression or classification)? To understand the types of decisions it’s making, understand if it’s biased or overfitting, etc.? 

This is a pretty broad question but I’m looking to create a checklist of things that should be done ensure you have a “good model” 

Things like:

*Check the correlation between variables (heatmaps, VIF, etc.)

*Check the feature importance’s/model coefficients 

*Use SHAP values / charts to understand the directionality of model features 

*Plot the drop-off in accuracy when eliminating features (either through backward elimination or pruning the most important features) 

*Plotting interaction terms between your variables 

*Checking the model performance for different encoding strategies (one-hot, target encoding, etc) 

*Plotting performance by different subregions in your data  

*Compare different algorithms for performance",t2_j5474,What is in your model check list?,discussion,t3_gwiue7,0.83,11,Discussion,11,1591310863.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What are some of the things you do after fitting a model (i.e. regression or classification)? To understand the types of decisions it’s making, understand if it’s biased or overfitting, etc.? &lt;/p&gt;

&lt;p&gt;This is a pretty broad question but I’m looking to create a checklist of things that should be done ensure you have a “good model” &lt;/p&gt;

&lt;p&gt;Things like:&lt;/p&gt;

&lt;p&gt;*Check the correlation between variables (heatmaps, VIF, etc.)&lt;/p&gt;

&lt;p&gt;*Check the feature importance’s/model coefficients &lt;/p&gt;

&lt;p&gt;*Use SHAP values / charts to understand the directionality of model features &lt;/p&gt;

&lt;p&gt;*Plot the drop-off in accuracy when eliminating features (either through backward elimination or pruning the most important features) &lt;/p&gt;

&lt;p&gt;*Plotting interaction terms between your variables &lt;/p&gt;

&lt;p&gt;*Checking the model performance for different encoding strategies (one-hot, target encoding, etc) &lt;/p&gt;

&lt;p&gt;*Plotting performance by different subregions in your data  &lt;/p&gt;

&lt;p&gt;*Compare different algorithms for performance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwiue7,goat211,4,/r/datascience/comments/gwiue7/what_is_in_your_model_check_list/,https://www.reddit.com/r/datascience/comments/gwiue7/what_is_in_your_model_check_list/,1591282063.0
r/datascience,,t2_3op9qx89,What combinations of colors have you found work best for plotting data? Obviously yellow on a white background doesn't work so well...,discussion,t3_gwzrm1,0.2,0,Discussion,0,1591369900.0,,gwzrm1,LatterConcentrate6,8,/r/datascience/comments/gwzrm1/what_combinations_of_colors_have_you_found_work/,https://www.reddit.com/r/datascience/comments/gwzrm1/what_combinations_of_colors_have_you_found_work/,1591341100.0
r/datascience,"Background:  
Hey guys, long time lurker first time poster so please bare with me. I am currently a  sophomore student at UTD who is majoring in ITS , who will be completing his fist professional level job in August. I have been working at American Airlines as a junior Data analyst for what will be 8 months in August. and as its quickly approaching, my concern for life post coop are growing.  Before getting this coop, I could barely support myself financially and so I have been making the most of my coop income by paying off debt, but as I look at what I was making pre coop I am realizing that my debt reduction rate at the moment still wont reduce my monthly expenses enough to were I will be able to sustain myself.   


Question: 

While working at AA, I learned python, machine learning, sql, and neural networks for the most part and I am wanting to know given the pandemic and my financial situation how do I best prepare myself now so that I have a fighting chance to make a transition from AA to another job in my field?  What should I be focusing my extra time on so that when the coop ends i can land preferably a part time jr data analyst position or something similar?",t2_11qd7v,Career advice as my coop comes to a close,career,t3_gwmj5h,0.75,2,Career,2,1591322354.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Background:&lt;br/&gt;
Hey guys, long time lurker first time poster so please bare with me. I am currently a  sophomore student at UTD who is majoring in ITS , who will be completing his fist professional level job in August. I have been working at American Airlines as a junior Data analyst for what will be 8 months in August. and as its quickly approaching, my concern for life post coop are growing.  Before getting this coop, I could barely support myself financially and so I have been making the most of my coop income by paying off debt, but as I look at what I was making pre coop I am realizing that my debt reduction rate at the moment still wont reduce my monthly expenses enough to were I will be able to sustain myself.   &lt;/p&gt;

&lt;p&gt;Question: &lt;/p&gt;

&lt;p&gt;While working at AA, I learned python, machine learning, sql, and neural networks for the most part and I am wanting to know given the pandemic and my financial situation how do I best prepare myself now so that I have a fighting chance to make a transition from AA to another job in my field?  What should I be focusing my extra time on so that when the coop ends i can land preferably a part time jr data analyst position or something similar?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwmj5h,AndriodFanBoy,2,/r/datascience/comments/gwmj5h/career_advice_as_my_coop_comes_to_a_close/,https://www.reddit.com/r/datascience/comments/gwmj5h/career_advice_as_my_coop_comes_to_a_close/,1591293554.0
r/datascience,"This may be a silly question, but I notice that a lot of job postings are asking for ""Bachelor’s Degree or equivalent in Math, Information Systems, Computer Science, Engineering or related field "". 

All this time, I've been assuming that the Data management / Data analytics degree that I'm working on obtaining will fall into the ""Or related field"" category, but I'm asking this question, because I don't want to assume. 

Does anyone here have any insight on this? 

Do any of you have this particular degree?

If not, what are your opinions on this degree? (I'm working on getting this degree from WGU.)",t2_5jfhzbn9,Why don't job postings ask for Data management / analytics degrees?,education,t3_gw84jk,0.81,32,Education,32,1591265524.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This may be a silly question, but I notice that a lot of job postings are asking for &amp;quot;Bachelor’s Degree or equivalent in Math, Information Systems, Computer Science, Engineering or related field &amp;quot;. &lt;/p&gt;

&lt;p&gt;All this time, I&amp;#39;ve been assuming that the Data management / Data analytics degree that I&amp;#39;m working on obtaining will fall into the &amp;quot;Or related field&amp;quot; category, but I&amp;#39;m asking this question, because I don&amp;#39;t want to assume. &lt;/p&gt;

&lt;p&gt;Does anyone here have any insight on this? &lt;/p&gt;

&lt;p&gt;Do any of you have this particular degree?&lt;/p&gt;

&lt;p&gt;If not, what are your opinions on this degree? (I&amp;#39;m working on getting this degree from WGU.)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gw84jk,WrathOfChevy,36,/r/datascience/comments/gw84jk/why_dont_job_postings_ask_for_data_management/,https://www.reddit.com/r/datascience/comments/gw84jk/why_dont_job_postings_ask_for_data_management/,1591236724.0
r/datascience,"Context : I’m an international student in the United States currently looking for an entry level job in data science. Due to covid-19 and it’s impact on the economy, I’ve been told by my batch mates and seniors who have graduated that it’s difficult/almost impossible to get a full time job right now. I’ll graduate next month after which I have till November/ December to get a job which offers sponsorship. Just want to know how much has hiring been affected in these circumstances for data science positions (data scientist, data analyst, business analyst, business intelligence analyst, risk analyst)",t2_f41e4od,Is the job market really fucked ?,,t3_gwa6nt,0.95,20,Job Search,20,1591273645.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Context : I’m an international student in the United States currently looking for an entry level job in data science. Due to covid-19 and it’s impact on the economy, I’ve been told by my batch mates and seniors who have graduated that it’s difficult/almost impossible to get a full time job right now. I’ll graduate next month after which I have till November/ December to get a job which offers sponsorship. Just want to know how much has hiring been affected in these circumstances for data science positions (data scientist, data analyst, business analyst, business intelligence analyst, risk analyst)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwa6nt,MicropylarCyclist,11,/r/datascience/comments/gwa6nt/is_the_job_market_really_fucked/,https://www.reddit.com/r/datascience/comments/gwa6nt/is_the_job_market_really_fucked/,1591244845.0
r/datascience,"Hi, I want to compile a small list (for personal use) of interesting R packages that are worth checking out. I've been using R for many years and know most of the usual stuff (caret, tidyverse, packrat, ggplot, data.table,...), so I'd like to find packages that could help with more high-level concerns of a project, so to speak (say, reproducibility, iteration speed,..). For example I didn't know [Drake](https://books.ropensci.org/drake/) until recently, and I thought it was an interesting thing to try. I hope this makes sense, and thanks in advance for any suggestion.",t2_2vipzd36,Interesting R packages for experienced users,tooling,t3_gwf2fw,1.0,6,Tooling,6,1591296320.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I want to compile a small list (for personal use) of interesting R packages that are worth checking out. I&amp;#39;ve been using R for many years and know most of the usual stuff (caret, tidyverse, packrat, ggplot, data.table,...), so I&amp;#39;d like to find packages that could help with more high-level concerns of a project, so to speak (say, reproducibility, iteration speed,..). For example I didn&amp;#39;t know &lt;a href=""https://books.ropensci.org/drake/""&gt;Drake&lt;/a&gt; until recently, and I thought it was an interesting thing to try. I hope this makes sense, and thanks in advance for any suggestion.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwf2fw,autisticmice,11,/r/datascience/comments/gwf2fw/interesting_r_packages_for_experienced_users/,https://www.reddit.com/r/datascience/comments/gwf2fw/interesting_r_packages_for_experienced_users/,1591267520.0
r/datascience,Does anyone work in machine learning in the cyber security domain? I am curious about opportunities in it. I know that ML is used heavily in CS but just curious about insider info from people working in the industry.,t2_4sqrvy8d,ML within Cyber Security,career,t3_gwf0yf,0.99,5,Career,5,1591296119.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone work in machine learning in the cyber security domain? I am curious about opportunities in it. I know that ML is used heavily in CS but just curious about insider info from people working in the industry.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwf0yf,steph_back41,4,/r/datascience/comments/gwf0yf/ml_within_cyber_security/,https://www.reddit.com/r/datascience/comments/gwf0yf/ml_within_cyber_security/,1591267319.0
r/datascience,"Hello people of reddit! I am Stella and this is my first post \^\_\^

So I am about to finish a Master's program from university on computational intelligence and I want to go deeper since I decided to take this seriously as a career scenario. I have a bachelor in Physics with a specialization on Astrophysics so research is the main area that I will go hunting for a job.

So I am between 2 books( both from O'reilly Publishing company ):

1. **Python Data Science Handbook: Tools and Techniques for Developers** by Wes Mckinney
2. **Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems** by Aurelien Geron

Is anyone familiar with either the books themselves/ Publishing company / authors that has something to add because this is a new area for me and I looking for feedback.

Do you have any book/tutorials recommendations?

Cheers",t2_2bg4trp8,Book Hunting,discussion,t3_gwml6j,0.6,1,Discussion,1,1591322513.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello people of reddit! I am Stella and this is my first post ^_^&lt;/p&gt;

&lt;p&gt;So I am about to finish a Master&amp;#39;s program from university on computational intelligence and I want to go deeper since I decided to take this seriously as a career scenario. I have a bachelor in Physics with a specialization on Astrophysics so research is the main area that I will go hunting for a job.&lt;/p&gt;

&lt;p&gt;So I am between 2 books( both from O&amp;#39;reilly Publishing company ):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Python Data Science Handbook: Tools and Techniques for Developers&lt;/strong&gt; by Wes Mckinney&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems&lt;/strong&gt; by Aurelien Geron&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Is anyone familiar with either the books themselves/ Publishing company / authors that has something to add because this is a new area for me and I looking for feedback.&lt;/p&gt;

&lt;p&gt;Do you have any book/tutorials recommendations?&lt;/p&gt;

&lt;p&gt;Cheers&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwml6j,kerrvature,4,/r/datascience/comments/gwml6j/book_hunting/,https://www.reddit.com/r/datascience/comments/gwml6j/book_hunting/,1591293713.0
r/datascience,"Hello guys!  
I just created space for people interested in ML.NET library, I encourage you to join there!

[https://www.reddit.com/r/ml\_dotnet/](https://www.reddit.com/r/ml_dotnet/)",t2_1myz87vv,ML.NET community,network,t3_gwczhn,0.84,4,Networking,4,1591286129.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys!&lt;br/&gt;
I just created space for people interested in ML.NET library, I encourage you to join there!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.reddit.com/r/ml_dotnet/""&gt;https://www.reddit.com/r/ml_dotnet/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwczhn,bush_dev,1,/r/datascience/comments/gwczhn/mlnet_community/,https://www.reddit.com/r/datascience/comments/gwczhn/mlnet_community/,1591257329.0
r/datascience,"Hi All,

I am working on a problem of binary classification. With a pretty small data set (100 observations, 21 features, and 70-30 target split)

Using cross-validation I found LogisticRegression (with liblinear and l1 penalty) to work best, giving my high AUC score (my metric of focus for the project). Please note that l1 penalty shrank all of the features except for 2.

I plotted the learning curve to understand how to proceed next. Here is the plot - https://i.imgur.com/Vm224zi.png

My problem is I am not able to interpret this plot. Is this a case of high bias or high variance? And why so?

Note: Y-axis denotes AUC Score

Here is the code I used to get the learning curve params (if it helps) - 


```
train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(penalty='l1', solver = 'liblinear'), 
                                                        X, y, cv=10, shuffle=True
                                                        , scoring='roc_auc'
                                                       )
```

Please Help",t2_nis5p,How do I interpret this learning curve? Is this a case of high bias or high variance?,discussion,t3_gwfjie,1.0,2,Discussion,2,1591298419.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All,&lt;/p&gt;

&lt;p&gt;I am working on a problem of binary classification. With a pretty small data set (100 observations, 21 features, and 70-30 target split)&lt;/p&gt;

&lt;p&gt;Using cross-validation I found LogisticRegression (with liblinear and l1 penalty) to work best, giving my high AUC score (my metric of focus for the project). Please note that l1 penalty shrank all of the features except for 2.&lt;/p&gt;

&lt;p&gt;I plotted the learning curve to understand how to proceed next. Here is the plot - &lt;a href=""https://i.imgur.com/Vm224zi.png""&gt;https://i.imgur.com/Vm224zi.png&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My problem is I am not able to interpret this plot. Is this a case of high bias or high variance? And why so?&lt;/p&gt;

&lt;p&gt;Note: Y-axis denotes AUC Score&lt;/p&gt;

&lt;p&gt;Here is the code I used to get the learning curve params (if it helps) - &lt;/p&gt;

&lt;p&gt;&lt;code&gt;
train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(penalty=&amp;#39;l1&amp;#39;, solver = &amp;#39;liblinear&amp;#39;), 
                                                        X, y, cv=10, shuffle=True
                                                        , scoring=&amp;#39;roc_auc&amp;#39;
                                                       )
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Please Help&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwfjie,iCHAIT,2,/r/datascience/comments/gwfjie/how_do_i_interpret_this_learning_curve_is_this_a/,https://www.reddit.com/r/datascience/comments/gwfjie/how_do_i_interpret_this_learning_curve_is_this_a/,1591269619.0
r/datascience,"How important is it to develop domain expertise? I'm struggling a bit right now because I've focused my past efforts on gaining general knowledge (e.g. universal time series forecasting strategies) instead of domain knowledge. As a result, I feel more like a consultant at times. What do you think are the career advantages/disadvantages to this?",t2_1q6oq5dl,Importance of domain expertise to career growth,career,t3_gw84ce,0.83,7,Career,7,1591265505.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How important is it to develop domain expertise? I&amp;#39;m struggling a bit right now because I&amp;#39;ve focused my past efforts on gaining general knowledge (e.g. universal time series forecasting strategies) instead of domain knowledge. As a result, I feel more like a consultant at times. What do you think are the career advantages/disadvantages to this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gw84ce,dmorris87,5,/r/datascience/comments/gw84ce/importance_of_domain_expertise_to_career_growth/,https://www.reddit.com/r/datascience/comments/gw84ce/importance_of_domain_expertise_to_career_growth/,1591236705.0
r/datascience," Anybody have a way to create markdowns within Spyder IDE? Most reporting I've done in the past is in R using RMarkdown, knitr, etc and have not had the need to use Spyder for creating a markdown report before. I looked into spyder-reports and am not sure if that is still functioning. Any suggestions would be appreciated!",t2_7agyhf,Spyder IDE Markdown,discussion,t3_gw0ql9,0.84,29,Discussion,29,1591241279.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anybody have a way to create markdowns within Spyder IDE? Most reporting I&amp;#39;ve done in the past is in R using RMarkdown, knitr, etc and have not had the need to use Spyder for creating a markdown report before. I looked into spyder-reports and am not sure if that is still functioning. Any suggestions would be appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gw0ql9,The_Doc_P,16,/r/datascience/comments/gw0ql9/spyder_ide_markdown/,https://www.reddit.com/r/datascience/comments/gw0ql9/spyder_ide_markdown/,1591212479.0
r/datascience,"I wonder what work are people actually doing under the data scientist title?

For me, I am doing a spectrum of technical-related data activties such as data cleaning, data pipeline building, data analysis, ML modelling, and data-driven company's internal improvement. I realized that in other companies, some DS mostly do ML modelling, some are doing data product building, and some are doing entirely data cleaning. It depends on how company sees the benefit of data people.

I begin to feel that data scientist is an umbrella term for everything data-related.

So I am wondering what actual work you are doing with this title?

Maybe my goal with this thread is to crowdsource information on how company is utilizing data-savvy people and what data related activities that a company is having.",t2_13jg67,What work you are actually doing when your title is data scientist?,discussion,t3_gwapzk,0.86,5,Discussion,5,1591275930.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I wonder what work are people actually doing under the data scientist title?&lt;/p&gt;

&lt;p&gt;For me, I am doing a spectrum of technical-related data activties such as data cleaning, data pipeline building, data analysis, ML modelling, and data-driven company&amp;#39;s internal improvement. I realized that in other companies, some DS mostly do ML modelling, some are doing data product building, and some are doing entirely data cleaning. It depends on how company sees the benefit of data people.&lt;/p&gt;

&lt;p&gt;I begin to feel that data scientist is an umbrella term for everything data-related.&lt;/p&gt;

&lt;p&gt;So I am wondering what actual work you are doing with this title?&lt;/p&gt;

&lt;p&gt;Maybe my goal with this thread is to crowdsource information on how company is utilizing data-savvy people and what data related activities that a company is having.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gwapzk,addictzz,14,/r/datascience/comments/gwapzk/what_work_you_are_actually_doing_when_your_title/,https://www.reddit.com/r/datascience/comments/gwapzk/what_work_you_are_actually_doing_when_your_title/,1591247130.0
r/datascience,"I feel micromanaged and like I am expected to do analysis like an engineer churns out code. Daily stand ups, retros, bleh. There is also a sharp divide between ""product owners"" and worker bees who execute someone else's vision, so all my time is accounted for. No room to scope/source new projects at all.

What I love about analytics/data science and where my true value lies is defining problems and creatively working with stakeholders to solve them.

Does anyone have any recommendations about industries/companies/job titles to explore that give data scientists the scope to come up with new projects and where there isn't a strong product owner/technical divide?

Edit: Wow data people. Thanks for the responses! Been really interesting to read the diverging opinions and advice. My takeaway is that there can be a time and a place for these tools and perhaps the explanatory variable is management and company culture. Personally, I will try to be the change in my org that makes these processes work better. Thanks for enlightening me and breaking me out of my mental local minimum.",t2_ggrx8,Agile/scum is... the worst?,career,t3_gvlcie,0.93,389,Career,389,1591180270.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I feel micromanaged and like I am expected to do analysis like an engineer churns out code. Daily stand ups, retros, bleh. There is also a sharp divide between &amp;quot;product owners&amp;quot; and worker bees who execute someone else&amp;#39;s vision, so all my time is accounted for. No room to scope/source new projects at all.&lt;/p&gt;

&lt;p&gt;What I love about analytics/data science and where my true value lies is defining problems and creatively working with stakeholders to solve them.&lt;/p&gt;

&lt;p&gt;Does anyone have any recommendations about industries/companies/job titles to explore that give data scientists the scope to come up with new projects and where there isn&amp;#39;t a strong product owner/technical divide?&lt;/p&gt;

&lt;p&gt;Edit: Wow data people. Thanks for the responses! Been really interesting to read the diverging opinions and advice. My takeaway is that there can be a time and a place for these tools and perhaps the explanatory variable is management and company culture. Personally, I will try to be the change in my org that makes these processes work better. Thanks for enlightening me and breaking me out of my mental local minimum.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gvlcie,therockhound,121,/r/datascience/comments/gvlcie/agilescum_is_the_worst/,https://www.reddit.com/r/datascience/comments/gvlcie/agilescum_is_the_worst/,1591151470.0
r/datascience,"How do we evaluate the model performance after it is deployed? If it was normal prediction model, we could evaluate based on the actual outcome. However if there is outside interference to change the outcome of that model, how can we evaluate it? When I talk about outside interference. I mean someone takes some action so that that prediction doesn’t occur. Eg we are predicting if an apple will rot, if the prediction is greater than 60% we do something so that the apple will not rot. How can we measure the model performance? How can we know if the prediction was correct?",t2_3z99h,How to evaluate a model performance after deploying into production?,discussion,t3_gvzaik,0.84,15,Discussion,15,1591237133.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How do we evaluate the model performance after it is deployed? If it was normal prediction model, we could evaluate based on the actual outcome. However if there is outside interference to change the outcome of that model, how can we evaluate it? When I talk about outside interference. I mean someone takes some action so that that prediction doesn’t occur. Eg we are predicting if an apple will rot, if the prediction is greater than 60% we do something so that the apple will not rot. How can we measure the model performance? How can we know if the prediction was correct?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gvzaik,shonesum,16,/r/datascience/comments/gvzaik/how_to_evaluate_a_model_performance_after/,https://www.reddit.com/r/datascience/comments/gvzaik/how_to_evaluate_a_model_performance_after/,1591208333.0
r/datascience," I work in a B2B sales organization and our Director of Sales wants me to find the commonalities between the companies that each sales rep has had success selling to. I have data where each observation is a company the sales rep tried to sell to (opportunity), the characteristics (qual. and quant.) of the company, and the outcome (won/lost). Below are a few ideas I had on tackling this question, but I am wondering how you would approach this. 

1. Use a factor analysis method on the won opportunities for a sales rep and analyze the axes with low explanation of variance. Would this essentially tell me what makes these companies the same, as opposed to different? 

2. Use logistic regression with all the opportunities and analyze the significant variables that increase the probability of winning.",t2_re71mrd,Advice in B2B Sales Analysis,discussion,t3_gw2pg1,1.0,9,Discussion,9,1591247294.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work in a B2B sales organization and our Director of Sales wants me to find the commonalities between the companies that each sales rep has had success selling to. I have data where each observation is a company the sales rep tried to sell to (opportunity), the characteristics (qual. and quant.) of the company, and the outcome (won/lost). Below are a few ideas I had on tackling this question, but I am wondering how you would approach this. &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Use a factor analysis method on the won opportunities for a sales rep and analyze the axes with low explanation of variance. Would this essentially tell me what makes these companies the same, as opposed to different? &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use logistic regression with all the opportunities and analyze the significant variables that increase the probability of winning.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gw2pg1,butteryflakycrus,10,/r/datascience/comments/gw2pg1/advice_in_b2b_sales_analysis/,https://www.reddit.com/r/datascience/comments/gw2pg1/advice_in_b2b_sales_analysis/,1591218494.0
r/datascience,"I am wondering if anyone use technique like Weighted Least Square or robust regression in their work. How does these models stack up against tree-based model, regularized model, or other ml model?

&amp;#x200B;

I also posted the question in stackexchange.

[https://stats.stackexchange.com/questions/470044/when-does-we-use-weighted-ls-regression-generalized-ls-regression-or-robust-re](https://stats.stackexchange.com/questions/470044/when-does-we-use-weighted-ls-regression-generalized-ls-regression-or-robust-re)",t2_sw70d,Does anyone use or came across weighted least square or robust regression in their work?,discussion,t3_gw7wxe,0.67,2,Discussion,2,1591264758.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am wondering if anyone use technique like Weighted Least Square or robust regression in their work. How does these models stack up against tree-based model, regularized model, or other ml model?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I also posted the question in stackexchange.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://stats.stackexchange.com/questions/470044/when-does-we-use-weighted-ls-regression-generalized-ls-regression-or-robust-re""&gt;https://stats.stackexchange.com/questions/470044/when-does-we-use-weighted-ls-regression-generalized-ls-regression-or-robust-re&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gw7wxe,bot_cereal,7,/r/datascience/comments/gw7wxe/does_anyone_use_or_came_across_weighted_least/,https://www.reddit.com/r/datascience/comments/gw7wxe/does_anyone_use_or_came_across_weighted_least/,1591235958.0
r/datascience,"I'm trying to run an experiment, and the lag time to measure the impact of the experiment is about 4 months.  Has anyone come across this problem?",t2_1o26bmw3,Experiments with infrequently updating metrics,discussion,t3_gw38m8,0.8,3,Discussion,3,1591248907.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to run an experiment, and the lag time to measure the impact of the experiment is about 4 months.  Has anyone come across this problem?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gw38m8,da_chosen1,3,/r/datascience/comments/gw38m8/experiments_with_infrequently_updating_metrics/,https://www.reddit.com/r/datascience/comments/gw38m8/experiments_with_infrequently_updating_metrics/,1591220107.0
r/datascience,"Hi folks! I am currently working as a Software Engineer in a Reporting/Analysis team using SAP BO and SQL. I am trying to get a job as a data scientist and had applied to a bunch of companies and did attend interview in a few. In the last interview which I gave, the interviewer asked me the above question, and I couldn't say anything which was able to convince him.

I have taken a bunch of MOOC courses and had worked on common UCI datasets. I have recently started with Kaggle as well (trying the basic one's right now). I know I have to improve a lot, but this question keeps on pondering me, as the interviewer was okay with me working with iris dataset as I am fresher with less than 1 year of full-time experience. He just wanted to know my answer to the above question. I tried thinking and giving a generalized answer but he wasn't impressed and asked how did you solve iris problem. Having watched n number of tutorials, the bias kicked in and I just said that I need to do EDA, understand the relationship between parameters and then go about solving the problem by applying, any of the many Classification algorithm, which I had done.

But he wasn't having it and this got me thinking that in the real-world you won't be given a dataset to work with, forget about proper expectation/requirement. And you cannot waste/invest a lot of time doing EDA as the client is looking for a working model and not a bunch of graphs and visualizations, so how to actually approach a ML/DS problem?

Can some of the folks working in the field describe to me, as how would have you answered the above question and typical tasks or problem statement you get during your job and your thought process in approaching the task.

thanks for your time, much appreciated :)",t2_17b1sm,How do you approach ML/ DS problem?,discussion,t3_gvwo3j,0.64,3,Discussion,3,1591229031.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi folks! I am currently working as a Software Engineer in a Reporting/Analysis team using SAP BO and SQL. I am trying to get a job as a data scientist and had applied to a bunch of companies and did attend interview in a few. In the last interview which I gave, the interviewer asked me the above question, and I couldn&amp;#39;t say anything which was able to convince him.&lt;/p&gt;

&lt;p&gt;I have taken a bunch of MOOC courses and had worked on common UCI datasets. I have recently started with Kaggle as well (trying the basic one&amp;#39;s right now). I know I have to improve a lot, but this question keeps on pondering me, as the interviewer was okay with me working with iris dataset as I am fresher with less than 1 year of full-time experience. He just wanted to know my answer to the above question. I tried thinking and giving a generalized answer but he wasn&amp;#39;t impressed and asked how did you solve iris problem. Having watched n number of tutorials, the bias kicked in and I just said that I need to do EDA, understand the relationship between parameters and then go about solving the problem by applying, any of the many Classification algorithm, which I had done.&lt;/p&gt;

&lt;p&gt;But he wasn&amp;#39;t having it and this got me thinking that in the real-world you won&amp;#39;t be given a dataset to work with, forget about proper expectation/requirement. And you cannot waste/invest a lot of time doing EDA as the client is looking for a working model and not a bunch of graphs and visualizations, so how to actually approach a ML/DS problem?&lt;/p&gt;

&lt;p&gt;Can some of the folks working in the field describe to me, as how would have you answered the above question and typical tasks or problem statement you get during your job and your thought process in approaching the task.&lt;/p&gt;

&lt;p&gt;thanks for your time, much appreciated :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gvwo3j,pratikkejriwal,4,/r/datascience/comments/gvwo3j/how_do_you_approach_ml_ds_problem/,https://www.reddit.com/r/datascience/comments/gvwo3j/how_do_you_approach_ml_ds_problem/,1591200231.0
r/datascience,"Hi All,

I am pretty new to data science so pardon me if this is a silly question. 

So I am working on a binary classification problem and found out that Logistic Regression works best for my dataset based on 10 fold cross-validation accuracy score.  (Mean acc = 93.5%)


Now, I want to put a model into production to actually make some kind of prediction on future incoming data. 

Which model do I put into production? When I split my data into training and test and train the model it gives me different accuracy each time. I understand why that is happening. But when it comes to deploying this Logistic Regression model, what do i do?",t2_u3mrb,How to proceed after the cross-validation step?,discussion,t3_gvrll8,0.84,8,Discussion,8,1591209494.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi All,&lt;/p&gt;

&lt;p&gt;I am pretty new to data science so pardon me if this is a silly question. &lt;/p&gt;

&lt;p&gt;So I am working on a binary classification problem and found out that Logistic Regression works best for my dataset based on 10 fold cross-validation accuracy score.  (Mean acc = 93.5%)&lt;/p&gt;

&lt;p&gt;Now, I want to put a model into production to actually make some kind of prediction on future incoming data. &lt;/p&gt;

&lt;p&gt;Which model do I put into production? When I split my data into training and test and train the model it gives me different accuracy each time. I understand why that is happening. But when it comes to deploying this Logistic Regression model, what do i do?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gvrll8,arke47,12,/r/datascience/comments/gvrll8/how_to_proceed_after_the_crossvalidation_step/,https://www.reddit.com/r/datascience/comments/gvrll8/how_to_proceed_after_the_crossvalidation_step/,1591180694.0
r/datascience,"&amp;#x200B;

I keep seeing threads on this forum about how disappointed so many people are with their data science jobs.

&amp;#x200B;

I think expectations need to be managed, in any line of work:

1. **Seniority / juniority**:  When you start as a medical doctor, you won't start by diagnosing Dr. House-like rare, life-threatening conditions straight away. If you join a law firm, you won't start by passionately and single-handedly defending your clients in court like in a John Grisham book. If you join Goldman Sachs as a graduate, you won't start by managing multi-billion trades and investments straight away. **Any job has a certain amount of grunt work, which is greater at the very beginning of your career**. The world is full of bright kids disappointed with their first jobs, wondering: ""did I really study 3/4/5 years to change the colours of a PowerPoint slide?"".
2. **Importance within the organisation**: this varies wildly from place to place but, generally, regardless of the guff HR says, in many organisations there is a clear difference in the food chain between the functions which are seen as generating revenues and those which are seen as support functions. In many places, the sales team (or equivalent) brings home the money, and everyone else is seen as a support function. You don't need to argue with me that this is shortsighted: you need to understand that this attitude is common, need to do your homework on what the culture is like before joining a company, and make your decisions accordingly.
3. **(related to #2): what is the background of the senior people?** If you are a data scientist in a company where most senior executives have some kind of technical background, you are more likely to be appreciated than in a company where the senior guys (it's almost always guys...) are all salespeople who go into sensory shutdown the moment you mention anything more complicated than the times tables.
4. **what are the real needs of the business?** Even in the most enlightened organisation, with the most technical sensible competent open-minded etc etc executives, **there will be more need for boring work than for exciting, cutting-edge work**. For every person that must do proper R&amp;D and brand-new, cutting edge models processes technologies etc, there will need to be many more people that must manage and maintain the existing processes and models, which is important even if less interesting",t2_3gsivx5o,"So many people disappointed with their jobs. You need to manage your expectations, especially if you're very junior.",discussion,t3_gv3i57,0.96,676,Discussion,676,1591115576.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I keep seeing threads on this forum about how disappointed so many people are with their data science jobs.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I think expectations need to be managed, in any line of work:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Seniority / juniority&lt;/strong&gt;:  When you start as a medical doctor, you won&amp;#39;t start by diagnosing Dr. House-like rare, life-threatening conditions straight away. If you join a law firm, you won&amp;#39;t start by passionately and single-handedly defending your clients in court like in a John Grisham book. If you join Goldman Sachs as a graduate, you won&amp;#39;t start by managing multi-billion trades and investments straight away. &lt;strong&gt;Any job has a certain amount of grunt work, which is greater at the very beginning of your career&lt;/strong&gt;. The world is full of bright kids disappointed with their first jobs, wondering: &amp;quot;did I really study 3/4/5 years to change the colours of a PowerPoint slide?&amp;quot;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Importance within the organisation&lt;/strong&gt;: this varies wildly from place to place but, generally, regardless of the guff HR says, in many organisations there is a clear difference in the food chain between the functions which are seen as generating revenues and those which are seen as support functions. In many places, the sales team (or equivalent) brings home the money, and everyone else is seen as a support function. You don&amp;#39;t need to argue with me that this is shortsighted: you need to understand that this attitude is common, need to do your homework on what the culture is like before joining a company, and make your decisions accordingly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(related to #2): what is the background of the senior people?&lt;/strong&gt; If you are a data scientist in a company where most senior executives have some kind of technical background, you are more likely to be appreciated than in a company where the senior guys (it&amp;#39;s almost always guys...) are all salespeople who go into sensory shutdown the moment you mention anything more complicated than the times tables.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;what are the real needs of the business?&lt;/strong&gt; Even in the most enlightened organisation, with the most technical sensible competent open-minded etc etc executives, &lt;strong&gt;there will be more need for boring work than for exciting, cutting-edge work&lt;/strong&gt;. For every person that must do proper R&amp;amp;D and brand-new, cutting edge models processes technologies etc, there will need to be many more people that must manage and maintain the existing processes and models, which is important even if less interesting&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gv3i57,MonthyPythonista,98,/r/datascience/comments/gv3i57/so_many_people_disappointed_with_their_jobs_you/,https://www.reddit.com/r/datascience/comments/gv3i57/so_many_people_disappointed_with_their_jobs_you/,1591086776.0
r/datascience,"Hello everyone, this is a little spot where I've learned a lot. After a few searches I could not find something that could help me learn about how to assess quantitatively the impact of a model.

Do you have any literature/video/article suggestions that I could put my attention to?


Thank you so much for your time.",t2_azbcf,Frameworks to assess impact of models,,t3_gvr8p3,1.0,1,,1,1591207765.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, this is a little spot where I&amp;#39;ve learned a lot. After a few searches I could not find something that could help me learn about how to assess quantitatively the impact of a model.&lt;/p&gt;

&lt;p&gt;Do you have any literature/video/article suggestions that I could put my attention to?&lt;/p&gt;

&lt;p&gt;Thank you so much for your time.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gvr8p3,Lechateau,7,/r/datascience/comments/gvr8p3/frameworks_to_assess_impact_of_models/,https://www.reddit.com/r/datascience/comments/gvr8p3/frameworks_to_assess_impact_of_models/,1591178965.0
r/datascience,"Did someone already build a model (not necessariliy DS but plain DA/calculations) to get Uplift value from marketing campaigns (e.g. TV) onto web traffic in Corona times and can talk about a bit about it?

I see a lot of spikes and a mismatching baseline due to increased Corona online shopping and wonder how I can calculate a new, good fitting baseline?",t2_kn00t,How to best calculate uplift from web traffic data?,discussion,t3_gveu5l,0.84,4,Discussion,4,1591157647.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Did someone already build a model (not necessariliy DS but plain DA/calculations) to get Uplift value from marketing campaigns (e.g. TV) onto web traffic in Corona times and can talk about a bit about it?&lt;/p&gt;

&lt;p&gt;I see a lot of spikes and a mismatching baseline due to increased Corona online shopping and wonder how I can calculate a new, good fitting baseline?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gveu5l,Yojihito,2,/r/datascience/comments/gveu5l/how_to_best_calculate_uplift_from_web_traffic_data/,https://www.reddit.com/r/datascience/comments/gveu5l/how_to_best_calculate_uplift_from_web_traffic_data/,1591128847.0
r/datascience,"That's why we're all here, right? 

I'd like to share with you a nice little story. I've recently been working on a difficult scoring problem that determined a rank from numerous features. There were numerous issues: which features were most important, did it make sense to have so many features, do we condense them, do we take the mean and so on. I had been working on this problem for weeks, and after numerous measurements, reports, reading and testing, I conked out -- I gave up. 

Man, Data Science was done for me; I was so over it. I started talking more with my colleagues in different departments, primarily in PR. I just felt like doing something else for a few days. I asked one of my colleagues in PR, ""so, what would you do if you had to rank X, Y, and Z?"" ""Hmm... I'm not so sure, I think I would be more interested in Z than X, why is X even necessary?"" She was right. Statistically, X was absolutely necessary in many of my modes. My boss thought this was the key to solving our problem, why would she think it's unnecessary? It turns out... as Data Scientists, we weren't the ones using the product. My colleague -- bless her soul -- is exactly our target audience. We were so in solutions mode, we forgot to just think about the problem and WHOM it concerns. 

I decided to take a walk and put pen to paper. I even asked the barista at the local cafe. It was so obvious. 

We were solving the WRONG problem the whole time -- well, at least we weren't making it any easier for ourselves.

To all of the great DS minds out there, sometimes we need to stop and reset. 

Problems are realised in different ways; it's our job as Data Scientists to understand who the realisation is for. 

Now, I'd love to know what your experiences were and how simplicity overcame complexity?",t2_5e34w9d2,Do less Data Science,discussion,t3_guuer4,0.94,258,Discussion,258,1591078688.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;That&amp;#39;s why we&amp;#39;re all here, right? &lt;/p&gt;

&lt;p&gt;I&amp;#39;d like to share with you a nice little story. I&amp;#39;ve recently been working on a difficult scoring problem that determined a rank from numerous features. There were numerous issues: which features were most important, did it make sense to have so many features, do we condense them, do we take the mean and so on. I had been working on this problem for weeks, and after numerous measurements, reports, reading and testing, I conked out -- I gave up. &lt;/p&gt;

&lt;p&gt;Man, Data Science was done for me; I was so over it. I started talking more with my colleagues in different departments, primarily in PR. I just felt like doing something else for a few days. I asked one of my colleagues in PR, &amp;quot;so, what would you do if you had to rank X, Y, and Z?&amp;quot; &amp;quot;Hmm... I&amp;#39;m not so sure, I think I would be more interested in Z than X, why is X even necessary?&amp;quot; She was right. Statistically, X was absolutely necessary in many of my modes. My boss thought this was the key to solving our problem, why would she think it&amp;#39;s unnecessary? It turns out... as Data Scientists, we weren&amp;#39;t the ones using the product. My colleague -- bless her soul -- is exactly our target audience. We were so in solutions mode, we forgot to just think about the problem and WHOM it concerns. &lt;/p&gt;

&lt;p&gt;I decided to take a walk and put pen to paper. I even asked the barista at the local cafe. It was so obvious. &lt;/p&gt;

&lt;p&gt;We were solving the WRONG problem the whole time -- well, at least we weren&amp;#39;t making it any easier for ourselves.&lt;/p&gt;

&lt;p&gt;To all of the great DS minds out there, sometimes we need to stop and reset. &lt;/p&gt;

&lt;p&gt;Problems are realised in different ways; it&amp;#39;s our job as Data Scientists to understand who the realisation is for. &lt;/p&gt;

&lt;p&gt;Now, I&amp;#39;d love to know what your experiences were and how simplicity overcame complexity?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",guuer4,expatwithajetpack,37,/r/datascience/comments/guuer4/do_less_data_science/,https://www.reddit.com/r/datascience/comments/guuer4/do_less_data_science/,1591049888.0
r/datascience,"Today OpenAI published a Weights &amp; Biases Report ([here](https://app.wandb.ai/openai/published-work/Learning-Dexterity-End-to-End--VmlldzoxMTUyMDQ)) on some recent work done by the Robotics team at OpenAI where they trained a policy to manipulate objects with a robotic hand in an end-to-end manner. Specifically, they solved the block reorientation task from our 2018 release ""[Learning Dexterity](https://openai.com/blog/learning-dexterity/)"" using a policy with image inputs rather than training separate vision and policy models (as in the original release).

In the report they describe their experimental process in general and then detail the findings of this specific work. In particular, they contrast the use of Behavioral Cloning and Reinforcement Learning for this task, and ablate several aspects of our setup including model architecture, batch size, etc.

Alex and I happy to discuss this and answer any questions about it.",t2_wyr6m,OpenAI – Learning Dexterity End-to-End - Experiment Report,discussion,t3_gvgc0f,0.67,1,Discussion,1,1591162280.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Today OpenAI published a Weights &amp;amp; Biases Report (&lt;a href=""https://app.wandb.ai/openai/published-work/Learning-Dexterity-End-to-End--VmlldzoxMTUyMDQ""&gt;here&lt;/a&gt;) on some recent work done by the Robotics team at OpenAI where they trained a policy to manipulate objects with a robotic hand in an end-to-end manner. Specifically, they solved the block reorientation task from our 2018 release &amp;quot;&lt;a href=""https://openai.com/blog/learning-dexterity/""&gt;Learning Dexterity&lt;/a&gt;&amp;quot; using a policy with image inputs rather than training separate vision and policy models (as in the original release).&lt;/p&gt;

&lt;p&gt;In the report they describe their experimental process in general and then detail the findings of this specific work. In particular, they contrast the use of Behavioral Cloning and Reinforcement Learning for this task, and ablate several aspects of our setup including model architecture, batch size, etc.&lt;/p&gt;

&lt;p&gt;Alex and I happy to discuss this and answer any questions about it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gvgc0f,0_marauders_0,1,/r/datascience/comments/gvgc0f/openai_learning_dexterity_endtoend_experiment/,https://www.reddit.com/r/datascience/comments/gvgc0f/openai_learning_dexterity_endtoend_experiment/,1591133480.0
r/datascience,"Hey guys, 

So we’re looking to cluster our social demographic data. I’m pretty new to clustering validation and when to say, “this is good enough.” 

We have no pre labeled data to test our clusters,  only silhouette scores of ~ 0.65

At what point do I stop optimizing clustering problems, or is it subjective? 

For some background on the problem: 
We aim to label the data into 5~6 clusters (domain knowledge from my boss suggests in theory there should be 5~6 categories. Will discuss with him more), 

We wish to use the data to synthesize new data. I’m not too sure how we will achieve this, maybe a variational Autoencoder, or we simply find the closest centroid for data of our choice and sample from the centroid (this is the added restriction that our data is distributed in different ways as we are working with real estate data)

Given the problem, I’d say it’s important we have very clearly defined clusters, but
I’m just getting my head in a real knot knowing when it’s good enough, and my boss has said it’s entirely up to me. 

Thanks guys!",t2_5e34w9d2,At what point do you stop with a clustering problem?,tooling,t3_gumr3u,0.99,117,Tooling,117,1591054650.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, &lt;/p&gt;

&lt;p&gt;So we’re looking to cluster our social demographic data. I’m pretty new to clustering validation and when to say, “this is good enough.” &lt;/p&gt;

&lt;p&gt;We have no pre labeled data to test our clusters,  only silhouette scores of ~ 0.65&lt;/p&gt;

&lt;p&gt;At what point do I stop optimizing clustering problems, or is it subjective? &lt;/p&gt;

&lt;p&gt;For some background on the problem: 
We aim to label the data into 5~6 clusters (domain knowledge from my boss suggests in theory there should be 5~6 categories. Will discuss with him more), &lt;/p&gt;

&lt;p&gt;We wish to use the data to synthesize new data. I’m not too sure how we will achieve this, maybe a variational Autoencoder, or we simply find the closest centroid for data of our choice and sample from the centroid (this is the added restriction that our data is distributed in different ways as we are working with real estate data)&lt;/p&gt;

&lt;p&gt;Given the problem, I’d say it’s important we have very clearly defined clusters, but
I’m just getting my head in a real knot knowing when it’s good enough, and my boss has said it’s entirely up to me. &lt;/p&gt;

&lt;p&gt;Thanks guys!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gumr3u,expatwithajetpack,50,/r/datascience/comments/gumr3u/at_what_point_do_you_stop_with_a_clustering/,https://www.reddit.com/r/datascience/comments/gumr3u/at_what_point_do_you_stop_with_a_clustering/,1591025850.0
r/datascience,"Hi, I am a recent college grad and I majored in data science so I have taken my fair share of courses and projects in machine learning and statistics. However, most, if not all of the projects I do in school and even the personal projects I work on the data is very readily available and in decent shape where I just need to do some cleaning and manipulation of the data.

Currently, I am working on a project where I am trying to process emails and build a type of importance algorithm based on the contents/data of the email.

The emails contain sensitive information and the preliminary dataset I have been testing on (very small size, &lt;100 emails) has any sensitive info redacted which is fine. But when I get to the point where I will need tens of thousands of emails it is extremely impractical to redact each one.

I was wondering if anyone has any ideas of ways to build a model that either doesn't use the contents of the emails, or a way to deal with the sensitive information problem.

Thanks.",t2_2suon3n,Real World Data Collection,projects,t3_gumw43,0.81,9,Projects,9,1591055092.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I am a recent college grad and I majored in data science so I have taken my fair share of courses and projects in machine learning and statistics. However, most, if not all of the projects I do in school and even the personal projects I work on the data is very readily available and in decent shape where I just need to do some cleaning and manipulation of the data.&lt;/p&gt;

&lt;p&gt;Currently, I am working on a project where I am trying to process emails and build a type of importance algorithm based on the contents/data of the email.&lt;/p&gt;

&lt;p&gt;The emails contain sensitive information and the preliminary dataset I have been testing on (very small size, &amp;lt;100 emails) has any sensitive info redacted which is fine. But when I get to the point where I will need tens of thousands of emails it is extremely impractical to redact each one.&lt;/p&gt;

&lt;p&gt;I was wondering if anyone has any ideas of ways to build a model that either doesn&amp;#39;t use the contents of the emails, or a way to deal with the sensitive information problem.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gumw43,za0880,15,/r/datascience/comments/gumw43/real_world_data_collection/,https://www.reddit.com/r/datascience/comments/gumw43/real_world_data_collection/,1591026292.0
r/datascience,"Help with expotential functions

Hey guys,

I have a problem with expotentially rising weighting of allocations. I have a given:

total number of assets --&gt; total
maximum allocation(in weights) --&gt; max = .15
minimum allocation (in weights) -&gt; min = 1/total/2
My goal is that the algortihm gives the first asset the maximum --&gt; P(1|max),
The y value should be expotentially decreasing but should not be lower than min.
And the sum of weights should be close as possible to 1.
How can I accomplish that ?
--&gt; I looked into scipy curve fitting, but I do not know how to apply it",t2_67qidbzz,Exponential functions and optimisation,education,t3_gusf6x,1.0,3,Education,3,1591072463.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Help with expotential functions&lt;/p&gt;

&lt;p&gt;Hey guys,&lt;/p&gt;

&lt;p&gt;I have a problem with expotentially rising weighting of allocations. I have a given:&lt;/p&gt;

&lt;p&gt;total number of assets --&amp;gt; total
maximum allocation(in weights) --&amp;gt; max = .15
minimum allocation (in weights) -&amp;gt; min = 1/total/2
My goal is that the algortihm gives the first asset the maximum --&amp;gt; P(1|max),
The y value should be expotentially decreasing but should not be lower than min.
And the sum of weights should be close as possible to 1.
How can I accomplish that ?
--&amp;gt; I looked into scipy curve fitting, but I do not know how to apply it&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gusf6x,Anonymushacker8,2,/r/datascience/comments/gusf6x/exponential_functions_and_optimisation/,https://www.reddit.com/r/datascience/comments/gusf6x/exponential_functions_and_optimisation/,1591043663.0
r/datascience,"I'm 5 years into my data science career and at my third job and I just find it incredibly boring and tedious and am thinking of leaving the field and moving into a software engineering role just to do something new.  I found it interesting in the beginning when I was learning new things but now it just seems like pretty much 95% of all data science work falls into moving data around, cleaning data, build a model by calling some outside machine learning library, or trying to explain things to business people.  I imagine there are some data science jobs out there where the work is interesting but they seem incredibly rare.  Have I just gotten unlucky in the jobs I've had or do other people who have been in the field for a while feel the same way as me?",t2_biow8,Does anyone else that has been doing data science for a while find it incredibly boring?,discussion,t3_gu2raf,0.96,304,Discussion,304,1590973801.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m 5 years into my data science career and at my third job and I just find it incredibly boring and tedious and am thinking of leaving the field and moving into a software engineering role just to do something new.  I found it interesting in the beginning when I was learning new things but now it just seems like pretty much 95% of all data science work falls into moving data around, cleaning data, build a model by calling some outside machine learning library, or trying to explain things to business people.  I imagine there are some data science jobs out there where the work is interesting but they seem incredibly rare.  Have I just gotten unlucky in the jobs I&amp;#39;ve had or do other people who have been in the field for a while feel the same way as me?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gu2raf,xbomber88,95,/r/datascience/comments/gu2raf/does_anyone_else_that_has_been_doing_data_science/,https://www.reddit.com/r/datascience/comments/gu2raf/does_anyone_else_that_has_been_doing_data_science/,1590945001.0
r/datascience,"Hello, first time system architect here. Or rather, I'm just the most experienced dev so [they gave me the reins over the project architecture](https://i.imgur.com/43eedLE.jpg).

Anyway, we're building a data analytics platform and just finished our first pipeline that ETLs from a DB into our data warehouse. We were provided a read only account for that DB and initially, we saved the username and password in a gitignored credentials.ini file that we would manually copy paste during deployment.

We're about to start our second pipeline which will involve another DB and another set of credentials and it's becoming apparent that our project will eventually contain all the (read only) keys to the kingdom. We've switched to saving the credentials in a keepass vault (.kdbx) which is checked into our repository while manually copying the keyfile.

I understand that if we want these pipelines to be automated, those credentials are going to need to be accessible from within the system so really, I'm just wondering if there's a better way to manage the storage/deploying of them within our project.

We're using Python btw",t2_4xjob,How do you manage credentials/passwords for your data pipelines/ETL jobs?,discussion,t3_gue1fu,0.95,26,Discussion,26,1591015177.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, first time system architect here. Or rather, I&amp;#39;m just the most experienced dev so &lt;a href=""https://i.imgur.com/43eedLE.jpg""&gt;they gave me the reins over the project architecture&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Anyway, we&amp;#39;re building a data analytics platform and just finished our first pipeline that ETLs from a DB into our data warehouse. We were provided a read only account for that DB and initially, we saved the username and password in a gitignored credentials.ini file that we would manually copy paste during deployment.&lt;/p&gt;

&lt;p&gt;We&amp;#39;re about to start our second pipeline which will involve another DB and another set of credentials and it&amp;#39;s becoming apparent that our project will eventually contain all the (read only) keys to the kingdom. We&amp;#39;ve switched to saving the credentials in a keepass vault (.kdbx) which is checked into our repository while manually copying the keyfile.&lt;/p&gt;

&lt;p&gt;I understand that if we want these pipelines to be automated, those credentials are going to need to be accessible from within the system so really, I&amp;#39;m just wondering if there&amp;#39;s a better way to manage the storage/deploying of them within our project.&lt;/p&gt;

&lt;p&gt;We&amp;#39;re using Python btw&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gue1fu,noun_verber,6,/r/datascience/comments/gue1fu/how_do_you_manage_credentialspasswords_for_your/,https://www.reddit.com/r/datascience/comments/gue1fu/how_do_you_manage_credentialspasswords_for_your/,1590986377.0
r/datascience,"I'm in a data science ethics course over the summer. In a few weeks I'll be giving a 3-5 minute presentation that is supposed to serve as an overview on a data science ethics issue. I know that data science touches a lot of large, overarching domains such as privacy concerns, but I was hoping to find something specific and unique since many other people will be giving presentations as well. For example, in class we read through an article by [Propublica about machine bias in court sentencing](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing). 

Googling ""data science ethics topics"" seems to be a recipe for somewhat mundane articles that are overly broad. 

I'll happily take any suggestions anyone is offering or resources on where to look for topics such as this. 

Thank you.",t2_dbxfs,Data Science Ethic Issues Suggestions,discussion,t3_gur7t8,0.57,1,Discussion,1,1591068684.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m in a data science ethics course over the summer. In a few weeks I&amp;#39;ll be giving a 3-5 minute presentation that is supposed to serve as an overview on a data science ethics issue. I know that data science touches a lot of large, overarching domains such as privacy concerns, but I was hoping to find something specific and unique since many other people will be giving presentations as well. For example, in class we read through an article by &lt;a href=""https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing""&gt;Propublica about machine bias in court sentencing&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Googling &amp;quot;data science ethics topics&amp;quot; seems to be a recipe for somewhat mundane articles that are overly broad. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ll happily take any suggestions anyone is offering or resources on where to look for topics such as this. &lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gur7t8,thebdup,8,/r/datascience/comments/gur7t8/data_science_ethic_issues_suggestions/,https://www.reddit.com/r/datascience/comments/gur7t8/data_science_ethic_issues_suggestions/,1591039884.0
r/datascience,"Hey guys -

Had the opportunity to interview a Data Scientist at Uber on their Shared Rides Team. Thought I'd share some of it here, in case you find it helpful :)

**What do you do &amp; where do you work?**

My name is Divyansh Agarwal and I am a data scientist at Uber in San Francisco. I’m working on  the Shared Rides business, and work on building products that grow the business. Some of my work also involves optimizing the efficiency of Uber’s ride sharing marketplace by improving graph optimization algorithms for rider-driver matching, and evaluating their performance via experimentation and simulations.

**When did you first become interested in Data Science?**

So, I had an interest in machine learning and predictive analytics before going into university. I wrote about it in my college essays as well.

But I was also interested in software engineering and fields like security. What really made me truly interested in data science was taking [Data 8](http://data8.org/) at UC Berkeley. I really liked the fact that you could use statistics to extract insights from data and provide value - and although I had always been aware of this, I only realized then how powerful statistics could be and how computing facilitates all of this.

After that, I started doing a bunch of projects, some internships, and got involved in research.

**When applying for jobs, was it hard to choose between going for a software engineering role as opposed to a data science role?**

Not really - I was always set on data science once I got into it. I used software engineering more as a backup, because given my CS background it would have been easy to get a software job if I just prepped hard for their interviews.

It’s actually harder to get a data science job out of undergrad. This is because there’s a general bias towards people with graduate degrees and people with a lot of experience. So you need to have either of both - either you need to have a lot of work experience, or you need to have a PHD.

So that’s why I built experience through doing projects, research, internships, etc.

For Data Science, there’s no real standardized process when it comes to interviewing - it varies a lot from company to company (this is in contrast to software engineering where using websites like LeetCode can get you ready for almost all jobs).

So I had to spend a lot of time prepping for each specific company I interviewed with - at every stage of the process - and this ended up taking a lot of time.

**When applying to Uber, did you have projects in mind you wanted to work on? How much did you know about the company?**

After my sophomore year of college, I was invited for this intern open house at Uber. That’s when I met some of the team across rides, security, and eats. I spoke to this guy on the marketplace team and another guy on the maps team, I was really interested in those teams.

What’s really cool about the marketplace team specifically is that it’s at the intersection of computer science, economics, optimization, statistics, and there’s a lot of hard &amp; interesting problems that can be solved from an algorithmic perspective.

So after this event I attended, I knew that I wanted to be on the marketplace team at Uber. So during my senior year recruiting, I reached out to someone on the marketplace team, and they were interested in me, so that’s how I started interviewing at Uber.

**What is your team responsible for and why is this work critical to Uber’s business?**

I’m on the Shared Rides team (which is a part of Marketplace Dynamics). The core of building new shared rides products and features come from [matching improvements](https://marketplace.uber.com/matching) or UI and experience improvements. So either tweaking these algorithms, designing &amp; analyzing experiments, understanding how users are responding to new product features - these are all very important and central to Uber’s business.

What are some challenges (both technical and non-technical) your team faces?

The biggest challenge for our team (and I think this is true for any consumer internet product) is building something that people actually like that meets your business objectives. Because everytime you change something with the product, one metric might become worse and the other might become better.

It’s also really hard to figure out what users really want and what they really like. This involves a lot of UX research, as well as experimentation. This stuff is really challenging. Here’s another example:

So, there’s an optimization &amp; efficiency side of Shared Rides - there’s always a tension between the two. If I make something more optimal, it might hurt the experience. If I make the experience better, we have to give some leeway on the optimization side of things. So that’s this underlying technical tension that’s always there.

On the product side, as I had already mentioned, it just comes down to building something users really want. So we have designers and UX researchers who are embedded within shared rides, as well as marketing folks, and I have to work cross functionally with these guys to problem solve on a daily basis.

**You interned at Quora before Uber - can you tell me differences between both companies and how that affected your work?**

So Quora was a very small company - there were only 230 people or so when I was working there (two years ago). There were fewer layers of management, it was easier to know people across the company - for example I even got the chance to speak with the CEO on a couple of occasions. There was also less bureaucracy I guess.

At Uber, since it’s a bigger company, sometimes if you want to build something you might need to get buy-in from another team, there’s more bureaucracy, there’s more layers between you and executive management.

Like at Quora, I knew the Head of Data Science very well, but at Uber I can’t imagine doing that currently (given I’ve just begun my career).

At a bigger company like Uber though, you’re working on projects that have bigger scope, bigger impact on the world, and you work with a lot more people. I’m also more specialized within my role here at Uber - at Quora I could have had more flexibility in terms of what I wanted to work on. At Uber, I’m on a very specific team, in a very specific role, working on a very specific part of the product. This has significant advantages: We’re working on specialized problems that are really challenging, and I’m surrounded by people who have been thinking deeply about these problems for a while are are super passionate about these problems. There’s some incredible learning to be had there.

Finally, in a smaller company it’s also a lot easier to hang out with your teammates - Quora for instance had organized clubs (poker, badminton etc) across the board that made it really easy to meet people in different teams. At Uber, that’s much harder to do, but you meet an equivalent amount of people within your own team, since teams are much larger at Uber.

**What advice would you give to someone looking to become a Data Scientist (either a career changer or a college student)?**

Data science roles are defined very differently based on the team, company, size, role you’re working on. For instance, even Uber Data Science can vary greatly across teams - for example, I work on the Shared Rides / Matching team, which is mostly Operations Research, which is a field about optimization. And I didn’t even study Operations Research in college. The important thing to understand is that different teams have different scopes. For instance, the pricing team does a lot of machine learning. Some other teams are trying to understand user experience. So having a strong base is really important, because at companies like Uber, there’s many directions you could go in.

In the Data Science industry overall, there’s broadly three tracks:

1. Algorithms (building models, doing ML)
2. Inference (understanding causality)
3. Analytics (building dashboards, writing SQL, reporting metrics, analyzing simple A/Bs)

Most of the Data Science jobs involve Analytics or Inference.

At Quora, they were mostly on the inference side of things. They were trying to understand product opportunities, trends in user behavior, and see if new product features were impactful.

On Uber, on my team at least, I’m more focused on building algorithms.

So in terms of advice: you need to focus on what you’re actually interested in (within the domains listed above). Of course, there’s going to be work that’s a mix of both, but knowing which topics interest you will help you map out and identify which companies you want to work for.

Everything is going to be very team and company specific, so don’t look at titles, but actually look at what the role is, talk to people on the team, and do your research.

Stats theory is also important, but on the job you’re not really going to be actively using theory too much. What really matters is understanding and gaining intuition. For example, I didn’t study a lot of Operations Research in college, but I took a bunch of Machine Learning and Algorithms classes in college which helped me build intuition for how Operations Research works, since the field is about optimization - which is what Machine Learning and Algorithms are about.

The purpose of theory is to build intuition and understand things.

**Hope you guys liked the interview! If you did, feel free to check out more interviews at** [CareerFair](https://www.careerfair.io/reviews/datascientist).

I'm planning on interviewing more data scientists across a wide range of companies - let me know if you have any specific questions you'd like me to ask them :)",t2_qr5uf,I got the chance to interview a Data Scientist at Uber on their Shared Rides Team!,discussion,t3_gtv2c9,0.96,435,Discussion,435,1590941018.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys -&lt;/p&gt;

&lt;p&gt;Had the opportunity to interview a Data Scientist at Uber on their Shared Rides Team. Thought I&amp;#39;d share some of it here, in case you find it helpful :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What do you do &amp;amp; where do you work?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;My name is Divyansh Agarwal and I am a data scientist at Uber in San Francisco. I’m working on  the Shared Rides business, and work on building products that grow the business. Some of my work also involves optimizing the efficiency of Uber’s ride sharing marketplace by improving graph optimization algorithms for rider-driver matching, and evaluating their performance via experimentation and simulations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;When did you first become interested in Data Science?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So, I had an interest in machine learning and predictive analytics before going into university. I wrote about it in my college essays as well.&lt;/p&gt;

&lt;p&gt;But I was also interested in software engineering and fields like security. What really made me truly interested in data science was taking &lt;a href=""http://data8.org/""&gt;Data 8&lt;/a&gt; at UC Berkeley. I really liked the fact that you could use statistics to extract insights from data and provide value - and although I had always been aware of this, I only realized then how powerful statistics could be and how computing facilitates all of this.&lt;/p&gt;

&lt;p&gt;After that, I started doing a bunch of projects, some internships, and got involved in research.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;When applying for jobs, was it hard to choose between going for a software engineering role as opposed to a data science role?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Not really - I was always set on data science once I got into it. I used software engineering more as a backup, because given my CS background it would have been easy to get a software job if I just prepped hard for their interviews.&lt;/p&gt;

&lt;p&gt;It’s actually harder to get a data science job out of undergrad. This is because there’s a general bias towards people with graduate degrees and people with a lot of experience. So you need to have either of both - either you need to have a lot of work experience, or you need to have a PHD.&lt;/p&gt;

&lt;p&gt;So that’s why I built experience through doing projects, research, internships, etc.&lt;/p&gt;

&lt;p&gt;For Data Science, there’s no real standardized process when it comes to interviewing - it varies a lot from company to company (this is in contrast to software engineering where using websites like LeetCode can get you ready for almost all jobs).&lt;/p&gt;

&lt;p&gt;So I had to spend a lot of time prepping for each specific company I interviewed with - at every stage of the process - and this ended up taking a lot of time.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;When applying to Uber, did you have projects in mind you wanted to work on? How much did you know about the company?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After my sophomore year of college, I was invited for this intern open house at Uber. That’s when I met some of the team across rides, security, and eats. I spoke to this guy on the marketplace team and another guy on the maps team, I was really interested in those teams.&lt;/p&gt;

&lt;p&gt;What’s really cool about the marketplace team specifically is that it’s at the intersection of computer science, economics, optimization, statistics, and there’s a lot of hard &amp;amp; interesting problems that can be solved from an algorithmic perspective.&lt;/p&gt;

&lt;p&gt;So after this event I attended, I knew that I wanted to be on the marketplace team at Uber. So during my senior year recruiting, I reached out to someone on the marketplace team, and they were interested in me, so that’s how I started interviewing at Uber.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is your team responsible for and why is this work critical to Uber’s business?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I’m on the Shared Rides team (which is a part of Marketplace Dynamics). The core of building new shared rides products and features come from &lt;a href=""https://marketplace.uber.com/matching""&gt;matching improvements&lt;/a&gt; or UI and experience improvements. So either tweaking these algorithms, designing &amp;amp; analyzing experiments, understanding how users are responding to new product features - these are all very important and central to Uber’s business.&lt;/p&gt;

&lt;p&gt;What are some challenges (both technical and non-technical) your team faces?&lt;/p&gt;

&lt;p&gt;The biggest challenge for our team (and I think this is true for any consumer internet product) is building something that people actually like that meets your business objectives. Because everytime you change something with the product, one metric might become worse and the other might become better.&lt;/p&gt;

&lt;p&gt;It’s also really hard to figure out what users really want and what they really like. This involves a lot of UX research, as well as experimentation. This stuff is really challenging. Here’s another example:&lt;/p&gt;

&lt;p&gt;So, there’s an optimization &amp;amp; efficiency side of Shared Rides - there’s always a tension between the two. If I make something more optimal, it might hurt the experience. If I make the experience better, we have to give some leeway on the optimization side of things. So that’s this underlying technical tension that’s always there.&lt;/p&gt;

&lt;p&gt;On the product side, as I had already mentioned, it just comes down to building something users really want. So we have designers and UX researchers who are embedded within shared rides, as well as marketing folks, and I have to work cross functionally with these guys to problem solve on a daily basis.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;You interned at Quora before Uber - can you tell me differences between both companies and how that affected your work?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So Quora was a very small company - there were only 230 people or so when I was working there (two years ago). There were fewer layers of management, it was easier to know people across the company - for example I even got the chance to speak with the CEO on a couple of occasions. There was also less bureaucracy I guess.&lt;/p&gt;

&lt;p&gt;At Uber, since it’s a bigger company, sometimes if you want to build something you might need to get buy-in from another team, there’s more bureaucracy, there’s more layers between you and executive management.&lt;/p&gt;

&lt;p&gt;Like at Quora, I knew the Head of Data Science very well, but at Uber I can’t imagine doing that currently (given I’ve just begun my career).&lt;/p&gt;

&lt;p&gt;At a bigger company like Uber though, you’re working on projects that have bigger scope, bigger impact on the world, and you work with a lot more people. I’m also more specialized within my role here at Uber - at Quora I could have had more flexibility in terms of what I wanted to work on. At Uber, I’m on a very specific team, in a very specific role, working on a very specific part of the product. This has significant advantages: We’re working on specialized problems that are really challenging, and I’m surrounded by people who have been thinking deeply about these problems for a while are are super passionate about these problems. There’s some incredible learning to be had there.&lt;/p&gt;

&lt;p&gt;Finally, in a smaller company it’s also a lot easier to hang out with your teammates - Quora for instance had organized clubs (poker, badminton etc) across the board that made it really easy to meet people in different teams. At Uber, that’s much harder to do, but you meet an equivalent amount of people within your own team, since teams are much larger at Uber.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What advice would you give to someone looking to become a Data Scientist (either a career changer or a college student)?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Data science roles are defined very differently based on the team, company, size, role you’re working on. For instance, even Uber Data Science can vary greatly across teams - for example, I work on the Shared Rides / Matching team, which is mostly Operations Research, which is a field about optimization. And I didn’t even study Operations Research in college. The important thing to understand is that different teams have different scopes. For instance, the pricing team does a lot of machine learning. Some other teams are trying to understand user experience. So having a strong base is really important, because at companies like Uber, there’s many directions you could go in.&lt;/p&gt;

&lt;p&gt;In the Data Science industry overall, there’s broadly three tracks:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Algorithms (building models, doing ML)&lt;/li&gt;
&lt;li&gt;Inference (understanding causality)&lt;/li&gt;
&lt;li&gt;Analytics (building dashboards, writing SQL, reporting metrics, analyzing simple A/Bs)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Most of the Data Science jobs involve Analytics or Inference.&lt;/p&gt;

&lt;p&gt;At Quora, they were mostly on the inference side of things. They were trying to understand product opportunities, trends in user behavior, and see if new product features were impactful.&lt;/p&gt;

&lt;p&gt;On Uber, on my team at least, I’m more focused on building algorithms.&lt;/p&gt;

&lt;p&gt;So in terms of advice: you need to focus on what you’re actually interested in (within the domains listed above). Of course, there’s going to be work that’s a mix of both, but knowing which topics interest you will help you map out and identify which companies you want to work for.&lt;/p&gt;

&lt;p&gt;Everything is going to be very team and company specific, so don’t look at titles, but actually look at what the role is, talk to people on the team, and do your research.&lt;/p&gt;

&lt;p&gt;Stats theory is also important, but on the job you’re not really going to be actively using theory too much. What really matters is understanding and gaining intuition. For example, I didn’t study a lot of Operations Research in college, but I took a bunch of Machine Learning and Algorithms classes in college which helped me build intuition for how Operations Research works, since the field is about optimization - which is what Machine Learning and Algorithms are about.&lt;/p&gt;

&lt;p&gt;The purpose of theory is to build intuition and understand things.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hope you guys liked the interview! If you did, feel free to check out more interviews at&lt;/strong&gt; &lt;a href=""https://www.careerfair.io/reviews/datascientist""&gt;CareerFair&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m planning on interviewing more data scientists across a wide range of companies - let me know if you have any specific questions you&amp;#39;d like me to ask them :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gtv2c9,ibsurvivors,40,/r/datascience/comments/gtv2c9/i_got_the_chance_to_interview_a_data_scientist_at/,https://www.reddit.com/r/datascience/comments/gtv2c9/i_got_the_chance_to_interview_a_data_scientist_at/,1590912218.0
r/datascience,"I was thinking if there is a supply/demand enough for such a platform (where you can buy/sell) to exist. There is a ton of demand, but are there enough people willing to supply?  


Here the data providers can be organizations, or the people generating data themselves.",t2_1bfw6r93,Is there a website/platform where you can sell/buy datasets for ML?,discussion,t3_gu9lym,0.76,6,Discussion,6,1590997171.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was thinking if there is a supply/demand enough for such a platform (where you can buy/sell) to exist. There is a ton of demand, but are there enough people willing to supply?  &lt;/p&gt;

&lt;p&gt;Here the data providers can be organizations, or the people generating data themselves.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gu9lym,vasa_develop,8,/r/datascience/comments/gu9lym/is_there_a_websiteplatform_where_you_can_sellbuy/,https://www.reddit.com/r/datascience/comments/gu9lym/is_there_a_websiteplatform_where_you_can_sellbuy/,1590968371.0
r/datascience,"Dear data-scientists,

**How do you guys prevent non-technical errors and bugs ?**

&amp;#x200B;

I work as a data-scientist in a junior position. My typical workflow consist of the following steps :

 1) the client gives us a problem 

2) think about proper methodology 

3) gather the data necessary to solve the problem 

4) apply some statistical procedures to solve the problem (generally a model) 

5) build a report to send to the client (this report must follow the company's format and standards).

One aspect where I notice I am having difficulties or improvement are in what I will call the non-technical or non-statistical aspects of the workflow above. That is suppose you gather the right data and think about the proper methodology to solve the problem, but then how can I prevent errors on the coding and reporting, for instance:

\- you have the right methodology, but when you are coding the model you assign a wrong variable in the code in some step and then the results are not valid ( for instance you have x\_train and x\_test and you mistakenly do m = x\_test / 2 instead of m = x\_train / 2).

\- on the reporting stage, you exported the wrong results.

These are just examples.

Then you send your report and under scrutiny from your managers or revising things to answer additional questions you find this errors. Then it looks unprofessional to say that the initial results were wrong and you will have to update it. It may not inspire much confidence in your results in the future.

It has been hard for me to find ways to improve in this aspect because these types of errors are hard to predict. When you are coding you are already doing what you think it is correct. Given the time frames we have, it is also unfeasible to double check every single line of code. Also, the problems are generally very diverse in nature, so it is not like you can just adopt an automated or semi-automated methodology that you can work upon and improve, many things you have to build from scratch every time you receive a new project.

&amp;#x200B;

**How do you guys prevent this type of errors ?**

&amp;#x200B;

Thanks in advance.",t2_1fyghm,How to avoid non-technical errors and bugs ?,discussion,t3_gufkqn,0.67,1,Discussion,1,1591022842.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Dear data-scientists,&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How do you guys prevent non-technical errors and bugs ?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I work as a data-scientist in a junior position. My typical workflow consist of the following steps :&lt;/p&gt;

&lt;p&gt;1) the client gives us a problem &lt;/p&gt;

&lt;p&gt;2) think about proper methodology &lt;/p&gt;

&lt;p&gt;3) gather the data necessary to solve the problem &lt;/p&gt;

&lt;p&gt;4) apply some statistical procedures to solve the problem (generally a model) &lt;/p&gt;

&lt;p&gt;5) build a report to send to the client (this report must follow the company&amp;#39;s format and standards).&lt;/p&gt;

&lt;p&gt;One aspect where I notice I am having difficulties or improvement are in what I will call the non-technical or non-statistical aspects of the workflow above. That is suppose you gather the right data and think about the proper methodology to solve the problem, but then how can I prevent errors on the coding and reporting, for instance:&lt;/p&gt;

&lt;p&gt;- you have the right methodology, but when you are coding the model you assign a wrong variable in the code in some step and then the results are not valid ( for instance you have x_train and x_test and you mistakenly do m = x_test / 2 instead of m = x_train / 2).&lt;/p&gt;

&lt;p&gt;- on the reporting stage, you exported the wrong results.&lt;/p&gt;

&lt;p&gt;These are just examples.&lt;/p&gt;

&lt;p&gt;Then you send your report and under scrutiny from your managers or revising things to answer additional questions you find this errors. Then it looks unprofessional to say that the initial results were wrong and you will have to update it. It may not inspire much confidence in your results in the future.&lt;/p&gt;

&lt;p&gt;It has been hard for me to find ways to improve in this aspect because these types of errors are hard to predict. When you are coding you are already doing what you think it is correct. Given the time frames we have, it is also unfeasible to double check every single line of code. Also, the problems are generally very diverse in nature, so it is not like you can just adopt an automated or semi-automated methodology that you can work upon and improve, many things you have to build from scratch every time you receive a new project.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How do you guys prevent this type of errors ?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gufkqn,nothingveryserious,8,/r/datascience/comments/gufkqn/how_to_avoid_nontechnical_errors_and_bugs/,https://www.reddit.com/r/datascience/comments/gufkqn/how_to_avoid_nontechnical_errors_and_bugs/,1590994042.0
r/datascience,"I am trying to share the google colab document (that contains my data-visualization project) with friends so they can run the code but not actually see the code, because I don't want them to copy the code. How do I do this?",t2_5tyhpule,Does anybody know how to share the google colab document so people can run the notebook but cannot see the actual code?,education,t3_guafw0,0.54,1,Education,1,1591000197.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to share the google colab document (that contains my data-visualization project) with friends so they can run the code but not actually see the code, because I don&amp;#39;t want them to copy the code. How do I do this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",guafw0,RohanJ2006,8,/r/datascience/comments/guafw0/does_anybody_know_how_to_share_the_google_colab/,https://www.reddit.com/r/datascience/comments/guafw0/does_anybody_know_how_to_share_the_google_colab/,1590971397.0
r/datascience,"Hey there, 

Anyone know of a way to get a free limited version of Tableau for personal use and self-study?",t2_p484a,Tableau software,tooling,t3_gu2zys,0.65,5,Tooling,5,1590974642.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there, &lt;/p&gt;

&lt;p&gt;Anyone know of a way to get a free limited version of Tableau for personal use and self-study?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gu2zys,JaeBreezy,10,/r/datascience/comments/gu2zys/tableau_software/,https://www.reddit.com/r/datascience/comments/gu2zys/tableau_software/,1590945842.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 31 May 2020 - 07 Jun 2020,,t3_gtxvnc,1.0,9,Discussion,9,1590955231.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gtxvnc,datascience-bot,121,/r/datascience/comments/gtxvnc/weekly_entering_transitioning_thread_31_may_2020/,https://www.reddit.com/r/datascience/comments/gtxvnc/weekly_entering_transitioning_thread_31_may_2020/,1590926431.0
r/datascience,"I am currently a Lead Data Scientist at a large defense contractor, primarily applying data science solutions to business-facing homerooms. Think supply chain, business management, etc. 

A few highlights about me...

* Very strong SQL skills, and I have done a large amount of data ETL
* Moderately strong Python skills
* Top 1% on Stack Overflow (I answer a lot of SQL and Python questions, also ask some)
* Nearly 10 internal Trade Secrets awarded to products I have built
* B.S. in Information Technology, I am graduating in August with my M.S. in Computer Science w/ an AI concentration from Hopkins
* About 3.5 years of work experience out of undergrad, two internships at Defense contractors before that
* Also have security related certifications (Security+)
* I mentor both the cybersecurity and AI clubs for my high school (along with a few other alumni)

I was contacted on LinkedIn by a recruiter. I have never really had an intention of working at FAANG organizations. From what I have read both on Reddit and elsewhere, the ""work 7 days a week"" and high pressure culture doesn't fit what I am really looking for. However, the recruiter mentioned almost 60% more than I make now, so that was enticing.

I feel technically sound -- but I definitely don't know how succinctly I could give an answer to some technical questions. I've looked at:

 [https://towardsdatascience.com/the-amazon-data-scientist-interview-93ba7195e4c9](https://towardsdatascience.com/the-amazon-data-scientist-interview-93ba7195e4c9) 

 [https://towardsdatascience.com/amazon-data-scientist-interview-practice-problems-15b9b86e86c6](https://towardsdatascience.com/amazon-data-scientist-interview-practice-problems-15b9b86e86c6) 

 [https://www.reddit.com/r/datascience/comments/dn5uxq/amazon\_data\_scienceml\_interview\_questions/](https://www.reddit.com/r/datascience/comments/dn5uxq/amazon_data_scienceml_interview_questions/) 

Are these good resources? Should I be prepared to write an algorithm from scratch? Would it be easier things, like kmeans, or am I expected to code backprop from scratch? I've done these things from scratch before, but I used reference material... I am nervous about not being able to demonstrate my skills because of being too focused on providing these overly technical answers.

Any advice is appreciated!

Edit: Wow! This blew up. I certainly was not expecting this much feedback, and certainly not so much kindness. As a somewhat new graduate ( &lt; 5 years) who is still figuring out their own self confidence, getting to share a little bit of my background and my fears moving forward with you all has been cathartic, not to mention the sheer volume of incredibly useful feedback I have gotten. I am going to think some thing through tomorrow, and I'll be sure to update this post. If I go along with the interview, which I think i will based on this feedback, ill be sure to create an update post to let you all know what happened!",t2_c5ky8gr,Interview at Amazon for Data Scientist Role -- how to prepare?,,t3_gthgfw,0.95,284,Job Search,284,1590886663.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently a Lead Data Scientist at a large defense contractor, primarily applying data science solutions to business-facing homerooms. Think supply chain, business management, etc. &lt;/p&gt;

&lt;p&gt;A few highlights about me...&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Very strong SQL skills, and I have done a large amount of data ETL&lt;/li&gt;
&lt;li&gt;Moderately strong Python skills&lt;/li&gt;
&lt;li&gt;Top 1% on Stack Overflow (I answer a lot of SQL and Python questions, also ask some)&lt;/li&gt;
&lt;li&gt;Nearly 10 internal Trade Secrets awarded to products I have built&lt;/li&gt;
&lt;li&gt;B.S. in Information Technology, I am graduating in August with my M.S. in Computer Science w/ an AI concentration from Hopkins&lt;/li&gt;
&lt;li&gt;About 3.5 years of work experience out of undergrad, two internships at Defense contractors before that&lt;/li&gt;
&lt;li&gt;Also have security related certifications (Security+)&lt;/li&gt;
&lt;li&gt;I mentor both the cybersecurity and AI clubs for my high school (along with a few other alumni)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I was contacted on LinkedIn by a recruiter. I have never really had an intention of working at FAANG organizations. From what I have read both on Reddit and elsewhere, the &amp;quot;work 7 days a week&amp;quot; and high pressure culture doesn&amp;#39;t fit what I am really looking for. However, the recruiter mentioned almost 60% more than I make now, so that was enticing.&lt;/p&gt;

&lt;p&gt;I feel technically sound -- but I definitely don&amp;#39;t know how succinctly I could give an answer to some technical questions. I&amp;#39;ve looked at:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://towardsdatascience.com/the-amazon-data-scientist-interview-93ba7195e4c9""&gt;https://towardsdatascience.com/the-amazon-data-scientist-interview-93ba7195e4c9&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://towardsdatascience.com/amazon-data-scientist-interview-practice-problems-15b9b86e86c6""&gt;https://towardsdatascience.com/amazon-data-scientist-interview-practice-problems-15b9b86e86c6&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.reddit.com/r/datascience/comments/dn5uxq/amazon_data_scienceml_interview_questions/""&gt;https://www.reddit.com/r/datascience/comments/dn5uxq/amazon_data_scienceml_interview_questions/&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Are these good resources? Should I be prepared to write an algorithm from scratch? Would it be easier things, like kmeans, or am I expected to code backprop from scratch? I&amp;#39;ve done these things from scratch before, but I used reference material... I am nervous about not being able to demonstrate my skills because of being too focused on providing these overly technical answers.&lt;/p&gt;

&lt;p&gt;Any advice is appreciated!&lt;/p&gt;

&lt;p&gt;Edit: Wow! This blew up. I certainly was not expecting this much feedback, and certainly not so much kindness. As a somewhat new graduate ( &amp;lt; 5 years) who is still figuring out their own self confidence, getting to share a little bit of my background and my fears moving forward with you all has been cathartic, not to mention the sheer volume of incredibly useful feedback I have gotten. I am going to think some thing through tomorrow, and I&amp;#39;ll be sure to update this post. If I go along with the interview, which I think i will based on this feedback, ill be sure to create an update post to let you all know what happened!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gthgfw,bm0r3son,120,/r/datascience/comments/gthgfw/interview_at_amazon_for_data_scientist_role_how/,https://www.reddit.com/r/datascience/comments/gthgfw/interview_at_amazon_for_data_scientist_role_how/,1590857863.0
r/datascience,"This post is not meant to be a statement of political belief or discussion about current events, necessarily. That being said, current events have led me to wonder: what can the data science community do to identify instances of systemic racial bias? What if you could apply the spirit of a fault detection model to a sociological/demographic/economic-related dataset?

Anyone aware of any datasets (or even bounds for what would constitute a useful dataset) with this goal in mind?

I'm not asserting that you can just throw code, models, and data at a deeply rooted social issue and expect it to magically resolve - just that maybe there are some opportunities here.",t2_48nf7,What would be some good datasets to explore for identifying systemic/institutionalized racism?,projects,t3_gu99p1,0.43,0,Projects,0,1590995912.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This post is not meant to be a statement of political belief or discussion about current events, necessarily. That being said, current events have led me to wonder: what can the data science community do to identify instances of systemic racial bias? What if you could apply the spirit of a fault detection model to a sociological/demographic/economic-related dataset?&lt;/p&gt;

&lt;p&gt;Anyone aware of any datasets (or even bounds for what would constitute a useful dataset) with this goal in mind?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m not asserting that you can just throw code, models, and data at a deeply rooted social issue and expect it to magically resolve - just that maybe there are some opportunities here.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gu99p1,sjksjksjk,5,/r/datascience/comments/gu99p1/what_would_be_some_good_datasets_to_explore_for/,https://www.reddit.com/r/datascience/comments/gu99p1/what_would_be_some_good_datasets_to_explore_for/,1590967112.0
r/datascience,"There are a huge number of options and architectures available for AWS. Although the individual instance types and services are described well by the AWS informational resources, I'm having a hard time finding good resources on how to actually combine them to build a reliable and cost-effective infrastructure for a given project. Are there any good resources for learning about AWS project scoping and project management?",t2_dqh9j,What are good resources to learn about AWS project scoping and management?,discussion,t3_gu1jdh,1.0,3,Discussion,3,1590969555.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;There are a huge number of options and architectures available for AWS. Although the individual instance types and services are described well by the AWS informational resources, I&amp;#39;m having a hard time finding good resources on how to actually combine them to build a reliable and cost-effective infrastructure for a given project. Are there any good resources for learning about AWS project scoping and project management?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gu1jdh,Stewthulhu,0,/r/datascience/comments/gu1jdh/what_are_good_resources_to_learn_about_aws/,https://www.reddit.com/r/datascience/comments/gu1jdh/what_are_good_resources_to_learn_about_aws/,1590940755.0
r/datascience,"Full disclosure: I used to like Medium, but nowadays I think not all of their content is necessarily very high quality (or maybe it's just me who matured in the past two years). I'd love to find something similar like Nature is in the natural sciences, although I realize DS is probably too small of a field at the moment to produce a comparably popular *and* high quality journal.",t2_kd4bj,What Stats/IT journals or magazines do you regularly read?,education,t3_gu090a,0.71,3,Education,3,1590964796.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Full disclosure: I used to like Medium, but nowadays I think not all of their content is necessarily very high quality (or maybe it&amp;#39;s just me who matured in the past two years). I&amp;#39;d love to find something similar like Nature is in the natural sciences, although I realize DS is probably too small of a field at the moment to produce a comparably popular &lt;em&gt;and&lt;/em&gt; high quality journal.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gu090a,malasi,5,/r/datascience/comments/gu090a/what_statsit_journals_or_magazines_do_you/,https://www.reddit.com/r/datascience/comments/gu090a/what_statsit_journals_or_magazines_do_you/,1590935996.0
r/datascience,"I'm really interested in getting an idea of who is a part of this community and where they are right now.

[View Poll](https://www.reddit.com/poll/gu1iqk)",t2_zohps,Who are you?,discussion,t3_gu1iqk,0.57,2,Discussion,2,1590969493.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m really interested in getting an idea of who is a part of this community and where they are right now.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.reddit.com/poll/gu1iqk""&gt;View Poll&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gu1iqk,RyBread7,8,/r/datascience/comments/gu1iqk/who_are_you/,https://www.reddit.com/r/datascience/comments/gu1iqk/who_are_you/,1590940693.0
r/datascience,"I am working on a certain prediction based project. I now have 3-4 models and around 2-3 varients of each models (different hyperparameters, minor changes in architecture etc). Currently I am making a seperate folder for each model, sub folder for each of it's variant and maintaining a report (basically a summary table) of accuracy of models and other meta details. I realised that this approach is not scalable. What system/approach do you use to tackle this and reduce your stress in maintaining model versions ?",t2_3roejhk5,Industry working professionals: What do you use to maintain different versions of models ?,discussion,t3_gtt0sq,0.91,8,Discussion,8,1590930253.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working on a certain prediction based project. I now have 3-4 models and around 2-3 varients of each models (different hyperparameters, minor changes in architecture etc). Currently I am making a seperate folder for each model, sub folder for each of it&amp;#39;s variant and maintaining a report (basically a summary table) of accuracy of models and other meta details. I realised that this approach is not scalable. What system/approach do you use to tackle this and reduce your stress in maintaining model versions ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gtt0sq,kkziga,9,/r/datascience/comments/gtt0sq/industry_working_professionals_what_do_you_use_to/,https://www.reddit.com/r/datascience/comments/gtt0sq/industry_working_professionals_what_do_you_use_to/,1590901453.0
r/datascience,"I'm putting together a data set of \~100k randomly played games of a two-player board game. The games are stored as JSON files with each board state and the turns that were made throughout, as well as which player won the game. 

So far I've split the files in to two folders (one for wins by the first player, other folder for wins by the second player), and written a [README.md](https://README.md) describing the structure of the JSON files and info on how the games were generated.

What are some things you would wish to see included in a data set like this that I might be overlooking?",t2_ai7ba,What do you look for/wish to see in a public data set?,discussion,t3_gu0wp1,1.0,1,Discussion,1,1590967271.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m putting together a data set of ~100k randomly played games of a two-player board game. The games are stored as JSON files with each board state and the turns that were made throughout, as well as which player won the game. &lt;/p&gt;

&lt;p&gt;So far I&amp;#39;ve split the files in to two folders (one for wins by the first player, other folder for wins by the second player), and written a &lt;a href=""https://README.md""&gt;README.md&lt;/a&gt; describing the structure of the JSON files and info on how the games were generated.&lt;/p&gt;

&lt;p&gt;What are some things you would wish to see included in a data set like this that I might be overlooking?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gu0wp1,JayWalkerC,0,/r/datascience/comments/gu0wp1/what_do_you_look_forwish_to_see_in_a_public_data/,https://www.reddit.com/r/datascience/comments/gu0wp1/what_do_you_look_forwish_to_see_in_a_public_data/,1590938471.0
r/datascience,,t2_de5yq,Any data science centered Slack workspaces in English you recommend?,meta,t3_gtzaeo,0.5,0,Meta,0,1590961618.0,,gtzaeo,Optimesh,0,/r/datascience/comments/gtzaeo/any_data_science_centered_slack_workspaces_in/,https://www.reddit.com/r/datascience/comments/gtzaeo/any_data_science_centered_slack_workspaces_in/,1590932818.0
r/datascience,"This is more to the folks that are not necessarily in a DS role, but do DS in their day-to-day tasks; care to share experiences, stories or even anecdotes seeing how DS helped you with your career?

For me, I was interested in Game theory (and wanted to be a bit more ""politically"" involved in the company that I was working with e.g. showing my ability to be more precise in my articulation, and get upper management approvals); I developed a somewhat simple descriptive model, a small dashboard and analytics during a critical phase of the company and did a presentation; to this day I was known to be ""unique"" in my abilities to articulate facts, which got the attention of my higher ups!

How about you guys?",t2_3z6gqvrh,How DS has helped you with your career?,discussion,t3_gtye56,0.57,1,Discussion,1,1590957621.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is more to the folks that are not necessarily in a DS role, but do DS in their day-to-day tasks; care to share experiences, stories or even anecdotes seeing how DS helped you with your career?&lt;/p&gt;

&lt;p&gt;For me, I was interested in Game theory (and wanted to be a bit more &amp;quot;politically&amp;quot; involved in the company that I was working with e.g. showing my ability to be more precise in my articulation, and get upper management approvals); I developed a somewhat simple descriptive model, a small dashboard and analytics during a critical phase of the company and did a presentation; to this day I was known to be &amp;quot;unique&amp;quot; in my abilities to articulate facts, which got the attention of my higher ups!&lt;/p&gt;

&lt;p&gt;How about you guys?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gtye56,runnersgo,0,/r/datascience/comments/gtye56/how_ds_has_helped_you_with_your_career/,https://www.reddit.com/r/datascience/comments/gtye56/how_ds_has_helped_you_with_your_career/,1590928821.0
r/datascience,"Interested in learning more about the whole data ecosystem and wondering if anyone has book recommendations on: data warehousing, data engineering &amp; data management.",t2_pzyc3,Data management books for data scientists?,discussion,t3_gtbase,0.98,148,Discussion,148,1590858486.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Interested in learning more about the whole data ecosystem and wondering if anyone has book recommendations on: data warehousing, data engineering &amp;amp; data management.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gtbase,stigmatic666,18,/r/datascience/comments/gtbase/data_management_books_for_data_scientists/,https://www.reddit.com/r/datascience/comments/gtbase/data_management_books_for_data_scientists/,1590829686.0
r/datascience,I have to build a dashboard for one of my work projects. I have choosen dash as my choice. I was wondering if there are any themes/templates that I can use as the base and build on top of it. THe main reason is that I am not that good with CSS and this can help me design something that has good look and feel.,t2_12pez0,Themes/Templates for plotly dash,discussion,t3_gttm8e,1.0,2,Discussion,2,1590933261.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have to build a dashboard for one of my work projects. I have choosen dash as my choice. I was wondering if there are any themes/templates that I can use as the base and build on top of it. THe main reason is that I am not that good with CSS and this can help me design something that has good look and feel.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gttm8e,aryancodify,1,/r/datascience/comments/gttm8e/themestemplates_for_plotly_dash/,https://www.reddit.com/r/datascience/comments/gttm8e/themestemplates_for_plotly_dash/,1590904461.0
r/datascience,Working on a project where I'm doing some curve fitting. Wondering if there's an easy way to group many separate results based on similarity? Either on a visual plotting of the curves themselves or on the underlying values (list of 100 numbers). Working in python but also know R if that's a better fit for this task.,t2_4uy7nsid,Clustering analysis for curves?,projects,t3_gtqxbu,0.72,3,Projects,3,1590920682.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Working on a project where I&amp;#39;m doing some curve fitting. Wondering if there&amp;#39;s an easy way to group many separate results based on similarity? Either on a visual plotting of the curves themselves or on the underlying values (list of 100 numbers). Working in python but also know R if that&amp;#39;s a better fit for this task.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gtqxbu,30minute_un,14,/r/datascience/comments/gtqxbu/clustering_analysis_for_curves/,https://www.reddit.com/r/datascience/comments/gtqxbu/clustering_analysis_for_curves/,1590891882.0
r/datascience,"I've been reading about what the future will hold for Data science, and some of the stuff is bleak. I keep hearing that AI will replace the need for real data science work and that data engineers are more important. I wanted to see what you guys think.",t2_ioig6,Future of Data science?,discussion,t3_gtrro4,0.62,3,Discussion,3,1590924445.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been reading about what the future will hold for Data science, and some of the stuff is bleak. I keep hearing that AI will replace the need for real data science work and that data engineers are more important. I wanted to see what you guys think.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gtrro4,Rocktrees,11,/r/datascience/comments/gtrro4/future_of_data_science/,https://www.reddit.com/r/datascience/comments/gtrro4/future_of_data_science/,1590895645.0
r/datascience,"I feel my situation is a little unique. Work as the only data scientist for my company and pretty much any recommendation I put forward goes through without any push back from management. There are no conflicts etc as I'm the only data scientist and my manager is really chill so no tight deadlines and issues with management either.

My issue is that now that I'm looking to move to another company, the interviews require you to answer behavioral questions but with a technical aspect to it. I just don't know how to answer conflict or deadline or last minute change questions in a technical manner because I've never faced such situations at my current job. I don't know if i would be answering incorrectly in an over simplistic manner would be too simple of an example for the tech recruiter.

At this point i sort of have to come up with fake scenarios around my work to make it seem like there were conflicts and tight deadlines

Does anyone have any suggestions on how to frame my answers or create such scenarios that seem behavioral based but also technically challenging. Like what exactly do I talk about.. pvalues?? Feature selection?",t2_1xfhmho7,How do you answer behavioral based tech questions if you work in a calm job environment?,,t3_gtgcj4,0.82,7,Job Search,7,1590882717.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I feel my situation is a little unique. Work as the only data scientist for my company and pretty much any recommendation I put forward goes through without any push back from management. There are no conflicts etc as I&amp;#39;m the only data scientist and my manager is really chill so no tight deadlines and issues with management either.&lt;/p&gt;

&lt;p&gt;My issue is that now that I&amp;#39;m looking to move to another company, the interviews require you to answer behavioral questions but with a technical aspect to it. I just don&amp;#39;t know how to answer conflict or deadline or last minute change questions in a technical manner because I&amp;#39;ve never faced such situations at my current job. I don&amp;#39;t know if i would be answering incorrectly in an over simplistic manner would be too simple of an example for the tech recruiter.&lt;/p&gt;

&lt;p&gt;At this point i sort of have to come up with fake scenarios around my work to make it seem like there were conflicts and tight deadlines&lt;/p&gt;

&lt;p&gt;Does anyone have any suggestions on how to frame my answers or create such scenarios that seem behavioral based but also technically challenging. Like what exactly do I talk about.. pvalues?? Feature selection?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gtgcj4,dt25to,14,/r/datascience/comments/gtgcj4/how_do_you_answer_behavioral_based_tech_questions/,https://www.reddit.com/r/datascience/comments/gtgcj4/how_do_you_answer_behavioral_based_tech_questions/,1590853917.0
r/datascience,"Doing a data science boot camp thing rn ( before graduate school) and I’m finding the pace a bit fast. Kinda normal for a boot camp to be fast paced but it makes me wonder if  the actual work actually go at this pace. I like having room to breathe and lots and lots of time to really mull over a difficult problem, like an academic might have. I always enjoyed that aspect of university. Does your  average data scientist get that kinda time to devote to just thinking.",t2_47oivru,How fast paced is data science work?,career,t3_gt3j7l,0.96,108,Career,108,1590823052.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Doing a data science boot camp thing rn ( before graduate school) and I’m finding the pace a bit fast. Kinda normal for a boot camp to be fast paced but it makes me wonder if  the actual work actually go at this pace. I like having room to breathe and lots and lots of time to really mull over a difficult problem, like an academic might have. I always enjoyed that aspect of university. Does your  average data scientist get that kinda time to devote to just thinking.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gt3j7l,Greenface1998,39,/r/datascience/comments/gt3j7l/how_fast_paced_is_data_science_work/,https://www.reddit.com/r/datascience/comments/gt3j7l/how_fast_paced_is_data_science_work/,1590794252.0
r/datascience,"As we know, EDA (Exploratory Data Analysis) is a very common procedure in the field. We use it mainly to find inconsistencies in the data, to uncover simple patterns that could alter our perceptions of what we are dealing with and to build insightful visualizations. I think we can all agree how this type of information can be critical. What I would like to do here, and I hope you bear with me, is to question what seems to me a overly optimistic application of this technique.

So, a little context. I've been working on a small consultant startup that leverage data science techniques to serve our costumers. As you can probably guess, most of our services involve helping our clients make sense of their data and extract useful information that can maximize their profits. 

In the project I'm in, for 3 months we have been doing EDA and communicating our results through Power Point presentations. Although sometimes we could find something that was potentially interesting, this experience left me questioning the value of EDA when applied in isolation. 

To explicit my argument, let's go through an example: suppose I have a database with 20 variables and my goal is to find ""something interesting"". What we usually do is trying to find correlations between these variables (be it in form of graphs of statistical tests). Suppose that I find a positive correlation between X and Y, though. What is this really saying to me? How is this accounting for confounding variables and how much variance is it capturing? My bosses don't seem to me very concerned with these questions and usually think the finding of a correlation is already an insightful thing to communicate. 

I have been trying to argument with them that no analysis could be detached from previsibility. If this variable is correlated with the outcome, but it isn't helping to predict it, then why are we so focused on it? My concerns are usually met with the same answers: ""it is important to visualize what is happening"", ""we are still exploring our data"". 

This makes me think that my approach (predictability in the first place) is kind of unusual in the field? It appears to me that EDA has became a branch of data science that is not connecting very well with everything and is becoming embedded in some other kind of rules? 

I would love to hear your opinions about it.",t2_h7p3jaf,EDA revisited,discussion,t3_gtjczf,0.6,1,Discussion,1,1590892973.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As we know, EDA (Exploratory Data Analysis) is a very common procedure in the field. We use it mainly to find inconsistencies in the data, to uncover simple patterns that could alter our perceptions of what we are dealing with and to build insightful visualizations. I think we can all agree how this type of information can be critical. What I would like to do here, and I hope you bear with me, is to question what seems to me a overly optimistic application of this technique.&lt;/p&gt;

&lt;p&gt;So, a little context. I&amp;#39;ve been working on a small consultant startup that leverage data science techniques to serve our costumers. As you can probably guess, most of our services involve helping our clients make sense of their data and extract useful information that can maximize their profits. &lt;/p&gt;

&lt;p&gt;In the project I&amp;#39;m in, for 3 months we have been doing EDA and communicating our results through Power Point presentations. Although sometimes we could find something that was potentially interesting, this experience left me questioning the value of EDA when applied in isolation. &lt;/p&gt;

&lt;p&gt;To explicit my argument, let&amp;#39;s go through an example: suppose I have a database with 20 variables and my goal is to find &amp;quot;something interesting&amp;quot;. What we usually do is trying to find correlations between these variables (be it in form of graphs of statistical tests). Suppose that I find a positive correlation between X and Y, though. What is this really saying to me? How is this accounting for confounding variables and how much variance is it capturing? My bosses don&amp;#39;t seem to me very concerned with these questions and usually think the finding of a correlation is already an insightful thing to communicate. &lt;/p&gt;

&lt;p&gt;I have been trying to argument with them that no analysis could be detached from previsibility. If this variable is correlated with the outcome, but it isn&amp;#39;t helping to predict it, then why are we so focused on it? My concerns are usually met with the same answers: &amp;quot;it is important to visualize what is happening&amp;quot;, &amp;quot;we are still exploring our data&amp;quot;. &lt;/p&gt;

&lt;p&gt;This makes me think that my approach (predictability in the first place) is kind of unusual in the field? It appears to me that EDA has became a branch of data science that is not connecting very well with everything and is becoming embedded in some other kind of rules? &lt;/p&gt;

&lt;p&gt;I would love to hear your opinions about it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gtjczf,kreuzguy,4,/r/datascience/comments/gtjczf/eda_revisited/,https://www.reddit.com/r/datascience/comments/gtjczf/eda_revisited/,1590864173.0
r/datascience,"I work as an Analytics Manager and normally I don't really share with my colleagues the in depth details of my work because nobody is technical. They just know I use SQL and Python to spit out a report and that's all they really understand.

Recently I had an opportunity to do something interesting where I had a very skewed data set and was asked to make sense of it. I thought applying a log transformation to normalize the data as the distribution was extremely skewed and thought it would make the data easier to interpret and I was happy with the results.

My colleagues wanted to know how I arrived at my conclusion for my recommendation so I walked them through the process. I provided a high level overview, but they really wanted to get into the nitty gritty of exactly HOW I got to where I got. Again, I normally don't like to do this because they tend ask very detailed questions like ""Can you explain exactly how this works so I can understand?"" and it gets tough to explain certain things (e.g., I would say something like ""I got this raw data from the API"" but then it's followed up by a question like ""What is an API and why didn't you just use the vendor's dashboard? Why doesn't the vendor's interface provide the data? Why do you have to go through this step?"").

Well anyway I was explaining my logic and really tip toed around the stats by really trying to say essentially that I applied some logic that would more even distribute the data. I stupidly said the word ""log"" and it was over. Their faces froze for a good 10 seconds before someone spoke.

""I'm sorry..but what? What is log? Why do you need this log? I'm really confused. How am I suppose to explain this to the SVP? Can you just change it so you're indexing off the median or mean? This doesn't make any sense.""

I'm dead.

So guys, how do you avoid getting away with having to explain things by  not using technical jargon? I mean like I said, I normally just show people the output of my report and I don't get too many in depth questions about it, but when people really pry, it gets tough. I don't know how to avoid saying ""I ran a regression model"" because it freaks people out and they get upset because they don't understand it and want me to do something that is easier to interpret. It's already frustrating that they think I'm over complicating things by using Python instead of Excel, but I can at least tell them certain things like Excel can't handle 1+ million rows and they can understand that.

EDIT: Hey all, appreciate all you feedback, both positive and negative. I think it's all constructive. There's a lot of replies in this thread so it's hard to answer everyone's questions. Some of you ask the same things and I do answer them, but you might have to dig through the comments to find it. In any case, let me post some frequently asked ones:

1) Did you use graphs and visuals?

Answer: I did. I actually stayed away from using the word log at first and just showed them a histogram of what the data looked like before the log transform and then after the log transform. What followed up was ""How did you do this? What did you use to index the numbers?"" And that's when I mentioned I used a log transformation.

2) How did you explain what a log transform was?

Answer: I didn't directly explain it in math terms. I described it in the form of an analogy or comparable example. This is what I said: 

""Imagine we were looking at salaries for a company. Most people for example will make a salary between something like $40 - 100k right? Well what if the top execs in the company make like $10 million dollars. Now imagine you tried to index using the mean? Wouldn't the mean say the average employee at this company makes a salary of $1 million dollars or something? That's not right. Basically, a log transformation would keep everyone's differences in consideration, but minimize the importance of some of those execs who are not entirely representative of the rest of the company. That way you can better see the difference in salary among every worker and not have your vision obscured by some of these execs who are throwing off that balance. ""

Unfortunately, this proved to be even more confusing and my colleagues really zoned in on exactly what a log was and how it's calculated and it was tough to navigate from there.

3) What is SVP?

Answer: It stands for Senior Vice President. It basically is a reference to our execs.",t2_ako9886,Well today was a depressing day for data science at work. What can I do better?,discussion,t3_gsn5lz,0.93,386,Discussion,386,1590760828.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work as an Analytics Manager and normally I don&amp;#39;t really share with my colleagues the in depth details of my work because nobody is technical. They just know I use SQL and Python to spit out a report and that&amp;#39;s all they really understand.&lt;/p&gt;

&lt;p&gt;Recently I had an opportunity to do something interesting where I had a very skewed data set and was asked to make sense of it. I thought applying a log transformation to normalize the data as the distribution was extremely skewed and thought it would make the data easier to interpret and I was happy with the results.&lt;/p&gt;

&lt;p&gt;My colleagues wanted to know how I arrived at my conclusion for my recommendation so I walked them through the process. I provided a high level overview, but they really wanted to get into the nitty gritty of exactly HOW I got to where I got. Again, I normally don&amp;#39;t like to do this because they tend ask very detailed questions like &amp;quot;Can you explain exactly how this works so I can understand?&amp;quot; and it gets tough to explain certain things (e.g., I would say something like &amp;quot;I got this raw data from the API&amp;quot; but then it&amp;#39;s followed up by a question like &amp;quot;What is an API and why didn&amp;#39;t you just use the vendor&amp;#39;s dashboard? Why doesn&amp;#39;t the vendor&amp;#39;s interface provide the data? Why do you have to go through this step?&amp;quot;).&lt;/p&gt;

&lt;p&gt;Well anyway I was explaining my logic and really tip toed around the stats by really trying to say essentially that I applied some logic that would more even distribute the data. I stupidly said the word &amp;quot;log&amp;quot; and it was over. Their faces froze for a good 10 seconds before someone spoke.&lt;/p&gt;

&lt;p&gt;&amp;quot;I&amp;#39;m sorry..but what? What is log? Why do you need this log? I&amp;#39;m really confused. How am I suppose to explain this to the SVP? Can you just change it so you&amp;#39;re indexing off the median or mean? This doesn&amp;#39;t make any sense.&amp;quot;&lt;/p&gt;

&lt;p&gt;I&amp;#39;m dead.&lt;/p&gt;

&lt;p&gt;So guys, how do you avoid getting away with having to explain things by  not using technical jargon? I mean like I said, I normally just show people the output of my report and I don&amp;#39;t get too many in depth questions about it, but when people really pry, it gets tough. I don&amp;#39;t know how to avoid saying &amp;quot;I ran a regression model&amp;quot; because it freaks people out and they get upset because they don&amp;#39;t understand it and want me to do something that is easier to interpret. It&amp;#39;s already frustrating that they think I&amp;#39;m over complicating things by using Python instead of Excel, but I can at least tell them certain things like Excel can&amp;#39;t handle 1+ million rows and they can understand that.&lt;/p&gt;

&lt;p&gt;EDIT: Hey all, appreciate all you feedback, both positive and negative. I think it&amp;#39;s all constructive. There&amp;#39;s a lot of replies in this thread so it&amp;#39;s hard to answer everyone&amp;#39;s questions. Some of you ask the same things and I do answer them, but you might have to dig through the comments to find it. In any case, let me post some frequently asked ones:&lt;/p&gt;

&lt;p&gt;1) Did you use graphs and visuals?&lt;/p&gt;

&lt;p&gt;Answer: I did. I actually stayed away from using the word log at first and just showed them a histogram of what the data looked like before the log transform and then after the log transform. What followed up was &amp;quot;How did you do this? What did you use to index the numbers?&amp;quot; And that&amp;#39;s when I mentioned I used a log transformation.&lt;/p&gt;

&lt;p&gt;2) How did you explain what a log transform was?&lt;/p&gt;

&lt;p&gt;Answer: I didn&amp;#39;t directly explain it in math terms. I described it in the form of an analogy or comparable example. This is what I said: &lt;/p&gt;

&lt;p&gt;&amp;quot;Imagine we were looking at salaries for a company. Most people for example will make a salary between something like $40 - 100k right? Well what if the top execs in the company make like $10 million dollars. Now imagine you tried to index using the mean? Wouldn&amp;#39;t the mean say the average employee at this company makes a salary of $1 million dollars or something? That&amp;#39;s not right. Basically, a log transformation would keep everyone&amp;#39;s differences in consideration, but minimize the importance of some of those execs who are not entirely representative of the rest of the company. That way you can better see the difference in salary among every worker and not have your vision obscured by some of these execs who are throwing off that balance. &amp;quot;&lt;/p&gt;

&lt;p&gt;Unfortunately, this proved to be even more confusing and my colleagues really zoned in on exactly what a log was and how it&amp;#39;s calculated and it was tough to navigate from there.&lt;/p&gt;

&lt;p&gt;3) What is SVP?&lt;/p&gt;

&lt;p&gt;Answer: It stands for Senior Vice President. It basically is a reference to our execs.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gsn5lz,dontlookmeupplease,232,/r/datascience/comments/gsn5lz/well_today_was_a_depressing_day_for_data_science/,https://www.reddit.com/r/datascience/comments/gsn5lz/well_today_was_a_depressing_day_for_data_science/,1590732028.0
r/datascience,"Howdy,

So, everyone knows about K-Means as a form of general clustering algorithm. Vector quantization is similarly centroid based, but rather uses a feed forward network to generate that Veroni styled segregation pattern via a (for lack of a better phrase) loser takes all output.

Is there any significant difference in these two algorithms? They seem like they would both have similar results; they both use random starting states, and rely on small adjustments potentially locking them in local minima. It seems like the only real difference is that k means is simpler, more efficient, and more direct.",t2_200q8u9g,K-Means vs vector quantization,discussion,t3_gt7wv3,0.67,4,Discussion,4,1590841130.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Howdy,&lt;/p&gt;

&lt;p&gt;So, everyone knows about K-Means as a form of general clustering algorithm. Vector quantization is similarly centroid based, but rather uses a feed forward network to generate that Veroni styled segregation pattern via a (for lack of a better phrase) loser takes all output.&lt;/p&gt;

&lt;p&gt;Is there any significant difference in these two algorithms? They seem like they would both have similar results; they both use random starting states, and rely on small adjustments potentially locking them in local minima. It seems like the only real difference is that k means is simpler, more efficient, and more direct.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gt7wv3,warlax56,2,/r/datascience/comments/gt7wv3/kmeans_vs_vector_quantization/,https://www.reddit.com/r/datascience/comments/gt7wv3/kmeans_vs_vector_quantization/,1590812330.0
r/datascience,"**It's Friday, lets vent!**

Will share my story but heavily changed to protect the guilty.  

I work(ed) in a safety field where people die based on decisions. We risk rate things, and use our limited resources to prioritise what we need to fix. For arguments sake, I have put this in the context of safety of vehicles.

Someone in another department came up with a subjective but otherwise understandable way of risk rating. Things  like 

* if there are seatbelts, subtract 1
* add the number of accidents in the last year
* if there is speed monitoring, subtract 1
* if no licence is required, add 2
* subtract 1 for every time they have been inspected  


As you can see, some of these were real numbers, some ordinal, some categorical and so on.

These numbers are added to give a final ""risk"" score for a vehicle. So far, so dodgy.

However, this total ""number"" was then ranked, and then multiplied by the number of passengers to give an overall value, which was then multiplied by the amount of safety dollars we had to spend to work out what we should do.

Needless to say, my mood quickly went from appalled to ""holy shit we need to never let anyone outside the organisation see how we do this...""",t2_3yzfxkch,Worst example of data stupidity you have seen?,discussion,t3_gsqs45,0.97,103,Discussion,103,1590778573.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;It&amp;#39;s Friday, lets vent!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Will share my story but heavily changed to protect the guilty.  &lt;/p&gt;

&lt;p&gt;I work(ed) in a safety field where people die based on decisions. We risk rate things, and use our limited resources to prioritise what we need to fix. For arguments sake, I have put this in the context of safety of vehicles.&lt;/p&gt;

&lt;p&gt;Someone in another department came up with a subjective but otherwise understandable way of risk rating. Things  like &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;if there are seatbelts, subtract 1&lt;/li&gt;
&lt;li&gt;add the number of accidents in the last year&lt;/li&gt;
&lt;li&gt;if there is speed monitoring, subtract 1&lt;/li&gt;
&lt;li&gt;if no licence is required, add 2&lt;/li&gt;
&lt;li&gt;subtract 1 for every time they have been inspected&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you can see, some of these were real numbers, some ordinal, some categorical and so on.&lt;/p&gt;

&lt;p&gt;These numbers are added to give a final &amp;quot;risk&amp;quot; score for a vehicle. So far, so dodgy.&lt;/p&gt;

&lt;p&gt;However, this total &amp;quot;number&amp;quot; was then ranked, and then multiplied by the number of passengers to give an overall value, which was then multiplied by the amount of safety dollars we had to spend to work out what we should do.&lt;/p&gt;

&lt;p&gt;Needless to say, my mood quickly went from appalled to &amp;quot;holy shit we need to never let anyone outside the organisation see how we do this...&amp;quot;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gsqs45,BaikAussie,77,/r/datascience/comments/gsqs45/worst_example_of_data_stupidity_you_have_seen/,https://www.reddit.com/r/datascience/comments/gsqs45/worst_example_of_data_stupidity_you_have_seen/,1590749773.0
r/datascience,"Just built a PC that blows my work computer out of the water in terms of computing power and speed, and it got me thinking about how much more productive I could be if I was able to run some of my heavier scripts/tools from work on it. My company has pretty tight InfoSec, but I do have a soft token for VPN on my personal phone, so I do know they do allow personal devices to be used in that capacity. 

I'm curious if anyone out there has done something like this before? Or maybe the takeaway is I should just request a more powerful work computer.

Thanks!",t2_wfqzg,Anyone use their home rigs for work?,tooling,t3_gt8yac,0.6,1,Tooling,1,1590846043.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just built a PC that blows my work computer out of the water in terms of computing power and speed, and it got me thinking about how much more productive I could be if I was able to run some of my heavier scripts/tools from work on it. My company has pretty tight InfoSec, but I do have a soft token for VPN on my personal phone, so I do know they do allow personal devices to be used in that capacity. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m curious if anyone out there has done something like this before? Or maybe the takeaway is I should just request a more powerful work computer.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gt8yac,Kassme,4,/r/datascience/comments/gt8yac/anyone_use_their_home_rigs_for_work/,https://www.reddit.com/r/datascience/comments/gt8yac/anyone_use_their_home_rigs_for_work/,1590817243.0
r/datascience,,t2_65da1lk0,[D] What is the tool stack of ML teams at startups? + intel from 41 companies,tooling,t3_gsbtwn,0.94,103,Tooling,103,1590719589.0,,gsbtwn,katienec,12,/r/datascience/comments/gsbtwn/d_what_is_the_tool_stack_of_ml_teams_at_startups/,/r/MachineLearning/comments/gs23ks/d_what_is_the_tool_stack_of_ml_teams_at_startups/,1590690789.0
r/datascience,"I have been a data scientist / data engineer for about 2 years with only a BA in Economics. I have always wanted to learn more on the CS side and recently decided to take night classes at the local community college. I start my first class (Programming fundamentals I) which will be taught using C++. I am pretty proficient in R and Python for modeling and ETL, but I don't have any experience with lower level languages. 

I'm super excited, and I want to know if anyone has any advice about what to focus on in my class? 

Will C++ be useful as a data scientist/engineer?

I plan on taking Programmin fundamentals II and III next. They are offered in C++ or Java. Should I pick one over the other?

My ultimate goal is to get into Georgia Tech's OMSCS program while at the same time learning valuable skills for my job",t2_kyu8a,Data scientist going back to school for CS,education,t3_gsg5eh,0.94,49,Education,49,1590733079.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been a data scientist / data engineer for about 2 years with only a BA in Economics. I have always wanted to learn more on the CS side and recently decided to take night classes at the local community college. I start my first class (Programming fundamentals I) which will be taught using C++. I am pretty proficient in R and Python for modeling and ETL, but I don&amp;#39;t have any experience with lower level languages. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m super excited, and I want to know if anyone has any advice about what to focus on in my class? &lt;/p&gt;

&lt;p&gt;Will C++ be useful as a data scientist/engineer?&lt;/p&gt;

&lt;p&gt;I plan on taking Programmin fundamentals II and III next. They are offered in C++ or Java. Should I pick one over the other?&lt;/p&gt;

&lt;p&gt;My ultimate goal is to get into Georgia Tech&amp;#39;s OMSCS program while at the same time learning valuable skills for my job&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gsg5eh,azzipog,23,/r/datascience/comments/gsg5eh/data_scientist_going_back_to_school_for_cs/,https://www.reddit.com/r/datascience/comments/gsg5eh/data_scientist_going_back_to_school_for_cs/,1590704279.0
r/datascience,"I’ve seen some of the visualizations showing different viewing patterns by state and it makes me wonder
- What’s working there like
- How’s the pay (I could see it either being really good or really bad
- how rich is their dataset

As one of the most viewed sites on the internet they must have some data science types working there",t2_68vll2wy,"I know it’s a weird question but, What do you think it would be like to be a data scientist at pornhub?",discussion,t3_grvwzg,0.93,409,Discussion,409,1590654827.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve seen some of the visualizations showing different viewing patterns by state and it makes me wonder
- What’s working there like
- How’s the pay (I could see it either being really good or really bad
- how rich is their dataset&lt;/p&gt;

&lt;p&gt;As one of the most viewed sites on the internet they must have some data science types working there&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",grvwzg,a_wsty,166,/r/datascience/comments/grvwzg/i_know_its_a_weird_question_but_what_do_you_think/,https://www.reddit.com/r/datascience/comments/grvwzg/i_know_its_a_weird_question_but_what_do_you_think/,1590626027.0
r/datascience,"I am exploring Dash at the moment a and finding it very interesting.

My question is: How easy or hard is to deploy Dash on custom Linux server?",t2_an3zj,How easy or hard is to deploy Dash dashboard on a custom server?,discussion,t3_gsgtzn,1.0,6,Discussion,6,1590735394.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am exploring Dash at the moment a and finding it very interesting.&lt;/p&gt;

&lt;p&gt;My question is: How easy or hard is to deploy Dash on custom Linux server?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gsgtzn,vasili111,6,/r/datascience/comments/gsgtzn/how_easy_or_hard_is_to_deploy_dash_dashboard_on_a/,https://www.reddit.com/r/datascience/comments/gsgtzn/how_easy_or_hard_is_to_deploy_dash_dashboard_on_a/,1590706594.0
r/datascience,What’s your favorite ETL tool?,t2_j2qne,"Just sitting around, waiting for my data to load...",discussion,t3_gsnbun,0.5,0,Discussion,0,1590761652.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What’s your favorite ETL tool?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gsnbun,r0ck13r4c00n,6,/r/datascience/comments/gsnbun/just_sitting_around_waiting_for_my_data_to_load/,https://www.reddit.com/r/datascience/comments/gsnbun/just_sitting_around_waiting_for_my_data_to_load/,1590732852.0
r/datascience,"Hi guys, I'm trying to build a binary outcome classifier for a dataset and I'm kind of stumped by a particular feature in the data which have \~20% of its values missing in both the training and testing sets. This feature has about a r=0.077 correlation with the outcome (measured from observed data in the training set).

I'm looking to do Multiple Imputation on the missing values and I gather that I basically need to do the following:

1. Choose a single imputation method with a random component (regression with random error term, regression with bootstrap samples, etc.), impute missing values x times to get x separate datasets
2. Do my analysis (build an ML model) x times to get x different sets of results (model parameters)
3. Average the results to get 1 set of model parameters

I was wondering if it would be okay if I just did step 1 and averaged the missing values into 1 complete dataset? I ask because this seems like it may not be worth the hassle for something with only a r=0.077 with the outcome, and coupled with missing values in other features I would end up with a lot of models if I chose this approach. Is there a better way to do this? Also how would this approach work from a testing point of view? Would I just impute multiple testing sets and take a majority vote of the predictions?",t2_45ghaste,Convention on Multiple Imputation for ML models?,discussion,t3_gsgcup,1.0,5,Discussion,5,1590733768.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, I&amp;#39;m trying to build a binary outcome classifier for a dataset and I&amp;#39;m kind of stumped by a particular feature in the data which have ~20% of its values missing in both the training and testing sets. This feature has about a r=0.077 correlation with the outcome (measured from observed data in the training set).&lt;/p&gt;

&lt;p&gt;I&amp;#39;m looking to do Multiple Imputation on the missing values and I gather that I basically need to do the following:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Choose a single imputation method with a random component (regression with random error term, regression with bootstrap samples, etc.), impute missing values x times to get x separate datasets&lt;/li&gt;
&lt;li&gt;Do my analysis (build an ML model) x times to get x different sets of results (model parameters)&lt;/li&gt;
&lt;li&gt;Average the results to get 1 set of model parameters&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I was wondering if it would be okay if I just did step 1 and averaged the missing values into 1 complete dataset? I ask because this seems like it may not be worth the hassle for something with only a r=0.077 with the outcome, and coupled with missing values in other features I would end up with a lot of models if I chose this approach. Is there a better way to do this? Also how would this approach work from a testing point of view? Would I just impute multiple testing sets and take a majority vote of the predictions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gsgcup,___word___,6,/r/datascience/comments/gsgcup/convention_on_multiple_imputation_for_ml_models/,https://www.reddit.com/r/datascience/comments/gsgcup/convention_on_multiple_imputation_for_ml_models/,1590704968.0
r/datascience,"Hi!
I’m on a project team, aimed at determining best integration and API platforms. We’ve spoken a lot about DataStage (internally), but less about Rhapsody and mulesoft. 

Can anyone share a brief pro/con of the two? Or maybe when you would choose one over the other (other than cost and worker capacity)?",t2_db4uwn6,Mulesoft vs rhapsody,tooling,t3_gsd55l,0.6,1,Tooling,1,1590723533.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi!
I’m on a project team, aimed at determining best integration and API platforms. We’ve spoken a lot about DataStage (internally), but less about Rhapsody and mulesoft. &lt;/p&gt;

&lt;p&gt;Can anyone share a brief pro/con of the two? Or maybe when you would choose one over the other (other than cost and worker capacity)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gsd55l,datajen,1,/r/datascience/comments/gsd55l/mulesoft_vs_rhapsody/,https://www.reddit.com/r/datascience/comments/gsd55l/mulesoft_vs_rhapsody/,1590694733.0
r/datascience,"A recurring issue I've had to deal with in my career has been IT governance and the ability of myself (or my teams) to be able to use or test out cloud functionality independently (i.e., not needing IT to set everything up for my first).

For those in companies with tight permission policies:

1. How is your access to cloud resources set up?
   1. Are you able to spin up compute resources by yourself (e.g., EC2)?
   2. Are you able to connect these compute resources to production DBs, or are you only able to create these in dev environments/connect to test/backup DBs?
2. Are you happy with it?

EDIT for clarification:

* I am not advocating against IT governance - I think it certainly has a purpose and just giving users ""God privileges"" as u/lacompacida so eloquently referred to is not the answer. What I am interested in is how others (companies) are managing the tradeoff between cybersecurity risks and data scientist's autonomy.
* For example, I think u/SlightBerry brings up what seems like a valid stance - users should be able to deploy resources as needed, and security should be handled not by overseeing what users are spinning up, but by making sure that whatever they spin up is isolated enough not to generate issues. I certainly have questions regarding that setup, but clearly there is a balance between giving any joe shmoe complete access to prod vs. requiring even your most senior DS to open a ticket to get a compute instance stood up.",t2_3epw0pud,Cloud permissions for Data Scientists - anyone happy with their company's setup?,,t3_grmbms,0.97,77,,77,1590623878.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A recurring issue I&amp;#39;ve had to deal with in my career has been IT governance and the ability of myself (or my teams) to be able to use or test out cloud functionality independently (i.e., not needing IT to set everything up for my first).&lt;/p&gt;

&lt;p&gt;For those in companies with tight permission policies:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;How is your access to cloud resources set up?

&lt;ol&gt;
&lt;li&gt;Are you able to spin up compute resources by yourself (e.g., EC2)?&lt;/li&gt;
&lt;li&gt;Are you able to connect these compute resources to production DBs, or are you only able to create these in dev environments/connect to test/backup DBs?&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Are you happy with it?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;EDIT for clarification:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I am not advocating against IT governance - I think it certainly has a purpose and just giving users &amp;quot;God privileges&amp;quot; as &lt;a href=""/u/lacompacida""&gt;u/lacompacida&lt;/a&gt; so eloquently referred to is not the answer. What I am interested in is how others (companies) are managing the tradeoff between cybersecurity risks and data scientist&amp;#39;s autonomy.&lt;/li&gt;
&lt;li&gt;For example, I think &lt;a href=""/u/SlightBerry""&gt;u/SlightBerry&lt;/a&gt; brings up what seems like a valid stance - users should be able to deploy resources as needed, and security should be handled not by overseeing what users are spinning up, but by making sure that whatever they spin up is isolated enough not to generate issues. I certainly have questions regarding that setup, but clearly there is a balance between giving any joe shmoe complete access to prod vs. requiring even your most senior DS to open a ticket to get a compute instance stood up.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",grmbms,dfphd,48,/r/datascience/comments/grmbms/cloud_permissions_for_data_scientists_anyone/,https://www.reddit.com/r/datascience/comments/grmbms/cloud_permissions_for_data_scientists_anyone/,1590595078.0
r/datascience,"Hello all, I got laid off from a Data Quality Assurance job due to covid at the beginning of April, and I was accepted into an applied data science masters program at USC (University of Southern California) during this time off. The pay was good at the job, but I was extremely stressed out and didn’t receive overtime on days I would work extra. I was only there for 3 months, and now they’re asking me to come back. Do you think I should pursue a masters (2 year program) at $70K tuition or accept the offer again which pays 75k?

Background: I graduated in January of 2019 and have about 1.5 years of data ANALYST experience under my belt so far.

Thanks in advance!

Edit: I should also note that this is without FAFSA considered as I haven’t received notice yet. 
I have experience in Power BI, SQL, Python, and Excel which are all fine for data analyst roles, but my question would be is experience enough to get me from an analyst position to a scientist position?
The USC program focuses on Machine Learning and Webscraping, as well as Hadoop/MapReduce/Spark. 
I have a bachelors in Business Analytics if that matters.
Appreciate the input from everyone so far as well",t2_r0krk,Masters Degree or Old Stressful Job,,t3_grq9ik,0.83,38,,38,1590635841.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all, I got laid off from a Data Quality Assurance job due to covid at the beginning of April, and I was accepted into an applied data science masters program at USC (University of Southern California) during this time off. The pay was good at the job, but I was extremely stressed out and didn’t receive overtime on days I would work extra. I was only there for 3 months, and now they’re asking me to come back. Do you think I should pursue a masters (2 year program) at $70K tuition or accept the offer again which pays 75k?&lt;/p&gt;

&lt;p&gt;Background: I graduated in January of 2019 and have about 1.5 years of data ANALYST experience under my belt so far.&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;

&lt;p&gt;Edit: I should also note that this is without FAFSA considered as I haven’t received notice yet. 
I have experience in Power BI, SQL, Python, and Excel which are all fine for data analyst roles, but my question would be is experience enough to get me from an analyst position to a scientist position?
The USC program focuses on Machine Learning and Webscraping, as well as Hadoop/MapReduce/Spark. 
I have a bachelors in Business Analytics if that matters.
Appreciate the input from everyone so far as well&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",grq9ik,sizzlepoop,53,/r/datascience/comments/grq9ik/masters_degree_or_old_stressful_job/,https://www.reddit.com/r/datascience/comments/grq9ik/masters_degree_or_old_stressful_job/,1590607041.0
r/datascience,"Hi everyone,

I have data on three years of weekly sales for a market, plus some information about brands, promos etc . Researching about Time Series analysis, I came about ARIMA and SAIRMA models, which seems to be the standard approach for this type of data analysis and forecast.

I was wondering, is it ARIMA also the only or best option? Is it possible to use also some other algorithms that may turn out to be more effective? If so, what would you suggest?

Thank you",t2_177ggj,Alternative approaches to ARIMA for Time Series prediction (No Neural Networks),discussion,t3_gro5w8,0.92,27,Discussion,27,1590629426.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I have data on three years of weekly sales for a market, plus some information about brands, promos etc . Researching about Time Series analysis, I came about ARIMA and SAIRMA models, which seems to be the standard approach for this type of data analysis and forecast.&lt;/p&gt;

&lt;p&gt;I was wondering, is it ARIMA also the only or best option? Is it possible to use also some other algorithms that may turn out to be more effective? If so, what would you suggest?&lt;/p&gt;

&lt;p&gt;Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gro5w8,cmprogrammers,28,/r/datascience/comments/gro5w8/alternative_approaches_to_arima_for_time_series/,https://www.reddit.com/r/datascience/comments/gro5w8/alternative_approaches_to_arima_for_time_series/,1590600626.0
r/datascience," Are you a data scientist and you haven't deployed machine learning model yet  .... then this one is for you ☟  

Our latest medium post is a step-by-step beginner’s guide to containerize and deploy machine learning pipeline on Google Kubernetes Engine.  

If you have never heard about containerization, docker and Kubernetes before, no problem - this is what this tutorial is all about. In this tutorial you will learn:  

✔ What is a Container, What is Docker, What is Kubernetes, and What is Google Kubernetes Engine? 

✔ Build a Docker image and upload it on Google Container Registry (GCR). 

✔ Create clusters and deploy a machine learning pipeline with Flask app as a web service. 

✔ See a web app in action that uses a trained machine learning pipeline to predict on new data points in real-time. 

[https://medium.com/@moez\_62905/deploy-machine-learning-model-on-google-kubernetes-engine-94daac85108b](https://medium.com/@moez_62905/deploy-machine-learning-model-on-google-kubernetes-engine-94daac85108b)",t2_6b23z3qw,Deploy Machine Learning Pipeline on Google Kubernetes Engine,education,t3_gryp8p,0.57,1,Education,1,1590665824.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Are you a data scientist and you haven&amp;#39;t deployed machine learning model yet  .... then this one is for you ☟  &lt;/p&gt;

&lt;p&gt;Our latest medium post is a step-by-step beginner’s guide to containerize and deploy machine learning pipeline on Google Kubernetes Engine.  &lt;/p&gt;

&lt;p&gt;If you have never heard about containerization, docker and Kubernetes before, no problem - this is what this tutorial is all about. In this tutorial you will learn:  &lt;/p&gt;

&lt;p&gt;✔ What is a Container, What is Docker, What is Kubernetes, and What is Google Kubernetes Engine? &lt;/p&gt;

&lt;p&gt;✔ Build a Docker image and upload it on Google Container Registry (GCR). &lt;/p&gt;

&lt;p&gt;✔ Create clusters and deploy a machine learning pipeline with Flask app as a web service. &lt;/p&gt;

&lt;p&gt;✔ See a web app in action that uses a trained machine learning pipeline to predict on new data points in real-time. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://medium.com/@moez_62905/deploy-machine-learning-model-on-google-kubernetes-engine-94daac85108b""&gt;https://medium.com/@moez_62905/deploy-machine-learning-model-on-google-kubernetes-engine-94daac85108b&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gryp8p,moezali,1,/r/datascience/comments/gryp8p/deploy_machine_learning_pipeline_on_google/,https://www.reddit.com/r/datascience/comments/gryp8p/deploy_machine_learning_pipeline_on_google/,1590637024.0
r/datascience,"I am creating a ""tool box"" that is pretty much a big google colab file with useful codes, this way my basic projects would be more modulated and easily implanted, but not sure if i am doing it the best way, so thought you guys may be doing something like this.",t2_3tsihkqy,How do you keep your useful / reusable codes?,discussion,t3_gryhrf,0.75,4,Discussion,4,1590664964.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am creating a &amp;quot;tool box&amp;quot; that is pretty much a big google colab file with useful codes, this way my basic projects would be more modulated and easily implanted, but not sure if i am doing it the best way, so thought you guys may be doing something like this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gryhrf,barata_de_gravata,4,/r/datascience/comments/gryhrf/how_do_you_keep_your_useful_reusable_codes/,https://www.reddit.com/r/datascience/comments/gryhrf/how_do_you_keep_your_useful_reusable_codes/,1590636164.0
r/datascience,"I work a lot with ""heavy"" statisticians (mostly bio-statisticians). They typically get involve after we do all the data engineering and NLP part. Their knowledge of stats of course overshadows that of my team, which brings me to the question - what is the value of a data scientist without such knowledge?

It's true that we do all the heavy work, but the statisticians are the ones making the calls about the study design, scrutinize the results etc. 

It makes my teammate feel like low-skilled workers in the whole process, and they fear that they will be easily replaceable. 

What do you think?",t2_8r6nnv,How deep is your statistics knowledge?,discussion,t3_gr8jz1,0.98,271,Discussion,271,1590565778.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work a lot with &amp;quot;heavy&amp;quot; statisticians (mostly bio-statisticians). They typically get involve after we do all the data engineering and NLP part. Their knowledge of stats of course overshadows that of my team, which brings me to the question - what is the value of a data scientist without such knowledge?&lt;/p&gt;

&lt;p&gt;It&amp;#39;s true that we do all the heavy work, but the statisticians are the ones making the calls about the study design, scrutinize the results etc. &lt;/p&gt;

&lt;p&gt;It makes my teammate feel like low-skilled workers in the whole process, and they fear that they will be easily replaceable. &lt;/p&gt;

&lt;p&gt;What do you think?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gr8jz1,CacheMeUp,120,/r/datascience/comments/gr8jz1/how_deep_is_your_statistics_knowledge/,https://www.reddit.com/r/datascience/comments/gr8jz1/how_deep_is_your_statistics_knowledge/,1590536978.0
r/datascience,"I am trying to develop my first DS project using cookiecutter but I am having hard time understanding its bits and pieces.

If anyone knows or have developed any actual DS projects developed using it or any other template, please share links. it will be easier to understand the whole process. Thank you",t2_68lu8dj8,Cookiecutter projects,education,t3_grp93m,0.86,5,Education,5,1590632710.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to develop my first DS project using cookiecutter but I am having hard time understanding its bits and pieces.&lt;/p&gt;

&lt;p&gt;If anyone knows or have developed any actual DS projects developed using it or any other template, please share links. it will be easier to understand the whole process. Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",grp93m,idkwhattoxhuz,6,/r/datascience/comments/grp93m/cookiecutter_projects/,https://www.reddit.com/r/datascience/comments/grp93m/cookiecutter_projects/,1590603910.0
r/datascience,"Conceptually, it seems to me that partial least squares regression should be excellent in some situations. However, ISLR states ""...it often performs no better than ridge regression or PCR (principle component regression)"" and that ""...the overall benefit of PLS relative to PCR is a wash"". Applied Predictive Modelling, on the other hand, describes PLS in a much more positive light. I was hoping someone might be able to speak from experience as to whether they have found PLS to significantly outperform other methods or not.",t2_zohps,Have you found PLS regression useful?,discussion,t3_grxxp1,0.67,1,Discussion,1,1590662697.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Conceptually, it seems to me that partial least squares regression should be excellent in some situations. However, ISLR states &amp;quot;...it often performs no better than ridge regression or PCR (principle component regression)&amp;quot; and that &amp;quot;...the overall benefit of PLS relative to PCR is a wash&amp;quot;. Applied Predictive Modelling, on the other hand, describes PLS in a much more positive light. I was hoping someone might be able to speak from experience as to whether they have found PLS to significantly outperform other methods or not.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",grxxp1,RyBread7,7,/r/datascience/comments/grxxp1/have_you_found_pls_regression_useful/,https://www.reddit.com/r/datascience/comments/grxxp1/have_you_found_pls_regression_useful/,1590633897.0
r/datascience,"I have a dataset of images collected from google and bing images (scraped). basically I want to classify these images into binary classes (positive, negative). Images that contain a text originally from the image (a photo of contract) should be classified positive (there are some other cases where the image also should be positive but my problem is with the textual images). I'm facing a problem that many negative images have text and caption that's add on the photo like a website address or logo (not original from the image). I'm afraid these images could hurt the model performance, in this case, what should I do? It doesn't make sense to through away useful images because of tiny text added on them. And could that actually hurt the model or the model would be able to capture the actual pattern from the dataset?

Thanks",t2_99sn10x,How to deal with images with text noise?,discussion,t3_grttya,1.0,2,Discussion,2,1590647259.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a dataset of images collected from google and bing images (scraped). basically I want to classify these images into binary classes (positive, negative). Images that contain a text originally from the image (a photo of contract) should be classified positive (there are some other cases where the image also should be positive but my problem is with the textual images). I&amp;#39;m facing a problem that many negative images have text and caption that&amp;#39;s add on the photo like a website address or logo (not original from the image). I&amp;#39;m afraid these images could hurt the model performance, in this case, what should I do? It doesn&amp;#39;t make sense to through away useful images because of tiny text added on them. And could that actually hurt the model or the model would be able to capture the actual pattern from the dataset?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",grttya,SuccessfulLeadership,1,/r/datascience/comments/grttya/how_to_deal_with_images_with_text_noise/,https://www.reddit.com/r/datascience/comments/grttya/how_to_deal_with_images_with_text_noise/,1590618459.0
r/datascience,"I've used matlab but now I mainly use python 3. Matlabs plotting is complete utter garbage and I will never understand the logic behind it, I hate it with all my heart. Matplotlib in python 3 is a little bit better, but it still seems unnecessarily confusing, despite changing tick label sizes hundreds of times I always have to google it.

Is there a simple python library that can handle all the common charts patterns, outputting them aesthetically with selectable color schemes and font sizes that are fucking readable by default?",t2_5cr3wiq3,Python library to make data visualization less autistic,tooling,t3_gs4irw,0.3,0,Tooling,0,1590694025.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve used matlab but now I mainly use python 3. Matlabs plotting is complete utter garbage and I will never understand the logic behind it, I hate it with all my heart. Matplotlib in python 3 is a little bit better, but it still seems unnecessarily confusing, despite changing tick label sizes hundreds of times I always have to google it.&lt;/p&gt;

&lt;p&gt;Is there a simple python library that can handle all the common charts patterns, outputting them aesthetically with selectable color schemes and font sizes that are fucking readable by default?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gs4irw,autistic_alpha,15,/r/datascience/comments/gs4irw/python_library_to_make_data_visualization_less/,https://www.reddit.com/r/datascience/comments/gs4irw/python_library_to_make_data_visualization_less/,1590665225.0
r/datascience,"Data scientists who play competitive video games(e.g. moba, autochess, hearthstone), how would you model the problem of game balancing? Most stat websites(hsreplay.net, op.gg, etc) focus on winrates only. How do you quantify ideas like strategy diversity, comeback potential, interactivity/counterplay, skill cap/floor, learning curve, etc?",t2_banwy,How do you approach game balancing as a data scientist?,discussion,t3_grgc0e,0.89,7,Discussion,7,1590599629.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Data scientists who play competitive video games(e.g. moba, autochess, hearthstone), how would you model the problem of game balancing? Most stat websites(hsreplay.net, op.gg, etc) focus on winrates only. How do you quantify ideas like strategy diversity, comeback potential, interactivity/counterplay, skill cap/floor, learning curve, etc?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",grgc0e,saintshing,5,/r/datascience/comments/grgc0e/how_do_you_approach_game_balancing_as_a_data/,https://www.reddit.com/r/datascience/comments/grgc0e/how_do_you_approach_game_balancing_as_a_data/,1590570829.0
r/datascience,,t2_bi6kztp,XKCD : Confidence Interval,fun,t3_gqns9k,0.98,589,Fun/Trivia,589,1590485875.0,,gqns9k,rohan36,26,/r/datascience/comments/gqns9k/xkcd_confidence_interval/,https://xkcd.com/2311/,1590457075.0
r/datascience,"At my job, I am juggling keeping our development pace going for the project I'm assigned to while making improvements to our workflow.

I figured out that you can dump a .csv file of a waveform from an [oscilloscope](https://en.wikipedia.org/wiki/Oscilloscope), and it is over a million rows. Python is too slow, because I only have access to a dual core 4 GB machine (I am thinking about writing a persuasive letter about getting a cheap 16 GB ram machine with secure, local-only remote access for the entire engineering team, probably either a quad core Intel or Ryzen 3600) so I was wondering what would be best:

*Learn some [R lang](https://www.r-project.org/) basics? C++ was the first thing that came to mind because I figured I could just declare 300-400 MB of memory, placing the whole .csv file in 200 and the rest of the program in 100-200? [This is the second link that comes up for me when I google ""C++ .csv"".](https://www.gormanalysis.com/blog/reading-and-writing-csv-files-with-cpp/) Admittedly, he has a point. I am about using the right tool for a job.

*Learn [Postgres](https://www.postgresqltutorial.com/import-csv-file-into-posgresql-table/)? I like the idea of having an excuse to put a database on my resume and then interfacing it with my tried-and-true Python or C++. 

*Go with my first instinct and [do it in C++ anyways](https://github.com/ben-strasser/fast-cpp-csv-parser)? I already use python at work and I'm wondering if a tool featuring a C++ parser as the back-end and something like [pysimplegui](https://pysimplegui.readthedocs.io/en/latest/) as the front end could be a game-changer at my job.",,Strategies for processing .csv files over 1 million rows long (~200 MB .csv files),discussion,t3_gqgpwo,0.92,142,Discussion,142,1590461307.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;At my job, I am juggling keeping our development pace going for the project I&amp;#39;m assigned to while making improvements to our workflow.&lt;/p&gt;

&lt;p&gt;I figured out that you can dump a .csv file of a waveform from an &lt;a href=""https://en.wikipedia.org/wiki/Oscilloscope""&gt;oscilloscope&lt;/a&gt;, and it is over a million rows. Python is too slow, because I only have access to a dual core 4 GB machine (I am thinking about writing a persuasive letter about getting a cheap 16 GB ram machine with secure, local-only remote access for the entire engineering team, probably either a quad core Intel or Ryzen 3600) so I was wondering what would be best:&lt;/p&gt;

&lt;p&gt;*Learn some &lt;a href=""https://www.r-project.org/""&gt;R lang&lt;/a&gt; basics? C++ was the first thing that came to mind because I figured I could just declare 300-400 MB of memory, placing the whole .csv file in 200 and the rest of the program in 100-200? &lt;a href=""https://www.gormanalysis.com/blog/reading-and-writing-csv-files-with-cpp/""&gt;This is the second link that comes up for me when I google &amp;quot;C++ .csv&amp;quot;.&lt;/a&gt; Admittedly, he has a point. I am about using the right tool for a job.&lt;/p&gt;

&lt;p&gt;*Learn &lt;a href=""https://www.postgresqltutorial.com/import-csv-file-into-posgresql-table/""&gt;Postgres&lt;/a&gt;? I like the idea of having an excuse to put a database on my resume and then interfacing it with my tried-and-true Python or C++. &lt;/p&gt;

&lt;p&gt;*Go with my first instinct and &lt;a href=""https://github.com/ben-strasser/fast-cpp-csv-parser""&gt;do it in C++ anyways&lt;/a&gt;? I already use python at work and I&amp;#39;m wondering if a tool featuring a C++ parser as the back-end and something like &lt;a href=""https://pysimplegui.readthedocs.io/en/latest/""&gt;pysimplegui&lt;/a&gt; as the front end could be a game-changer at my job.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gqgpwo,[deleted],132,/r/datascience/comments/gqgpwo/strategies_for_processing_csv_files_over_1/,https://www.reddit.com/r/datascience/comments/gqgpwo/strategies_for_processing_csv_files_over_1/,1590432507.0
r/datascience,"I'm looking for a graph algorithm with a ""know each other"" functionality. A general input will be total number of people (50-100) and a closeness rating of 1 to 4 associated. So for example, person A knows person B and their closeness rating is 1 (meaning they are unfamiliar to each other). Person A knows C (with a closeness rating of 4 - familiar) and B knows C (with a closeness rating of 4 - familiar). Therefore, A and B are unfamiliar, but C is their mutual friend.",t2_4m93gkvu,Looking for a graph algorithm (with possible implementation) for social network,tooling,t3_gr77qh,0.3,0,Tooling,0,1590561106.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for a graph algorithm with a &amp;quot;know each other&amp;quot; functionality. A general input will be total number of people (50-100) and a closeness rating of 1 to 4 associated. So for example, person A knows person B and their closeness rating is 1 (meaning they are unfamiliar to each other). Person A knows C (with a closeness rating of 4 - familiar) and B knows C (with a closeness rating of 4 - familiar). Therefore, A and B are unfamiliar, but C is their mutual friend.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gr77qh,booblaboobloo,6,/r/datascience/comments/gr77qh/looking_for_a_graph_algorithm_with_possible/,https://www.reddit.com/r/datascience/comments/gr77qh/looking_for_a_graph_algorithm_with_possible/,1590532306.0
r/datascience,"I have a dataset of bill payment transactions of our customers with a period of over 1 year and some features like paid amount, transaction date, bill type (power, internet, etc.). At first, I was able to build a classification model from this data to classify whether a customer has a bill payment transaction in the next  7 days (\*), but now my boss wants to go a step further: Could you predict a specific date per customer with a reliable margin of error? (\*\*) I'm not sure how one would reformulate and approach this 'new' problem, and how one would backtest/validate the model (what would be the metrics, etc.). Any pointers or ideas would be appreciated.

Edit: I did do some feature engineering in order to fit a gradient boosting into the data for (\*) and came up with some aggregated features (per customer) including:

\- recency 

\- frequency

\- customer age (time from first transaction to the end of the studied period)

\- statistics of the bill amount (mean, median, kurtosis, min, max, etc.)

\- statistics of the day difference between bill payments

\- Mode of bill types

\- Counts of each bill type, normalised

One thing that confuses me a bit: There are some customers with zero day differences, meaning they paid 2 or more bills in 1 day. I don't know if it will affect the model for (\*), and potentially (\*\*). Should those cases be counted as 1 'compound' bill payment?",t2_12uxuf9j,Is it possible to predict a specific date for a customer's next transaction (with some margin of error) ?,discussion,t3_gqshph,0.8,6,Discussion,6,1590507101.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a dataset of bill payment transactions of our customers with a period of over 1 year and some features like paid amount, transaction date, bill type (power, internet, etc.). At first, I was able to build a classification model from this data to classify whether a customer has a bill payment transaction in the next  7 days (*), but now my boss wants to go a step further: Could you predict a specific date per customer with a reliable margin of error? (**) I&amp;#39;m not sure how one would reformulate and approach this &amp;#39;new&amp;#39; problem, and how one would backtest/validate the model (what would be the metrics, etc.). Any pointers or ideas would be appreciated.&lt;/p&gt;

&lt;p&gt;Edit: I did do some feature engineering in order to fit a gradient boosting into the data for (*) and came up with some aggregated features (per customer) including:&lt;/p&gt;

&lt;p&gt;- recency &lt;/p&gt;

&lt;p&gt;- frequency&lt;/p&gt;

&lt;p&gt;- customer age (time from first transaction to the end of the studied period)&lt;/p&gt;

&lt;p&gt;- statistics of the bill amount (mean, median, kurtosis, min, max, etc.)&lt;/p&gt;

&lt;p&gt;- statistics of the day difference between bill payments&lt;/p&gt;

&lt;p&gt;- Mode of bill types&lt;/p&gt;

&lt;p&gt;- Counts of each bill type, normalised&lt;/p&gt;

&lt;p&gt;One thing that confuses me a bit: There are some customers with zero day differences, meaning they paid 2 or more bills in 1 day. I don&amp;#39;t know if it will affect the model for (*), and potentially (**). Should those cases be counted as 1 &amp;#39;compound&amp;#39; bill payment?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gqshph,commoner9x,13,/r/datascience/comments/gqshph/is_it_possible_to_predict_a_specific_date_for_a/,https://www.reddit.com/r/datascience/comments/gqshph/is_it_possible_to_predict_a_specific_date_for_a/,1590478301.0
r/datascience,"I'm curious if anyone here has any experience building a PC for work? I've been reading online and some say to have a lot of PCIe lanes while others say it's not important. Same thing regarding dual GPUs, getting a threadripper CPU, and more.

I primarily do cluster analysis, random forests, and regression, but I want to expand my skills in deep learning. I have been working on an RNN for the past 6 months and plan on trying my hand at computer vision. I'm still just learning and working with relatively small datasets, so I don't need a crazy powerful machine.",t2_dsi8i,Seeking Advice: Building a PC For Data Science Work,discussion,t3_gqhzwk,0.85,17,Discussion,17,1590465218.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m curious if anyone here has any experience building a PC for work? I&amp;#39;ve been reading online and some say to have a lot of PCIe lanes while others say it&amp;#39;s not important. Same thing regarding dual GPUs, getting a threadripper CPU, and more.&lt;/p&gt;

&lt;p&gt;I primarily do cluster analysis, random forests, and regression, but I want to expand my skills in deep learning. I have been working on an RNN for the past 6 months and plan on trying my hand at computer vision. I&amp;#39;m still just learning and working with relatively small datasets, so I don&amp;#39;t need a crazy powerful machine.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gqhzwk,RaffikiDaBaboon,20,/r/datascience/comments/gqhzwk/seeking_advice_building_a_pc_for_data_science_work/,https://www.reddit.com/r/datascience/comments/gqhzwk/seeking_advice_building_a_pc_for_data_science_work/,1590436418.0
r/datascience,"I have always been in this ambivalence phase with R software: I like what it can do, but I hate R. 

Is it just me?",t2_50rhgplx,Does anyone else not like R until they actually use it?,,t3_gqj6f8,0.64,7,,7,1590469001.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have always been in this ambivalence phase with R software: I like what it can do, but I hate R. &lt;/p&gt;

&lt;p&gt;Is it just me?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gqj6f8,o_fly_on,45,/r/datascience/comments/gqj6f8/does_anyone_else_not_like_r_until_they_actually/,https://www.reddit.com/r/datascience/comments/gqj6f8/does_anyone_else_not_like_r_until_they_actually/,1590440201.0
r/datascience,,t2_v5npq,"Remember that humans pour energy into the tools we use - Michael Waskom: ""I had been planning on working this afternoon to implement a new feature I am excited about. Then a data science influencer tweeted about how seaborn sucks...""",discussion,t3_gpwpgw,0.96,273,Discussion,273,1590380713.0,,gpwpgw,brhkim,88,/r/datascience/comments/gpwpgw/remember_that_humans_pour_energy_into_the_tools/,https://twitter.com/michaelwaskom/status/1264285989498953728?s=20,1590351913.0
r/datascience,"I have interested in sports analytics since a few years ago, but now I want to start learning it. That is why I ask you for advice on how to start with sports analytics (readings, courses, public datasets) and any career advice you can provide. Also, for those who are working on it, could you please tell me how did you start on this and what are the tasks you developed in a daily basis regarding SA.",t2_21t2bpv,Anyone working on Sports Analytics?,career,t3_gpvq28,0.96,261,Career,261,1590377337.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have interested in sports analytics since a few years ago, but now I want to start learning it. That is why I ask you for advice on how to start with sports analytics (readings, courses, public datasets) and any career advice you can provide. Also, for those who are working on it, could you please tell me how did you start on this and what are the tasks you developed in a daily basis regarding SA.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gpvq28,peterlaanguila8,74,/r/datascience/comments/gpvq28/anyone_working_on_sports_analytics/,https://www.reddit.com/r/datascience/comments/gpvq28/anyone_working_on_sports_analytics/,1590348537.0
r/datascience,"Really don't want to be bound to freelancing platforms such as Upwork/Freelancer.com but still want to find project opportunities in data science, any ideas how?",t2_14izoucv,Any ideas how I could find freelancing data science clients outside freelancing platforms?,,t3_gppx26,0.86,38,Job Search,38,1590356753.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Really don&amp;#39;t want to be bound to freelancing platforms such as Upwork/Freelancer.com but still want to find project opportunities in data science, any ideas how?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gppx26,AILaunchpad,29,/r/datascience/comments/gppx26/any_ideas_how_i_could_find_freelancing_data/,https://www.reddit.com/r/datascience/comments/gppx26/any_ideas_how_i_could_find_freelancing_data/,1590327953.0
r/datascience,"Why are 99% of the posts here about jobs or up-skilling? Please stop

I want something like ycombinator where the latest developments in technology and research are posted. Library updates, hot takes. Where there are discussions about statistics, machine learning, etc. 

I post insights here but I can't do it alone. 

I've reported nearly every post on the front page for: not being in the sticky thread, treating /r/datascience as a homework helper or crowd-sourced google. 

This sub is just overrun by college students.",,What is up with this subreddit. A plea for help,discussion,t3_gp98rt,0.82,495,Discussion,495,1590285024.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Why are 99% of the posts here about jobs or up-skilling? Please stop&lt;/p&gt;

&lt;p&gt;I want something like ycombinator where the latest developments in technology and research are posted. Library updates, hot takes. Where there are discussions about statistics, machine learning, etc. &lt;/p&gt;

&lt;p&gt;I post insights here but I can&amp;#39;t do it alone. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve reported nearly every post on the front page for: not being in the sticky thread, treating &lt;a href=""/r/datascience""&gt;/r/datascience&lt;/a&gt; as a homework helper or crowd-sourced google. &lt;/p&gt;

&lt;p&gt;This sub is just overrun by college students.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gp98rt,[deleted],122,/r/datascience/comments/gp98rt/what_is_up_with_this_subreddit_a_plea_for_help/,https://www.reddit.com/r/datascience/comments/gp98rt/what_is_up_with_this_subreddit_a_plea_for_help/,1590256224.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 24 May 2020 - 31 May 2020,,t3_gpojpv,0.93,12,Discussion,12,1590350430.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gpojpv,datascience-bot,171,/r/datascience/comments/gpojpv/weekly_entering_transitioning_thread_24_may_2020/,https://www.reddit.com/r/datascience/comments/gpojpv/weekly_entering_transitioning_thread_24_may_2020/,1590321630.0
r/datascience,,t2_wf68kb,Episode #262 Build a career in data science,career,t3_gpvdy2,0.61,5,Career,5,1590376190.0,,gpvdy2,csmidwest,4,/r/datascience/comments/gpvdy2/episode_262_build_a_career_in_data_science/,https://talkpython.fm/episodes/show/262/build-a-career-in-data-science,1590347390.0
r/datascience,"Edit: Thanks to the person who gave this gold but I would much rather prefer that you donate the amount to a cause/charity you support. Thanks!

Edit 2: Thanks to everyone who answered! All the responses were very insightful.",t2_3cazlzfl,Is anyone here into marketing analytics? How did you get into it? What are the skills needed?,discussion,t3_gp0ctd,0.89,122,Discussion,122,1590245104.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Edit: Thanks to the person who gave this gold but I would much rather prefer that you donate the amount to a cause/charity you support. Thanks!&lt;/p&gt;

&lt;p&gt;Edit 2: Thanks to everyone who answered! All the responses were very insightful.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gp0ctd,Kpopaddiction,51,/r/datascience/comments/gp0ctd/is_anyone_here_into_marketing_analytics_how_did/,https://www.reddit.com/r/datascience/comments/gp0ctd/is_anyone_here_into_marketing_analytics_how_did/,1590216304.0
r/datascience,I'm curious to hear about data science in a context that's outside of machine learning or predictive algorithms since they are not as talked about. I've heard time-series is pretty popular in finance companies (unsurprisingly) and survival analysis in some insurance companies. I'd love to hear more about how different types of statistics are being used in data science these days!,t2_5xux0a4p,Data Scientists who aren't doing ML: what kind of statistical work do you do?,discussion,t3_gomivv,0.97,315,Discussion,315,1590193714.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m curious to hear about data science in a context that&amp;#39;s outside of machine learning or predictive algorithms since they are not as talked about. I&amp;#39;ve heard time-series is pretty popular in finance companies (unsurprisingly) and survival analysis in some insurance companies. I&amp;#39;d love to hear more about how different types of statistics are being used in data science these days!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gomivv,___24601,141,/r/datascience/comments/gomivv/data_scientists_who_arent_doing_ml_what_kind_of/,https://www.reddit.com/r/datascience/comments/gomivv/data_scientists_who_arent_doing_ml_what_kind_of/,1590164914.0
r/datascience,"So I'm wondering if anyone else has had this issue before. I'm using a Plackett-Luce Latent Variable model to determine rankings based on sets of ranked data. In my dataset, the problem is occasionally the typical top 5 ranked elements (""winners"") could drop to near bottom as some anomaly. In the new updated rankings, the low ranked elements that ""beat"" the winners  immediately skyrocket to the top, even though the drops are clearly anomalies. Does anyone know of strategies to counteract this? Besides just arbitrarily picking this anomalies and excluding them from the rankings, I'm not sure if there's some form of ""smoothing"" I can do to not rapidly adjust the rankings for each set. It seems like just a single anomaly has a massive effect on the rankings, when it probably shouldn't.",t2_5idhxh2k,Plackett-Luce Latent Variable Modeling issues,education,t3_gpaskw,1.0,2,Education,2,1590290300.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I&amp;#39;m wondering if anyone else has had this issue before. I&amp;#39;m using a Plackett-Luce Latent Variable model to determine rankings based on sets of ranked data. In my dataset, the problem is occasionally the typical top 5 ranked elements (&amp;quot;winners&amp;quot;) could drop to near bottom as some anomaly. In the new updated rankings, the low ranked elements that &amp;quot;beat&amp;quot; the winners  immediately skyrocket to the top, even though the drops are clearly anomalies. Does anyone know of strategies to counteract this? Besides just arbitrarily picking this anomalies and excluding them from the rankings, I&amp;#39;m not sure if there&amp;#39;s some form of &amp;quot;smoothing&amp;quot; I can do to not rapidly adjust the rankings for each set. It seems like just a single anomaly has a massive effect on the rankings, when it probably shouldn&amp;#39;t.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gpaskw,gremlin0x,2,/r/datascience/comments/gpaskw/plackettluce_latent_variable_modeling_issues/,https://www.reddit.com/r/datascience/comments/gpaskw/plackettluce_latent_variable_modeling_issues/,1590261500.0
r/datascience,"I'm not looking to pursue a career in it, at least not for the time being. Yet, as I have time to spare during this lockdown and have a great interest in mathematics, I thought I might as well try to learn it.",t2_l4mvvgs,Is it worth investing time learning data science if I only want to freelance part-time?,discussion,t3_gpbvz0,0.57,1,Discussion,1,1590294088.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m not looking to pursue a career in it, at least not for the time being. Yet, as I have time to spare during this lockdown and have a great interest in mathematics, I thought I might as well try to learn it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gpbvz0,RowHowlx,10,/r/datascience/comments/gpbvz0/is_it_worth_investing_time_learning_data_science/,https://www.reddit.com/r/datascience/comments/gpbvz0/is_it_worth_investing_time_learning_data_science/,1590265288.0
r/datascience,"I have been practicing with a mental math app however, I still feel anxious dealing with basic operations like multiplying and subtraction. I think I have gotten my self into a negative self fulfilling prophecy. 

Does any one have any suggestions how I can overcome this incompetence/insecurity?

I’m concerned when I get into industry everyone will see me as an outlier.",t2_ymkj2,"Please excuse the cliched, Imposter Syndrome post. I still get anxiety when performing basic arithmetic although I can comprehend and explain complex concepts, e.g how a NN works. I feel like there is such a big gap in my math background. Am I alone?",discussion,t3_godbf1,0.85,129,Discussion,129,1590153941.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been practicing with a mental math app however, I still feel anxious dealing with basic operations like multiplying and subtraction. I think I have gotten my self into a negative self fulfilling prophecy. &lt;/p&gt;

&lt;p&gt;Does any one have any suggestions how I can overcome this incompetence/insecurity?&lt;/p&gt;

&lt;p&gt;I’m concerned when I get into industry everyone will see me as an outlier.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",godbf1,elisimicr,54,/r/datascience/comments/godbf1/please_excuse_the_cliched_imposter_syndrome_post/,https://www.reddit.com/r/datascience/comments/godbf1/please_excuse_the_cliched_imposter_syndrome_post/,1590125141.0
r/datascience,"I’m looking for a tool to keep track of experiments and I’m wondering if anyone has good experience with any tools out there? Ideally I’m looking something that

- uses an api so that I can just log parameters or metrics during my experimental runs
- has a decent UI where I can manually add parameters and add notes on experiments
- provides some simple comparisons between experiments.",t2_w46yz,Which experiment tracking tools do you recommend?,,t3_gp0jfd,1.0,1,,1,1590246113.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m looking for a tool to keep track of experiments and I’m wondering if anyone has good experience with any tools out there? Ideally I’m looking something that&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;uses an api so that I can just log parameters or metrics during my experimental runs&lt;/li&gt;
&lt;li&gt;has a decent UI where I can manually add parameters and add notes on experiments&lt;/li&gt;
&lt;li&gt;provides some simple comparisons between experiments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gp0jfd,yet41,4,/r/datascience/comments/gp0jfd/which_experiment_tracking_tools_do_you_recommend/,https://www.reddit.com/r/datascience/comments/gp0jfd/which_experiment_tracking_tools_do_you_recommend/,1590217313.0
r/datascience,"I saw a lot of folks that are in top management or leading financial institutions (such as banks) having MBAs, ACCA, and such, and I've always wondered if you've seen top management or successful folks having degrees or postgrads in DS?

I think it will great to see those who have studied the field putting the field into practice, especially in leadership!",t2_3z6gqvrh,"Successful people that studied DS, and now are in leadership",education,t3_gohc84,0.79,8,Education,8,1590174371.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I saw a lot of folks that are in top management or leading financial institutions (such as banks) having MBAs, ACCA, and such, and I&amp;#39;ve always wondered if you&amp;#39;ve seen top management or successful folks having degrees or postgrads in DS?&lt;/p&gt;

&lt;p&gt;I think it will great to see those who have studied the field putting the field into practice, especially in leadership!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gohc84,runnersgo,10,/r/datascience/comments/gohc84/successful_people_that_studied_ds_and_now_are_in/,https://www.reddit.com/r/datascience/comments/gohc84/successful_people_that_studied_ds_and_now_are_in/,1590145571.0
r/datascience,,,Interesting article (with a click bait-y name) Don’t Democratize Data Science,career,t3_go2joo,0.88,113,Career,113,1590115318.0,,go2joo,[deleted],84,/r/datascience/comments/go2joo/interesting_article_with_a_click_baity_name_dont/,https://builtin.com/data-science/dont-democratize-data-science,1590086518.0
r/datascience,"Wondering if anyone who’s had to remotely present a personal project as part of a technical interview would be willing to share:  
1. technologies used for presentation
2. general outline of presentation (slides first, then live demo?)
3. general tips &amp; tricks

The specific video conferencing service is irrelevant. You’re obviously going to be sharing your screen.

EDIT: the interviewers are data scientists themselves and will presumably be fairly familiar with most technical concepts in my project.",t2_11oao4,Tips for presenting a personal project via video conferencing,discussion,t3_gokeht,1.0,2,Discussion,2,1590186664.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Wondering if anyone who’s had to remotely present a personal project as part of a technical interview would be willing to share:&lt;br/&gt;
1. technologies used for presentation
2. general outline of presentation (slides first, then live demo?)
3. general tips &amp;amp; tricks&lt;/p&gt;

&lt;p&gt;The specific video conferencing service is irrelevant. You’re obviously going to be sharing your screen.&lt;/p&gt;

&lt;p&gt;EDIT: the interviewers are data scientists themselves and will presumably be fairly familiar with most technical concepts in my project.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gokeht,hendrix616,12,/r/datascience/comments/gokeht/tips_for_presenting_a_personal_project_via_video/,https://www.reddit.com/r/datascience/comments/gokeht/tips_for_presenting_a_personal_project_via_video/,1590157864.0
r/datascience,"Hi everyone, 

I work as a cook at a seafood restaurant and feel like this gives me a unique opportunity to collect some data on how much food we cook/waste a day. I would like to complete a project that predicts how much food we will sell at certain times on different days of the week, is this doable? The restaurant throws out a lot of each night, and I feel like completing a project like this could help solve this problem by predicting how much food needs to be cooked within the last hour of being open and it would also look great on a resume. Do you all have any tips on data collection or models to use? Thanks!",t2_mns2w,Data Science in a Restaurant?,projects,t3_gnpe2e,0.97,288,Projects,288,1590060575.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;

&lt;p&gt;I work as a cook at a seafood restaurant and feel like this gives me a unique opportunity to collect some data on how much food we cook/waste a day. I would like to complete a project that predicts how much food we will sell at certain times on different days of the week, is this doable? The restaurant throws out a lot of each night, and I feel like completing a project like this could help solve this problem by predicting how much food needs to be cooked within the last hour of being open and it would also look great on a resume. Do you all have any tips on data collection or models to use? Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gnpe2e,pmp1321,50,/r/datascience/comments/gnpe2e/data_science_in_a_restaurant/,https://www.reddit.com/r/datascience/comments/gnpe2e/data_science_in_a_restaurant/,1590031775.0
r/datascience,"I have experience with deploying API end points for internal apps that get maybe a hundred or so requests a day.

How does it differ from a large applications with for example hundreds of thousands a request a day, what do I need to consider?",t2_4hvq3cy6,Deploying machine learning models at scale,,t3_gnynqo,0.87,19,,19,1590102833.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have experience with deploying API end points for internal apps that get maybe a hundred or so requests a day.&lt;/p&gt;

&lt;p&gt;How does it differ from a large applications with for example hundreds of thousands a request a day, what do I need to consider?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gnynqo,ClassicRelation,12,/r/datascience/comments/gnynqo/deploying_machine_learning_models_at_scale/,https://www.reddit.com/r/datascience/comments/gnynqo/deploying_machine_learning_models_at_scale/,1590074033.0
r/datascience,"Would you consider it a ""step down"" to go from Data Scientist to Senior Analyst/Product Analyst?",t2_dayu5,How important is title?,career,t3_go4arp,1.0,7,Career,7,1590120787.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Would you consider it a &amp;quot;step down&amp;quot; to go from Data Scientist to Senior Analyst/Product Analyst?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",go4arp,TryWforWumbo,14,/r/datascience/comments/go4arp/how_important_is_title/,https://www.reddit.com/r/datascience/comments/go4arp/how_important_is_title/,1590091987.0
r/datascience,"Hello,

I've been hearing polarising opinions on using using Jupyter notebooks in production. My read is that people generally agree on notebooks being useful for exploratory analysis, but the path from there to production seems very vague and very different for different workflows.

Here is what I've found quite useful for my team, made of data analysts, data scientists and me as production engineer. We start from notebooks and gradually end up with code in .py files. It usually involves a hybrid setup of Jupyter web UI and VsCode connected remotely to SageMaker machine, opening the same dir notebooks are in.

There is not quantitative data to back it up, but I feel it didn't decrease the iteration speed and it definitely avoids a lot of ""translation"" from what they write into production code.

What are your thoughts on this?

Do you do something similar?

Is your data setup so complex that it's almost impossible to move from notebook to the production code?

How do you iterate on products where the initial exploration is needed?

How do you make sure there is no loss in the ""translation process""?

Lots of questions, I know :).",t2_2zijr2cb,Making exploratory Jupyter notebooks more production friendly,discussion,t3_gnyn98,1.0,8,Discussion,8,1590102786.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been hearing polarising opinions on using using Jupyter notebooks in production. My read is that people generally agree on notebooks being useful for exploratory analysis, but the path from there to production seems very vague and very different for different workflows.&lt;/p&gt;

&lt;p&gt;Here is what I&amp;#39;ve found quite useful for my team, made of data analysts, data scientists and me as production engineer. We start from notebooks and gradually end up with code in .py files. It usually involves a hybrid setup of Jupyter web UI and VsCode connected remotely to SageMaker machine, opening the same dir notebooks are in.&lt;/p&gt;

&lt;p&gt;There is not quantitative data to back it up, but I feel it didn&amp;#39;t decrease the iteration speed and it definitely avoids a lot of &amp;quot;translation&amp;quot; from what they write into production code.&lt;/p&gt;

&lt;p&gt;What are your thoughts on this?&lt;/p&gt;

&lt;p&gt;Do you do something similar?&lt;/p&gt;

&lt;p&gt;Is your data setup so complex that it&amp;#39;s almost impossible to move from notebook to the production code?&lt;/p&gt;

&lt;p&gt;How do you iterate on products where the initial exploration is needed?&lt;/p&gt;

&lt;p&gt;How do you make sure there is no loss in the &amp;quot;translation process&amp;quot;?&lt;/p&gt;

&lt;p&gt;Lots of questions, I know :).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gnyn98,derivablefunc,16,/r/datascience/comments/gnyn98/making_exploratory_jupyter_notebooks_more/,https://www.reddit.com/r/datascience/comments/gnyn98/making_exploratory_jupyter_notebooks_more/,1590073986.0
r/datascience,,t2_5w13df9u,What are some bad coding practice you've noticed among Data Scientists?,discussion,t3_gnetpw,0.98,269,Discussion,269,1590021774.0,,gnetpw,shlushfundbaby,204,/r/datascience/comments/gnetpw/what_are_some_bad_coding_practice_youve_noticed/,https://www.reddit.com/r/datascience/comments/gnetpw/what_are_some_bad_coding_practice_youve_noticed/,1589992974.0
r/datascience,"How do you keep your statistical knowledge fresh and not get rusty?

I haven't come across many jobs in which you need to explain *why* a model does what it does, either because they're happy when it works or they glaze over the moment you mention anything remotely technical. But you're expected to know it all in an interview if you change jobs.",t2_15h4ul,Keeping statistical knowledge fresh?,discussion,t3_gnlelq,0.87,27,Discussion,27,1590045538.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How do you keep your statistical knowledge fresh and not get rusty?&lt;/p&gt;

&lt;p&gt;I haven&amp;#39;t come across many jobs in which you need to explain &lt;em&gt;why&lt;/em&gt; a model does what it does, either because they&amp;#39;re happy when it works or they glaze over the moment you mention anything remotely technical. But you&amp;#39;re expected to know it all in an interview if you change jobs.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gnlelq,BlackJack5027,29,/r/datascience/comments/gnlelq/keeping_statistical_knowledge_fresh/,https://www.reddit.com/r/datascience/comments/gnlelq/keeping_statistical_knowledge_fresh/,1590016738.0
r/datascience,,,A foolproof way to shrink deep learning models,discussion,t3_gn4vkx,0.97,227,Discussion,227,1589978738.0,,gn4vkx,[deleted],22,/r/datascience/comments/gn4vkx/a_foolproof_way_to_shrink_deep_learning_models/,http://news.mit.edu/2020/foolproof-way-shrink-deep-learning-models-0430,1589949938.0
r/datascience,"I have this doubt regarding feature selection chapter in ISLR. In the forward and backward subset selection procedure, the textbook says ""the best model is selected"". 

So what is the ""model""? Is it a linear regression model? Polynomial regression model? What is the model using which the best subset of features are evaluated?

&amp;#x200B;

PS. Sorry if this is a really dumb question, I am new to Data Science and started off with some online courses reading ISLR.",t2_12rbzk,What is the model used in Forward and Backward feature selection?,discussion,t3_gnhv8i,0.78,5,Discussion,5,1590031123.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have this doubt regarding feature selection chapter in ISLR. In the forward and backward subset selection procedure, the textbook says &amp;quot;the best model is selected&amp;quot;. &lt;/p&gt;

&lt;p&gt;So what is the &amp;quot;model&amp;quot;? Is it a linear regression model? Polynomial regression model? What is the model using which the best subset of features are evaluated?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;PS. Sorry if this is a really dumb question, I am new to Data Science and started off with some online courses reading ISLR.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gnhv8i,JayFaraday,5,/r/datascience/comments/gnhv8i/what_is_the_model_used_in_forward_and_backward/,https://www.reddit.com/r/datascience/comments/gnhv8i/what_is_the_model_used_in_forward_and_backward/,1590002323.0
r/datascience,"I’m posting this here hoping the Data Scientists working in AMS could help me gauge whether this is a good offer.

I have 2 years experience as a DS leading projects in ML &amp; cloud architecting. I interviewed for a Senior DS role at a listed tech company. They instead offered me a medior DS role: 67k base + 10% bonus + 18k RSU(annually, can vest 25% per year). So in total the package is worth of 78k. The work content will be recommender systems and NLP. The interview went really well and I could tell that they wanted me. I also liked the interviewers who seems open and friendly.

Do you guys think 67k base+10%+18k RSUs is a fair package for a med-DS role in Amsterdam?",t2_3zt6hoi,"Offer suggestion, data scientist in Amsterdam",career,t3_gn9eu6,0.93,12,Career,12,1590001698.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m posting this here hoping the Data Scientists working in AMS could help me gauge whether this is a good offer.&lt;/p&gt;

&lt;p&gt;I have 2 years experience as a DS leading projects in ML &amp;amp; cloud architecting. I interviewed for a Senior DS role at a listed tech company. They instead offered me a medior DS role: 67k base + 10% bonus + 18k RSU(annually, can vest 25% per year). So in total the package is worth of 78k. The work content will be recommender systems and NLP. The interview went really well and I could tell that they wanted me. I also liked the interviewers who seems open and friendly.&lt;/p&gt;

&lt;p&gt;Do you guys think 67k base+10%+18k RSUs is a fair package for a med-DS role in Amsterdam?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gn9eu6,gaeioran,7,/r/datascience/comments/gn9eu6/offer_suggestion_data_scientist_in_amsterdam/,https://www.reddit.com/r/datascience/comments/gn9eu6/offer_suggestion_data_scientist_in_amsterdam/,1589972898.0
r/datascience,I'm looking to improve my understanding of how to structure the UI/UX for my data products. I too often find myself using just intuition to decide whether to build a report or dashboard and how to structure whatever product I choose. I'm never quite sure how to determine how many visualizations to include in my dashboards or how often to update them. How do good data analysts assess the needs and abilities of their audience? When should you add some flashiness to your products to encourage adoption and when should you stick with something sparse and boring? Is there a good reference or training for these questions?,t2_2cbvlar,Book or online training about structuring UI/UX for data products?,education,t3_gncbsc,1.0,4,Education,4,1590013729.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking to improve my understanding of how to structure the UI/UX for my data products. I too often find myself using just intuition to decide whether to build a report or dashboard and how to structure whatever product I choose. I&amp;#39;m never quite sure how to determine how many visualizations to include in my dashboards or how often to update them. How do good data analysts assess the needs and abilities of their audience? When should you add some flashiness to your products to encourage adoption and when should you stick with something sparse and boring? Is there a good reference or training for these questions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gncbsc,JustAnotherDataNerd,0,/r/datascience/comments/gncbsc/book_or_online_training_about_structuring_uiux/,https://www.reddit.com/r/datascience/comments/gncbsc/book_or_online_training_about_structuring_uiux/,1589984929.0
r/datascience,"Do all libraries run on a mac/linux with nvidia graphics card ? 

what laptop do you recommend that would last for years with at least 64gb RAM ? 

Can I run Excel and PowerBi on Linux/Mac OS ? 

Thank you",t2_3ftiaba8,For my next laptop should i buy a mac or windows for data science and analytics ?,discussion,t3_gnbsqz,0.73,5,Discussion,5,1590011867.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do all libraries run on a mac/linux with nvidia graphics card ? &lt;/p&gt;

&lt;p&gt;what laptop do you recommend that would last for years with at least 64gb RAM ? &lt;/p&gt;

&lt;p&gt;Can I run Excel and PowerBi on Linux/Mac OS ? &lt;/p&gt;

&lt;p&gt;Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gnbsqz,Zenith_N,13,/r/datascience/comments/gnbsqz/for_my_next_laptop_should_i_buy_a_mac_or_windows/,https://www.reddit.com/r/datascience/comments/gnbsqz/for_my_next_laptop_should_i_buy_a_mac_or_windows/,1589983067.0
r/datascience,"**Dean Hoffman from the thread** ""[A ""Data Science"" company stole my gf's ML project and reposted it as their own. What do I do?](https://www.reddit.com/r/datascience/comments/glfdmm/a_data_science_company_stole_my_gfs_ml_project/)**"" responded. He authorised me to repost his response. Here it is:**

""Under no circumstances should someone claim credit for someone else's work. I was involved in litigation against Google for something similar over 10 years ago.

[https://docs.justia.com/cases/federal/district-courts/california/cacdce/2:2004cv09484/167815/776](https://docs.justia.com/cases/federal/district-courts/california/cacdce/2:2004cv09484/167815/776)

RSS feed readers ingest content and republish it with credit to the author. This step gives the author added exposure, like how radio stations offer musicians free advertising to sell their music.

Examples of news aggregators include Google News, Drudge Report, Huffington Post, Fark, Zero Hedge, Newslookup, Newsvine, World News (WN) Network and Daily Beast, where the aggregation is entirely automatic

I see that the automated algorithm was incorrectly listing the admin as the author on some of the articles, but there was no intent to deceive. If you look, you will see that EVERY ITEM had the ""ORIGINAL SOURCE"" listed at the bottom of EACH ARTICLE, and that linked to the ORIGINAL AUTHOR. One more time: If you look, you will see that EVERY ITEM had the ""ORIGINAL SOURCE"" listed at the bottom of each piece that then linked to the ORIGINAL AUTHOR.

There was no intent to claim ownership. If so, it was a pretty hair-brained try, but I apologize to anyone who feels deserving.

Since I have no financial gain from this site, and no good deed goes unpunished, I decided to take it down. I don't need the aggravation to share useful content and authors if the reward is getting attacked.

I am an awarding winning researcher, as published in at least two national magazines. I don't need anybody else's credibility.

Many articles picked up by the RSS feeds I would be embarrassed to publish under my name.

I am confident that NOBODY, with a clue about data science, thought someone was writing hundreds of articles a week. Especially when posting the ORIGINAL SOURCE, and it links to the ORIGINAL AUTHOR at the bottom of each piece! Seriously!? SERIOUSLY!!!?

I've not made a penny from the site, nor have I ever tried (or wanted to). It was built as a news aggregator to promote the work of others and create a place to stay up to date without navigating to hundreds of sources (yes hundreds). That IS what news aggregators do! I received many thank you notes from authors happy to have extra exposure.

I apologize for my oversite in the way the aggregation algorithm posted. In hindsight, I wish the ""Original Source and Author"" link was on the top rather than the bottom (besides a few other items). I assure you my intent was genuinely excellent; I was trying to give those interested a convenient news aggregation a resource.

I don't create excuses, but please, it is sophomoric to jump from unintentional RSS feed read result to first-degree murder.

Trust me; if anybody worth their weight in Data Science thought you or anybody else got fooled by something so obvious, they would likely think you were in the wrong profession. I asked my 7th-grade daughter to read a few articles and then decipher who the source and author were, and she had NO PROBLEM correctly identifying them (hint, it was not me). I'm pretty sure you can relax.

Again, look at all the ORIGINAL SOURCES and AUTHORS linked to in every case.

I will use the site for personal purposes to save my own time; it got built as my individual RSS reader; I will return it to that.

I apologize to those authors and readers that were happy I had put in the work to create the content aggregation location and add more exposure to others' work. (with zero pay to me)

If you intended to be disruptive, trolling, punitive, and silencing, congratulations, job well done, not worth my time anymore. Honestly, I was getting a little tired of putting in the work anyway. Feel free to navigate the hundreds of sources on your own (yes hundreds); it should only take you 10 or 12 hours a day. Once again, my apologies for my failed try at providing you time-saving value and exposure. Site is down, time-saving, content aggregating, author visibility-enhancing site is no longer available.

Maybe you will enjoy these guys news aggregation: [https://news.google.com/search?q=Artificial%20Intelligence&amp;hl=en-US&amp;gl=US&amp;ceid=US%3Aen](https://news.google.com/search?q=Artificial%20Intelligence&amp;hl=en-US&amp;gl=US&amp;ceid=US%3Aen)""",t2_ip8ut,"My Apologies - From ""A Data Science company stole my gf's ML project and reposted it as their own. What do I do?""",career,t3_gmirks,0.82,420,Career,420,1589896415.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;Dean Hoffman from the thread&lt;/strong&gt; &amp;quot;&lt;a href=""https://www.reddit.com/r/datascience/comments/glfdmm/a_data_science_company_stole_my_gfs_ml_project/""&gt;A &amp;quot;Data Science&amp;quot; company stole my gf&amp;#39;s ML project and reposted it as their own. What do I do?&lt;/a&gt;&lt;strong&gt;&amp;quot; responded. He authorised me to repost his response. Here it is:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&amp;quot;Under no circumstances should someone claim credit for someone else&amp;#39;s work. I was involved in litigation against Google for something similar over 10 years ago.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://docs.justia.com/cases/federal/district-courts/california/cacdce/2:2004cv09484/167815/776""&gt;https://docs.justia.com/cases/federal/district-courts/california/cacdce/2:2004cv09484/167815/776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;RSS feed readers ingest content and republish it with credit to the author. This step gives the author added exposure, like how radio stations offer musicians free advertising to sell their music.&lt;/p&gt;

&lt;p&gt;Examples of news aggregators include Google News, Drudge Report, Huffington Post, Fark, Zero Hedge, Newslookup, Newsvine, World News (WN) Network and Daily Beast, where the aggregation is entirely automatic&lt;/p&gt;

&lt;p&gt;I see that the automated algorithm was incorrectly listing the admin as the author on some of the articles, but there was no intent to deceive. If you look, you will see that EVERY ITEM had the &amp;quot;ORIGINAL SOURCE&amp;quot; listed at the bottom of EACH ARTICLE, and that linked to the ORIGINAL AUTHOR. One more time: If you look, you will see that EVERY ITEM had the &amp;quot;ORIGINAL SOURCE&amp;quot; listed at the bottom of each piece that then linked to the ORIGINAL AUTHOR.&lt;/p&gt;

&lt;p&gt;There was no intent to claim ownership. If so, it was a pretty hair-brained try, but I apologize to anyone who feels deserving.&lt;/p&gt;

&lt;p&gt;Since I have no financial gain from this site, and no good deed goes unpunished, I decided to take it down. I don&amp;#39;t need the aggravation to share useful content and authors if the reward is getting attacked.&lt;/p&gt;

&lt;p&gt;I am an awarding winning researcher, as published in at least two national magazines. I don&amp;#39;t need anybody else&amp;#39;s credibility.&lt;/p&gt;

&lt;p&gt;Many articles picked up by the RSS feeds I would be embarrassed to publish under my name.&lt;/p&gt;

&lt;p&gt;I am confident that NOBODY, with a clue about data science, thought someone was writing hundreds of articles a week. Especially when posting the ORIGINAL SOURCE, and it links to the ORIGINAL AUTHOR at the bottom of each piece! Seriously!? SERIOUSLY!!!?&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve not made a penny from the site, nor have I ever tried (or wanted to). It was built as a news aggregator to promote the work of others and create a place to stay up to date without navigating to hundreds of sources (yes hundreds). That IS what news aggregators do! I received many thank you notes from authors happy to have extra exposure.&lt;/p&gt;

&lt;p&gt;I apologize for my oversite in the way the aggregation algorithm posted. In hindsight, I wish the &amp;quot;Original Source and Author&amp;quot; link was on the top rather than the bottom (besides a few other items). I assure you my intent was genuinely excellent; I was trying to give those interested a convenient news aggregation a resource.&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t create excuses, but please, it is sophomoric to jump from unintentional RSS feed read result to first-degree murder.&lt;/p&gt;

&lt;p&gt;Trust me; if anybody worth their weight in Data Science thought you or anybody else got fooled by something so obvious, they would likely think you were in the wrong profession. I asked my 7th-grade daughter to read a few articles and then decipher who the source and author were, and she had NO PROBLEM correctly identifying them (hint, it was not me). I&amp;#39;m pretty sure you can relax.&lt;/p&gt;

&lt;p&gt;Again, look at all the ORIGINAL SOURCES and AUTHORS linked to in every case.&lt;/p&gt;

&lt;p&gt;I will use the site for personal purposes to save my own time; it got built as my individual RSS reader; I will return it to that.&lt;/p&gt;

&lt;p&gt;I apologize to those authors and readers that were happy I had put in the work to create the content aggregation location and add more exposure to others&amp;#39; work. (with zero pay to me)&lt;/p&gt;

&lt;p&gt;If you intended to be disruptive, trolling, punitive, and silencing, congratulations, job well done, not worth my time anymore. Honestly, I was getting a little tired of putting in the work anyway. Feel free to navigate the hundreds of sources on your own (yes hundreds); it should only take you 10 or 12 hours a day. Once again, my apologies for my failed try at providing you time-saving value and exposure. Site is down, time-saving, content aggregating, author visibility-enhancing site is no longer available.&lt;/p&gt;

&lt;p&gt;Maybe you will enjoy these guys news aggregation: &lt;a href=""https://news.google.com/search?q=Artificial%20Intelligence&amp;amp;hl=en-US&amp;amp;gl=US&amp;amp;ceid=US%3Aen""&gt;https://news.google.com/search?q=Artificial%20Intelligence&amp;amp;hl=en-US&amp;amp;gl=US&amp;amp;ceid=US%3Aen&lt;/a&gt;&amp;quot;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gmirks,eawal,130,/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/,https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/,1589867615.0
r/datascience,"Hi guys,

Just a quick one. What are the best drag and drop (or other user friendly) ML or Deep Learning platforms available in the market? 

I know of  Data Robot and Dataiku. What is your view of these and are there others? 

For context. I'm a startup owner (no technical data science background) and am looking to quickly create and integrate some predictive models into the platform we are developing. 

First prize would be to develop our own algorithms and analytics platform, but that will take time, so wanted to explore alternatives using existing platforms.

All thoughts and feedback appreciated!",t2_3h03za08,Best ML platforms for a non-technical startup owner,discussion,t3_gn5ddq,0.67,3,Discussion,3,1589981066.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys,&lt;/p&gt;

&lt;p&gt;Just a quick one. What are the best drag and drop (or other user friendly) ML or Deep Learning platforms available in the market? &lt;/p&gt;

&lt;p&gt;I know of  Data Robot and Dataiku. What is your view of these and are there others? &lt;/p&gt;

&lt;p&gt;For context. I&amp;#39;m a startup owner (no technical data science background) and am looking to quickly create and integrate some predictive models into the platform we are developing. &lt;/p&gt;

&lt;p&gt;First prize would be to develop our own algorithms and analytics platform, but that will take time, so wanted to explore alternatives using existing platforms.&lt;/p&gt;

&lt;p&gt;All thoughts and feedback appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gn5ddq,Njabz,18,/r/datascience/comments/gn5ddq/best_ml_platforms_for_a_nontechnical_startup_owner/,https://www.reddit.com/r/datascience/comments/gn5ddq/best_ml_platforms_for_a_nontechnical_startup_owner/,1589952266.0
r/datascience,"I'm trying to cluster a rather large data set (~400k samples, somewhere between 20-30 features). The features are mostly continuous, although there are some discrete/categorical variables.

Because of the mixed data types, I'm not sure if k-means is what I want to use. I tried running a DBSCAN but after it was running for what seemed like forever I gave up.

What clustering algorithm is recommended for such a large number of samples? What would give me a reasonable run time, while also dealing with the fact that I don't just have continuous, numerical data?

For an idea of the data I have, it's basically information about customers. I have number of accounts (discrete variable), account status (e.g, Gold, Platinum, etc. this is my cateogorical) and then some other things like age/how long they've been a customer, how much they've spent etc. (continuous variables).",t2_82jo4,Clustering a large dataset in python (sklearn),discussion,t3_gmx51a,0.91,9,Discussion,9,1589950676.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to cluster a rather large data set (~400k samples, somewhere between 20-30 features). The features are mostly continuous, although there are some discrete/categorical variables.&lt;/p&gt;

&lt;p&gt;Because of the mixed data types, I&amp;#39;m not sure if k-means is what I want to use. I tried running a DBSCAN but after it was running for what seemed like forever I gave up.&lt;/p&gt;

&lt;p&gt;What clustering algorithm is recommended for such a large number of samples? What would give me a reasonable run time, while also dealing with the fact that I don&amp;#39;t just have continuous, numerical data?&lt;/p&gt;

&lt;p&gt;For an idea of the data I have, it&amp;#39;s basically information about customers. I have number of accounts (discrete variable), account status (e.g, Gold, Platinum, etc. this is my cateogorical) and then some other things like age/how long they&amp;#39;ve been a customer, how much they&amp;#39;ve spent etc. (continuous variables).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gmx51a,mydogissnoring,17,/r/datascience/comments/gmx51a/clustering_a_large_dataset_in_python_sklearn/,https://www.reddit.com/r/datascience/comments/gmx51a/clustering_a_large_dataset_in_python_sklearn/,1589921876.0
r/datascience,"I have been collecting data for the past couple of months, that includes my daily mood, activities I performed, physical activity (steps, calories and such) as well as sleep.
I already curated my mood dataset (by that I mean I made it readable and interpretable) and will proceed with the physical one relatively soon. 

I've been struggling to define what kind of insights I want to get out of it, outside of the simple correlation between mood, physical activity and sleep. 
Would anyone with a bit of experience be interested in looking at the data and pointing me in the right direction? Or even working with me on offering a similar service to others if it ends up providing any kind of value?
Let me know and I can share more details!",t2_h99rtgp,Physical &amp; mood data interpretation,projects,t3_gmykak,1.0,3,Projects,3,1589955235.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been collecting data for the past couple of months, that includes my daily mood, activities I performed, physical activity (steps, calories and such) as well as sleep.
I already curated my mood dataset (by that I mean I made it readable and interpretable) and will proceed with the physical one relatively soon. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been struggling to define what kind of insights I want to get out of it, outside of the simple correlation between mood, physical activity and sleep. 
Would anyone with a bit of experience be interested in looking at the data and pointing me in the right direction? Or even working with me on offering a similar service to others if it ends up providing any kind of value?
Let me know and I can share more details!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gmykak,FatNonconformist,9,/r/datascience/comments/gmykak/physical_mood_data_interpretation/,https://www.reddit.com/r/datascience/comments/gmykak/physical_mood_data_interpretation/,1589926435.0
r/datascience,"Hello fellow data people. I was recently working with a dataset I had cleaned up and filtered. Machine learning (Tensorflow, custum, Microsoft Azure), trend functions (linear, exponential, etc.), and a bunch of other forecasting techniques had terrible results (yes, I tried using autoregressive inputs). I then plotted the frequency distribution of the outputs of the dataset, only to find out that it is an exponential probability distribution. Basically, there's 8 billion 0s, 3 billion 1s, 1.5 billion 2s (they're count values). I was wondering what useful forecasting can even be done when a dataset looks like this. Honestly, I can't even imagine any useful summary statistics (like, ""Oh, great! I have a 90% chance of it being less than 2""). This is like the third dataset I've had that looks like this and I'm always lost when I get them (I've done hackathons in the past that have had this same problem). Any help would be appreciated.",t2_s1q046f,Get Use Out of Exponential Probability Distribution,projects,t3_gmscll,0.81,6,Projects,6,1589935959.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello fellow data people. I was recently working with a dataset I had cleaned up and filtered. Machine learning (Tensorflow, custum, Microsoft Azure), trend functions (linear, exponential, etc.), and a bunch of other forecasting techniques had terrible results (yes, I tried using autoregressive inputs). I then plotted the frequency distribution of the outputs of the dataset, only to find out that it is an exponential probability distribution. Basically, there&amp;#39;s 8 billion 0s, 3 billion 1s, 1.5 billion 2s (they&amp;#39;re count values). I was wondering what useful forecasting can even be done when a dataset looks like this. Honestly, I can&amp;#39;t even imagine any useful summary statistics (like, &amp;quot;Oh, great! I have a 90% chance of it being less than 2&amp;quot;). This is like the third dataset I&amp;#39;ve had that looks like this and I&amp;#39;m always lost when I get them (I&amp;#39;ve done hackathons in the past that have had this same problem). Any help would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gmscll,muh_reddit_accout,9,/r/datascience/comments/gmscll/get_use_out_of_exponential_probability/,https://www.reddit.com/r/datascience/comments/gmscll/get_use_out_of_exponential_probability/,1589907159.0
r/datascience,"I am implementing a semantic search engine using BERT (using cosine distance) To a certain extend the method is able to find out sentences in a high level context. However when it comes narrowed down context of the sentence, it gives several issues.

Example: If my search term is ""Wrong Product"", the search engine might match with sentences like ""I bought a washing machine but it was defective"".

I understand that the fixes to these is always finding some equilibrium and live with minor errors.

However if there are any rules, techniques which has improved your semantic search implementation accuracy please do share.",t2_egq7bhn,What are some techniques to improve contextual accuracy of semantic search engine using BERT?,discussion,t3_gmubil,1.0,2,Discussion,2,1589941970.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am implementing a semantic search engine using BERT (using cosine distance) To a certain extend the method is able to find out sentences in a high level context. However when it comes narrowed down context of the sentence, it gives several issues.&lt;/p&gt;

&lt;p&gt;Example: If my search term is &amp;quot;Wrong Product&amp;quot;, the search engine might match with sentences like &amp;quot;I bought a washing machine but it was defective&amp;quot;.&lt;/p&gt;

&lt;p&gt;I understand that the fixes to these is always finding some equilibrium and live with minor errors.&lt;/p&gt;

&lt;p&gt;However if there are any rules, techniques which has improved your semantic search implementation accuracy please do share.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gmubil,abdush,5,/r/datascience/comments/gmubil/what_are_some_techniques_to_improve_contextual/,https://www.reddit.com/r/datascience/comments/gmubil/what_are_some_techniques_to_improve_contextual/,1589913170.0
r/datascience,"So there have been a couple of posts about content sharing done wrong:  [https://www.reddit.com/r/datascience/comments/gmirks/my\_apologies\_from\_a\_data\_science\_company\_stole\_my/](https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/) 

See what I did there? I posted a link with a bit of an explanation. That's fine. If you want to know more, you have to go to their content on their site. We all do that in our social media feeds. Putting all their content on my site so readers don't need to go to theirs is theft. It doesn't matter if I put the attribution somewhere with the post. No permission=theft.

When another site wants to repost something I've written, they send me a message and ask for permission. That's been the way it is done for the eight years I have been writing. With a site like KDNuggets, I am always good with giving them the OK and not asking for compensation. Some major outlets will ask me to rebuild a post to appeal to their target audience. They have millions of readers. I do that for free too.

I have worked with consulting companies. They want content to drive people to their site as a form of organic marketing. It's usually pretty fluffy, buzzword bingo type posts. I get paid for that. If someone is advertising their services on the site, they are making money off that site and you should too.

I have worked with companies that make products. They want technical content to explain how to use their product in the real world. Again, they use that content to market their products. I get paid for that and you should too.

In the research world, works are cited. There can be a longer quotation from the original work which will have the primary authors' names next to it. Supporting works without quotes will be linked to at the end of the research paper. That's fine. Copy paste research, paraphrasing, releasing implementations as original works, all of that is plagiarism. That gets you blacklisted.

I have posted content that was very close to someone else's. They posted first. I issued an apology and a link to their content. It happens. The right response is to put your hand up and say, ""I messed up. I must have seen their post and that triggered mine."" No excuses. I felt like garbage for doing it.

Hopefully that helps. If you have any questions about re-purposing content, let me know.",t2_2ort2os7,"Rules for sharing machine learning content of all kinds or ""What that tool should have done.""",discussion,t3_gmq9ss,0.56,1,Discussion,1,1589929495.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So there have been a couple of posts about content sharing done wrong:  &lt;a href=""https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/""&gt;https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;See what I did there? I posted a link with a bit of an explanation. That&amp;#39;s fine. If you want to know more, you have to go to their content on their site. We all do that in our social media feeds. Putting all their content on my site so readers don&amp;#39;t need to go to theirs is theft. It doesn&amp;#39;t matter if I put the attribution somewhere with the post. No permission=theft.&lt;/p&gt;

&lt;p&gt;When another site wants to repost something I&amp;#39;ve written, they send me a message and ask for permission. That&amp;#39;s been the way it is done for the eight years I have been writing. With a site like KDNuggets, I am always good with giving them the OK and not asking for compensation. Some major outlets will ask me to rebuild a post to appeal to their target audience. They have millions of readers. I do that for free too.&lt;/p&gt;

&lt;p&gt;I have worked with consulting companies. They want content to drive people to their site as a form of organic marketing. It&amp;#39;s usually pretty fluffy, buzzword bingo type posts. I get paid for that. If someone is advertising their services on the site, they are making money off that site and you should too.&lt;/p&gt;

&lt;p&gt;I have worked with companies that make products. They want technical content to explain how to use their product in the real world. Again, they use that content to market their products. I get paid for that and you should too.&lt;/p&gt;

&lt;p&gt;In the research world, works are cited. There can be a longer quotation from the original work which will have the primary authors&amp;#39; names next to it. Supporting works without quotes will be linked to at the end of the research paper. That&amp;#39;s fine. Copy paste research, paraphrasing, releasing implementations as original works, all of that is plagiarism. That gets you blacklisted.&lt;/p&gt;

&lt;p&gt;I have posted content that was very close to someone else&amp;#39;s. They posted first. I issued an apology and a link to their content. It happens. The right response is to put your hand up and say, &amp;quot;I messed up. I must have seen their post and that triggered mine.&amp;quot; No excuses. I felt like garbage for doing it.&lt;/p&gt;

&lt;p&gt;Hopefully that helps. If you have any questions about re-purposing content, let me know.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gmq9ss,warmremy,3,/r/datascience/comments/gmq9ss/rules_for_sharing_machine_learning_content_of_all/,https://www.reddit.com/r/datascience/comments/gmq9ss/rules_for_sharing_machine_learning_content_of_all/,1589900695.0
r/datascience,"As this NGram link below from google suggests, the recent use of “deep learning” has skyrocketed. Curiously, though, it was used at times well into the past. Anyone aware of how this term got adopted for use in machine learning?

https://books.google.com/ngrams/graph?content=Deep+learning&amp;year_start=1800&amp;year_end=2008&amp;corpus=15&amp;smoothing=3&amp;share=&amp;direct_url=t1%3B%2CDeep%20learning%3B%2Cc0",t2_fwbbn,Where did the term deep learning come from and how did it get associated with artificial intelligent approaches to machine learning?,discussion,t3_gm3yh7,0.82,32,Discussion,32,1589845778.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As this NGram link below from google suggests, the recent use of “deep learning” has skyrocketed. Curiously, though, it was used at times well into the past. Anyone aware of how this term got adopted for use in machine learning?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://books.google.com/ngrams/graph?content=Deep+learning&amp;amp;year_start=1800&amp;amp;year_end=2008&amp;amp;corpus=15&amp;amp;smoothing=3&amp;amp;share=&amp;amp;direct_url=t1%3B%2CDeep%20learning%3B%2Cc0""&gt;https://books.google.com/ngrams/graph?content=Deep+learning&amp;amp;year_start=1800&amp;amp;year_end=2008&amp;amp;corpus=15&amp;amp;smoothing=3&amp;amp;share=&amp;amp;direct_url=t1%3B%2CDeep%20learning%3B%2Cc0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gm3yh7,Frogmarsh,19,/r/datascience/comments/gm3yh7/where_did_the_term_deep_learning_come_from_and/,https://www.reddit.com/r/datascience/comments/gm3yh7/where_did_the_term_deep_learning_come_from_and/,1589816978.0
r/datascience,"I’m posting this here hoping the Data Scientists working in AMS could help me gauge whether this is a good offer.

I have a CS bachelor and DS master (cum laude for both) with 2 years experience in ML &amp; cloud architecting. I interviewed for a Senior DS role at a tech company. They instead offered me a medior DS role: 65k base + 10% bonus + 18k RSU(annually, can vest 25% per year). I managed to negotiate the base to 67k. So in total the package is worth of 78k. The work content will be recommender systems and NLP. The interview went really well and I could tell that they wanted me. I also liked the interviewers who seems open and friendly.

I initially tried to negotiate a 10% raise on the base which I then lowered to 5% during negotiation (cause they said 10% would lead to a senior role) but eventually they come back with a 3% instead.

Do you guys think this is a fair package for a med-DS role in Amsterdam?",t2_3zt6hoi,Data scientist offer in Amsterdam,career,t3_gmpbam,0.33,0,Career,0,1589926312.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m posting this here hoping the Data Scientists working in AMS could help me gauge whether this is a good offer.&lt;/p&gt;

&lt;p&gt;I have a CS bachelor and DS master (cum laude for both) with 2 years experience in ML &amp;amp; cloud architecting. I interviewed for a Senior DS role at a tech company. They instead offered me a medior DS role: 65k base + 10% bonus + 18k RSU(annually, can vest 25% per year). I managed to negotiate the base to 67k. So in total the package is worth of 78k. The work content will be recommender systems and NLP. The interview went really well and I could tell that they wanted me. I also liked the interviewers who seems open and friendly.&lt;/p&gt;

&lt;p&gt;I initially tried to negotiate a 10% raise on the base which I then lowered to 5% during negotiation (cause they said 10% would lead to a senior role) but eventually they come back with a 3% instead.&lt;/p&gt;

&lt;p&gt;Do you guys think this is a fair package for a med-DS role in Amsterdam?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gmpbam,gaeioran,7,/r/datascience/comments/gmpbam/data_scientist_offer_in_amsterdam/,https://www.reddit.com/r/datascience/comments/gmpbam/data_scientist_offer_in_amsterdam/,1589897512.0
r/datascience,"Dean Hoffman responds: [https://www.reddit.com/r/datascience/comments/gmirks/my\_apologies\_from\_a\_data\_science\_company\_stole\_my/](https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/)

Hi,

My girlfriend is a 22 year old university student passionate about data science, and she just posted my first article on Medium using Machine-Learning (that took her months of research and coding to put together). Her post only has about 500 views, but to her surprise today a reddit user called [**Dean-Hoffman**](https://www.reddit.com/user/Dean-Hoffman/) **posted a link to his own data science company where he copy-pasted her article.** He didn't contact her about reposting it, didn't give her proper credit and **ridiculously added a ""Contact Data Scientist"" at the end with his name on it**. On the article, he clearly stated he is the author in multiple locations. This is the ""Data Science"" company that links from the article on his website: [https://www.actionablelabs.com/](https://www.actionablelabs.com/)

Apparently the guy Dean Hoffman is the ""founder"" of the company and refers to himself on the About Us as **""offering the highest commitment to excellence, personal integrity, and business ethics.""**

Update: Hey, this is the girlfriend that wrote the article. First of all, thank you all that made the time to reply, research and help me find answers. It's really appreciated.  So far, this is what we know about this person (or people):

\- This website has been stealing hundreds, if not thousands, of data science projects and articles from legitimate data scientists and writers.

\- The stolen content website in definitely bot-operated as the owner posts dozens of articles a day, completely copy+paste, mainly from Medium, TechCrunch and Towards Data Science.

\- It's confirmed that Dean-Hoffman from the Linkedin that links from his company (Actionable Labs) is a real person and the same Dean-Hoffman that is stealing content and running a data company.

\- If you go on his linkedin, under ""Data Scientist - Pennsylvania Department of General Services"" you will find that he mentions ""Actionable Insights"" (the stolen content website) in one of his experiences. Completely absurd.

UPDATE 2: Medium and TDS unfortunately can't do much for me individually as the authors are the ones who own the rights to the articles. TDS will try to reach out to the owner and ask them to take the posts down. I hope they see that their whole website is being copied, which would most likely infringe their TOS.

Please don't comment anything that contains the words ""copyright"", ""infringement"" or related words on her article as it may trigger keyword algorithms that delete copyrighted articles posted to Medium (and thus could have her article deleted). Thank you!

This is his post on reddit: [https://www.reddit.com/user/Dean-Hoffman/comments/gkoxpd/ai\_and\_real\_state\_predicting\_rental\_prices\_in/](https://www.reddit.com/user/Dean-Hoffman/comments/gkoxpd/ai_and_real_state_predicting_rental_prices_in/)

This is the article he stole from her: [https://www.actionableinsights.org/ai-and-real-state-predicting-rental-prices-in-amsterdam/](https://www.actionableinsights.org/ai-and-real-state-predicting-rental-prices-in-amsterdam/)

This is her article, posted on Medium, which has very strict plagiarism protections posted on April 24th: [https://towardsdatascience.com/ai-and-real-state-renting-in-amsterdam-part-1-5fce18238dbc](https://towardsdatascience.com/ai-and-real-state-renting-in-amsterdam-part-1-5fce18238dbc)",t2_ip8ut,"A ""Data Science"" company stole my gf's ML project and reposted it as their own. What do I do?",career,t3_glfdmm,0.97,1448,Career,1448,1589750768.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Dean Hoffman responds: &lt;a href=""https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/""&gt;https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;My girlfriend is a 22 year old university student passionate about data science, and she just posted my first article on Medium using Machine-Learning (that took her months of research and coding to put together). Her post only has about 500 views, but to her surprise today a reddit user called &lt;a href=""https://www.reddit.com/user/Dean-Hoffman/""&gt;&lt;strong&gt;Dean-Hoffman&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;posted a link to his own data science company where he copy-pasted her article.&lt;/strong&gt; He didn&amp;#39;t contact her about reposting it, didn&amp;#39;t give her proper credit and &lt;strong&gt;ridiculously added a &amp;quot;Contact Data Scientist&amp;quot; at the end with his name on it&lt;/strong&gt;. On the article, he clearly stated he is the author in multiple locations. This is the &amp;quot;Data Science&amp;quot; company that links from the article on his website: &lt;a href=""https://www.actionablelabs.com/""&gt;https://www.actionablelabs.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Apparently the guy Dean Hoffman is the &amp;quot;founder&amp;quot; of the company and refers to himself on the About Us as &lt;strong&gt;&amp;quot;offering the highest commitment to excellence, personal integrity, and business ethics.&amp;quot;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Update: Hey, this is the girlfriend that wrote the article. First of all, thank you all that made the time to reply, research and help me find answers. It&amp;#39;s really appreciated.  So far, this is what we know about this person (or people):&lt;/p&gt;

&lt;p&gt;- This website has been stealing hundreds, if not thousands, of data science projects and articles from legitimate data scientists and writers.&lt;/p&gt;

&lt;p&gt;- The stolen content website in definitely bot-operated as the owner posts dozens of articles a day, completely copy+paste, mainly from Medium, TechCrunch and Towards Data Science.&lt;/p&gt;

&lt;p&gt;- It&amp;#39;s confirmed that Dean-Hoffman from the Linkedin that links from his company (Actionable Labs) is a real person and the same Dean-Hoffman that is stealing content and running a data company.&lt;/p&gt;

&lt;p&gt;- If you go on his linkedin, under &amp;quot;Data Scientist - Pennsylvania Department of General Services&amp;quot; you will find that he mentions &amp;quot;Actionable Insights&amp;quot; (the stolen content website) in one of his experiences. Completely absurd.&lt;/p&gt;

&lt;p&gt;UPDATE 2: Medium and TDS unfortunately can&amp;#39;t do much for me individually as the authors are the ones who own the rights to the articles. TDS will try to reach out to the owner and ask them to take the posts down. I hope they see that their whole website is being copied, which would most likely infringe their TOS.&lt;/p&gt;

&lt;p&gt;Please don&amp;#39;t comment anything that contains the words &amp;quot;copyright&amp;quot;, &amp;quot;infringement&amp;quot; or related words on her article as it may trigger keyword algorithms that delete copyrighted articles posted to Medium (and thus could have her article deleted). Thank you!&lt;/p&gt;

&lt;p&gt;This is his post on reddit: &lt;a href=""https://www.reddit.com/user/Dean-Hoffman/comments/gkoxpd/ai_and_real_state_predicting_rental_prices_in/""&gt;https://www.reddit.com/user/Dean-Hoffman/comments/gkoxpd/ai_and_real_state_predicting_rental_prices_in/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is the article he stole from her: &lt;a href=""https://www.actionableinsights.org/ai-and-real-state-predicting-rental-prices-in-amsterdam/""&gt;https://www.actionableinsights.org/ai-and-real-state-predicting-rental-prices-in-amsterdam/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is her article, posted on Medium, which has very strict plagiarism protections posted on April 24th: &lt;a href=""https://towardsdatascience.com/ai-and-real-state-renting-in-amsterdam-part-1-5fce18238dbc""&gt;https://towardsdatascience.com/ai-and-real-state-renting-in-amsterdam-part-1-5fce18238dbc&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",glfdmm,eawal,80,/r/datascience/comments/glfdmm/a_data_science_company_stole_my_gfs_ml_project/,https://www.reddit.com/r/datascience/comments/glfdmm/a_data_science_company_stole_my_gfs_ml_project/,1589721968.0
r/datascience,"For example you have a dataset from the years 2015-2019. Would you have the training data be 2015-2018, and the test data be 2019. Or, you could use training data from every year, and the test data would be small chunks each year.",t2_4cu8moke,"If you are making a machine learning algorithm that takes place over a period of time, would you make the test data the most recent year or is it a better idea to use test data from every year?",discussion,t3_glclxb,0.87,43,Discussion,43,1589736701.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For example you have a dataset from the years 2015-2019. Would you have the training data be 2015-2018, and the test data be 2019. Or, you could use training data from every year, and the test data would be small chunks each year.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",glclxb,SwoleJohll,23,/r/datascience/comments/glclxb/if_you_are_making_a_machine_learning_algorithm/,https://www.reddit.com/r/datascience/comments/glclxb/if_you_are_making_a_machine_learning_algorithm/,1589707901.0
r/datascience,"Welcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).",t2_4l4cxw07,Weekly Entering &amp; Transitioning Thread | 17 May 2020 - 24 May 2020,,t3_gle83b,0.83,7,Discussion,7,1589745630.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;
&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;
&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;
&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;
&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=""https://www.reddit.com/r/datascience/wiki/frequently-asked-questions""&gt;FAQ&lt;/a&gt; and [Resources](Resources) pages on our wiki. You can also search for answers in &lt;a href=""https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new""&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gle83b,datascience-bot,173,/r/datascience/comments/gle83b/weekly_entering_transitioning_thread_17_may_2020/,https://www.reddit.com/r/datascience/comments/gle83b/weekly_entering_transitioning_thread_17_may_2020/,1589716830.0
r/datascience,"TLDR; DS working at a bank with images/nlp but having an affair with Time Series (I love this). Haven't found a job on that (so no experience) and recently found a position at the current workplace involved with Risk (might not have ts either). Seeking for advice. 

Hello everyone! 

I'm a DS working at an important Bank in my country. Here I've been dealing with solving problems with unstructured data, like videos, images and text. It's being interesting, but I feel quite unsatisfied. I mean, I studied economics and I'm doing a MSc in Statistics. I love time series in a theoretical way, since I can't find a job that works with them. 

I thought that working at a bank would be cool and have some forecast related projects I could work on... but I couldn't work on any.  

You see in my department there are many areas for data analysis, but not for data modeling, except mine and other. The other area makes churn models, and sometimes recommendation systems. 

I feel I'm taking a wrong path for my future. I have no finance related experience (images, text?) Neither time series Modelling experience (aside from the theoretical one). 

I want to change and I recently found a position at the bank that deals with Risk and I think I might go for it (it's no time series related, but is bank related).  But my boss and the director of the area I work on don't want me to move. They say they really like my work, and that we have many projects we can work on, particularly since my area is gaining a lot of credibility. 

I don't know what to do. I'm not sure if the position in Risk involves modelling and predicting as much as I'd like, or if it will just be analyzing and giving back raw numbers. 

Should I stay and keep looking for TS related jobs, or change to the Risk to gain insights and learn from the bank duties and may find place for forecasting? Should I just take this, grow in this side and hope to find something in the future? 

I'm very confused. And I think that this decision could impact my future, my happiness and many things in my life.",t2_11ggjx7,Advice? I like Time Series but don't have experience in it (just in other stuff),career,t3_gl1uen,0.94,106,Career,106,1589690035.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TLDR; DS working at a bank with images/nlp but having an affair with Time Series (I love this). Haven&amp;#39;t found a job on that (so no experience) and recently found a position at the current workplace involved with Risk (might not have ts either). Seeking for advice. &lt;/p&gt;

&lt;p&gt;Hello everyone! &lt;/p&gt;

&lt;p&gt;I&amp;#39;m a DS working at an important Bank in my country. Here I&amp;#39;ve been dealing with solving problems with unstructured data, like videos, images and text. It&amp;#39;s being interesting, but I feel quite unsatisfied. I mean, I studied economics and I&amp;#39;m doing a MSc in Statistics. I love time series in a theoretical way, since I can&amp;#39;t find a job that works with them. &lt;/p&gt;

&lt;p&gt;I thought that working at a bank would be cool and have some forecast related projects I could work on... but I couldn&amp;#39;t work on any.  &lt;/p&gt;

&lt;p&gt;You see in my department there are many areas for data analysis, but not for data modeling, except mine and other. The other area makes churn models, and sometimes recommendation systems. &lt;/p&gt;

&lt;p&gt;I feel I&amp;#39;m taking a wrong path for my future. I have no finance related experience (images, text?) Neither time series Modelling experience (aside from the theoretical one). &lt;/p&gt;

&lt;p&gt;I want to change and I recently found a position at the bank that deals with Risk and I think I might go for it (it&amp;#39;s no time series related, but is bank related).  But my boss and the director of the area I work on don&amp;#39;t want me to move. They say they really like my work, and that we have many projects we can work on, particularly since my area is gaining a lot of credibility. &lt;/p&gt;

&lt;p&gt;I don&amp;#39;t know what to do. I&amp;#39;m not sure if the position in Risk involves modelling and predicting as much as I&amp;#39;d like, or if it will just be analyzing and giving back raw numbers. &lt;/p&gt;

&lt;p&gt;Should I stay and keep looking for TS related jobs, or change to the Risk to gain insights and learn from the bank duties and may find place for forecasting? Should I just take this, grow in this side and hope to find something in the future? &lt;/p&gt;

&lt;p&gt;I&amp;#39;m very confused. And I think that this decision could impact my future, my happiness and many things in my life.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gl1uen,saikjuan,29,/r/datascience/comments/gl1uen/advice_i_like_time_series_but_dont_have/,https://www.reddit.com/r/datascience/comments/gl1uen/advice_i_like_time_series_but_dont_have/,1589661235.0
r/datascience,"Hi everyone,

I'm working on a paper with a few people and we are almost ready to publish. None of us have published anything before and we are wondering what are some good journals to publish in.

Our topic is about using machine learning to help end homelessness.

So far we have found 2 journals that we are considering :

Journal of Urban Economics - Elsevier 
Journal of Machine Learning - Springer

Should we be looking at sociology journals or data science?

Any advice would be greatly appreciated.

Thanks!",t2_12pe73,Data Science Journals,education,t3_gl6lpa,0.89,27,Education,27,1589707613.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m working on a paper with a few people and we are almost ready to publish. None of us have published anything before and we are wondering what are some good journals to publish in.&lt;/p&gt;

&lt;p&gt;Our topic is about using machine learning to help end homelessness.&lt;/p&gt;

&lt;p&gt;So far we have found 2 journals that we are considering :&lt;/p&gt;

&lt;p&gt;Journal of Urban Economics - Elsevier 
Journal of Machine Learning - Springer&lt;/p&gt;

&lt;p&gt;Should we be looking at sociology journals or data science?&lt;/p&gt;

&lt;p&gt;Any advice would be greatly appreciated.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gl6lpa,ryipp,15,/r/datascience/comments/gl6lpa/data_science_journals/,https://www.reddit.com/r/datascience/comments/gl6lpa/data_science_journals/,1589678813.0
r/datascience,"I've heard from numerous people that data science problems are starting to become software engineering problems. Is this true? And if so, what are the reasons behind this morph into engineering?",t2_5xux0a4p,"I've heard people say that data science is becoming closer to software engineering. Is this true, and if so, what are the reasons behind this trend?",discussion,t3_gla11f,0.63,4,Discussion,4,1589722542.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve heard from numerous people that data science problems are starting to become software engineering problems. Is this true? And if so, what are the reasons behind this morph into engineering?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gla11f,___24601,11,/r/datascience/comments/gla11f/ive_heard_people_say_that_data_science_is/,https://www.reddit.com/r/datascience/comments/gla11f/ive_heard_people_say_that_data_science_is/,1589693742.0
r/datascience,"I ran in to this problem trying to build a model to predict loan defaulters using credit history features. A few of the features are of the format ""number of months since X"" where X could be the borrower's last late payment, last account of a particular type opened, etc. Some of these seem like they could be strong features, but have many missing values (with good reason). For instance, ""months since last delinquency"" feature only applies to those borrowers which have a delinquency on their record. Imputing a value of 0 would imply those with no delinquencies are the same as those with an extremely recent delinquency, and imputing a very large value (say 9999) just doesn't sit right with me. My only other idea was to introduce an ordinal feature instead of a numeric one, binning delinquency recency by say ""never"", ""&lt;1 year"", ""1-2 years"", ""3-4 years"" etc. The issue I have with that is I would be deciding the cut off points at the expense of granularity, while it may be better to let the module ""learn"" those cutoff points.

&amp;#x200B;

&amp;#x200B;

Any insights would be greatly appreciated. Thank you lots :)",t2_yaaix,"Dealing with ""conditional"" features",projects,t3_gktrxo,0.82,11,Projects,11,1589660480.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I ran in to this problem trying to build a model to predict loan defaulters using credit history features. A few of the features are of the format &amp;quot;number of months since X&amp;quot; where X could be the borrower&amp;#39;s last late payment, last account of a particular type opened, etc. Some of these seem like they could be strong features, but have many missing values (with good reason). For instance, &amp;quot;months since last delinquency&amp;quot; feature only applies to those borrowers which have a delinquency on their record. Imputing a value of 0 would imply those with no delinquencies are the same as those with an extremely recent delinquency, and imputing a very large value (say 9999) just doesn&amp;#39;t sit right with me. My only other idea was to introduce an ordinal feature instead of a numeric one, binning delinquency recency by say &amp;quot;never&amp;quot;, &amp;quot;&amp;lt;1 year&amp;quot;, &amp;quot;1-2 years&amp;quot;, &amp;quot;3-4 years&amp;quot; etc. The issue I have with that is I would be deciding the cut off points at the expense of granularity, while it may be better to let the module &amp;quot;learn&amp;quot; those cutoff points.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any insights would be greatly appreciated. Thank you lots :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gktrxo,unlikely1879,25,/r/datascience/comments/gktrxo/dealing_with_conditional_features/,https://www.reddit.com/r/datascience/comments/gktrxo/dealing_with_conditional_features/,1589631680.0
r/datascience,"As the title says, what kind are you, and which do you see being more in demand?",t2_3uoce3bn,What kind of data science do you perform? Analytical [A] or Building/ML [B]? Which is more in demand?,meta,t3_gl41nk,0.5,0,Meta,0,1589698078.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As the title says, what kind are you, and which do you see being more in demand?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gl41nk,Tender_Figs,7,/r/datascience/comments/gl41nk/what_kind_of_data_science_do_you_perform/,https://www.reddit.com/r/datascience/comments/gl41nk/what_kind_of_data_science_do_you_perform/,1589669278.0
r/datascience,"Coming from the engineering field where the main artefacts of work are source code and production systems, I sometimes feel a bit short in processes around organising and saving the work my team does.

I've noticed there are several types of projects:

* once off data analysis
* exploration that leads to a feature shipped in a product
* explorations that never get shipped
* data analysis for debugging purposes. Let's say we run an A/B test and want to figure out whether we set it up correctly. We won't really share results outside of the team.

I guess different project will possibly get different answers, but let's kick off with these questions:

* where do you store the sidecar data? We store the code on GitHub, but don't want to package the data with the code (security/compliance reasons)
* do you make all your explorations reproducible? For example, a piece of code calls the warehouse. Do you store the snapshot of the data somewhere so you know exactly what was analysed?
* do you store all analysis you perform? For example, exec asks you for some numbers for a PPT
* do you keep track of different experiments? What do you use for that? Notion/Confluence/Gdocs/something ML specific?

&amp;#x200B;

Cheers!",t2_2zijr2cb,"How do you organise your data science projects? Code, data, learnings.",discussion,t3_gk9ggo,0.99,152,Discussion,152,1589579412.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Coming from the engineering field where the main artefacts of work are source code and production systems, I sometimes feel a bit short in processes around organising and saving the work my team does.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve noticed there are several types of projects:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;once off data analysis&lt;/li&gt;
&lt;li&gt;exploration that leads to a feature shipped in a product&lt;/li&gt;
&lt;li&gt;explorations that never get shipped&lt;/li&gt;
&lt;li&gt;data analysis for debugging purposes. Let&amp;#39;s say we run an A/B test and want to figure out whether we set it up correctly. We won&amp;#39;t really share results outside of the team.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I guess different project will possibly get different answers, but let&amp;#39;s kick off with these questions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;where do you store the sidecar data? We store the code on GitHub, but don&amp;#39;t want to package the data with the code (security/compliance reasons)&lt;/li&gt;
&lt;li&gt;do you make all your explorations reproducible? For example, a piece of code calls the warehouse. Do you store the snapshot of the data somewhere so you know exactly what was analysed?&lt;/li&gt;
&lt;li&gt;do you store all analysis you perform? For example, exec asks you for some numbers for a PPT&lt;/li&gt;
&lt;li&gt;do you keep track of different experiments? What do you use for that? Notion/Confluence/Gdocs/something ML specific?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Cheers!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gk9ggo,derivablefunc,28,/r/datascience/comments/gk9ggo/how_do_you_organise_your_data_science_projects/,https://www.reddit.com/r/datascience/comments/gk9ggo/how_do_you_organise_your_data_science_projects/,1589550612.0
r/datascience,"I can't figure out what's the great advantage of R over Python. 

R is a single-use language, Python can be used on way more things than just data science. 

Plotting is not harder in Python. 

Libraries are also not a problem in Python. In fact I'd say being a general purpose language, there's way more libraries for way more uses for Python than R. 

Is it the build-in datasets? But I don't care about iris flowers, I have my own problem to solve. And even if I do care, I can easily download it from the internet. 

So what's the reason why should anyone spend time learning R? I don't get it.",t2_pkmbp,What's R good for?,discussion,t3_gl9mzz,0.3,0,Discussion,0,1589720590.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I can&amp;#39;t figure out what&amp;#39;s the great advantage of R over Python. &lt;/p&gt;

&lt;p&gt;R is a single-use language, Python can be used on way more things than just data science. &lt;/p&gt;

&lt;p&gt;Plotting is not harder in Python. &lt;/p&gt;

&lt;p&gt;Libraries are also not a problem in Python. In fact I&amp;#39;d say being a general purpose language, there&amp;#39;s way more libraries for way more uses for Python than R. &lt;/p&gt;

&lt;p&gt;Is it the build-in datasets? But I don&amp;#39;t care about iris flowers, I have my own problem to solve. And even if I do care, I can easily download it from the internet. &lt;/p&gt;

&lt;p&gt;So what&amp;#39;s the reason why should anyone spend time learning R? I don&amp;#39;t get it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gl9mzz,donjoe234,48,/r/datascience/comments/gl9mzz/whats_r_good_for/,https://www.reddit.com/r/datascience/comments/gl9mzz/whats_r_good_for/,1589691790.0
r/datascience,"I need to establish a framework for formatting, matching and tracking changes to a dataset that can only be accessed through a CSV-file. I know how to do that using Excel and VBA, but I was wondering if there isn't a better way.

The problems goes:

1. The goal is to gather a weekly COMPANY : SHARES summary (could be limited to 30 pre-selected companies).
2. Twice a year I get a COMPANY : FUND overview.
3. I can pull an extensive dataset (around 54k obs) structured as FUND : SHARES, but the dataset FUND-string often also includes a lot of noise, such as the company address, company name, telephone etc.
4. To aggregate COMPANY : SHARES, I thus need to match COMPANY : FUND by scanning through the dataset FUND string and match with keywords relating to each specific company (such as a fund name, or the company's own name).
5. Because of the bad quality of the dataset, I will need to manually look at the results of the sorting to adjust the keywords for faulty matches, e.g. a new fund has been attributed because it matched with the company name keyword, but the string also includes some info which makes it clear that it shouldn't have been matched here so I include a non-match keyword filter it out from being matched with that company. This is unfortunate, but bearable as a total of \~200 funds are matched if the number of companies are limited to 30.

I know how to do streamline most of this process with some hassle using Excel Power Query for formatting and importing the CSV, VBA for for matching the data and a Pivot Table for creating a summary. I also know some Python and have SQL experience. I see how SQL would ease the sorting, but I would still need to manually download and format the CSV before feeding it into, say, MS Access. It would be so nice with a setup where I could more easily set the company match/don't-match keywords, see exactly which rows has been matched per company from the dataset, adjust keywords and re-run, and maybe even point out new matches that wasn't there last time it was run.

I would be very grateful for any tips or ideas.",t2_fvrju,What setup should I use for matching and monitoring this project?,projects,t3_gktz5p,0.5,0,Projects,0,1589661424.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I need to establish a framework for formatting, matching and tracking changes to a dataset that can only be accessed through a CSV-file. I know how to do that using Excel and VBA, but I was wondering if there isn&amp;#39;t a better way.&lt;/p&gt;

&lt;p&gt;The problems goes:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The goal is to gather a weekly COMPANY : SHARES summary (could be limited to 30 pre-selected companies).&lt;/li&gt;
&lt;li&gt;Twice a year I get a COMPANY : FUND overview.&lt;/li&gt;
&lt;li&gt;I can pull an extensive dataset (around 54k obs) structured as FUND : SHARES, but the dataset FUND-string often also includes a lot of noise, such as the company address, company name, telephone etc.&lt;/li&gt;
&lt;li&gt;To aggregate COMPANY : SHARES, I thus need to match COMPANY : FUND by scanning through the dataset FUND string and match with keywords relating to each specific company (such as a fund name, or the company&amp;#39;s own name).&lt;/li&gt;
&lt;li&gt;Because of the bad quality of the dataset, I will need to manually look at the results of the sorting to adjust the keywords for faulty matches, e.g. a new fund has been attributed because it matched with the company name keyword, but the string also includes some info which makes it clear that it shouldn&amp;#39;t have been matched here so I include a non-match keyword filter it out from being matched with that company. This is unfortunate, but bearable as a total of ~200 funds are matched if the number of companies are limited to 30.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I know how to do streamline most of this process with some hassle using Excel Power Query for formatting and importing the CSV, VBA for for matching the data and a Pivot Table for creating a summary. I also know some Python and have SQL experience. I see how SQL would ease the sorting, but I would still need to manually download and format the CSV before feeding it into, say, MS Access. It would be so nice with a setup where I could more easily set the company match/don&amp;#39;t-match keywords, see exactly which rows has been matched per company from the dataset, adjust keywords and re-run, and maybe even point out new matches that wasn&amp;#39;t there last time it was run.&lt;/p&gt;

&lt;p&gt;I would be very grateful for any tips or ideas.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gktz5p,Mikjo,3,/r/datascience/comments/gktz5p/what_setup_should_i_use_for_matching_and/,https://www.reddit.com/r/datascience/comments/gktz5p/what_setup_should_i_use_for_matching_and/,1589632624.0
r/datascience,,,Request: One day a week when all career questions are banned,meta,t3_gk4alt,0.86,131,Meta,131,1589554975.0,,gk4alt,[deleted],33,/r/datascience/comments/gk4alt/request_one_day_a_week_when_all_career_questions/,https://www.reddit.com/r/datascience/comments/gk4alt/request_one_day_a_week_when_all_career_questions/,1589526175.0
r/datascience,"Am I the only one who hates using Business Intelligence tools? Something about the interface...and all the clicking...and the ""hidden"" options that only appear in a certain ""context"", ugh.

In contrast, I love using a programming language to express my analytical ideas. I find it easier to get into a good ""flow."" The statements come naturally to me, and I can spend hours coding without losing focus.

How can I move forward in my career towards a goal of only developing data products with code? I'm learning Python, am fairly adept at SQL, and have used R for a number of years.

My group is heavily invested in a BI tool ( and are fairly advanced at it ). I'm scared to quit my job during this pandemic, but geez I would love duties that did not include reformatting old reports.",t2_3orbikss,How to have a career where I'm not using BI tools?,,t3_gkam51,0.9,26,,26,1589583421.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Am I the only one who hates using Business Intelligence tools? Something about the interface...and all the clicking...and the &amp;quot;hidden&amp;quot; options that only appear in a certain &amp;quot;context&amp;quot;, ugh.&lt;/p&gt;

&lt;p&gt;In contrast, I love using a programming language to express my analytical ideas. I find it easier to get into a good &amp;quot;flow.&amp;quot; The statements come naturally to me, and I can spend hours coding without losing focus.&lt;/p&gt;

&lt;p&gt;How can I move forward in my career towards a goal of only developing data products with code? I&amp;#39;m learning Python, am fairly adept at SQL, and have used R for a number of years.&lt;/p&gt;

&lt;p&gt;My group is heavily invested in a BI tool ( and are fairly advanced at it ). I&amp;#39;m scared to quit my job during this pandemic, but geez I would love duties that did not include reformatting old reports.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gkam51,MyWickedCharity,11,/r/datascience/comments/gkam51/how_to_have_a_career_where_im_not_using_bi_tools/,https://www.reddit.com/r/datascience/comments/gkam51/how_to_have_a_career_where_im_not_using_bi_tools/,1589554621.0
r/datascience,"So let's say I have some code that postprocesses some big, computationally expensive output (say a pretty picture). Now I'm trying to make an open source project fit for github that can be shared...

How do you deal with tracking giant, constantly changing files? If you keep them in the git repo your repo becomes huge. If you keep them out of the repo, well, these files are extremely expensive to generate. 

How can you share this data without keeping track of its unneeded history?",t2_3mz07,"Git and huge code generated files. How do you deal with big, constantly changing files?",discussion,t3_gkprqy,0.6,1,Discussion,1,1589638124.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So let&amp;#39;s say I have some code that postprocesses some big, computationally expensive output (say a pretty picture). Now I&amp;#39;m trying to make an open source project fit for github that can be shared...&lt;/p&gt;

&lt;p&gt;How do you deal with tracking giant, constantly changing files? If you keep them in the git repo your repo becomes huge. If you keep them out of the repo, well, these files are extremely expensive to generate. &lt;/p&gt;

&lt;p&gt;How can you share this data without keeping track of its unneeded history?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gkprqy,subheight640,6,/r/datascience/comments/gkprqy/git_and_huge_code_generated_files_how_do_you_deal/,https://www.reddit.com/r/datascience/comments/gkprqy/git_and_huge_code_generated_files_how_do_you_deal/,1589609324.0
r/datascience,"I'm having a few days off so I want to spend the time learning Julia. I'm working mostly in R and Python, and my work involved a lot of Bayesian stuffs which I usually use either Stan or PyMC3 for. Recently I've been playing around with Julia, and I've heard a lot of praises for Turing.jl for probabilistic programming. I wonder if anyone here ever used it? What are some pros and cons against, say, Stan or PyMC3?",t2_2k9lntox,Turing.jl vs Stan in Julia?,tooling,t3_gkg186,0.75,2,Tooling,2,1589600625.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m having a few days off so I want to spend the time learning Julia. I&amp;#39;m working mostly in R and Python, and my work involved a lot of Bayesian stuffs which I usually use either Stan or PyMC3 for. Recently I&amp;#39;ve been playing around with Julia, and I&amp;#39;ve heard a lot of praises for Turing.jl for probabilistic programming. I wonder if anyone here ever used it? What are some pros and cons against, say, Stan or PyMC3?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gkg186,LiberalHobbit,1,/r/datascience/comments/gkg186/turingjl_vs_stan_in_julia/,https://www.reddit.com/r/datascience/comments/gkg186/turingjl_vs_stan_in_julia/,1589571825.0
r/datascience,"My mother is a data scientist for the school district where she assist in coordinating and analyzing standardized testing for K-12, identifies students that may need extra resources and coordinates powerschool; her birthday is coming up and I wanted to pay for her to join some kind of data science association for a year. I'm familiar with psychiatric, pharmaceutical, and otherwise medical associations, but know next to nothing about the data science community. Does anyone have suggestions for organizations to investigate or other places to look/ask around?

I'd like it to provide benefit to her and her career beyond being something cool she did once, but am not sure where to look. I've seen a couple that seem to be focused on research and ethics, but I'm not sure if there are organizations that would apply more directly to her field. Id like to make it a one time investment over the summer and not have to pay for any further benefit from the organisation as im currently in college and only have disposable income in the summer. Thank you for anyone that shares thier knowledge or spends time to help me!",t2_5tdl2vpe,Data Science Association Membership as a Gift,network,t3_gkia5h,0.5,0,Networking,0,1589608132.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My mother is a data scientist for the school district where she assist in coordinating and analyzing standardized testing for K-12, identifies students that may need extra resources and coordinates powerschool; her birthday is coming up and I wanted to pay for her to join some kind of data science association for a year. I&amp;#39;m familiar with psychiatric, pharmaceutical, and otherwise medical associations, but know next to nothing about the data science community. Does anyone have suggestions for organizations to investigate or other places to look/ask around?&lt;/p&gt;

&lt;p&gt;I&amp;#39;d like it to provide benefit to her and her career beyond being something cool she did once, but am not sure where to look. I&amp;#39;ve seen a couple that seem to be focused on research and ethics, but I&amp;#39;m not sure if there are organizations that would apply more directly to her field. Id like to make it a one time investment over the summer and not have to pay for any further benefit from the organisation as im currently in college and only have disposable income in the summer. Thank you for anyone that shares thier knowledge or spends time to help me!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gkia5h,N8E_ZombieBait,3,/r/datascience/comments/gkia5h/data_science_association_membership_as_a_gift/,https://www.reddit.com/r/datascience/comments/gkia5h/data_science_association_membership_as_a_gift/,1589579332.0
r/datascience,One of my colleague suggested to use RBMs for clustering. My question is isn't it a bit of overkill when I have a mixture of binary and continuous data and also not all the variables will have a gaussian distribution. Isn't something like K-prototype a simpler and more intuitive solution. Please correct me if I am wrong.,t2_12pez0,RBMs for clustering ?,discussion,t3_gkcz9w,1.0,1,Discussion,1,1589590926.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;One of my colleague suggested to use RBMs for clustering. My question is isn&amp;#39;t it a bit of overkill when I have a mixture of binary and continuous data and also not all the variables will have a gaussian distribution. Isn&amp;#39;t something like K-prototype a simpler and more intuitive solution. Please correct me if I am wrong.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gkcz9w,aryancodify,0,/r/datascience/comments/gkcz9w/rbms_for_clustering/,https://www.reddit.com/r/datascience/comments/gkcz9w/rbms_for_clustering/,1589562126.0
r/datascience," 

Hey guys, I'm a huge fan of the nba and there are some ideas I have for projects for data science/analysis related to the nba. I'd love to know your feedback on these ideas or if you guys have any ideas of your own, please share as well.

1. Does homecourt affect a team's chances of winning a game? I wanna see how homecourt affects a team's chances of winning a game, and predict the chance each hometeam has of winning a game. I believe it comes down to skill more than whether a team is the home team or not.
2. Predicting a team's chances of winning the nba draft lottery. Ik that have a worse record gives you a higher chance of winning the lottery, and thus, you get more ping pong balls in the draw. But what would be other features or factors that affect a team's chances of landing the number one pick in the draft?
3. Predicting an nba player's aav salary. I wanna see how durability, the more games you play, winshares, ppg, points allowed per game, three point percentage, and apg would affect a free agent's chances of getting more money in their next contract",t2_4uimyesu,NBA Data Science Project ideas,projects,t3_gjy5ub,0.78,5,Projects,5,1589529146.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, I&amp;#39;m a huge fan of the nba and there are some ideas I have for projects for data science/analysis related to the nba. I&amp;#39;d love to know your feedback on these ideas or if you guys have any ideas of your own, please share as well.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Does homecourt affect a team&amp;#39;s chances of winning a game? I wanna see how homecourt affects a team&amp;#39;s chances of winning a game, and predict the chance each hometeam has of winning a game. I believe it comes down to skill more than whether a team is the home team or not.&lt;/li&gt;
&lt;li&gt;Predicting a team&amp;#39;s chances of winning the nba draft lottery. Ik that have a worse record gives you a higher chance of winning the lottery, and thus, you get more ping pong balls in the draw. But what would be other features or factors that affect a team&amp;#39;s chances of landing the number one pick in the draft?&lt;/li&gt;
&lt;li&gt;Predicting an nba player&amp;#39;s aav salary. I wanna see how durability, the more games you play, winshares, ppg, points allowed per game, three point percentage, and apg would affect a free agent&amp;#39;s chances of getting more money in their next contract&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gjy5ub,freshdeezy,20,/r/datascience/comments/gjy5ub/nba_data_science_project_ideas/,https://www.reddit.com/r/datascience/comments/gjy5ub/nba_data_science_project_ideas/,1589500346.0
r/datascience,"In my area, I'm noticing 5 to 1 more Data Engineering job postings. Anybody else noticing the same in their neck of the woods? If so, curious what you're thoughts are on why DE's seem to be more in demand.",t2_10n4k9,Job Prospects: Data Engineering vs Data Scientist,,t3_gjd820,0.93,164,Job Search,164,1589451095.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In my area, I&amp;#39;m noticing 5 to 1 more Data Engineering job postings. Anybody else noticing the same in their neck of the woods? If so, curious what you&amp;#39;re thoughts are on why DE&amp;#39;s seem to be more in demand.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gjd820,st789,183,/r/datascience/comments/gjd820/job_prospects_data_engineering_vs_data_scientist/,https://www.reddit.com/r/datascience/comments/gjd820/job_prospects_data_engineering_vs_data_scientist/,1589422295.0
r/datascience,What’s the difference? Does Product Analyst require more product/overall industry experience?,t2_15y4isrg,Data Analyst vs Product Analyst,career,t3_gjv1bn,0.63,2,Career,2,1589519031.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What’s the difference? Does Product Analyst require more product/overall industry experience?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gjv1bn,xtremech,4,/r/datascience/comments/gjv1bn/data_analyst_vs_product_analyst/,https://www.reddit.com/r/datascience/comments/gjv1bn/data_analyst_vs_product_analyst/,1589490231.0
r/datascience,I left my job just before the lockdown. I'm struggling without daily intelligent interactions. I've found a number of good subreddits including this one for work stuff. Where else can I find the quality OC?,t2_jwfmoa6,Great communities for Data science and related in addition to this one?,network,t3_gjlhag,0.46,0,Networking,0,1589488436.0,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I left my job just before the lockdown. I&amp;#39;m struggling without daily intelligent interactions. I&amp;#39;ve found a number of good subreddits including this one for work stuff. Where else can I find the quality OC?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",gjlhag,UnicornPrince4U,10,/r/datascience/comments/gjlhag/great_communities_for_data_science_and_related_in/,https://www.reddit.com/r/datascience/comments/gjlhag/great_communities_for_data_science_and_related_in/,1589459636.0
